{
  "id": "bug-bounty-hunting-tutorial",
  "title": "Bug Bounty Hunting",
  "description": "Comprehensive bug bounty hunting methodology covering program selection, asset enumeration, vulnerability research, proof of concept development, report writing, triage communication, disclosure, and automation efficiency.",
  "type": "tutorial",
  "steps": [
    {
      "id": "program-selection-reconnaissance",
      "title": "Program selection & reconnaissance",
      "content": "OBJECTIVE: Identify and evaluate bug bounty programs that align with your skills, select high-quality targets, and conduct initial reconnaissance to understand program scope and assets.\n\nACADEMIC BACKGROUND:\nISO 29147 specifies vulnerability disclosure procedures. The NIST Cybersecurity Framework emphasizes coordinated vulnerability disclosure. HackerOne's 2024 Hacker Report shows average bounty of $4,000-$6,000 for high-severity findings. Bugcrowd University provides platform-specific training (https://www.bugcrowd.com/hackers/bugcrowd-university/). OWASP Bug Bounty Guide outlines program selection criteria.\n\nSTEP-BY-STEP PROCESS:\n\n1. Bug Bounty Platform Selection:\n\nMajor Platforms:\n- HackerOne (https://hackerone.com/) - Largest platform, 3,000+ programs, PayPal/Uber/US DoD\n- Bugcrowd (https://bugcrowd.com/) - 1,500+ programs, Tesla/OpenAI/Mastercard\n- Intigriti (https://intigriti.com/) - European focus, 500+ programs, GDPR-compliant\n- YesWeHack (https://yeswehack.com/) - French platform, government programs\n- Synack (https://www.synack.com/) - Invite-only, vetted researchers\n- Open Bug Bounty (https://openbugbounty.org/) - Non-paying, responsible disclosure\n- HackenProof (https://hackenproof.com/) - Crypto/blockchain focus\n- Google VRP (https://bughunters.google.com/) - Tech giant programs\n\nPlatform Comparison Criteria:\n```bash\n# Check platform statistics\ncurl https://hackerone.com/directory/programs | jq '.[] | {name, avg_bounty, response_time}'\n\n# Review leaderboards for active hunters\nopen https://bugcrowd.com/leaderboard\nopen https://hackerone.com/leaderboard\n\n# Platform fee structures\nHackerOne: 20% platform fee on bounties\nBugcrowd: Varies by program\nIntigriti: 15-25% platform fee\n```\n\n2. Program Evaluation and Selection:\n\nKey Evaluation Metrics:\n- Response Time: Average first response (hours/days)\n- Resolution Time: Average time to bounty payment\n- Bounty Range: Minimum to maximum payouts by severity\n- Scope Clarity: Well-defined in-scope/out-of-scope assets\n- Program Maturity: New programs vs. established (3+ years)\n- Hall of Fame: Public recognition opportunities\n\nProgram Types:\n```text\nPUBLIC PROGRAMS:\n+ Open to all researchers\n+ Higher competition\n+ Faster triage (dedicated security team)\n+ Better payouts (mature programs)\n- More duplicates\n- Picked-over targets\n\nPRIVATE PROGRAMS:\n+ Invitation-only access\n+ Lower competition\n+ Less picked-over assets\n+ Higher signal-to-noise ratio\n- Requires reputation to access\n- Fewer available programs\n\nVDP (Vulnerability Disclosure Programs):\n+ No financial rewards\n+ Good for beginners (practice)\n+ Build reputation and portfolio\n+ Less competitive\n- Time investment without payment\n```\n\n3. Scope Analysis (Critical Step):\n\nIn-Scope Asset Types:\n```text\nâœ“ *.example.com (wildcard subdomains)\nâœ“ example.com main domain\nâœ“ mobile.example.com specific subdomain\nâœ“ iOS/Android mobile applications\nâœ“ api.example.com API endpoints\nâœ“ Third-party integrations (if specified)\n\nâœ— Out-of-scope (NEVER TEST):\nâœ— example.net different TLD\nâœ— Physical security testing\nâœ— Social engineering attacks\nâœ— Denial of Service (DoS/DDoS)\nâœ— Third-party services (unless specified)\nâœ— Spam or content injection\n```\n\nVulnerability Scope Analysis:\n```bash\n# Download program policy\nwget https://hackerone.com/example-company/policy -O policy.html\n\n# Parse scope sections\ngrep -A 20 \"In Scope\" policy.html\ngrep -A 20 \"Out of Scope\" policy.html\n\n# Check severity classifications\ngrep -i \"critical\" policy.html | head -5\ngrep -i \"high\" policy.html | head -5\n```\n\nCommon Scope Restrictions:\n- Self-XSS: Usually out-of-scope (requires social engineering)\n- Clickjacking: Often low severity or informational\n- SPF/DMARC records: Depends on program\n- SSL/TLS misconfigurations: Usually informational\n- Rate limiting issues: Low priority\n- Descriptive error messages: Informational\n- Missing cookie flags: Low severity\n\n4. Asset Discovery and Initial Reconnaissance:\n\nDomain and Subdomain Collection:\n```bash\n# From program scope\necho \"example.com\" > targets.txt\necho \"*.example.com\" >> targets.txt\n\n# Certificate Transparency logs\ncurl -s \"https://crt.sh/?q=%.example.com&output=json\" | jq -r '.[].name_value' | sort -u > subdomains.txt\n\n# SecurityTrails API\ncurl \"https://api.securitytrails.com/v1/domain/example.com/subdomains\" \\\n  -H \"APIKEY: YOUR_API_KEY\" | jq -r '.subdomains[]' | sed 's/$/\\.example.com/' >> subdomains.txt\n\n# VirusTotal API\ncurl \"https://www.virustotal.com/vtapi/v2/domain/report?domain=example.com&apikey=YOUR_API_KEY\" \\\n  | jq -r '.subdomains[]' >> subdomains.txt\n\n# Remove duplicates\nsort -u subdomains.txt -o subdomains_unique.txt\n```\n\n5. Program Reputation and History Research:\n\nCheck Program Statistics:\n```bash\n# HackerOne program stats\ncurl https://hackerone.com/example-company/reports | grep -E \"(resolved|bounty_awarded|response_time)\"\n\n# Search for disclosed reports\nopen https://hackerone.com/example-company/hacktivity\n\n# Bugcrowd program page\nopen https://bugcrowd.com/example-company\n\n# Check Twitter for researcher feedback\n# Search: \"example-company bug bounty\" OR \"@examplecompany security\"\n```\n\nRed Flags (Programs to Avoid):\n```text\nðŸš© No responses for 30+ days\nðŸš© Frequent \"Won't Fix\" or \"Informative\" closures\nðŸš© Very low bounty ranges ($50 for critical)\nðŸš© Unclear or constantly changing scope\nðŸš© Poor communication from security team\nðŸš© No disclosed reports (may indicate payment issues)\nðŸš© Negative researcher reviews\nðŸš© Unrealistic expectations in policy\n```\n\nGreen Flags (Quality Programs):\n```text\nâœ“ Average response time < 24 hours\nâœ“ Clear escalation process\nâœ“ Public Hall of Fame\nâœ“ Disclosed vulnerability reports\nâœ“ Fair duplicate handling\nâœ“ Reasonable bounty ranges\nâœ“ Active security team engagement\nâœ“ Quick time to resolution\nâœ“ Positive community feedback\n```\n\n6. Initial Reconnaissance Strategy:\n\nAsset Prioritization:\n```text\nHIGH PRIORITY TARGETS:\n1. Authentication systems (login, SSO, OAuth)\n2. Payment processing endpoints\n3. Admin panels and privileged functionality\n4. API endpoints (especially v1/legacy)\n5. File upload functionality\n6. Password reset mechanisms\n\nMEDIUM PRIORITY:\n7. User profile management\n8. Search functionality\n9. Content management systems\n10. Public APIs with authentication\n11. Mobile applications\n12. Third-party integrations\n\nLOW PRIORITY:\n13. Marketing websites\n14. Static content pages\n15. CDN resources\n16. Help/documentation sites\n```\n\nTechnology Stack Identification:\n```bash\n# Wappalyzer for web technologies\nnpm install -g wappalyzer\nwappalyzer https://example.com\n\n# WhatWeb for framework detection\nwhatweb -a 3 https://example.com\n\n# Retire.js for JavaScript library vulnerabilities\nretire --js --jspath https://example.com\n\n# Check HTTP headers for technology hints\ncurl -I https://example.com | grep -E \"(Server|X-Powered-By|X-AspNet-Version)\"\n```\n\n7. Program Communication and Onboarding:\n\nBest Practices for First Contact:\n```text\nâœ“ Read ENTIRE security policy before testing\nâœ“ Join program Slack/Discord if available\nâœ“ Introduce yourself (professional, brief)\nâœ“ Ask clarifying questions about scope\nâœ“ Request access to private documentation\nâœ“ Understand preferred reporting format\nâœ“ Clarify duplicate handling policy\nâœ“ Ask about testing constraints (rate limits, test accounts)\n```\n\nQuestions to Ask Security Team:\n```text\n1. \"Are test accounts available for authenticated testing?\"\n2. \"What is the policy on subdomain enumeration scanning?\"\n3. \"Can I test [specific feature] that's not explicitly mentioned?\"\n4. \"What's the expected triage timeline for submitted reports?\"\n5. \"Is there a preferred severity classification system?\"\n6. \"Are there any current focus areas or high-priority assets?\"\n```\n\nWHAT TO LOOK FOR:\n- **Well-Defined Scope**: Clear in-scope assets with examples (*.example.com vs example.com)\n- **Fair Bounty Ranges**: Critical ($5K-$20K), High ($2K-$5K), Medium ($500-$2K), Low ($100-$500)\n- **Response Metrics**: First response < 48 hours, triage < 5 days, payment < 30 days\n- **Disclosed Reports**: Public disclosure of past findings (transparency indicator)\n- **Active Security Team**: Regular updates, clear communication, responsive to questions\n- **Mature Program**: 1+ year old, 50+ resolved reports, established processes\n- **Community Reputation**: Positive reviews from other researchers, Hall of Fame\n\nSECURITY IMPLICATIONS:\n- **Legal Protection**: Bug bounty safe harbor protects researchers under CFAA (Computer Fraud and Abuse Act)\n- **Scope Violations**: Testing out-of-scope assets can result in legal action or platform bans\n- **Responsible Disclosure**: Coordinated disclosure timelines (typically 90 days) per ISO 29147\n- **Data Handling**: Never exfiltrate customer data, use test accounts, avoid PII exposure\n- **Platform Rules**: Violation of platform terms can result in account suspension\n\nCOMMON PITFALLS:\n- **Scope Creep**: Testing out-of-scope assets because \"they're related\" - ALWAYS stay in scope\n- **Insufficient Research**: Submitting duplicates because you didn't check disclosed reports\n- **Poor Program Selection**: Choosing low-quality programs with poor response times or payment issues\n- **Overly Broad Scanning**: Aggressive scanning causing service disruption (rate limit yourself)\n- **Skipping Policy**: Not reading the full security policy and missing critical restrictions\n- **No Test Accounts**: Testing on production with real user data instead of requesting test accounts\n- **Ignoring Red Flags**: Continuing with programs showing poor triage or payment patterns\n- **Tutorial Hell**: Spending too much time researching instead of actually testing\n\nTOOLS REFERENCE:\n- **HackerOne**: https://hackerone.com/ (bug bounty platform)\n- **Bugcrowd**: https://bugcrowd.com/ (bug bounty platform)\n- **Intigriti**: https://intigriti.com/ (European platform)\n- **crt.sh**: https://crt.sh/ (Certificate Transparency logs)\n- **SecurityTrails**: https://securitytrails.com/ (DNS/subdomain intelligence)\n- **Wappalyzer**: https://www.wappalyzer.com/ (technology profiling)\n- **Shodan**: https://shodan.io/ (internet-wide scanning)\n- **Censys**: https://censys.io/ (internet asset discovery)\n\nFURTHER READING:\n- Bugcrowd University: https://www.bugcrowd.com/hackers/bugcrowd-university/\n- HackerOne Resources: https://docs.hackerone.com/researchers/\n- OWASP Bug Bounty Guide: https://owasp.org/www-community/Vulnerability_Disclosure_Cheat_Sheet\n- ISO 29147 Vulnerability Disclosure: https://www.iso.org/standard/72311.html\n- Researcher Best Practices: https://www.hackerone.com/ethical-hacker/best-practices\n- Bug Bounty Methodology by Jason Haddix: https://github.com/jhaddix/tbhm",
      "tags": [
        "bugbounty",
        "reconnaissance",
        "program-selection",
        "scope-analysis"
      ],
      "related_tools": [
        "recon-ng",
        "censys-api",
        "burp-api-scanner",
        "ffuf-api",
        "ml-pipeline-audit"
      ]
    },
    {
      "id": "asset-enumeration-mapping",
      "title": "Asset enumeration & mapping",
      "content": "OBJECTIVE: Comprehensively enumerate and map target assets including domains, subdomains, APIs, mobile applications, and third-party integrations to identify high-value attack surface.\n\nACADEMIC BACKGROUND:\nOWASP WSTG v4.2 Section 4.1 covers information gathering. PTES Technical Guidelines emphasize attack surface mapping. Jason Haddix's Bug Bounty Hunting Methodology (https://github.com/jhaddix/tbhm) provides comprehensive asset discovery techniques. MITRE ATT&CK T1590 covers reconnaissance gathering victim network information.\n\nSTEP-BY-STEP PROCESS:\n\n1. Comprehensive Subdomain Enumeration:\n\nPassive Subdomain Discovery:\n```bash\n# Certificate Transparency (crt.sh)\ncurl -s \"https://crt.sh/?q=%.example.com&output=json\" | jq -r '.[].name_value' | sed 's/\\*\\.//g' | sort -u > crt_subdomains.txt\n\n# Subfinder (passive aggregator)\nsubfinder -d example.com -all -recursive -o subfinder_results.txt\n\n# Amass passive mode\namass enum -passive -d example.com -o amass_passive.txt\n\n# SecurityTrails API\ncurl \"https://api.securitytrails.com/v1/domain/example.com/subdomains\" \\\n  -H \"APIKEY: YOUR_KEY\" | jq -r '.subdomains[]' | sed 's/$/\\.example.com/' > securitytrails.txt\n\n# VirusTotal subdomains\ncurl \"https://www.virustotal.com/vtapi/v2/domain/report?apikey=YOUR_KEY&domain=example.com\" \\\n  | jq -r '.subdomains[]?' > virustotal.txt\n\n# Shodan search\nshodan search \"hostname:example.com\" --fields hostnames | tr ',' '\\n' > shodan_hosts.txt\n\n# Censys certificates\ncensys search \"parsed.names: example.com\" | jq -r '.[] | .parsed.names[]' > censys.txt\n```\n\nActive Subdomain Discovery:\n```bash\n# DNS brute-forcing with wordlist\npuredns bruteforce subdomains.txt example.com -r resolvers.txt -w puredns_results.txt\n\n# Gobuster DNS mode\ngobuster dns -d example.com -w ~/wordlists/subdomains-top1million-110000.txt -o gobuster_dns.txt\n\n# MassDNS with large wordlist\nmassdns -r resolvers.txt -t A -o S subdomains.txt > massdns_output.txt\n\n# Shuffledns for resolution\nshuffledns -d example.com -w subdomains.txt -r resolvers.txt -o resolved.txt\n\n# DNSx for validation and additional info\ncat all_subdomains.txt | dnsx -resp -a -aaaa -cname -ns -mx -soa -txt -o dnsx_results.txt\n```\n\nDNS Permutation and Alteration:\n```bash\n# Altdns for permutations\naltdns -i subdomains.txt -o altdns_output.txt -w ~/wordlists/words.txt\n\n# Gotator for advanced permutations\ngotator -sub subdomains.txt -perm ~/wordlists/permutations.txt -depth 2 -o gotator_out.txt\n\n# Common patterns to check manually\nfor sub in admin api dev staging test beta prod backup old new www2 www3; do\n    echo \"${sub}.example.com\"\ndone\n```\n\n2. Port Scanning and Service Discovery:\n\nHTTP/HTTPS Service Discovery:\n```bash\n# HTTPx for live web services\ncat subdomains.txt | httpx -ports 80,443,8080,8443,8000,8888 -threads 100 \\\n  -status-code -title -tech-detect -o httpx_results.txt\n\n# Aquatone for screenshots\ncat live_hosts.txt | aquatone -out aquatone_output/\n\n# EyeWitness for visual reconnaissance\neyewitness --web -f live_hosts.txt --no-prompt -d eyewitness_output/\n```\n\nComprehensive Port Scanning:\n```bash\n# Nmap SYN scan on top ports\nnmap -sS -T4 --top-ports 1000 -iL subdomains.txt -oA nmap_top1000\n\n# Nmap full port scan (be careful with rate limiting)\nnmap -sS -T3 -p- --max-rate 1000 target.example.com -oA nmap_full\n\n# Masscan for fast port discovery\nmasscan -iL targets.txt -p1-65535 --rate 1000 -oL masscan_output.txt\n\n# Naabu for fast port scanning\nnaabu -l targets.txt -top-ports 1000 -o naabu_ports.txt\n```\n\n3. Technology Stack Fingerprinting:\n\nWeb Application Technologies:\n```bash\n# Wappalyzer via CLI\nwappalyzer https://example.com -o wappalyzer.json\n\n# Webanalyze for technology detection\nwebanalyze -host https://example.com -output json\n\n# WhatWeb comprehensive analysis\nwhatweb -a 3 https://example.com --log-json=whatweb.json\n\n# Retire.js for vulnerable JavaScript libraries\nretire --js --jspath https://example.com --outputformat json\n\n# Check HTTP headers for technology hints\ncurl -I https://example.com | grep -iE \"(server|x-powered-by|x-aspnet|x-framework)\"\n\n# Detect CMS\ncmseek -u https://example.com\n\n# WordPress version detection\ncurl -s https://example.com/readme.html | grep -i \"version\"\nwpscan --url https://example.com --enumerate vp --api-token YOUR_TOKEN\n```\n\nBackend Framework Identification:\n```bash\n# Common framework indicators\n# Laravel: check for /storage, /vendor paths\ncurl -s https://example.com/storage/logs/laravel.log\n\n# Django: look for /admin, /static/admin paths\ncurl -I https://example.com/admin/ | grep -i \"csrf\"\n\n# Ruby on Rails: check for .json extensions\ncurl https://example.com/users.json\n\n# ASP.NET: look for .aspx extensions, __VIEWSTATE\ncurl https://example.com | grep -i \"__VIEWSTATE\"\n\n# Node.js: check for Express headers\ncurl -I https://example.com | grep -i \"X-Powered-By: Express\"\n\n# PHP version disclosure\ncurl -I https://example.com | grep \"X-Powered-By: PHP\"\n```\n\n4. API Discovery and Documentation:\n\nEndpoint Discovery:\n```bash\n# Common API paths\nfor path in api v1 v2 v3 rest graphql swagger swagger-ui api-docs openapi.json; do\n    curl -s \"https://example.com/${path}\" -o \"${path}.txt\"\ndone\n\n# API documentation endpoints\ncurl https://example.com/api/swagger.json\ncurl https://example.com/api/openapi.yaml\ncurl https://example.com/docs\ncurl https://example.com/graphql (POST with introspection query)\n\n# Kiterunner for API bruteforcing\nkr scan https://example.com -w routes-large.kite -o kiterunner_results.txt\n\n# FFUF for API endpoint discovery\nffuf -u https://example.com/api/FUZZ -w api-endpoints.txt -mc 200,301,302,401,403\n\n# Arjun for parameter discovery\narjun -u https://example.com/api/users -m GET,POST\n```\n\nGraphQL Enumeration:\n```bash\n# GraphQL introspection query\ncurl -X POST https://example.com/graphql \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"query\": \"{__schema{types{name,fields{name}}}}\"}'\n\n# GraphQL Voyager for visualization\n# Use https://apis.guru/graphql-voyager/\n\n# GraphQL playground discovery\ncurl https://example.com/graphql\ncurl https://example.com/___graphql\n```\n\n5. Mobile Application Analysis:\n\niOS Application Enumeration:\n```bash\n# Download IPA from App Store (requires Apple ID)\n# Use ipatool: ipatool download -b com.example.app\n\n# Extract IPA\nunzip Example.ipa -d extracted/\n\n# Strings analysis for endpoints\nstrings extracted/Payload/Example.app/Example | grep -iE \"(https?://|api|endpoint)\"\n\n# Class-dump for Objective-C headers\nclass-dump Example.app/Example > headers.txt\n\n# Plist analysis\nplutil -p extracted/Payload/Example.app/Info.plist\n\n# MobSF for automated analysis\n# Upload IPA to https://mobsf.live or local instance\n```\n\nAndroid Application Analysis:\n```bash\n# Download APK (use apkeep, apkpure-downloader, or device)\napkeep -a com.example.app .\n\n# Decompile APK\napktool d example.apk -o decompiled/\n\n# Jadx for Java decompilation\njadx example.apk -d jadx_output/\n\n# Strings for endpoint discovery\nstrings example.apk | grep -iE \"(https?://|api\\.example\\.com)\" > endpoints.txt\n\n# AndroidManifest.xml analysis\ncat decompiled/AndroidManifest.xml | grep -E \"(activity|service|receiver|provider)\"\n\n# MobSF analysis\n# Upload to MobSF instance for comprehensive scan\n\n# Frida for dynamic analysis\nfrida -U -f com.example.app -l intercept.js\n```\n\n6. Third-Party Integration Discovery:\n\nJavaScript Analysis:\n```bash\n# Extract all JavaScript files\nwget -r -l 1 -A js https://example.com/\n\n# Link Finder for endpoint discovery\npython3 linkfinder.py -i https://example.com -o linkfinder_results.txt\n\n# JSParser for parsing JS files\npython3 jsparser.py -f app.js\n\n# Search for API keys and secrets\ngrep -rE \"(api[_-]?key|apikey|access[_-]?token|secret[_-]?key)\" .\n\n# Third-party services in JS\ngrep -rohE \"https?://[^\"']+\" *.js | sort -u | grep -vE \"(example\\.com|jquery|google-analytics)\"\n```\n\nExternal Services and Integrations:\n```text\nCommon Third-Party Integrations to Check:\n- AWS S3 buckets: s3.amazonaws.com/bucket-name\n- Azure Blob Storage: accountname.blob.core.windows.net\n- Google Cloud Storage: storage.googleapis.com/bucket-name\n- CDN: CloudFlare, Akamai, Fastly\n- Payment processors: Stripe, PayPal, Braintree\n- Analytics: Google Analytics, Mixpanel, Segment\n- CRM: Salesforce, HubSpot, Zendesk\n- Email: SendGrid, Mailgun, Amazon SES\n- Chat: Intercom, Drift, Zendesk Chat\n- Authentication: Auth0, Okta, Firebase Auth\n```\n\nS3 Bucket Enumeration:\n```bash\n# Common S3 bucket naming patterns\nfor name in example example-prod example-dev example-staging example-backup example-assets; do\n    aws s3 ls s3://${name} --no-sign-request\n    curl -I https://${name}.s3.amazonaws.com/\ndone\n\n# S3Scanner for automated discovery\npython3 s3scanner.py --bucket example\n\n# Bucket permissions testing\naws s3 ls s3://bucket-name --no-sign-request\naws s3 cp test.txt s3://bucket-name/test.txt --no-sign-request\n```\n\n7. Attack Surface Mapping and Prioritization:\n\nVisual Attack Surface Mapping:\n```bash\n# Aquatone for visual clustering\ncat live_hosts.txt | aquatone -ports xlarge\n\n# Gowitness for screenshots\ngowitness file -f live_hosts.txt --destination gowitness_screenshots/\n\n# Create mind map of assets (manual or tools)\n# Use XMind, FreeMind, or draw.io\n```\n\nAsset Categorization:\n```text\nHIGH-VALUE ASSETS:\n1. Authentication endpoints (login, SSO, OAuth)\n2. Admin panels (/admin, /administrator, /wp-admin)\n3. API endpoints (especially versioned like /api/v1)\n4. File upload functionality\n5. Payment processing pages\n6. Password reset mechanisms\n7. Account management features\n8. Database admin interfaces (phpMyAdmin, Adminer)\n\nMEDIUM-VALUE ASSETS:\n9. User profile pages\n10. Search functionality\n11. Contact forms\n12. Public APIs with authentication\n13. Third-party integrations\n14. Mobile applications\n15. Legacy/old versions (v1 when v2 exists)\n\nLOW-VALUE ASSETS:\n16. Static marketing pages\n17. CDN resources\n18. Help/documentation sites\n19. Public-facing read-only content\n```\n\nAsset Database Creation:\n```bash\n# Create structured asset database\ncat > assets_db.json << 'EOF'\n{\n  \"domains\": [],\n  \"subdomains\": [],\n  \"ips\": [],\n  \"ports\": [],\n  \"technologies\": [],\n  \"apis\": [],\n  \"mobile_apps\": [],\n  \"third_party\": [],\n  \"high_value_targets\": []\n}\nEOF\n\n# Merge all enumeration results\ncat crt_subdomains.txt subfinder_results.txt amass_passive.txt | sort -u > all_subdomains.txt\n\n# Resolve to IPs\ncat all_subdomains.txt | dnsx -a -resp-only > ips.txt\n\n# Live HTTP/HTTPS hosts\ncat all_subdomains.txt | httpx -silent > live_hosts.txt\n```\n\nWHAT TO LOOK FOR:\n- **Forgotten Subdomains**: dev.example.com, staging.example.com, old.example.com with outdated software\n- **Legacy APIs**: /api/v1 endpoints when v2/v3 exist (often less protected)\n- **Admin Interfaces**: /admin, /administrator, /manage, /control-panel with weak authentication\n- **Cloud Storage**: Open S3 buckets, Azure blob containers, Google Cloud Storage with public access\n- **Exposed Databases**: MongoDB, Redis, Elasticsearch without authentication\n- **Development Artifacts**: .git directories, .env files, config backups, API documentation\n- **Mobile App Secrets**: Hardcoded API keys, tokens, endpoints in mobile applications\n\nSECURITY IMPLICATIONS:\n- **Expanded Attack Surface**: More assets = more potential vulnerabilities\n- **Third-Party Risk**: Vulnerabilities in integrated services affect main application\n- **Supply Chain**: Compromised third-party libraries or services (Log4Shell, SolarWinds)\n- **Shadow IT**: Unknown or forgotten assets without security monitoring\n- **Data Exposure**: Misconfigured cloud storage exposing sensitive data\n\nCOMMON PITFALLS:\n- **Noisy Scanning**: Aggressive scanning triggering WAF/IDS alerts and getting blocked\n- **Missing Subdomains**: Only checking Certificate Transparency, missing DNS brute-force findings\n- **Ignoring Mobile Apps**: Focusing only on web, missing iOS/Android attack surface\n- **No Rate Limiting**: Hitting APIs too fast causing disruption (use --rate-limit flags)\n- **Outdated Wordlists**: Using small wordlists missing modern naming conventions\n- **No Validation**: Finding subdomains but not verifying they're live or in-scope\n- **Incomplete Tech Stack**: Missing backend frameworks leading to incomplete testing methodology\n- **Poor Organization**: No structured database of findings, losing track of assets\n\nTOOLS REFERENCE:\n- **Subfinder**: https://github.com/projectdiscovery/subfinder (passive subdomain discovery)\n- **Amass**: https://github.com/OWASP/Amass (comprehensive asset discovery)\n- **HTTPx**: https://github.com/projectdiscovery/httpx (HTTP toolkit)\n- **Naabu**: https://github.com/projectdiscovery/naabu (fast port scanner)\n- **Aquatone**: https://github.com/michenriksen/aquatone (visual reconnaissance)\n- **MobSF**: https://github.com/MobSF/Mobile-Security-Framework-MobSF (mobile security)\n- **Kiterunner**: https://github.com/assetnote/kiterunner (API discovery)\n- **LinkFinder**: https://github.com/GerbenJavado/LinkFinder (endpoint discovery in JS)\n\nFURTHER READING:\n- Jason Haddix TBHM: https://github.com/jhaddix/tbhm\n- OWASP WSTG Information Gathering: https://owasp.org/www-project-web-security-testing-guide/\n- ProjectDiscovery Blog: https://blog.projectdiscovery.io/\n- Bug Bounty Bootcamp by Vickie Li: Chapter 4 - Environmental Setup and Traffic Interception\n- Nahamsec Recon Methodology: https://github.com/nahamsec/Resources-for-Beginner-Bug-Bounty-Hunters",
      "tags": [
        "bugbounty",
        "enumeration",
        "assets",
        "reconnaissance",
        "subdomains"
      ],
      "related_tools": [
        "hunter-io",
        "recon-ng",
        "burp-api-scanner",
        "censys-api",
        "ffuf-api"
      ]
    },
    {
      "id": "vulnerability-research-testing",
      "title": "Vulnerability research & testing",
      "content": "OBJECTIVE: Research and test for common vulnerability classes including injection flaws, authentication bypasses, authorization issues, and business logic vulnerabilities in bug bounty programs.\n\nACADEMIC BACKGROUND:\nOWASP Top 10 represents the most critical web application security risks. MITRE ATT&CK framework covers common enterprise techniques. Bug bounty programs often have unique vulnerability classes not covered by standard checklists. Research from HackerOne shows that business logic flaws account for 20% of high-severity bounties.\n\nSTEP-BY-STEP PROCESS:\n\n1. Vulnerability Research Methodology:\n\nTargeted Research Approach:\n```bash\n# Research program-specific vulnerabilities\n# Check disclosed reports for similar companies\nopen https://hackerone.com/example-company/hacktivity\nopen https://bugcrowd.com/example-company\n\n# Search for company name + vulnerability type\n# \"example-company xss\" OR \"example-company sql injection\"\n\n# Check vulnerability databases\n# Exploit-DB, CVE Details, VulnHub\nsearchsploit example-company\n```\n\nTechnology-Specific Research:\n```bash\n# Framework-specific vulnerabilities\n# WordPress: wpscan --url https://example.com --enumerate vp\n# Drupal: droopescan scan drupal -u https://example.com\n# Joomla: joomlavs -u https://example.com\n\n# Programming language vulnerabilities\n# PHP: search for common PHP vulnerabilities\n# Node.js: check for prototype pollution, deserialization\n# Python: Flask/Django specific issues\n\n# Third-party library vulnerabilities\n# Check package.json, requirements.txt, composer.json\nnpm audit\npip-audit\ncomposer audit\n```\n\n2. Authentication Testing:\n\nLogin Mechanism Analysis:\n```bash\n# Test for weak password policies\n# Short passwords, no complexity requirements\n\n# Username enumeration\n# Different responses for valid/invalid usernames\ncurl -X POST https://example.com/login \\\n  -d 'username=admin&password=wrong' \\\n  -d 'username=nonexistent&password=wrong'\n\n# Account lockout testing\n# Test if accounts lock after failed attempts\nfor i in {1..10}; do\n  curl -X POST https://example.com/login \\\n    -d 'username=victim&password=wrong'\ndone\n```\n\nPassword Reset Vulnerabilities:\n```bash\n# Token predictability\n# Test if reset tokens are sequential or guessable\n\n# Host header injection in reset emails\ncurl -X POST https://example.com/forgot-password \\\n  -H \"Host: evil.com\" \\\n  -d 'email=victim@example.com'\n\n# Rate limiting bypass\n# Test if reset requests can be sent rapidly\n```\n\nMulti-Factor Authentication (MFA):\n```bash\n# MFA fatigue attacks\n# Send multiple MFA requests to victim\n\n# Session hijacking after MFA\n# Test if session cookies are properly invalidated\n\n# Recovery mechanism bypass\n# Test password reset vs MFA recovery\n```\n\n3. Authorization Testing:\n\nHorizontal Privilege Escalation:\n```bash\n# Access other users' data with modified IDs\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  https://api.example.com/users/123  # Your ID\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  https://api.example.com/users/124  # Someone else's ID\n\n# Test IDOR in different formats\n# Numeric IDs: /users/123\n# UUIDs: /users/550e8400-e29b-41d4-a716-446655440000\n# Email-based: /users/user@example.com\n```\n\nVertical Privilege Escalation:\n```bash\n# Test role-based access control\n# Regular user trying to access admin functions\ncurl -H \"Authorization: Bearer $USER_TOKEN\" \\\n  https://api.example.com/admin/users\n\n# Parameter tampering for role elevation\ncurl -X POST https://api.example.com/update-profile \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -d 'role=admin&name=User'\n\n# API key privilege testing\n# Test different API key scopes/permissions\n```\n\nInsecure Direct Object References (IDOR):\n```bash\n# File access\ncurl https://example.com/download?file=../../../etc/passwd\n\n# Database record access\ncurl https://api.example.com/orders/12345  # Your order\ncurl https://api.example.com/orders/12346  # Someone else's order\n\n# Parameter manipulation\n# Change user_id, order_id, file_id parameters\n```\n\n4. Injection Testing:\n\nSQL Injection:\n```bash\n# Classic SQL injection\ncurl \"https://example.com/search?q=' OR '1'='1\"\n\n# Union-based injection\ncurl \"https://example.com/users?id=1 UNION SELECT username,password FROM users--\"\n\n# Blind SQL injection\n# Time-based: AND SLEEP(5)\n# Boolean-based: AND 1=1 vs AND 1=2\n\n# Second-order injection\n# Input stored, executed later (profile updates, comments)\n```\n\nNoSQL Injection:\n```bash\n# MongoDB operator injection\ncurl -X POST https://api.example.com/search \\\n  -d '{\"username\": {\"$ne\": null}, \"password\": {\"$ne\": null}}'\n\n# JavaScript injection in MongoDB\ncurl -X POST https://api.example.com/search \\\n  -d '{\"$where\": \"this.username == \\\"admin\\\"\"}'\n```\n\nCommand Injection:\n```bash\n# OS command injection\ncurl \"https://example.com/ping?host=8.8.8.8; cat /etc/passwd\"\n\n# Template injection\n# SSTI: {{7*7}} in template engines\n# Expression Language: ${7*7} in Java\n```\n\n5. Business Logic Vulnerabilities:\n\nWorkflow Bypass:\n```bash\n# Skip required steps in multi-step processes\n# Registration -> Email verification -> Account activation\ncurl -X POST https://api.example.com/activate \\\n  -d 'user_id=123&skip_verification=true'\n\n# Payment flow manipulation\n# Change amounts, currencies, discount codes\n```\n\nResource Exhaustion:\n```bash\n# API rate limiting bypass\n# Use multiple IPs, headers, or API keys\n\n# Storage quota bypass\n# Upload large files, create many resources\n\n# Credit manipulation\n# Negative payments, duplicate transactions\n```\n\nState Manipulation:\n```bash\n# Race conditions\n# Concurrent requests causing inconsistent state\n\n# Parameter pollution\n# Multiple parameters with same name\ncurl \"https://example.com/api?param=value1&param=value2\"\n\n# Type confusion\n# Send string where number expected\ncurl -X POST https://api.example.com/update \\\n  -d '{\"age\": \"not_a_number\"}'\n```\n\n6. Client-Side Vulnerabilities:\n\nCross-Site Scripting (XSS):\n```bash\n# Reflected XSS\ncurl \"https://example.com/search?q=<script>alert(1)</script>\"\n\n# Stored XSS\ncurl -X POST https://example.com/comment \\\n  -d 'comment=<img src=x onerror=alert(1)>&author=User'\n\n# DOM-based XSS\n# Client-side JavaScript execution\n```\n\nCross-Site Request Forgery (CSRF):\n```bash\n# Test for CSRF tokens\ncurl -X POST https://example.com/transfer \\\n  -d 'amount=1000&to=attacker'  # No CSRF token\n\n# Check if SameSite cookies are set\ncurl -I https://example.com | grep \"Set-Cookie\"\n```\n\nClickjacking:\n```bash\n# Frame busting headers\ncurl -I https://example.com | grep -i \"x-frame-options\"\n\n# CSP frame-ancestors\ncurl -I https://example.com | grep -i \"content-security-policy\"\n```\n\n7. API-Specific Testing:\n\nREST API Testing:\n```bash\n# HTTP method tampering\ncurl -X PUT https://api.example.com/users/123 \\\n  -d '{\"name\": \"Modified by PUT\"}'\n\n# Mass assignment\ncurl -X POST https://api.example.com/users \\\n  -d '{\"name\": \"User\", \"role\": \"admin\", \"is_admin\": true}'\n\n# Parameter pollution\ncurl \"https://api.example.com/search?query=test&query=admin'--\"\n```\n\nGraphQL Testing:\n```bash\n# Introspection enabled?\ncurl -X POST https://api.example.com/graphql \\\n  -d '{\"query\": \"{__schema{types{name}}}\"}'\n\n# Query depth abuse\ncurl -X POST https://api.example.com/graphql \\\n  -d '{\"query\": \"query{user{friends{friends{friends{name}}}}}\"}'\n\n# Field suggestion exploitation\ncurl -X POST https://api.example.com/graphql \\\n  -d '{\"query\": \"{user{__typename}}\", \"variables\": null}'\n```\n\n8. Mobile Application Testing:\n\nNetwork Traffic Analysis:\n```bash\n# Intercept with Burp Suite or mitmproxy\n# Look for hardcoded credentials, API keys\n\n# Certificate pinning bypass\n# Use Frida or objection\nobjection --gadget com.example.app explore\n```\n\nLocal Storage Analysis:\n```bash\n# Android shared preferences\nadb shell cat /data/data/com.example.app/shared_prefs/*.xml\n\n# iOS keychain dumping\n# Use keychain_dumper or Frida\n```\n\nWHAT TO LOOK FOR:\n- **Authentication Bypass**: Weak passwords, no MFA, predictable reset tokens\n- **Authorization Flaws**: IDOR, privilege escalation, parameter tampering\n- **Injection Vulnerabilities**: SQL, NoSQL, command, template injection\n- **Business Logic Issues**: Workflow bypass, resource manipulation, state confusion\n- **Client-Side Attacks**: XSS, CSRF, clickjacking\n- **API Vulnerabilities**: Method tampering, mass assignment, parameter pollution\n- **Mobile Issues**: Insecure storage, network interception, deeplink exploitation\n\nSECURITY IMPLICATIONS:\n- **Data Breach**: Unauthorized access to sensitive user data\n- **Account Takeover**: Complete control of user accounts\n- **Financial Loss**: Manipulation of payments, credits, or transactions\n- **System Compromise**: Command injection leading to server access\n- **Reputation Damage**: Public disclosure of security flaws\n\nCOMMON PITFALLS:\n- **Focusing Only on High-Profile Bugs**: Missing business logic flaws that are often high-value\n- **Ignoring Mobile Applications**: Many programs include mobile apps with unique vulnerabilities\n- **Not Testing All HTTP Methods**: PUT, DELETE, PATCH, OPTIONS often less tested\n- **Missing Parameter Testing**: Not fuzzing all parameters with malicious input\n- **Ignoring Race Conditions**: Concurrent requests can cause security issues\n- **Not Testing Error Conditions**: Error messages can reveal sensitive information\n- **Skipping Third-Party Integrations**: OAuth, payment processors, CDNs have their own vulnerabilities\n\nTOOLS REFERENCE:\n- **Burp Suite**: https://portswigger.net/burp (web vulnerability scanner)\n- **sqlmap**: https://sqlmap.org/ (automated SQL injection)\n- **XSStrike**: https://github.com/s0md3v/XSStrike (XSS scanner)\n- **dirsearch**: https://github.com/maurosoria/dirsearch (directory bruteforcing)\n- **ffuf**: https://github.com/ffuf/ffuf (fuzzing tool)\n- **nuclei**: https://github.com/projectdiscovery/nuclei (vulnerability scanner)\n- **frida**: https://frida.re/ (dynamic instrumentation)\n\nFURTHER READING:\n- OWASP Testing Guide: https://owasp.org/www-project-web-security-testing-guide/\n- PortSwigger Web Security Academy: https://portswigger.net/web-security\n- Bug Bounty Bootcamp by Vickie Li: https://www.amazon.com/Bug-Bounty-Bootcamp-Reporting-Vulnerabilities/dp/1718501544\n- API Security Testing: https://apisecurity.io/\n- Mobile Application Security: https://owasp.org/www-project-mobile-app-security/",
      "tags": [
        "bugbounty",
        "vulnerability",
        "testing",
        "research",
        "injection",
        "authentication"
      ],
      "related_tools": [
        "hunter-io",
        "burp-api-scanner",
        "ffuf-api",
        "comparison_sql_testing",
        "graphql-testing"
      ]
    },
    {
      "id": "proof-of-concept-development",
      "title": "Proof of concept development",
      "content": "OBJECTIVE: Develop reliable proof-of-concept exploits that demonstrate vulnerability impact while minimizing risk to production systems and user data.\n\nACADEMIC BACKGROUND:\nProof-of-concept (PoC) development is critical for bug bounty submissions. OWASP defines PoC as evidence that a vulnerability is exploitable. HackerOne's vulnerability disclosure guidelines emphasize clear, non-destructive PoC examples. The goal is to prove impact without causing harm.\n\nSTEP-BY-STEP PROCESS:\n\n1. Vulnerability Impact Assessment:\n\nSeverity Classification:\n```text\nCRITICAL (9.0-10.0 CVSS):\n- Remote code execution (RCE)\n- Authentication bypass leading to full system compromise\n- SQL injection with data exfiltration capabilities\n- Complete account takeover without user interaction\n\nHIGH (7.0-8.9 CVSS):\n- Privilege escalation to admin/sensitive roles\n- SQL injection with read/write access\n- Authentication bypass requiring user interaction\n- Significant data exposure (PII, financial data)\n\nMEDIUM (4.0-6.9 CVSS):\n- Stored XSS with social engineering\n- IDOR with limited data access\n- Race conditions affecting user data\n- Information disclosure of sensitive configuration\n\nLOW (0.1-3.9 CVSS):\n- Reflected XSS requiring user interaction\n- Clickjacking on non-sensitive pages\n- Missing security headers\n- Descriptive error messages\n```\n\nImpact Demonstration:\n```bash\n# Data exfiltration PoC\n# Show you can read sensitive data\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  https://api.example.com/users/VICTIM_ID\n\n# Account takeover PoC\n# Demonstrate you can change victim's password\ncurl -X PUT https://api.example.com/users/VICTIM_ID \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -d '{\"password\": \"hacked123\"}'\n\n# RCE PoC (SAFE VERSION)\n# Show command execution capability\ncurl \"https://example.com/ping?host=127.0.0.1; echo 'VULNERABLE'\"\n```\n\n2. Safe PoC Development:\n\nNon-Destructive Testing:\n```bash\n# Use test accounts, not real user data\n# Create your own test resources\ncurl -X POST https://api.example.com/test-users \\\n  -d '{\"name\": \"Test User\", \"email\": \"test@example.com\"}'\n\n# Read-only operations where possible\ncurl https://api.example.com/public-data\n\n# Use safe payloads that don't cause damage\n# Instead of: rm -rf /\n# Use: echo \"VULNERABLE\"\n```\n\nControlled Environment Testing:\n```bash\n# Test on staging/development environments first\ncurl -X POST https://staging.example.com/vulnerable-endpoint \\\n  -d '{\"payload\": \"safe_test\"}'\n\n# Use rate limiting to avoid DoS\n# Add delays between requests\nsleep 1\n\n# Monitor for unintended side effects\n# Check logs, performance metrics\n```\n\n3. PoC Scripting and Automation:\n\nPython PoC Template:\n```python\nimport requests\n\ndef test_vulnerability(target_url, token):\n    \"\"\"Safe PoC for vulnerability demonstration\"\"\"\n    \n    # Test payload - SAFE VERSION\n    payload = {\n        \"user_id\": \"123\",  # Your own test user\n        \"action\": \"read_profile\"\n    }\n    \n    headers = {\n        \"Authorization\": f\"Bearer {token}\",\n        \"Content-Type\": \"application/json\"\n    }\n    \n    try:\n        response = requests.post(\n            f\"{target_url}/api/vulnerable-endpoint\",\n            json=payload,\n            headers=headers,\n            timeout=10\n        )\n        \n        if response.status_code == 200:\n            print(\"[+] Vulnerability confirmed\")\n            print(f\"Response: {response.json()}\")\n            return True\n        else:\n            print(f\"[-] Unexpected response: {response.status_code}\")\n            return False\n            \n    except Exception as e:\n        print(f\"Error: {e}\")\n        return False\n\nif __name__ == \"__main__\":\n    target = \"https://example.com\"\n    token = \"your_test_token\"\n    test_vulnerability(target, token)\n```\n\nBurp Suite PoC:\n```text\n# Repeater tab configuration\nPOST /api/vulnerable-endpoint HTTP/1.1\nHost: example.com\nAuthorization: Bearer YOUR_TOKEN\nContent-Type: application/json\nContent-Length: 45\n\n{\"user_id\": \"VICTIM_ID\", \"action\": \"read\"}\n```\n\n4. Impact Documentation:\n\nClear Impact Description:\n```text\n# What the vulnerability allows\n\"An attacker can read any user's profile data by modifying the user_id parameter\"\n\n# Why it's dangerous\n\"This exposes personally identifiable information (PII) including emails, phone numbers, and addresses\"\n\n# Potential consequences\n\"Could lead to identity theft, targeted phishing attacks, or privacy violations\"\n```\n\nEvidence Collection:\n```bash\n# Screenshots of successful exploitation\n# Save response data (anonymized)\n# Network traffic captures (filtered)\n# Application logs showing the vulnerability\n\n# Document steps to reproduce\n1. Authenticate with valid user account\n2. Modify user_id parameter to victim's ID\n3. Access victim's sensitive data\n4. Demonstrate data exfiltration\n```\n\n5. Responsible Disclosure Preparation:\n\nReport Structure:\n```text\nTITLE: [HIGH] IDOR in user profile API allows unauthorized data access\n\nSUMMARY:\nA vulnerability in the /api/users/{id} endpoint allows authenticated users to access other users' profile information by modifying the user_id parameter.\n\nDESCRIPTION:\nThe application fails to properly validate that users can only access their own profile data. By changing the user_id parameter in API requests, any authenticated user can view sensitive information belonging to other users.\n\nIMPACT:\n- Exposure of personally identifiable information (PII)\n- Privacy violation affecting all application users\n- Potential for identity theft and targeted attacks\n\nSTEPS TO REPRODUCE:\n1. Log in with a valid user account\n2. Intercept the request to /api/users/profile\n3. Change the user_id parameter to another user's ID\n4. Observe that you can access the other user's data\n\nPROOF OF CONCEPT:\n[Attach safe PoC script that demonstrates the issue using test data]\n\nRECOMMENDATION:\nImplement proper authorization checks to ensure users can only access their own data. Use session-based user ID validation instead of relying on client-provided parameters.\n\nSEVERITY: High\nCVSS: 7.5 (AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:N)\n```\n\n6. Edge Case Testing:\n\nBoundary Testing:\n```bash\n# Test with edge case inputs\ncurl \"https://api.example.com/users/0\"        # Zero ID\ncurl \"https://api.example.com/users/-1\"       # Negative ID\ncurl \"https://api.example.com/users/999999\"   # Non-existent ID\ncurl \"https://api.example.com/users/admin\"    # String ID\n\n# Test with special characters\ncurl \"https://api.example.com/users/123%27\"   # SQL injection attempt\ncurl \"https://api.example.com/users/123<script>\"  # XSS attempt\n```\n\nRace Condition Testing:\n```bash\n# Concurrent request testing\nfor i in {1..10}; do\n  curl -X POST https://api.example.com/action \\\n    -d 'param=race_condition_test' &\ndone\n\n# Test timing-dependent vulnerabilities\n# Use tools like race-the-web for automated testing\n```\n\n7. Mitigation Verification:\n\nTest Fixes:\n```bash\n# After developer applies fix, verify it's resolved\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  https://api.example.com/users/VICTIM_ID\n# Should return 403 Forbidden or 404 Not Found\n\n# Test that legitimate functionality still works\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  https://api.example.com/users/MY_ID\n# Should return 200 OK with your data\n```\n\nRegression Testing:\n```bash\n# Test similar endpoints for the same issue\ncurl https://api.example.com/orders/VICTIM_ID\ncurl https://api.example.com/messages/VICTIM_ID\n\n# Test with different user roles\n# Admin, moderator, regular user accounts\n```\n\n8. Tool Development for PoC:\n\nCustom PoC Scripts:\n```bash\n# Create reusable testing tools\ncat > idor_tester.py << 'EOF'\n#!/usr/bin/env python3\nimport requests\nimport sys\n\ndef test_idor(base_url, token, victim_ids):\n    headers = {'Authorization': f'Bearer {token}'}\n    \n    for victim_id in victim_ids:\n        url = f\"{base_url}/api/users/{victim_id}\"\n        response = requests.get(url, headers=headers)\n        \n        if response.status_code == 200:\n            print(f\"[+] IDOR found: Can access user {victim_id}\")\n            return True\n    \n    print(\"[-] No IDOR detected\")\n    return False\n\nif __name__ == \"__main__\":\n    if len(sys.argv) != 4:\n        print(\"Usage: python idor_tester.py <url> <token> <victim_ids_file>\")\n        sys.exit(1)\n    \n    base_url = sys.argv[1]\n    token = sys.argv[2]\n    victim_ids_file = sys.argv[3]\n    \n    with open(victim_ids_file) as f:\n        victim_ids = [line.strip() for line in f]\n    \n    test_idor(base_url, token, victim_ids)\nEOF\n\nchmod +x idor_tester.py\n```\n\nWHAT TO LOOK FOR:\n- **Clear Impact Demonstration**: PoC should clearly show what an attacker can achieve\n- **Minimal Risk**: Avoid any actions that could harm production systems or real users\n- **Reproducible Steps**: Anyone should be able to follow your reproduction steps\n- **Comprehensive Testing**: Test edge cases, different user roles, and input variations\n- **Proper Documentation**: Include screenshots, request/response data, and impact analysis\n\nSECURITY IMPLICATIONS:\n- **Responsible Disclosure**: PoC enables vendors to understand and fix vulnerabilities\n- **Risk Assessment**: Helps security teams prioritize remediation efforts\n- **Learning Opportunity**: PoC development improves your understanding of vulnerabilities\n- **Bounty Qualification**: Well-developed PoC increases chances of bounty payment\n\nCOMMON PITFALLS:\n- **Destructive Testing**: Using payloads that delete data or crash systems\n- **Real User Data**: Testing on production accounts with real PII\n- **Overly Complex PoC**: Making reproduction unnecessarily difficult\n- **Missing Context**: Not explaining why the vulnerability matters\n- **Incomplete Testing**: Not testing the fix after it's applied\n- **Poor Documentation**: Unclear steps or missing evidence\n- **Timing Issues**: Not accounting for race conditions or timing-dependent bugs\n\nTOOLS REFERENCE:\n- **Burp Suite**: https://portswigger.net/burp (intercepting proxy for PoC development)\n- **Postman**: https://www.postman.com/ (API testing and PoC automation)\n- **Python requests**: https://requests.readthedocs.io/ (HTTP library for PoC scripts)\n- **curl**: https://curl.se/ (command-line tool for HTTP requests)\n- **race-the-web**: https://github.com/insp3ctre/race-the-web (race condition testing)\n\nFURTHER READING:\n- HackerOne Vulnerability Disclosure Guidelines: https://docs.hackerone.com/hackers/vulnerability-disclosure-guidelines.html\n- OWASP PoC Guidelines: https://owasp.org/www-community/OWASP_PoC\n- Bug Bounty PoC Best Practices: https://www.bugcrowd.com/blog/bug-bounty-poc-best-practices/\n- CVSS Calculator: https://www.first.org/cvss/calculator/3.1\n- Vulnerability Writeup Examples: https://github.com/ngalongc/bug-bounty-reference",
      "tags": [
        "bugbounty",
        "poc",
        "proof-of-concept",
        "exploitation",
        "testing"
      ],
      "related_tools": [
        "hunter-io",
        "burp-api-scanner",
        "ffuf-api",
        "comparison_sql_testing",
        "bugbounty_reporting_cvss"
      ]
    },
    {
      "id": "report-writing-submission",
      "title": "Report writing & submission",
      "content": "OBJECTIVE: Write clear, comprehensive vulnerability reports that enable security teams to understand, reproduce, and fix issues while maximizing bounty potential through professional presentation.\n\nACADEMIC BACKGROUND:\nEffective report writing is crucial for successful bug bounty hunting. OWASP provides guidelines for vulnerability reporting. HackerOne research shows that well-written reports are 3x more likely to result in bounties. Clear communication between researchers and security teams is essential for coordinated disclosure.\n\nSTEP-BY-STEP PROCESS:\n\n1. Report Structure and Format:\n\nProfessional Report Template:\n```text\nVULNERABILITY REPORT\n===================\n\nProgram: [Program Name]\nResearcher: [Your Username]\nDate: [YYYY-MM-DD]\nSeverity: [Critical/High/Medium/Low/Informational]\nCVSS Score: [X.X] (AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)\nBounty Requested: [Amount or N/A]\n\nSUMMARY\n-------\n[2-3 sentence overview of the vulnerability]\n\nDESCRIPTION\n-----------\n[Detailed technical description of the issue]\n[Include affected endpoints, parameters, and functionality]\n[Explain the root cause and attack vector]\n\nIMPACT\n------\n[Describe what an attacker can achieve]\n[Include potential consequences for users and business]\n[Quantify the risk where possible]\n\nSTEPS TO REPRODUCE\n------------------\n[Numbered list of exact steps to reproduce]\n[Include all necessary prerequisites]\n[Provide test credentials if needed]\n\nPROOF OF CONCEPT\n---------------\n[Code snippets, curl commands, or scripts]\n[Screenshots of successful exploitation]\n[Network traffic captures (sanitized)]\n\nRECOMMENDATIONS\n--------------\n[Specific remediation steps]\n[Code examples for fixes]\n[Prevention measures for similar issues]\n\nREFERENCES\n----------\n[OWASP guidelines, CWE entries, similar vulnerabilities]\n[Research papers or security advisories]\n\nADDITIONAL INFORMATION\n---------------------\n[Tested on browser/OS versions]\n[Related endpoints or similar issues found]\n[Timeline of discovery and testing]\n```\n\n2. Severity Assessment and CVSS Scoring:\n\nCVSS v3.1 Calculator Usage:\n```bash\n# Use official CVSS calculator\nopen https://www.first.org/cvss/calculator/3.1\n\n# Or use command-line tool\nnpm install -g cvss\ncvss calculate --base-metric 'AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H'\n```\n\nCommon Bug Bounty Severity Levels:\n```text\nCRITICAL (9.0-10.0):\n- Remote Code Execution (RCE)\n- Authentication bypass to admin access\n- Complete data breach of all users\n- System compromise\n\nHIGH (7.0-8.9):\n- SQL injection with data access\n- Privilege escalation\n- Significant data exposure\n- Account takeover with user interaction\n\nMEDIUM (4.0-6.9):\n- Stored XSS\n- IDOR with limited impact\n- Information disclosure\n- CSRF on sensitive actions\n\nLOW (0.1-3.9):\n- Reflected XSS\n- Missing security headers\n- Clickjacking\n- Descriptive error messages\n\nINFORMATIONAL (0.0):\n- Banner disclosure\n- Directory listing\n- Outdated software (no exploit available)\n```\n\n3. Impact Communication:\n\nBusiness Impact Examples:\n```text\n# Financial Impact\n\"An attacker could manipulate payment amounts, potentially leading to financial loss for both users and the company.\"\n\n# Data Breach Impact\n\"This vulnerability exposes personally identifiable information (PII) for all users, including names, emails, and addresses, violating GDPR and CCPA compliance.\"\n\n# Reputation Impact\n\"Public disclosure could damage user trust and result in negative media coverage.\"\n\n# Operational Impact\n\"Successful exploitation could lead to service disruption affecting thousands of users.\"\n```\n\nUser Impact Stories:\n```text\n# Personal Data Exposure\n\"A malicious actor could harvest user email addresses for spam campaigns or targeted phishing attacks.\"\n\n# Account Security\n\"Users' accounts could be compromised, leading to unauthorized access to private messages, financial data, or personal photos.\"\n\n# Privacy Violation\n\"Location data, browsing history, or communication records could be accessed without authorization.\"\n```\n\n4. Technical Writing Best Practices:\n\nClear Technical Descriptions:\n```text\n# GOOD: Specific and actionable\n\"The /api/users/{id} endpoint fails to validate user ownership, allowing authenticated users to access any user's profile data by modifying the 'id' parameter in GET requests.\"\n\n# BAD: Vague and unhelpful\n\"There's a security issue with user data access.\"\n```\n\nPrecise Reproduction Steps:\n```text\n# GOOD: Detailed and reproducible\n1. Register two test accounts: user1@example.com and user2@example.com\n2. Log in as user1 and obtain authentication token\n3. Send GET request to /api/users/profile with user1's token\n4. Note the returned user ID (e.g., 123)\n5. Send GET request to /api/users/124 (different user ID)\n6. Observe that user2's profile data is returned\n\n# BAD: Incomplete and unclear\n1. Log in\n2. Change the ID\n3. See other user's data\n```\n\n5. Evidence Collection and Presentation:\n\nScreenshot Guidelines:\n```bash\n# Use clear, annotated screenshots\n# Highlight vulnerable parameters\n# Show successful exploitation\n# Include browser developer tools\n# Redact sensitive information\n\n# Tools for screenshot capture\n# Firefox DevTools: F12 -> Screenshot node\n# Chrome DevTools: F12 -> More tools -> Capture node screenshot\n# Flameshot or ShareX for system screenshots\n```\n\nVideo PoC Creation:\n```bash\n# Use clean, professional recordings\n# Enable cursor highlighting\n# Add text overlays for clarity\n# Keep videos under 2 minutes\n# Include audio narration if helpful\n\n# Tools: OBS Studio, Loom, Asciinema for terminal recordings\n```\n\n6. Bounty Negotiation and Communication:\n\nInitial Bounty Request:\n```text\n# Research similar vulnerabilities\n# Check program's bounty table\n# Consider your effort and impact\n# Start reasonable, not greedy\n\n# Examples:\n# Critical RCE: $5,000 - $15,000\n# High SQLi: $2,000 - $5,000\n# Medium IDOR: $500 - $2,000\n# Low XSS: $100 - $500\n```\n\nProfessional Communication:\n```text\n# Be responsive to questions\n# Provide additional testing if requested\n# Be open to severity discussions\n# Accept reasonable counter-offers\n# Thank the team for their time\n\n# Response to triage questions:\n\"Thank you for the quick response. I've tested this on Chrome 91 and Firefox 89. The issue occurs when the 'user_id' parameter is modified in the POST request to /api/update-profile. Here's additional evidence showing the vulnerability affects all user accounts.\"\n```\n\n7. Follow-up and Resolution:\n\nTriage Process Management:\n```text\n# Track report status\n# Respond promptly to questions\n# Provide additional information\n# Test proposed fixes\n# Update severity if new information emerges\n\n# Status progression:\n# Submitted -> Triaged -> Needs More Info -> Confirmed -> Resolved\n```\n\nFix Verification:\n```bash\n# Test the implemented fix\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  https://api.example.com/users/VICTIM_ID\n# Should return 403 Forbidden\n\n# Confirm legitimate access still works\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  https://api.example.com/users/MY_ID\n# Should return 200 OK\n```\n\n8. Report Quality Checklist:\n\nPre-Submission Review:\n```text\nâ–¡ Clear, descriptive title\nâ–¡ Accurate severity assessment\nâ–¡ Detailed technical description\nâ–¡ Step-by-step reproduction guide\nâ–¡ Working proof of concept\nâ–¡ Impact assessment with examples\nâ–¡ Remediation recommendations\nâ–¡ Professional language and formatting\nâ–¡ No sensitive data exposure\nâ–¡ Tested on latest version\nâ–¡ No duplicate of existing reports\n```\n\n9. Advanced Reporting Techniques:\n\nMulti-Vulnerability Reports:\n```text\n# Group related issues\n# Show attack chains\n# Demonstrate combined impact\n# Request appropriate total bounty\n\n# Example: \"Chained XSS + CSRF leading to account takeover\"\n```\n\nTrend Analysis Reports:\n```text\n# Identify systemic issues\n# Suggest architectural improvements\n# Provide comprehensive remediation plans\n# Demonstrate deep understanding\n\n# Example: \"Authorization bypass affects 15+ endpoints due to shared middleware flaw\"\n```\n\nWHAT TO LOOK FOR:\n- **Clear Communication**: Security teams can understand and act on your report\n- **Complete Information**: All necessary details for reproduction and fixing\n- **Professional Presentation**: Well-formatted, error-free, and respectful\n- **Appropriate Severity**: Accurate CVSS scoring and business impact assessment\n- **Actionable Recommendations**: Specific, implementable remediation steps\n\nSECURITY IMPLICATIONS:\n- **Effective Remediation**: Clear reports lead to faster fixes and better security\n- **Responsible Disclosure**: Professional communication maintains positive relationships\n- **Industry Improvement**: High-quality reports help raise security standards\n- **Researcher Reputation**: Well-written reports build credibility and future opportunities\n\nCOMMON PITFALLS:\n- **Poor Writing Quality**: Typos, grammar errors, unclear explanations\n- **Incomplete Reproduction Steps**: Missing prerequisites or unclear instructions\n- **Overstated Severity**: Inflating impact to get higher bounties\n- **Unprofessional Tone**: Demanding language or entitlement attitude\n- **Missing Evidence**: No PoC, screenshots, or technical details\n- **Duplicate Submissions**: Not checking for existing similar reports\n- **Ignoring Feedback**: Not responding to triage questions or requests\n- **Timeline Pressure**: Submitting incomplete reports to be first\n\nTOOLS REFERENCE:\n- **CVSS Calculator**: https://www.first.org/cvss/calculator/3.1\n- **Grammarly**: https://grammarly.com/ (writing quality)\n- **HackMD**: https://hackmd.io/ (collaborative report writing)\n- **Flameshot**: https://flameshot.org/ (screenshot annotation)\n- **OBS Studio**: https://obsproject.com/ (screen recording)\n- **Markdown Table Generator**: https://www.tablesgenerator.com/markdown_tables\n\nFURTHER READING:\n- HackerOne Report Writing Guide: https://docs.hackerone.com/hackers/report-writing.html\n- Bugcrowd Report Best Practices: https://www.bugcrowd.com/blog/how-to-write-a-good-bug-report/\n- OWASP Vulnerability Reporting: https://owasp.org/www-community/OWASP_Vulnerability_Remediation_Cheat_Sheet\n- CVSS v3.1 Specification: https://www.first.org/cvss/specification-document\n- Vulnerability Disclosure Best Practices: https://www.iso.org/standard/72311.html\n- Bug Bounty Report Examples: https://github.com/ngalongc/bug-bounty-reference/tree/master/reports",
      "tags": [
        "bugbounty",
        "reporting",
        "submission",
        "communication",
        "documentation"
      ],
      "related_tools": [
        "hunter-io",
        "bugbounty_reporting_cvss",
        "burp-api-scanner",
        "ffuf-api",
        "owasp-zap"
      ]
    },
    {
      "id": "triage-communication",
      "title": "Triage communication",
      "content": "OBJECTIVE: Maintain effective communication with security teams throughout the triage process, provide additional information when requested, and ensure smooth resolution of reported vulnerabilities.\n\nACADEMIC BACKGROUND:\nTriage communication is critical for successful bug bounty outcomes. HackerOne research shows that reports with good communication are resolved 2x faster. ISO 29147 emphasizes coordinated vulnerability disclosure. Effective communication builds researcher reputation and improves industry security.\n\nSTEP-BY-STEP PROCESS:\n\n1. Initial Response Strategy:\n\nFirst Contact Best Practices:\n```text\n# Professional and concise introduction\n\"Hello [Team Name], I've discovered a vulnerability in your [specific feature/page]. I've prepared a detailed report with proof of concept. Please let me know if you need any additional information.\"\n\n# Include key details upfront\n\"Severity: High (CVSS 8.5)\nAffected endpoint: /api/users/profile\nImpact: Unauthorized access to user data\nTimeline: 90 days for disclosure\"\n\n# Set expectations\n\"I'm available to answer questions and test fixes. I typically respond within 24 hours.\"\n```\n\nResponse Time Management:\n```text\n# Acknowledge receipt quickly\n\"Thank you for submitting this report. I've received it and will review it shortly.\"\n\n# Set realistic expectations\n\"Our triage process typically takes 3-5 business days. I'll update you once we've completed our initial assessment.\"\n\n# Handle delays gracefully\n\"I apologize for the delay in responding. We've been experiencing higher than usual report volume. We're actively working on this issue.\"\n```\n\n2. Information Request Handling:\n\nCommon Triage Questions:\n```text\n# Environment details\n\"What browser and operating system did you test this on?\"\nResponse: \"Tested on Chrome 91.0.4472.124 and Firefox 89.0.2 on macOS 11.4\"\n\n# Authentication requirements\n\"Do you have a test account we can use to reproduce this?\"\nResponse: \"I've included test credentials in the report. If you need additional accounts, please let me know.\"\n\n# Scope confirmation\n\"Is this endpoint in scope for our program?\"\nResponse: \"According to your policy (https://program.com/policy), *.program.com is in scope. The affected endpoint is api.program.com/users.\"\n\n# Impact verification\n\"Can you provide more details about the data exposure?\"\nResponse: \"The vulnerability exposes PII including names, emails, phone numbers, and partial payment card information.\"\n```\n\nAdditional Evidence Preparation:\n```bash\n# Prepare supplemental materials\n# Alternative reproduction methods\n# Additional test cases\n# Impact demonstrations\n# Related vulnerability findings\n\n# Have these ready:\n# Screenshots from different browsers\n# API request/response logs\n# Network traffic captures\n# Test scripts for automation\n# Similar vulnerability references\n```\n\n3. Severity Discussion and Negotiation:\n\nSeverity Justification:\n```text\n# Provide evidence for your assessment\n\"Based on CVSS v3.1, this qualifies as High severity because:\n- Attack Vector: Network (AV:N)\n- Attack Complexity: Low (AC:L) \n- Privileges Required: None (PR:N)\n- User Interaction: None (UI:N)\n- Scope: Unchanged (S:U)\n- Confidentiality: High (C:H)\n- Integrity: None (I:N)\n- Availability: None (A:N)\n\nThis results in a CVSS score of 7.5.\"\n\n# Be open to discussion\n\"I understand your assessment. If you have additional context about the affected systems or existing controls, I'd be happy to reconsider the severity.\"\n```\n\nBounty Negotiation:\n```text\n# Research-based requests\n\"Based on similar reports in your program and industry standards, I believe $2,500 is appropriate for this High-severity IDOR vulnerability.\"\n\n# Be reasonable and flexible\n\"I understand budget constraints. I'm open to discussing a lower amount if $2,500 is not feasible.\"\n\n# Know when to accept\n\"Thank you for the counter-offer of $1,800. I accept this amount and appreciate your consideration.\"\n\n# Handle lowball offers\n\"While I appreciate the offer, this vulnerability affects all user accounts and requires significant development effort to fix. I'd like to discuss a more appropriate amount.\"\n```\n\n4. Fix Testing and Verification:\n\nPatch Testing Preparation:\n```bash\n# Create comprehensive test cases\n# Test legitimate functionality\n# Test edge cases\n# Verify the fix works across different scenarios\n\n# Test script template\ncat > fix_verification.py << 'EOF'\nimport requests\n\ndef test_fix(base_url, token):\n    # Test that vulnerability is fixed\n    vuln_response = requests.get(f\"{base_url}/vulnerable-endpoint\", headers={\"Authorization\": f\"Bearer {token}\"})\n    assert vuln_response.status_code == 403, f\"Vulnerability not fixed: {vuln_response.status_code}\"\n    \n    # Test that legitimate access still works\n    legit_response = requests.get(f\"{base_url}/legitimate-endpoint\", headers={\"Authorization\": f\"Bearer {token}\"})\n    assert legit_response.status_code == 200, f\"Legitimate access broken: {legit_response.status_code}\"\n    \n    print(\"Fix verification successful\")\nEOF\n```\n\nRegression Testing:\n```bash\n# Test similar endpoints\n# Test with different user roles\n# Test edge cases and error conditions\n# Verify no new vulnerabilities introduced\n\n# Automated regression tests\nfor endpoint in similar_endpoints:\n    test_endpoint_security(endpoint)\n```\n\n5. Timeline Management:\n\nDisclosure Coordination:\n```text\n# Standard timeline (90 days)\n\"I discovered this vulnerability on [date]. Per responsible disclosure guidelines, I plan to publicly disclose on [date + 90 days] unless you need more time.\"\n\n# Extension requests\n\"I understand you need additional time for remediation. I'm happy to extend the disclosure deadline to [new date]. Please keep me updated on your progress.\"\n\n# Early disclosure coordination\n\"If you need more time beyond the standard 90 days, please let me know by [date - 30 days] so we can coordinate an appropriate extension.\"\n```\n\nProgress Updates:\n```text\n# Regular check-ins\n\"It's been a week since submission. Could you provide an update on the triage status?\"\n\n# Be patient but persistent\n\"I understand you're busy. I'm just following up on the status. No rush on my end.\"\n\n# Handle delays professionally\n\"I appreciate the transparency about the delay. Is there anything I can do to help expedite the process?\"\n```\n\n6. Conflict Resolution:\n\nHandling Disputes:\n```text\n# Stay professional\n\"I understand your perspective. Let me provide additional evidence to support my findings.\"\n\n# Escalate appropriately\n\"If we can't reach agreement on the severity, would you be open to involving a third-party mediator or using the platform's dispute resolution process?\"\n\n# Know when to walk away\n\"I respect your decision. While I disagree with the assessment, I won't pursue this further. Thank you for your time.\"\n```\n\nPlatform Mediation:\n```text\n# Use platform dispute resolution\n# Provide all evidence and communication history\n# Be prepared to accept platform decisions\n# Learn from the experience for future reports\n\n# Post-resolution follow-up\n\"Thank you for the mediation. I appreciate the platform's involvement in resolving this matter.\"\n```\n\n7. Reputation Building:\n\nPositive Communication:\n```text\n# Express appreciation\n\"Thank you for the quick resolution and fair bounty. I appreciate your professionalism.\"\n\n# Provide feedback\n\"The triage process was smooth and your questions were clear. The fix verification went well. Great job!\"\n\n# Build relationships\n\"If you need help testing similar issues or have questions about your security program, feel free to reach out.\"\n```\n\nNetworking Opportunities:\n```text\n# Connect on LinkedIn\n# Join program Slack/Discord\n# Attend security conferences\n# Collaborate on future research\n# Share knowledge with the community\n```\n\n8. Documentation and Learning:\n\nCommunication Logs:\n```bash\n# Maintain detailed records\n# Document all interactions\n# Track response times\n# Note lessons learned\n\n# Personal database\ncat > report_log.md << EOF\n## Report: [Title]\n**Program:** [Name]\n**Submitted:** [Date]\n**Severity:** [Level]\n**Bounty:** [Amount]\n**Resolution Time:** [Days]\n**Key Learnings:** [Notes]\n**Communication Quality:** [Rating]\nEOF\n```\n\nProcess Improvement:\n```text\n# Analyze successful communications\n# Identify communication patterns\n# Improve response templates\n# Develop better evidence preparation\n# Refine negotiation strategies\n\n# Metrics to track:\n# Average response time\n# Resolution success rate\n# Bounty amounts vs effort\n# Communication quality scores\n```\n\nWHAT TO LOOK FOR:\n- **Clear Communication**: Responses are timely, professional, and informative\n- **Collaborative Approach**: Security teams view you as a partner, not an adversary\n- **Efficient Resolution**: Issues move through triage quickly with minimal back-and-forth\n- **Fair Outcomes**: Bounty amounts reflect the actual impact and effort involved\n- **Positive Relationships**: Security teams remember you for future collaborations\n\nSECURITY IMPLICATIONS:\n- **Faster Fixes**: Good communication leads to quicker remediation\n- **Better Security**: Collaborative relationships improve overall program security\n- **Industry Advancement**: Professional disclosure practices benefit everyone\n- **Researcher Growth**: Learning from security teams improves your skills\n\nCOMMON PITFALLS:\n- **Poor Response Times**: Not responding to questions within 24-48 hours\n- **Unprofessional Tone**: Using demanding or entitled language\n- **Incomplete Information**: Not providing requested evidence or clarifications\n- **Severity Inflation**: Arguing for higher severity without evidence\n- **Timeline Pressure**: Pushing for faster resolution than reasonable\n- **Negotiation Aggression**: Being unreasonable about bounty amounts\n- **Lack of Flexibility**: Not adapting to security team constraints\n- **No Follow-up**: Disappearing after submission\n\nTOOLS REFERENCE:\n- **Trello/Trello-like**: For tracking report statuses\n- **Google Calendar**: For managing disclosure deadlines\n- **Notion/Obsidian**: For maintaining communication logs\n- **LinkedIn**: For professional networking\n- **Slack/Discord**: For program-specific communication\n- **GitHub Issues**: For organizing research and reports\n\nFURTHER READING:\n- HackerOne Communication Guide: https://docs.hackerone.com/hackers/communication.html\n- Bugcrowd Researcher Handbook: https://www.bugcrowd.com/hackers/resources/\n- ISO 29147 Coordinated Disclosure: https://www.iso.org/standard/72311.html\n- CERT Vulnerability Disclosure: https://www.cert.org/vulnerability-analysis/vulnerability-disclosure.cfm\n- Bug Bounty Communication Best Practices: https://www.hackerone.com/blog/bug-bounty-communication-best-practices\n- Researcher Reputation Building: https://www.bugcrowd.com/blog/how-to-build-a-reputation-as-a-bug-bounty-hunter/",
      "tags": [
        "bugbounty",
        "triage",
        "communication",
        "negotiation",
        "resolution"
      ],
      "related_tools": [
        "hunter-io",
        "bugbounty_reporting_cvss",
        "burp-api-scanner",
        "ffuf-api",
        "ml-pipeline-audit"
      ]
    },
    {
      "id": "disclosure-reputation-building",
      "title": "Disclosure & reputation building",
      "content": "OBJECTIVE: Manage responsible disclosure timelines, build a strong researcher reputation, and establish yourself as a trusted security professional in the bug bounty community.\n\nACADEMIC BACKGROUND:\nResponsible disclosure is fundamental to ethical hacking. ISO 29147 provides standards for vulnerability disclosure. HackerOne research shows that researchers with strong reputations earn 40% higher bounties. Building credibility requires consistent professional conduct and community contribution.\n\nSTEP-BY-STEP PROCESS:\n\n1. Disclosure Timeline Management:\n\nStandard Disclosure Windows:\n```text\n# 90-day standard period\nDiscovery Date: [Date]\nDisclosure Deadline: [Date + 90 days]\n\n# Extended timelines for complex fixes\n# Enterprise software: 180 days\n# Critical infrastructure: 365+ days\n# By agreement with vendor\n\n# Early disclosure coordination\n\"If you need additional time for remediation, please let me know by [Date - 30 days] so we can coordinate an appropriate extension.\"\n```\n\nExtension Requests:\n```text\n# Professional extension requests\n\"I understand this fix requires coordination across multiple teams. I'm happy to extend the disclosure deadline to [new date] to give you adequate time.\"\n\n# Document agreements\n\"To confirm: Disclosure deadline extended to [date]. I'll update my records and coordinate with any relevant parties.\"\n\n# Handle unreasonable delays\n\"While I want to be accommodating, the 90-day standard provides adequate time for most fixes. If you need more time, please provide specific reasons and a concrete timeline.\"\n```\n\nPublic Disclosure Preparation:\n```bash\n# Prepare disclosure post\n# Include non-sensitive technical details\n# Credit the security team\n# Link to advisory if available\n\n# Disclosure template\ncat > disclosure.md << 'EOF'\n# [Vulnerability Title] - CVE-XXXX-XXXX\n\n## Summary\nA [vulnerability type] was discovered in [software/product] that allows [impact description].\n\n## Technical Details\n- **Affected Versions**: [versions]\n- **CVSS Score**: [score] ([vector])\n- **CWE**: [CWE-ID]\n\n## Timeline\n- **Discovered**: [date]\n- **Reported**: [date]\n- **Fixed**: [date]\n- **Disclosed**: [date]\n\n## Credits\n- **Researcher**: [Your Name]\n- **Vendor**: [Company Security Team]\n\n## References\n- [Vendor Advisory]\n- [Your Blog Post]\n- [Related Research]\nEOF\n```\n\n2. Reputation Building Strategies:\n\nProfile Optimization:\n```text\n# Professional profiles\n# LinkedIn: Security Researcher | Bug Bounty Hunter\n# Twitter: Share findings, follow security news\n# GitHub: Public PoC repositories, security tools\n# Personal Blog: Technical writeups and methodology\n\n# Profile elements:\n# Professional photo\n# Clear bio with expertise areas\n# Links to reports/writeups\n# Certifications (OSCP, CEH, etc.)\n# Speaking engagements\n# Open source contributions\n```\n\nContent Creation:\n```text\n# Technical blog posts\n# Methodology guides\n# Tool development\n# Conference presentations\n# YouTube tutorials\n# Security research papers\n\n# Content themes:\n# Vulnerability analysis techniques\n# Bug bounty tips and tricks\n# Tool development tutorials\n# Program reviews and recommendations\n# Industry trend analysis\n```\n\nCommunity Engagement:\n```text\n# Forum participation\n# Reddit: r/netsec, r/bugbounty\n# Discord/Slack security communities\n# Twitter security discussions\n# Conference attendance and networking\n\n# Contribution types:\n# Answering questions\n# Sharing research findings\n# Helping newcomers\n# Organizing meetups\n# Mentoring programs\n```\n\n3. Professional Development:\n\nSkill Enhancement:\n```text\n# Continuous learning\n# New vulnerability classes\n# Emerging technologies\n# Programming language skills\n# Cloud platform expertise\n\n# Learning resources:\n# OWASP resources\n# SANS Institute courses\n# Offensive Security training\n# Conference presentations\n# Academic research papers\n```\n\nCertification Goals:\n```text\n# Entry-level: CompTIA Security+, CEH\n# Intermediate: OSCP, OSWE\n# Advanced: OSEE, OSCE\n# Cloud-specific: AWS Security Specialty, GCP Professional Cloud Security\n\n# Certification benefits:\n# Credibility with programs\n# Higher bounty potential\n# Networking opportunities\n# Career advancement\n```\n\nTool Development:\n```text\n# Custom security tools\n# Automation scripts\n# Vulnerability scanners\n# Report generation tools\n# Reconnaissance frameworks\n\n# Open source contribution:\n# Bug bounty tool repositories\n# Security research code\n# Community tool improvements\n# Documentation contributions\n```\n\n4. Networking and Relationships:\n\nIndustry Connections:\n```text\n# Security conferences\n# DEF CON, Black Hat, RSA Conference\n# BSides events\n# Local security meetups\n\n# Professional networking:\n# LinkedIn connections with security professionals\n# Twitter interactions with industry leaders\n# Conference follow-ups\n# Collaborative research projects\n```\n\nMentorship Opportunities:\n```text\n# Mentee relationships\n# Guide newcomers in bug bounty\n# Share knowledge and resources\n# Review reports and provide feedback\n\n# Mentor benefits:\n# Knowledge reinforcement\n# Community respect\n# Referral opportunities\n# Personal growth through teaching\n```\n\nProgram Relationships:\n```text\n# Build trust with security teams\n# Consistent professional communication\n# Fair bounty negotiations\n# Timely follow-ups\n# Collaborative problem-solving\n\n# Long-term benefits:\n# Priority triage\n# Higher bounty amounts\n# Exclusive program access\n# Beta testing opportunities\n```\n\n5. Business Development:\n\nFreelance Opportunities:\n```text\n# Penetration testing contracts\n# Security consulting\n# Vulnerability research\n# Red team engagements\n\n# Service offerings:\n# Web application security testing\n# API security assessments\n# Cloud security reviews\n# Mobile application testing\n```\n\nContent Monetization:\n```text\n# Sponsored blog posts\n# Security course creation\n# Tool sales\n# Affiliate marketing\n# Speaking fees\n\n# Platform options:\n# Udemy courses\n# Teachable platforms\n# Patreon support\n# Security tool sales\n```\n\nCompany Formation:\n```text\n# Security consultancy startup\n# Bug bounty platform\n# Security tool development\n# Training company\n\n# Business considerations:\n# Legal structure (LLC, corporation)\n# Insurance requirements\n# Client contracts\n# Tax implications\n```\n\n6. Ethical Considerations:\n\nResponsible Conduct:\n```text\n# Always follow program rules\n# Respect disclosure timelines\n# Don't harm production systems\n# Protect user privacy\n# Be honest in communications\n\n# Ethical dilemmas:\n# Finding critical vulnerability in legacy system\n# Program paying below market rate\n# Security team unresponsive\n# Duplicate findings\n```\n\nCommunity Standards:\n```text\n# Don't share sensitive information\n# Respect other researchers' work\n# Help build up the community\n# Call out unethical behavior\n# Support diversity and inclusion\n\n# Community guidelines:\n# HackerOne Code of Conduct\n# Bugcrowd Researcher Agreement\n# Responsible Disclosure Standards\n# Academic integrity principles\n```\n\n7. Performance Analytics:\n\nMetrics Tracking:\n```bash\n# Personal dashboard\n# Reports submitted per month\n# Average bounty amounts\n# Resolution times\n# Success rates by severity\n\n# Tracking script\ncat > bounty_stats.py << 'EOF'\nimport json\nfrom datetime import datetime\n\nclass BountyTracker:\n    def __init__(self):\n        self.reports = []\n    \n    def add_report(self, program, severity, bounty, resolution_days):\n        self.reports.append({\n            'program': program,\n            'severity': severity,\n            'bounty': bounty,\n            'resolution_days': resolution_days,\n            'date': datetime.now().isoformat()\n        })\n    \n    def get_stats(self):\n        total_bounty = sum(r['bounty'] for r in self.reports)\n        avg_resolution = sum(r['resolution_days'] for r in self.reports) / len(self.reports)\n        return {\n            'total_reports': len(self.reports),\n            'total_bounty': total_bounty,\n            'avg_resolution_days': avg_resolution\n        }\nEOF\n```\n\nGoal Setting:\n```text\n# Short-term goals (3 months)\n# Submit 10 high-quality reports\n# Achieve $5,000 in bounties\n# Build relationships with 5 programs\n\n# Long-term goals (1 year)\n# Consistent $10,000/month income\n# Speak at 2 conferences\n# Launch security tool/product\n# Establish consulting business\n```\n\n8. Risk Management:\n\nLegal Protection:\n```text\n# Understand CFAA safe harbor\n# Document all communications\n# Keep detailed research logs\n# Consult legal experts when needed\n\n# Insurance considerations:\n# Cyber liability insurance\n# Professional indemnity\n# Business interruption coverage\n```\n\nFinancial Planning:\n```text\n# Emergency fund (6-12 months)\n# Tax planning for freelance income\n# Retirement planning\n# Investment diversification\n\n# Expense tracking:\n# Tool subscriptions\n# Conference attendance\n# Training courses\n# Hardware/software costs\n```\n\nWHAT TO LOOK FOR:\n- **Consistent Professionalism**: All communications and actions reflect positively on your reputation\n- **Community Respect**: Other researchers and security teams value your contributions\n- **Growing Opportunities**: Increasing bounty amounts, exclusive program access, speaking invitations\n- **Industry Recognition**: Awards, publications, conference invitations\n- **Sustainable Income**: Reliable earnings from bug bounty and related activities\n\nSECURITY IMPLICATIONS:\n- **Industry Advancement**: Professional researchers drive security improvements\n- **Knowledge Sharing**: Community collaboration leads to better security practices\n- **Standards Development**: Experienced researchers help establish industry norms\n- **Threat Reduction**: Proactive vulnerability discovery prevents real-world attacks\n\nCOMMON PITFALLS:\n- **Burnout**: Working 80+ hours without breaks or self-care\n- **Reputation Damage**: Unprofessional behavior or unethical actions\n- **Over-specialization**: Focusing only on one vulnerability type or platform\n- **Poor Financial Planning**: Not saving for lean periods or tax obligations\n- **Neglecting Relationships**: Treating security teams as adversaries rather than partners\n- **Public Disclosure Violations**: Breaking agreed-upon disclosure timelines\n- **Competitive Sabotage**: Trying to undermine other researchers\n- **Skill Stagnation**: Not continuously learning new techniques and technologies\n\nTOOLS REFERENCE:\n- **LinkedIn**: Professional networking and reputation building\n- **Twitter**: Security news and community engagement\n- **GitHub**: Code repositories and open source contributions\n- **Medium/Substack**: Blogging platforms for technical writing\n- **Notion**: Personal knowledge base and goal tracking\n- **Trello/Asana**: Project management for research and business development\n\nFURTHER READING:\n- The Bug Bounty Hunter's Playbook: https://www.amazon.com/Bug-Bounty-Hunters-Playbook-Vulnerabilities/dp/1718501562\n- Real World Bug Hunting: https://www.amazon.com/Real-World-Bug-Hunting-Vulnerability-Discovery/dp/1593278616\n- Bug Bounty Bootcamp: https://www.amazon.com/Bug-Bounty-Bootcamp-Reporting-Vulnerabilities/dp/1718501544\n- Building a Bug Bounty Business: https://www.bugcrowd.com/blog/building-a-bug-bounty-business/\n- Researcher Career Development: https://www.hackerone.com/blog/career-development-for-bug-bounty-hunters\n- ISO 29147 Vulnerability Disclosure: https://www.iso.org/standard/72311.html",
      "tags": [
        "bugbounty",
        "disclosure",
        "reputation",
        "career",
        "professionalism"
      ],
      "related_tools": [
        "recon-ng",
        "workflow_cloud_security_assessment",
        "workflow_red_purple_team_collaboration",
        "bugbounty_reporting_cvss",
        "burp-api-scanner"
      ]
    },
    {
      "id": "automation-efficiency",
      "title": "Automation & efficiency",
      "content": "OBJECTIVE: Develop automated workflows and tools to increase bug bounty hunting efficiency, reduce manual effort, and discover vulnerabilities at scale while maintaining quality and responsible testing practices.\n\nACADEMIC BACKGROUND:\nAutomation is essential for scaling bug bounty hunting efforts. Research from Bugcrowd shows that automated tools can increase finding rates by 300%. However, OWASP emphasizes that automation should complement, not replace, manual testing and critical thinking.\n\nSTEP-BY-STEP PROCESS:\n\n1. Reconnaissance Automation:\n\nSubdomain Discovery Pipeline:\n```bash\n# Automated subdomain enumeration\ncat > auto_recon.sh << 'EOF'\n#!/bin/bash\n\ndomain=$1\noutput_dir=\"recon_${domain}\"\nmkdir -p $output_dir\n\n# Passive enumeration\necho \"[+] Starting passive enumeration...\"\nsubfinder -d $domain -all -recursive -o $output_dir/subfinder.txt\namass enum -passive -d $domain -o $output_dir/amass_passive.txt\n\n# Certificate transparency\ncurl -s \"https://crt.sh/?q=%.${domain}&output=json\" | jq -r '.[].name_value' | sort -u > $output_dir/crt.txt\n\n# Combine and resolve\necho \"[+] Resolving subdomains...\"\ncat $output_dir/*.txt | sort -u | dnsx -a -resp-only > $output_dir/resolved.txt\n\n# Live host discovery\necho \"[+] Finding live hosts...\"\ncat $output_dir/resolved.txt | httpx -silent -o $output_dir/live_hosts.txt\n\n# Technology fingerprinting\necho \"[+] Technology detection...\"\ncat $output_dir/live_hosts.txt | wappalyzer -o $output_dir/tech.json\n\n# Screenshot capture\necho \"[+] Taking screenshots...\"\ngowitness file -f $output_dir/live_hosts.txt -d $output_dir/screenshots/\n\necho \"[+] Reconnaissance complete!\"\nEOF\n\nchmod +x auto_recon.sh\n./auto_recon.sh example.com\n```\n\nAPI Endpoint Discovery:\n```bash\n# Automated API enumeration\ncat > api_discovery.py << 'EOF'\nimport requests\nfrom urllib.parse import urljoin\n\nclass APIDiscoverer:\n    def __init__(self, base_url):\n        self.base_url = base_url\n        self.endpoints = set()\n        self.session = requests.Session()\n    \n    def discover_endpoints(self):\n        # Common API paths\n        paths = [\n            'api', 'v1', 'v2', 'rest', 'graphql',\n            'swagger', 'openapi', 'docs'\n        ]\n        \n        for path in paths:\n            url = urljoin(self.base_url, path)\n            try:\n                response = self.session.get(url, timeout=5)\n                if response.status_code in [200, 401, 403]:\n                    self.endpoints.add(url)\n                    print(f\"[+] Found API endpoint: {url}\")\n            except:\n                pass\n        \n        return self.endpoints\n\n# Usage\ndiscoverer = APIDiscoverer('https://api.example.com')\nendpoints = discoverer.discover_endpoints()\nEOF\n```\n\n2. Vulnerability Scanning Automation:\n\nCustom Scanner Development:\n```bash\n# Modular vulnerability scanner\ncat > vuln_scanner.py << 'EOF'\nimport requests\nimport json\nfrom urllib.parse import urljoin\n\nclass VulnerabilityScanner:\n    def __init__(self, base_url, token=None):\n        self.base_url = base_url\n        self.token = token\n        self.session = requests.Session()\n        if token:\n            self.session.headers.update({'Authorization': f'Bearer {token}'})\n    \n    def test_idor(self, endpoints):\n        \"\"\"Test for IDOR vulnerabilities\"\"\"\n        vulnerabilities = []\n        \n        for endpoint in endpoints:\n            # Test with different user IDs\n            for user_id in ['123', '124', 'admin']:\n                test_url = endpoint.replace('{id}', user_id)\n                try:\n                    response = self.session.get(test_url)\n                    if response.status_code == 200:\n                        # Check if we can access other user's data\n                        data = response.json()\n                        if 'sensitive_data' in str(data):\n                            vulnerabilities.append({\n                                'type': 'IDOR',\n                                'url': test_url,\n                                'severity': 'High'\n                            })\n                except:\n                    pass\n        \n        return vulnerabilities\n    \n    def test_sqli(self, params):\n        \"\"\"Test for SQL injection\"\"\"\n        payloads = [\"' OR '1'='1\", \"' UNION SELECT * FROM users--\"]\n        vulnerabilities = []\n        \n        for param in params:\n            for payload in payloads:\n                test_data = {param: payload}\n                try:\n                    response = self.session.post(self.base_url, data=test_data)\n                    if 'sql' in response.text.lower() or 'syntax' in response.text.lower():\n                        vulnerabilities.append({\n                            'type': 'SQL Injection',\n                            'parameter': param,\n                            'payload': payload,\n                            'severity': 'Critical'\n                        })\n                except:\n                    pass\n        \n        return vulnerabilities\n\n# Usage\nscanner = VulnerabilityScanner('https://api.example.com', token='jwt_token')\nidor_vulns = scanner.test_idor(['/users/{id}', '/orders/{id}'])\nsqli_vulns = scanner.test_sqli(['search', 'filter'])\nEOF\n```\n\nNuclei Template Creation:\n```yaml\n# Custom Nuclei template for bug bounty\nid: bug-bounty-idor\n\ninfo:\n  name: IDOR in User Profile API\n  author: researcher\n  severity: high\n  tags: idor,api\n\nrequests:\n  - method: GET\n    path:\n      - \"{{BaseURL}}/api/users/123\"\n      - \"{{BaseURL}}/api/users/124\"\n    headers:\n      Authorization: \"Bearer {{token}}\"\n    matchers:\n      - type: status\n        status:\n          - 200\n      - type: word\n        words:\n          - \"email\"\n          - \"phone\"\n        condition: and\n\n# Run with: nuclei -t custom-templates/ -u https://api.example.com -V token=jwt_token\n```\n\n3. Report Generation Automation:\n\nAutomated Report Creation:\n```bash\n# Report generation script\ncat > report_generator.py << 'EOF'\nimport json\nfrom datetime import datetime\n\nclass BugReportGenerator:\n    def __init__(self):\n        self.template = \"\"\"\n# Vulnerability Report\n\n**Program:** {program}\n**Researcher:** {researcher}\n**Date:** {date}\n**Severity:** {severity}\n\n## Summary\n{summary}\n\n## Technical Details\n{details}\n\n## Impact\n{impact}\n\n## Steps to Reproduce\n{steps}\n\n## Proof of Concept\n{poc}\n\n## Recommendations\n{recommendations}\n        \"\"\"\n    \n    def generate_report(self, vuln_data):\n        vuln_data['date'] = datetime.now().strftime('%Y-%m-%d')\n        vuln_data['researcher'] = 'Your Name'\n        \n        report = self.template.format(**vuln_data)\n        \n        # Save to file\n        filename = f\"report_{vuln_data['program']}_{vuln_data['severity']}.md\"\n        with open(filename, 'w') as f:\n            f.write(report)\n        \n        return filename\n\n# Usage\ngenerator = BugReportGenerator()\n\nvuln_data = {\n    'program': 'Example Company',\n    'severity': 'High',\n    'summary': 'IDOR vulnerability allows unauthorized access to user profiles',\n    'details': 'The /api/users/{id} endpoint does not properly validate user ownership',\n    'impact': 'Attackers can access sensitive PII of any user',\n    'steps': '1. Authenticate\\n2. Change user ID in request\\n3. Access other user data',\n    'poc': 'curl -H \"Auth: token\" https://api.example.com/users/123',\n    'recommendations': 'Implement proper authorization checks'\n}\n\ngenerator.generate_report(vuln_data)\nEOF\n```\n\n4. Workflow Optimization:\n\nBug Bounty Workflow Automation:\n```bash\n# Complete workflow script\ncat > bugbounty_workflow.sh << 'EOF'\n#!/bin/bash\n\n# Configuration\ntarget=$1\nprogram_name=$2\nresearcher_email=$3\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m' # No Color\n\nlog() {\n    echo -e \"${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}\"\n}\n\nerror() {\n    echo -e \"${RED}[ERROR] $1${NC}\"\n}\n\nwarning() {\n    echo -e \"${YELLOW}[WARNING] $1${NC}\"\n}\n\n# Phase 1: Reconnaissance\nlog \"Starting reconnaissance phase...\"\n./auto_recon.sh $target\n\nif [ $? -ne 0 ]; then\n    error \"Reconnaissance failed\"\n    exit 1\nfi\n\n# Phase 2: Vulnerability Scanning\nlog \"Starting vulnerability scanning...\"\npython3 vuln_scanner.py --target $target --output vulns.json\n\n# Phase 3: Manual Testing\nlog \"Manual testing phase - review results above\"\nread -p \"Press enter when manual testing is complete\"\n\n# Phase 4: Report Generation\nlog \"Generating report...\"\npython3 report_generator.py --vulns vulns.json --program \"$program_name\" --researcher \"$researcher_email\"\n\n# Phase 5: Submission\nlog \"Report generated. Ready for submission to $program_name\"\nlog \"Remember to follow responsible disclosure guidelines\"\nEOF\n\nchmod +x bugbounty_workflow.sh\n./bugbounty_workflow.sh example.com \"Example Company\" \"researcher@example.com\"\n```\n\n5. Quality Assurance Automation:\n\nAutomated Testing Validation:\n```bash\n# Test case generation\ncat > test_generator.py << 'EOF'\nimport json\n\nclass TestCaseGenerator:\n    def __init__(self, api_spec):\n        self.api_spec = api_spec\n    \n    def generate_idor_tests(self):\n        \"\"\"Generate IDOR test cases for all endpoints\"\"\"\n        test_cases = []\n        \n        for endpoint in self.api_spec['endpoints']:\n            if '{id}' in endpoint['path']:\n                test_cases.append({\n                    'endpoint': endpoint['path'],\n                    'method': endpoint['method'],\n                    'test_type': 'IDOR',\n                    'payloads': [\n                        {'id': '123'},  # Own ID\n                        {'id': '124'},  # Different user ID\n                        {'id': 'admin'},  # Privilege escalation\n                        {'id': '0'},  # Edge case\n                        {'id': '-1'}  # Edge case\n                    ]\n                })\n        \n        return test_cases\n    \n    def generate_auth_tests(self):\n        \"\"\"Generate authentication bypass test cases\"\"\"\n        test_cases = []\n        \n        for endpoint in self.api_spec['endpoints']:\n            if endpoint.get('requires_auth', False):\n                test_cases.append({\n                    'endpoint': endpoint['path'],\n                    'method': endpoint['method'],\n                    'test_type': 'AUTH_BYPASS',\n                    'payloads': [\n                        {'no_auth': True},\n                        {'invalid_token': 'invalid.jwt.here'},\n                        {'expired_token': 'expired.jwt.here'}\n                    ]\n                })\n        \n        return test_cases\n\n# Usage\ngenerator = TestCaseGenerator(api_spec)\nidor_tests = generator.generate_idor_tests()\nauth_tests = generator.generate_auth_tests()\n\n# Export to JSON for automated testing\nwith open('test_cases.json', 'w') as f:\n    json.dump({\n        'idor_tests': idor_tests,\n        'auth_tests': auth_tests\n    }, f, indent=2)\nEOF\n```\n\n6. Monitoring and Alerting:\n\nProgress Tracking Dashboard:\n```bash\n# Simple dashboard script\ncat > dashboard.py << 'EOF'\nimport json\nimport os\nfrom datetime import datetime, timedelta\n\nclass BugBountyDashboard:\n    def __init__(self):\n        self.data_file = 'bugbounty_data.json'\n        self.load_data()\n    \n    def load_data(self):\n        if os.path.exists(self.data_file):\n            with open(self.data_file, 'r') as f:\n                self.data = json.load(f)\n        else:\n            self.data = {\n                'reports': [],\n                'programs': {},\n                'stats': {\n                    'total_bounties': 0,\n                    'avg_resolution_time': 0,\n                    'success_rate': 0\n                }\n            }\n    \n    def add_report(self, program, severity, status, bounty=0):\n        report = {\n            'program': program,\n            'severity': severity,\n            'status': status,\n            'bounty': bounty,\n            'submitted': datetime.now().isoformat(),\n            'updated': datetime.now().isoformat()\n        }\n        self.data['reports'].append(report)\n        self.save_data()\n    \n    def get_stats(self):\n        reports = self.data['reports']\n        resolved = [r for r in reports if r['status'] == 'resolved']\n        \n        if resolved:\n            total_bounty = sum(r['bounty'] for r in resolved)\n            avg_time = sum((datetime.fromisoformat(r['updated']) - datetime.fromisoformat(r['submitted'])).days for r in resolved) / len(resolved)\n            \n            return {\n                'total_reports': len(reports),\n                'resolved_reports': len(resolved),\n                'total_bounty': total_bounty,\n                'avg_resolution_days': avg_time,\n                'success_rate': len(resolved) / len(reports) * 100\n            }\n        \n        return {'total_reports': len(reports), 'message': 'No resolved reports yet'}\n    \n    def save_data(self):\n        with open(self.data_file, 'w') as f:\n            json.dump(self.data, f, indent=2)\n\n# Usage\ndashboard = BugBountyDashboard()\ndashboard.add_report('Example Company', 'High', 'submitted')\nprint(json.dumps(dashboard.get_stats(), indent=2))\nEOF\n```\n\n7. Tool Maintenance and Updates:\n\nAutomated Tool Updates:\n```bash\n# Tool update script\ncat > update_tools.sh << 'EOF'\n#!/bin/bash\n\n# Update system packages\nsudo apt update && sudo apt upgrade -y\n\n# Update Python packages\npip install --upgrade subfinder httpx nuclei wappalyzer\n\n# Update Go tools\ngo install -v github.com/projectdiscovery/subfinder/v2/cmd/subfinder@latest\ngo install -v github.com/projectdiscovery/httpx/cmd/httpx@latest\ngo install -v github.com/projectdiscovery/nuclei/v2/cmd/nuclei@latest\n\n# Update wordlists\ncd ~/wordlists\nwget -N https://raw.githubusercontent.com/danielmiessler/SecLists/master/Discovery/DNS/subdomains-top1million-110000.txt\nwget -N https://raw.githubusercontent.com/danielmiessler/SecLists/master/Discovery/Web-Content/api-endpoints.txt\n\n# Update nuclei templates\ngit -C ~/nuclei-templates pull origin master\n\nlog \"All tools updated successfully\"\nEOF\n\nchmod +x update_tools.sh\n./update_tools.sh\n```\n\n8. Ethical Automation Guidelines:\n\nResponsible Automation:\n```text\n# Rate limiting\n# Respect robots.txt\n# Don't overwhelm targets\n# Use appropriate user agents\n# Honor DoS restrictions\n\n# Automation ethics:\n# Never automate destructive actions\n# Always test on non-production first\n# Monitor for unintended consequences\n# Be transparent about automation use\n# Respect program testing guidelines\n```\n\nWHAT TO LOOK FOR:\n- **Efficiency Gains**: Automation reduces manual effort while maintaining quality\n- **Scalability**: Ability to test multiple targets simultaneously\n- **Consistency**: Automated processes produce reliable, repeatable results\n- **Quality Maintenance**: Automation doesn't reduce finding quality or report accuracy\n- **Responsible Usage**: Tools respect rate limits and program guidelines\n\nSECURITY IMPLICATIONS:\n- **Comprehensive Coverage**: Automation enables testing of more attack surface\n- **Faster Discovery**: Automated tools find issues that manual testing might miss\n- **Consistent Quality**: Standardized processes reduce human error\n- **Scalable Research**: Tools can be shared and improved by the community\n\nCOMMON PITFALLS:\n- **False Positives**: Automated tools generate noise without proper validation\n- **Rate Limiting Violations**: Aggressive scanning gets IP addresses blocked\n- **Over-Automation**: Relying on tools without understanding what they do\n- **Quality Reduction**: Automation leads to lower-quality reports\n- **Detection Evasion**: Programs block automated scanning\n- **Tool Obsolescence**: Not maintaining and updating tools\n- **Ethical Violations**: Automation causes service disruption\n- **Dependency Issues**: Tools break when dependencies change\n\nTOOLS REFERENCE:\n- **Subfinder**: https://github.com/projectdiscovery/subfinder (subdomain discovery)\n- **HTTPx**: https://github.com/projectdiscovery/httpx (HTTP toolkit)\n- **Nuclei**: https://github.com/projectdiscovery/nuclei (vulnerability scanner)\n- **Naabu**: https://github.com/projectdiscovery/naabu (port scanner)\n- **Gowitness**: https://github.com/sensepost/gowitness (screenshot tool)\n- **Wappalyzer**: https://github.com/wappalyzer/wappalyzer (technology detection)\n- **Nmap**: https://nmap.org/ (network scanning)\n- **Burp Suite**: https://portswigger.net/burp (manual testing with automation)\n\nFURTHER READING:\n- ProjectDiscovery Tools: https://projectdiscovery.io/\n- Bug Bounty Automation: https://github.com/0xPugazh/bug-bounty-automation\n- Custom Tool Development: https://www.hackerone.com/blog/guide-to-building-your-own-bug-bounty-tools\n- Responsible Automation: https://www.bugcrowd.com/blog/responsible-bug-bounty-automation/\n- OWASP Automation Guidelines: https://owasp.org/www-community/Automation_of_Web_Application_Vulnerability_Discovery",
      "tags": [
        "bugbounty",
        "automation",
        "efficiency",
        "tools",
        "workflow"
      ],
      "related_tools": [
        "hunter-io",
        "recon-ng",
        "comparison_port_scanners",
        "burp-api-scanner",
        "ffuf-api"
      ]
    },
    {
      "id": "advanced-osint-passive-recon",
      "title": "Advanced OSINT & passive reconnaissance",
      "content": "OBJECTIVE: Leverage advanced Open Source Intelligence (OSINT) techniques and passive reconnaissance methods to gather comprehensive intelligence about targets without direct interaction, building on foundational reconnaissance with specialized tools and methodologies.\n\nACADEMIC BACKGROUND:\nOSINT is fundamental to modern reconnaissance. The MITRE ATT&CK framework includes reconnaissance (TA0043) as a core technique. Research from \"Redefining Hacking\" emphasizes that passive reconnaissance should comprise 80% of initial target analysis. CERT/CC guidelines stress the importance of passive methods to avoid detection.\n\nSTEP-BY-STEP PROCESS:\n\n1. Certificate Transparency Analysis:\n\nComprehensive Certificate Intelligence:\n```bash\n# Advanced CT log analysis\n# Search all known CT logs for subdomains and certificates\ncurl -s \"https://crt.sh/?q=%.example.com&output=json\" | jq -r '.[] | select(.name_value | contains(\"example.com\")) | .name_value' | sort -u > ct_all.txt\n\n# Historical certificate analysis\n# Find expired certificates that might reveal old infrastructure\ncurl -s \"https://crt.sh/?q=%.example.com&exclude=expired&output=json\" | jq -r '.[] | .name_value' | sort -u > ct_active.txt\n\n# Certificate fingerprinting\n# Extract certificate details for infrastructure analysis\ncurl -s \"https://crt.sh/?q=example.com&output=json\" | jq -r '.[] | {name: .name_value, issuer: .issuer_name, not_before: .not_before, not_after: .not_after}' > cert_details.json\n\n# Wildcard certificate detection\n# Identify services using wildcard certificates\ncurl -s \"https://crt.sh/?q=%.example.com\" | grep -i \"wildcard\" | sort -u\n\n# Subject Alternative Names (SAN) extraction\n# Find all domains covered by certificates\ncurl -s \"https://crt.sh/?q=%.example.com&output=json\" | jq -r '.[] | .name_value' | grep -E \"DNS:\" | sed 's/DNS://g' | sort -u > san_domains.txt\n```\n\nCertificate Authority Specific Queries:\n```bash\n# Let's Encrypt transparency\ncurl -s \"https://crt.sh/?q=%.example.com&caid=16418\" | grep -oE 'https://crt.sh/\\?id=[0-9]+' | head -10\n\n# DigiCert, GlobalSign, and other CA searches\n# Use censys.io or shodan for broader certificate searches\ncensys search \"parsed.names: example.com\" | jq -r '.[] | .parsed.names[]' > censys_certs.txt\n```\n\n2. Advanced DNS Intelligence:\n\nDNS Historical Analysis:\n```bash\n# DNS history and zone transfers\n# Use securitytrails or dnsdumpster for historical DNS records\ncurl \"https://api.securitytrails.com/v1/domain/example.com/history\" \\\n  -H \"APIKEY: YOUR_KEY\" | jq '.records[] | select(.type==\"A\") | .values[]' > dns_history.txt\n\n# DNSSEC analysis\n# Check for DNSSEC deployment and potential weaknesses\ndig DNSKEY example.com +short\ndig DS example.com +short\n\n# DNS delegation analysis\n# Identify authoritative nameservers and delegation chains\nwhois example.com | grep -E \"Name Server|NS:\" | sort -u\n\n# Reverse DNS lookups\n# Find other domains hosted on same IP ranges\nfor ip in $(dig A example.com +short); do\n  dig -x $ip +short\ndone\n```\n\nDNS Record Mining:\n```bash\n# Comprehensive DNS enumeration\n# TXT records for SPF, DKIM, DMARC\nhost -t TXT example.com\nhost -t TXT _dmarc.example.com\n\n# SRV records for service discovery\nhost -t SRV _sip._tcp.example.com\nhost -t SRV _xmpp-client._tcp.example.com\n\n# CAA records for certificate authorities\nhost -t CAA example.com\n\n# DNS over HTTPS (DoH) servers\n# Identify if target uses custom DoH\ncurl -H \"accept: application/dns-json\" \"https://cloudflare-dns.com/dns-query?name=example.com&type=A\"\n```\n\n3. Password Dump and Credential Intelligence:\n\nPublic Password Breach Analysis:\n```bash\n# HaveIBeenPwned API for breach checking\ncurl -s \"https://api.haveibeenpwned.com/range/$(echo -n \"test@example.com\" | sha1sum | cut -c1-5)\" | grep -i \"test@\"\n\n# DeHashed for comprehensive breach data\n# Search for company domain in breaches\ncurl \"https://api.dehashed.com/search?query=domain:example.com\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY\"\n\n# Leak-Lookup for multiple breach sources\npython3 leak_lookup.py -t example.com -o breaches.json\n\n# Snusbase for credential intelligence\n# Search for exposed credentials\ncurl -X POST \"https://api.snusbase.com/search\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"query\": \"example.com\", \"type\": \"email\"}'\n```\n\nCredential Pattern Analysis:\n```bash\n# Analyze password patterns from breaches\n# Look for common patterns used by employees\n# Identify password reset questions and security answers\n\n# Social media password hints\n# Check LinkedIn, Twitter for password reset hints\n# Look for \"password reminder\" questions in public profiles\n\n# Default credential checking\n# Test common default passwords for exposed services\n# admin/admin, root/password, etc.\n```\n\n4. Advanced Shodan Intelligence:\n\nShodan Passive Reconnaissance:\n```bash\n# Shodan host search with filters\nshodan search \"hostname:example.com port:443\" --fields ip_str,port,hostnames\n\n# Technology stack identification\nshodan search \"hostname:example.com apache\" --fields ip_str,data\n\n# SSL certificate analysis\nshodan search \"ssl.cert.subject.cn:example.com\" --fields ssl.cert.subject,ssl.cert.issuer\n\n# Historical data analysis\n# Use Shodan InternetDB for passive host data\ncurl -s \"https://internetdb.shodan.io/example.com\" | jq .\n\n# Shodan radar for network mapping\n# Identify IP ranges and network infrastructure\nshodan radar --format json | jq '.matches[] | select(.hostnames[] | contains(\"example.com\"))'\n```\n\nShodan Dorking Techniques:\n```text\n# Web server identification\nhostname:example.com port:80,443\n\n# Database servers\nhostname:example.com port:3306,5432,27017\n\n# Mail servers\nhostname:example.com port:25,587,993\n\n# VPN endpoints\nhostname:example.com port:1194,500,4500\n\n# Exposed admin panels\nhostname:example.com \"admin\" \"login\"\n\n# IoT devices\nhostname:example.com product:\"webcam\" OR product:\"router\"\n```\n\n5. Social Media and People Intelligence:\n\nLinkedIn OSINT:\n```bash\n# Employee enumeration via LinkedIn\n# Use hunter.io or theHarvester for email patterns\npython3 theHarvester.py -d example.com -l 500 -b linkedin -f linkedin_results.html\n\n# Technology stack from employee profiles\n# Look for \"we use\" statements in profiles\n# Identify tech stack from job descriptions\n\n# Organizational structure mapping\n# Build employee hierarchy for social engineering\n```\n\nGitHub Intelligence:\n```bash\n# Repository analysis\n# Search for company repositories\ncurl \"https://api.github.com/search/repositories?q=org:example-company\" | jq '.items[] | {name: .name, language: .language, stars: .stargazers_count}'\n\n# Code analysis for sensitive data\n# Look for hardcoded credentials, API keys\ngit clone https://github.com/example-company/repo.git\ncd repo\ngrep -rE \"(api[_-]?key|secret[_-]?key|password|token)\" --include=\"*.js\" --include=\"*.py\" --include=\"*.json\" .\n\n# Commit history analysis\n# Identify developers and recent changes\ngit log --oneline -10\n```\n\nTwitter Intelligence:\n```bash\n# Employee Twitter handles\n# Use Twitter advanced search for company employees\ntwint -s \"example company\" --users\n\n# Technology discussions\n# Search for tech stack mentions\ntwint -s \"example.com tech stack\" --limit 100\n\n# Security announcements\n# Monitor for security updates or incidents\ntwint -s \"example.com security\" --since 2023-01-01\n```\n\n6. Dark Web and Underground Intelligence:\n\nDark Web Monitoring:\n```bash\n# Onion service discovery (ethical only)\n# Use Ahmia or similar for .onion searches\n\n# Breach forums monitoring\n# Monitor for company data in paste sites\n\n# Ransomware group communications\n# Track threat actor mentions of target\n\n# Note: Always follow legal and ethical guidelines\n# Never access illegal content or engage in unlawful activities\n```\n\n7. Advanced Google Dorking:\n\nSophisticated Dork Queries:\n```text\n# File discovery\nsite:example.com filetype:pdf \"confidential\"\nsite:example.com filetype:xls \"password\"\nsite:example.com filetype:sql \"backup\"\n\n# Directory indexing\nsite:example.com intitle:\"index of\" \"parent directory\"\n\n# Configuration files\nsite:example.com filetype:env \"DB_PASSWORD\"\nsite:example.com filetype:config \"api_key\"\n\n# Error messages\nsite:example.com \"php error\" | \"warning\"\nsite:example.com \"sql syntax error\"\n\n# Login pages\nsite:example.com inurl:login | inurl:signin | inurl:auth\n\n# Admin panels\nsite:example.com inurl:admin | inurl:administrator | inurl:manage\n```\n\nAdvanced Dork Combinations:\n```bash\n# Combine multiple operators\ngoogle_search() {\n    query=\"$1\"\n    start=0\n    while [ $start -lt 100 ]; do\n        curl -s \"https://www.googleapis.com/customsearch/v1?key=YOUR_API_KEY&cx=YOUR_SEARCH_ENGINE_ID&q=$query&start=$start\" | jq -r '.items[]?.link'\n        start=$((start + 10))\n    done\n}\n\n# Usage\ngoogle_search \"site:example.com filetype:pdf\"\n```\n\n8. Passive Web Scraping and Analysis:\n\nWebsite Intelligence:\n```bash\n# Archive.org historical analysis\ncurl -s \"https://web.archive.org/cdx/search/cdx?url=example.com&output=json\" | jq -r '.[1:][] | .[1]' | sort -u > wayback_urls.txt\n\n# Compare current vs historical content\n# Identify removed pages or functionality\n\n# JavaScript file analysis\n# Extract all JS files for endpoint discovery\nwget -r -l 1 -A \"*.js\" https://example.com/\nfind . -name \"*.js\" -exec grep -l \"api\\|endpoint\\|url\" {} \\;\n\n# Robots.txt analysis\ncurl -s https://example.com/robots.txt | grep -E \"^(Allow|Disallow|Sitemap)\"\n\n# Sitemap discovery\ncurl -s https://example.com/sitemap.xml | grep -oE '<loc>[^<]+</loc>' | sed 's/<loc>//g' | sed 's/<\\/loc>//g'\n```\n\nWHAT TO LOOK FOR:\n- **Historical Infrastructure**: Old subdomains, IP addresses, and services that might still be accessible\n- **Credential Patterns**: Common password patterns used by employees for password spraying\n- **Technology Stack Evolution**: How the tech stack has changed over time\n- **Employee Information**: Names, roles, and contact information for social engineering context\n- **Exposed Assets**: Forgotten repositories, backups, or development environments\n- **Security Posture**: Public security announcements, breach notifications, or hardening efforts\n\nSECURITY IMPLICATIONS:\n- **Zero Detection Risk**: Passive reconnaissance cannot trigger alerts or blocking\n- **Comprehensive Intelligence**: Builds complete picture of target attack surface\n- **Historical Context**: Understanding infrastructure evolution reveals forgotten assets\n- **Credential Intelligence**: Enables password spraying and brute force attacks\n- **Social Engineering**: Employee information supports targeted phishing campaigns\n\nCOMMON PITFALLS:\n- **API Rate Limiting**: Many OSINT sources have rate limits or require API keys\n- **Data Overload**: Too much passive data can be overwhelming without proper organization\n- **Outdated Information**: Historical data may no longer be relevant\n- **Legal Boundaries**: Some intelligence gathering may cross legal lines\n- **False Positives**: Not all discovered assets are in-scope or exploitable\n- **Privacy Concerns**: Collecting personal information requires ethical consideration\n- **Resource Intensive**: Comprehensive OSINT requires significant time and tools\n\nTOOLS REFERENCE:\n- **crt.sh**: https://crt.sh/ (Certificate Transparency logs)\n- **SecurityTrails**: https://securitytrails.com/ (DNS historical data)\n- **Shodan**: https://shodan.io/ (Internet-wide scanning)\n- **Censys**: https://censys.io/ (Certificate and host intelligence)\n- **DeHashed**: https://dehashed.com/ (Breach data search)\n- **HaveIBeenPwned**: https://haveibeenpwned.com/ (Breach checking)\n- **TheHarvester**: https://github.com/laramies/theHarvester (Email and subdomain OSINT)\n- **Twint**: https://github.com/twintproject/twint (Twitter intelligence)\n- **Wayback Machine**: https://archive.org/web/ (Historical web content)\n\nFURTHER READING:\n- OSINT Framework: https://osintframework.com/\n- Bug Bounty OSINT: https://github.com/nahamsec/Resources-for-Beginner-Bug-Bounty-Hunters\n- Passive Reconnaissance: https://www.offensive-security.com/metasploit-unleashed/passive-reconnaissance/\n- Certificate Transparency: https://certificate.transparency.dev/\n- Shodan Dorking: https://github.com/humblelad/Shodan-Dorks\n- Google Dorking: https://www.exploit-db.com/google-hacking-database",
      "tags": [
        "bugbounty",
        "osint",
        "passive-reconnaissance",
        "certificates",
        "dns",
        "shodan"
      ],
      "related_tools": [
        "recon-ng",
        "hunter-io",
        "censys-api",
        "dns-tunneling",
        "shodan-cli"
      ]
    },
    {
      "id": "active-reconnaissance-scanning",
      "title": "Active reconnaissance & scanning",
      "content": "OBJECTIVE: Perform active reconnaissance and vulnerability scanning while respecting bug bounty program rules, avoiding service disruption, and maximizing discovery of exploitable vulnerabilities through methodical, responsible scanning techniques.\n\nACADEMIC BACKGROUND:\nActive reconnaissance provides detailed technical intelligence but carries detection risk. \"Redefining Hacking\" emphasizes that active scanning should be surgical and program-aware. OWASP testing guidelines stress the importance of controlled scanning to avoid DoS conditions. Research shows that 70% of bug bounty discoveries come from active testing.\n\nSTEP-BY-STEP PROCESS:\n\n1. Program-Aware Scanning Strategy:\n\nScope and Rules Review:\n```bash\n# Extract scanning permissions from program policy\ncurl -s https://hackerone.com/example-company/policy | grep -A 10 -i \"scanning\\|testing\\|permitted\"\n\n# Identify out-of-scope assets\n# Create exclusion list for scanning\ncat > exclude_targets.txt << EOF\nout-of-scope.example.com\nadmin.example.com\nproduction-db.example.com\nEOF\n\n# Define testing windows\n# Avoid peak business hours\n# Schedule scans during off-hours when permitted\n```\n\nRate Limiting and Responsible Scanning:\n```bash\n# Implement intelligent rate limiting\n# Start slow, monitor for blocking\nnmap --scan-delay 1s --max-rate 10 example.com\n\n# Use residential proxies for large scans\n# Rotate IP addresses to avoid blocking\nproxychains nmap -sS -p 80,443 --script http-headers example.com\n\n# Monitor for WAF blocking\n# Check response times and block indicators\ncurl -w \"%{time_total}\" -s -o /dev/null https://example.com\n```\n\n2. Advanced Port Scanning Techniques:\n\nComprehensive Port Discovery:\n```bash\n# Full port scan with service detection\nnmap -sS -p- --min-rate 1000 --max-rate 2000 -T4 example.com -oA full_scan\n\n# UDP port scanning (careful with rate limits)\nnmap -sU --top-ports 100 -T3 example.com\n\n# Service version detection\nnmap -sV -p 80,443,8080,8443 example.com --version-intensity 5\n\n# Script scanning for vulnerabilities\nnmap -sC -p 80,443 example.com --script vuln\n\n# IPv6 scanning if applicable\nnmap -6 -sS example.com\n```\n\nStealth Scanning Techniques:\n```bash\n# Zombie scanning for anonymity\nnmap -sI zombie.example.com target.example.com\n\n# Decoy scanning to obscure source\nnmap -D decoy1,decoy2,decoy3 target.example.com\n\n# Fragmented packets to evade IDS\nnmap -f -sS target.example.com\n\n# Timing adjustments for stealth\nnmap -T2 --scan-delay 5s target.example.com\n```\n\n3. Web Application Scanning:\n\nComprehensive Web Recon:\n```bash\n# Directory and file enumeration\nffuf -u https://example.com/FUZZ -w /path/to/wordlist.txt -mc 200,301,302,403 -o directories.txt\n\ngobuster dir -u https://example.com -w /usr/share/wordlists/dirb/common.txt -o gobuster_dirs.txt\n\ndirsearch -u https://example.com -o dirsearch_results.txt\n\n# Virtual host discovery\nffuf -u https://FUZZ.example.com -w subdomains.txt -mc 200\n\ngobuster vhost -u https://example.com -w subdomains.txt\n```\n\nTechnology Stack Fingerprinting:\n```bash\n# Advanced technology detection\nwhatweb -a 3 https://example.com\n\nwappalyzer https://example.com --pretty\n\n# Server header analysis\ncurl -I https://example.com | grep -E \"(Server|X-Powered-By|X-AspNet|X-Framework)\"\n\n# Cookie analysis for framework detection\ncurl -I https://example.com | grep \"Set-Cookie\" | grep -E \"(PHPSESSID|JSESSIONID|ASP.NET)\"\n\n# Framework-specific scanning\n# WordPress\nwpscan --url https://example.com --enumerate vp,t,tt,u --api-token YOUR_TOKEN\n\n# Drupal\ndroopescan scan drupal -u https://example.com\n\n# Joomla\njoomlavs -u https://example.com\n```\n\n4. API Discovery and Testing:\n\nREST API Enumeration:\n```bash\n# Common API endpoint discovery\nfor endpoint in api v1 v2 v3 rest graphql swagger openapi docs; do\n    curl -s -w \"%{http_code}\" -o /dev/null https://example.com/$endpoint\n    echo \" - $endpoint: $status\"\ndone\n\n# API documentation discovery\ncurl -s https://example.com/swagger.json | jq '.paths | keys[]'\ncurl -s https://example.com/api-docs | grep -oE '\"/[^\"]*\"' | sed 's/\"//g'\n\n# GraphQL endpoint testing\ncurl -X POST https://example.com/graphql \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"query\": \"{__schema{types{name}}}\"}'\n```\n\nAPI Parameter Discovery:\n```bash\n# Parameter fuzzing\narjun -u https://example.com/api/users -m GET\n\n# Content-type testing\nfor ct in \"application/json\" \"application/xml\" \"text/plain\"; do\n    curl -X POST https://example.com/api/test \\\n      -H \"Content-Type: $ct\" \\\n      -d '{\"test\": \"data\"}'\ndone\n\n# HTTP method testing\nfor method in GET POST PUT DELETE PATCH OPTIONS; do\n    curl -X $method -s -w \"%{http_code}\" -o /dev/null https://example.com/api/users\n    echo \" $method: $status\"\ndone\n```\n\n5. Vulnerability Scanning Challenges:\n\nBug Bounty Scanning Constraints:\n```text\n# Rate limiting issues\n# Many programs limit requests per minute\n# Use --delay or --rate-limit flags\n\n# WAF/IDS evasion\n# Programs often have web application firewalls\n# Use techniques that don't trigger signatures\n\n# False positive management\n# Automated scanners generate many false positives\n# Manual verification required for all findings\n\n# Scope compliance\n# Ensure scanning stays within program boundaries\n# Double-check exclusions and inclusions\n```\n\nTargeted Vulnerability Scanning:\n```bash\n# Nuclei for template-based scanning\nnuclei -u https://example.com -t /path/to/templates/ -o nuclei_results.txt\n\n# Custom vulnerability checks\n# Write specific tests for known issues\ncat > custom_checks.py << 'EOF'\nimport requests\n\ndef check_sql_injection(url, params):\n    payloads = [\"' OR '1'='1 --\", \"' UNION SELECT 1 --\"]\n    for payload in params:\n        for injection in payloads:\n            test_params = {payload: injection}\n            try:\n                response = requests.get(url, params=test_params, timeout=5)\n                if \"sql\" in response.text.lower() or \"syntax\" in response.text.lower():\n                    return True\n            except:\n                pass\n    return False\n\n# Usage\nif check_sql_injection(\"https://example.com/search\", [\"q\", \"query\"]):\n    print(\"Potential SQL injection found\")\nEOF\n```\n\n6. Network Infrastructure Mapping:\n\nInternal Network Discovery:\n```bash\n# Cloud asset discovery\n# AWS S3 bucket enumeration\nfor bucket in $(cat potential_buckets.txt); do\n    aws s3 ls s3://$bucket --no-sign-request 2>/dev/null && echo \"Open bucket: $bucket\"\ndone\n\n# Azure storage enumeration\nfor account in $(cat potential_accounts.txt); do\n    curl -I https://$account.blob.core.windows.net/ 2>/dev/null | grep \"x-ms-error-code\"\ndone\n\n# GCP bucket discovery\nfor bucket in $(cat potential_buckets.txt); do\n    curl -I https://storage.googleapis.com/$bucket/ 2>/dev/null\n    if [ $? -eq 0 ]; then echo \"GCP bucket: $bucket\"; fi\ndone\n```\n\nCDN and WAF Detection:\n```bash\n# CDN identification\ncurl -s https://example.com | grep -iE \"(cloudflare|akamai|fastly|cloudfront)\"\n\n# WAF fingerprinting\nwafw00f https://example.com\n\n# Header analysis for protection layers\ncurl -I https://example.com | grep -E \"(CF-RAY|X-Sucuri|X-WAF|Mod_Security)\"\n```\n\n7. Mobile Application Testing Setup:\n\nMobile App Reconnaissance:\n```bash\n# Download app from stores\n# Use apkpure, apkmirror, or direct store links\n\n# Static analysis setup\n# Install JADX, MobSF, or similar tools\njadx -d decompiled_app app.apk\n\n# Dynamic analysis preparation\n# Set up Frida, objection for runtime analysis\n# Configure proxy for traffic interception\n\n# Certificate pinning bypass\n# Prepare for common pinning implementations\n```\n\n8. Scanning Result Analysis:\n\nFinding Prioritization:\n```bash\n# Categorize findings by severity\n# Critical: RCE, authentication bypass\n# High: SQL injection, IDOR\n# Medium: XSS, CSRF\n# Low: Information disclosure, misconfigurations\n\n# False positive elimination\n# Manually verify each finding\n# Test in isolated environment when possible\n\n# Impact assessment\n# Determine real-world exploitability\n# Consider business context and user impact\n```\n\nWHAT TO LOOK FOR:\n- **Service Misconfigurations**: Open ports, default credentials, exposed services\n- **Web Application Vulnerabilities**: Injection flaws, broken authentication, XSS\n- **API Weaknesses**: Missing authentication, parameter tampering, rate limit bypass\n- **Infrastructure Issues**: Exposed databases, misconfigured cloud storage, weak network segmentation\n- **Technology-Specific Flaws**: Framework vulnerabilities, outdated software, known CVEs\n- **Business Logic Issues**: Workflow bypasses, resource manipulation, privilege escalation\n\nSECURITY IMPLICATIONS:\n- **Detection Risk**: Active scanning can trigger alerts and blocking\n- **Service Disruption**: Aggressive scanning may cause DoS conditions\n- **Legal Boundaries**: Must stay within program scope and rules\n- **Resource Consumption**: Scanning requires significant bandwidth and time\n- **False Security**: Clean scans don't guarantee security\n\nCOMMON PITFALLS:\n- **Overly Aggressive Scanning**: Triggers WAF blocks or service disruption\n- **Scope Violations**: Scanning out-of-bounds assets\n- **Ignoring Rate Limits**: Gets IP addresses banned\n- **False Positive Flood**: Automated tools generate noise without validation\n- **Missing Manual Testing**: Relying solely on automated scans\n- **Peak Hour Scanning**: Disrupting production during business hours\n- **Noisy Tools**: Using tools that leave obvious signatures\n- **Incomplete Coverage**: Missing mobile apps, APIs, or cloud assets\n\nTOOLS REFERENCE:\n- **Nmap**: https://nmap.org/ (Comprehensive port scanning)\n- **FFUF**: https://github.com/ffuf/ffuf/ (Web fuzzing)\n- **Gobuster**: https://github.com/OJ/gobuster (Directory enumeration)\n- **Dirsearch**: https://github.com/maurosoria/dirsearch (Web content discovery)\n- **Nuclei**: https://github.com/projectdiscovery/nuclei (Vulnerability scanning)\n- **WhatWeb**: https://github.com/urbanadventurer/WhatWeb (Web technology fingerprinting)\n- **Wappalyzer**: https://github.com/wappalyzer/wappalyzer (Technology detection)\n- **Arjun**: https://github.com/s0md3v/Arjun (Parameter discovery)\n- **Wafw00f**: https://github.com/EnableSecurity/wafw00f (WAF detection)\n\nFURTHER READING:\n- Nmap Network Scanning: https://nmap.org/book/\n- Web Application Testing: https://owasp.org/www-project-web-security-testing-guide/\n- Bug Bounty Scanning: https://www.bugcrowd.com/blog/bug-bounty-scanning-guide/\n- Responsible Scanning: https://www.hackerone.com/blog/responsible-vulnerability-scanning\n- API Testing: https://apisecurity.io/encyclopedia/content/api-security-testing/\n- Mobile App Testing: https://owasp.org/www-project-mobile-app-security/",
      "tags": [
        "bugbounty",
        "active-reconnaissance",
        "scanning",
        "vulnerability-discovery",
        "port-scanning"
      ],
      "related_tools": [
        "recon-ng",
        "ffuf-api",
        "comparison_sql_testing",
        "burp-api-scanner",
        "graphql-testing"
      ]
    },
    {
      "id": "ai-assisted-bug-hunting",
      "title": "AI-assisted bug hunting",
      "content": "OBJECTIVE: Leverage artificial intelligence and machine learning tools to enhance reconnaissance, vulnerability discovery, and testing efficiency while maintaining human expertise and critical thinking in bug bounty hunting.\n\nACADEMIC BACKGROUND:\nAI integration in cybersecurity is rapidly evolving. \"Redefining Hacking\" discusses AI tools for reconnaissance and vulnerability analysis. Research from MIT shows AI can reduce false positives by 90% and increase discovery speed by 300%. However, AI should augment human analysis, not replace it.\n\nSTEP-BY-STEP PROCESS:\n\n1. AI-Powered Reconnaissance:\n\nIntelligent Subdomain Discovery:\n```bash\n# AI-enhanced subdomain enumeration\n# Use tools that learn from patterns\nsubfinder -d example.com -all -recursive -o ai_subdomains.txt\n\n# Machine learning-based prediction\n# Tools that predict likely subdomains\naltdns -i subdomains.txt -o ai_predictions.txt -w wordlist.txt\n\n# Pattern recognition for naming conventions\n# AI identifies common company subdomain patterns\ndomain_analyzer.py --predict example.com\n```\n\nAutomated Asset Classification:\n```bash\n# AI-powered asset categorization\n# Automatically classify discovered assets by type and priority\nasset_classifier.py --input assets.txt --output classified_assets.json\n\n# Risk scoring for discovered assets\n# ML models predict likelihood of vulnerabilities\nrisk_scorer.py --assets classified_assets.json --model trained_model.pkl\n```\n\n2. Intelligent Vulnerability Scanning:\n\nAI-Driven Vulnerability Detection:\n```bash\n# Machine learning-based scanners\n# Nuclei with AI-enhanced templates\nnuclei -u https://example.com -t ai-templates/ -o ai_scan_results.txt\n\n# Anomaly detection in responses\n# AI identifies unusual HTTP responses\nresponse_analyzer.py --url https://example.com --baseline normal_responses.json\n\n# Pattern recognition for vulnerabilities\n# AI learns from historical vulnerability patterns\nvuln_predictor.py --scan-results nmap_output.xml --predict\n```\n\nContext-Aware Scanning:\n```bash\n# Technology-specific AI scanning\n# AI chooses appropriate tests based on detected tech stack\nintelligent_scanner.py --url https://example.com --tech-stack wordpress --aggressive\n\n# Adaptive scanning based on previous results\n# AI modifies scan parameters based on findings\nadaptive_scanner.py --target example.com --previous-results scan1.json\n```\n\n3. AI-Enhanced Code Analysis:\n\nIntelligent Source Code Review:\n```bash\n# AI-powered code analysis tools\n# Semgrep with ML-enhanced rules\nsemgrep --config auto --lang python src/\n\n# AI code review assistants\n# Tools that suggest vulnerability patterns\ngpt_code_analyzer.py --repo https://github.com/example/repo --focus security\n\n# Automated code pattern recognition\n# ML identifies insecure coding patterns\ncode_pattern_detector.py --source src/ --patterns insecure_patterns.json\n```\n\nStatic Application Security Testing (SAST):\n```bash\n# AI-enhanced SAST tools\n# Deep learning-based vulnerability detection\nsonarcloud_ai.py --project example-project --scan\n\n# Context-aware vulnerability prioritization\n# AI considers code context for severity assessment\ncontext_analyzer.py --findings sonar_results.json --prioritize\n```\n\n4. Natural Language Processing for Intelligence:\n\nDocument and Report Analysis:\n```bash\n# AI-powered document intelligence\n# Extract insights from program policies\ndocument_analyzer.py --pdf policy.pdf --extract scope,rules,rewards\n\n# Automated report quality assessment\n# AI evaluates bug report completeness\nreport_scorer.py --report bug_report.md --score\n\n# Intelligence from security advisories\n# NLP extracts relevant vulnerabilities from CVEs\ncve_analyzer.py --keyword \"example technology\" --relevant\n```\n\nSocial Media Intelligence:\n```bash\n# AI-powered social media analysis\n# Extract technology stack from employee posts\nsocial_analyzer.py --company example --platform linkedin --extract tech-stack\n\n# Sentiment analysis for security discussions\n# Monitor social media for security incident discussions\nsentiment_analyzer.py --query \"example security breach\" --analyze\n```\n\n5. Machine Learning for Pattern Recognition:\n\nBehavioral Analysis:\n```bash\n# AI anomaly detection in application behavior\n# Learn normal patterns, detect deviations\nbehavior_analyzer.py --baseline normal_traffic.pcap --analyze suspicious_traffic.pcap\n\n# User behavior pattern recognition\n# Identify unusual authentication patterns\nauth_analyzer.py --logs auth_logs.json --detect anomalies\n```\n\nPredictive Vulnerability Analysis:\n```bash\n# ML models predict likely vulnerabilities\n# Based on technology stack and historical data\npredictor_model.py --tech-stack \"nginx,php,mysql\" --predict vulnerabilities\n\n# Risk assessment using historical data\n# AI learns from past bounties to predict success\nsuccess_predictor.py --target example.com --historical-data bounties.json\n```\n\n6. AI-Assisted Report Writing:\n\nIntelligent Report Generation:\n```bash\n# AI-enhanced report writing\n# Generate comprehensive reports from findings\nreport_generator_ai.py --findings scan_results.json --template professional --generate\n\n# Automated impact assessment\n# AI analyzes vulnerability impact\nimpact_assessor.py --vulnerability xss --context web-app --assess\n\n# Proof-of-concept automation\n# AI generates safe PoCs for vulnerabilities\npoc_generator.py --vuln sql-injection --target https://example.com/search --safe\n```\n\nReport Quality Enhancement:\n```bash\n# AI proofreading and improvement\n# Enhance technical writing quality\nreport_enhancer.py --input draft_report.md --improve\n\n# Automated CVSS scoring\n# AI calculates accurate severity scores\ncvss_calculator_ai.py --vulnerability-details vuln.json --calculate\n```\n\n7. AI Ethics and Limitations:\n\nResponsible AI Usage:\n```text\n# Human oversight required\n# AI suggestions must be validated by experts\n# Avoid over-reliance on automated tools\n\n# Bias consideration\n# AI models may have training data biases\n# Validate AI findings with manual testing\n\n# Transparency requirements\n# Document AI tools used in methodology\n# Explain AI-assisted decisions in reports\n```\n\nAI Tool Validation:\n```bash\n# Regular accuracy testing\n# Compare AI results with manual analysis\naccuracy_tester.py --ai-results ai_findings.json --manual-results human_findings.json --compare\n\n# False positive reduction\n# Train models on validated data\nmodel_trainer.py --validated-data clean_dataset.json --train\n```\n\n8. Integration with Traditional Tools:\n\nHybrid Analysis Approach:\n```bash\n# Combine AI with traditional scanning\n# Use AI to prioritize traditional tool results\nhybrid_scanner.py --traditional nmap_results.xml --ai-enhance --prioritize\n\n# Workflow optimization\n# AI suggests next testing steps based on findings\nworkflow_optimizer.py --current-findings findings.json --suggest-next\n```\n\nContinuous Learning:\n```bash\n# Model improvement over time\n# Incorporate new findings into training data\nmodel_updater.py --new-findings recent_bounties.json --update-model\n\n# Performance monitoring\n# Track AI tool effectiveness\nperformance_monitor.py --metrics accuracy,speed,false_positives --report\n```\n\nWHAT TO LOOK FOR:\n- **Pattern Recognition**: AI identifies complex vulnerability patterns humans might miss\n- **Efficiency Gains**: Faster scanning and analysis with reduced manual effort\n- **Accuracy Improvements**: Lower false positive rates through machine learning\n- **Predictive Capabilities**: Anticipating vulnerabilities based on patterns\n- **Scalability**: Handling large amounts of data that would overwhelm manual analysis\n- **Consistency**: Standardized analysis across different targets and assessments\n\nSECURITY IMPLICATIONS:\n- **Enhanced Discovery**: AI finds subtle vulnerabilities traditional tools miss\n- **Speed Advantage**: Rapid analysis of large attack surfaces\n- **Consistency**: Reduced human error in repetitive tasks\n- **Scalability**: Handle complex enterprise environments\n- **Predictive Security**: Anticipate future vulnerabilities\n- **Resource Efficiency**: Optimize security testing workflows\n\nCOMMON PITFALLS:\n- **Over-Reliance**: Treating AI as infallible without human validation\n- **Black Box Problem**: Not understanding how AI reaches conclusions\n- **Training Data Bias**: AI reflects biases in training data\n- **False Confidence**: Assuming AI accuracy without verification\n- **Ethical Concerns**: Privacy implications of AI data analysis\n- **Cost Barriers**: Advanced AI tools may be expensive\n- **Skill Gap**: Teams need AI literacy to use tools effectively\n- **Vendor Lock-in**: Dependency on specific AI platforms\n\nTOOLS REFERENCE:\n- **Nuclei**: https://github.com/projectdiscovery/nuclei (AI-enhanced scanning)\n- **Semgrep**: https://semgrep.dev/ (ML-powered code analysis)\n- **SonarQube**: https://www.sonarsource.com/products/sonarqube/ (AI-assisted SAST)\n- **GPT-4**: https://openai.com/gpt-4 (Code analysis and report writing)\n- **Claude**: https://anthropic.com/claude (Security analysis)\n- **GitHub Copilot**: https://github.com/features/copilot (Code vulnerability detection)\n- **Burp Suite AI**: https://portswigger.net/burp (AI-enhanced web scanning)\n- **OpenAI Codex**: https://openai.com/blog/openai-codex/ (Code generation and analysis)\n\nFURTHER READING:\n- AI in Cybersecurity: https://www.mitre.org/research/technology-transfer/open-source/ai-cybersecurity\n- Machine Learning for Vulnerability Discovery: https://arxiv.org/abs/2001.02350\n- AI-Assisted Bug Bounty Hunting: https://www.bugcrowd.com/blog/ai-assisted-bug-bounty-hunting/\n- Responsible AI in Security: https://www.owasp.org/index.php/OWASP_AI_Exchange\n- ML for Security Testing: https://github.com/0xInfection/Awesome-WAF\n- AI Ethics in Cybersecurity: https://www.enisa.europa.eu/publications/artificial-intelligence-cybersecurity",
      "tags": [
        "bugbounty",
        "ai",
        "machine-learning",
        "automation",
        "vulnerability-discovery"
      ],
      "related_tools": [
        "recon-ng",
        "workflow_cloud_security_assessment",
        "eslint-security",
        "retire-js",
        "ml-pipeline-audit"
      ]
    },
    {
      "id": "web-api-enumeration-techniques",
      "title": "Web & API enumeration techniques",
      "content": "OBJECTIVE: Systematically enumerate web applications and APIs to discover endpoints, parameters, and functionality that may contain vulnerabilities, using both passive and active techniques while respecting application constraints.\n\nACADEMIC BACKGROUND:\nWeb and API enumeration is critical for comprehensive testing. \"Redefining Hacking\" emphasizes methodical endpoint discovery. OWASP API Security Top 10 highlights the risks of improper API discovery. Research shows that 60% of API vulnerabilities stem from inadequate enumeration.\n\nSTEP-BY-STEP PROCESS:\n\n1. Comprehensive Endpoint Discovery:\n\nContent Discovery Methodologies:\n```bash\n# Multi-tool endpoint enumeration\n# Combine different tools for comprehensive coverage\n\n# FFUF for fast fuzzing\nffuf -u https://example.com/FUZZ -w /usr/share/wordlists/seclists/Discovery/Web-Content/common.txt -mc 200,301,302,403 -o ffuf_results.json\n\n# Gobuster for directory brute-forcing\ngobuster dir -u https://example.com -w /usr/share/wordlists/dirb/big.txt -x php,html,txt -o gobuster_results.txt\n\n# Dirsearch with extensions\ndirsearch -u https://example.com -e php,asp,aspx,jsp,html,txt,conf,config,bak,backup,swp,old,db,sql,zip,tar.gz,rar,7z,gz,bz2 -o dirsearch_results.txt\n\n# Ferret for file discovery\nferret -u https://example.com -d 2 -w /usr/share/wordlists/seclists/Discovery/Web-Content/big.txt\n```\n\nAdvanced Content Discovery:\n```bash\n# Extension-specific discovery\n# Test different file extensions based on tech stack\nfor ext in php jsp asp aspx html htm txt config conf bak old backup db sql xml json yaml yml; do\n    ffuf -u https://example.com/FUZZ.$ext -w filenames.txt -mc 200,301,302,403\n    echo \"Completed $ext enumeration\"\ndone\n\n# Path recursion testing\n# Discover nested directories\ngobuster dir -u https://example.com -w paths.txt -r -o recursive_results.txt\n\n# Case sensitivity testing\n# Some applications are case-sensitive\nffuf -u https://FUZZexample.com -w words.txt -mc 200  # Test case variations\n```\n\n2. API Documentation and Schema Discovery:\n\nOpenAPI/Swagger Detection:\n```bash\n# Common API documentation locations\napi_paths=(\n    \"swagger.json\" \"swagger.yaml\" \"api-docs\" \"api/swagger.json\"\n    \"swagger/index.html\" \"api/swagger-ui.html\" \"docs/api\"\n    \"openapi.json\" \"openapi.yaml\" \"api/openapi.json\"\n)\n\nfor path in \"${api_paths[@]}\"; do\n    status=$(curl -s -o /dev/null -w \"%{http_code}\" https://example.com/$path)\n    if [ \"$status\" = \"200\" ]; then\n        echo \"Found API docs: https://example.com/$path\"\n        curl -s https://example.com/$path | jq '.paths | keys[]' > api_endpoints.txt\n    fi\ndone\n\n# GraphQL schema discovery\ncurl -X POST https://example.com/graphql \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"query\": \"query { __schema { types { name fields { name } } } }\"}' \\\n  | jq '.data.__schema.types[] | select(.name | contains(\"Query\")) | .fields[].name'\n```\n\nAPI Endpoint Extraction:\n```bash\n# Extract endpoints from documentation\ncurl -s https://example.com/swagger.json | jq -r '.paths | keys[]' > swagger_endpoints.txt\n\n# Parameter discovery from schemas\ncurl -s https://example.com/swagger.json | jq -r '.paths[] | to_entries[] | select(.value.parameters) | .key as $path | .value.parameters[] | \"\\($path): \\(.name)\"'\n\n# Response schema analysis\n# Understand expected data structures\ncurl -s https://example.com/swagger.json | jq '.definitions'\n```\n\n3. Parameter and Input Discovery:\n\nSystematic Parameter Fuzzing:\n```bash\n# Arjun for parameter discovery\narjun -u https://example.com/api/users -m GET,POST,PUT,DELETE\n\n# Parameth for parameter mining\npython3 parameth.py -u https://example.com/page --min 3 --max 10\n\n# Custom parameter lists\n# Test common parameter names\nparam_list=(\n    \"id\" \"user_id\" \"userId\" \"userid\" \"user\" \"username\" \"email\" \"mail\"\n    \"page\" \"limit\" \"offset\" \"sort\" \"order\" \"filter\" \"search\" \"query\"\n    \"api_key\" \"token\" \"auth\" \"session\" \"cookie\" \"debug\" \"test\"\n)\n\nfor param in \"${param_list[@]}\"; do\n    curl -s \"https://example.com/api?${param}=test\" | grep -q \"error\\|invalid\" || echo \"Potential param: $param\"\ndone\n```\n\nHTTP Method Testing:\n```bash\n# Test all HTTP methods on endpoints\nmethods=(GET POST PUT DELETE PATCH OPTIONS HEAD TRACE CONNECT)\nendpoints=(\"/api/users\" \"/api/posts\" \"/admin\" \"/api/config\")\n\nfor endpoint in \"${endpoints[@]}\"; do\n    for method in \"${methods[@]}\"; do\n        status=$(curl -s -X $method -w \"%{http_code}\" -o /dev/null https://example.com$endpoint)\n        if [ \"$status\" != \"405\" ] && [ \"$status\" != \"501\" ]; then\n            echo \"$method $endpoint: $status\"\n        fi\n    done\ndone\n```\n\n4. JavaScript Source Analysis:\n\nClient-Side Endpoint Discovery:\n```bash\n# Download all JavaScript files\nwget -r -l 2 -A \"*.js\" https://example.com/ -P js_files/\n\n# Extract URLs and endpoints from JS\ngrep -rE \"https?://[^\\\"']+\" js_files/ | grep example.com | sort -u > js_endpoints.txt\n\ngrep -rE \"api/\\|endpoint\\|/v[0-9]+/\" js_files/ | sort -u > api_references.txt\n\n# Extract API keys and tokens\ngrep -rE \"(api[_-]?key|apikey|token|secret)\" js_files/ | sort -u > potential_secrets.txt\n\n# LinkFinder for comprehensive JS analysis\npython3 LinkFinder.py -i https://example.com/app.js -o linkfinder_results.html\n```\n\nDynamic JavaScript Analysis:\n```bash\n# Use browser automation for dynamic content\n# Selenium or Puppeteer to interact with SPA\ncat > js_analyzer.py << 'EOF'\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options\n\noptions = Options()\noptions.add_argument(\"--headless\")\ndriver = webdriver.Chrome(options=options)\n\ndriver.get(\"https://example.com\")\n\n# Extract all network requests\nlogs = driver.get_log(\"performance\")\nfor log in logs:\n    if \"Network.requestWillBeSent\" in log[\"message\"]:\n        request = json.loads(log[\"message\"])[\"message\"][\"params\"][\"request\"]\n        if \"example.com\" in request[\"url\"]:\n            print(f\"{request['method']} {request['url']}\")\n\ndriver.quit()\nEOF\n```\n\n5. WebSocket and Real-time Communication:\n\nWebSocket Discovery:\n```bash\n# Check for WebSocket support\ncurl -I https://example.com | grep -i \"upgrade\"\n\n# WebSocket endpoint enumeration\n# Common WebSocket paths\nws_paths=(\n    \"/ws\" \"/websocket\" \"/socket.io\" \"/api/ws\" \"/realtime\"\n)\n\nfor path in \"${ws_paths[@]}\"; do\n    # Test WebSocket connection\n    echo \"Testing ws://example.com$path\"\n    # Use websocat or similar tool\n    timeout 5 websocat \"ws://example.com$path\" <<< 'test' 2>/dev/null && echo \"WebSocket found: $path\"\ndone\n```\n\nReal-time API Testing:\n```bash\n# Socket.IO discovery\ncurl -s https://example.com/socket.io/?EIO=4&transport=polling | jq '.upgrades[]'\n\n# WebRTC endpoint discovery\n# Check for peer-to-peer communication endpoints\ngrep -r \"RTCPeerConnection\\|WebRTC\" js_files/\n```\n\n6. Mobile API Endpoint Discovery:\n\nMobile App API Analysis:\n```bash\n# Decompile mobile app\njadx -d decompiled/ app.apk\n\n# Extract hardcoded URLs\ngrep -rE \"https?://[^\\\"']*example\\.com\" decompiled/ | sort -u > mobile_endpoints.txt\n\n# Extract API keys from mobile apps\ngrep -rE \"(api[_-]?key|apikey|token|secret|password)\" decompiled/ | sort -u > mobile_secrets.txt\n\n# Certificate pinning detection\n# Check for pinning implementation\ngrep -r \"CertificatePinner\\|TrustKit\\|SSLPinning\" decompiled/\n```\n\nMobile Traffic Analysis:\n```bash\n# Intercept mobile app traffic\n# Use mitmproxy or Burp Suite mobile proxy\nmitmproxy --mode transparent --listen-host 0.0.0.0 --listen-port 8080\n\n# Configure mobile device proxy settings\n# IP: your_machine_ip, Port: 8080\n\n# Analyze API calls and endpoints\n# Document all discovered mobile API endpoints\n```\n\n7. API Security Testing:\n\nAuthentication Testing:\n```bash\n# Test authentication mechanisms\n# JWT, OAuth, API keys, Basic auth\n\n# Token format analysis\n# Identify token types and formats\ncurl -H \"Authorization: Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9...\" \\\n  https://api.example.com/users\n\n# Authentication bypass attempts\n# Test common auth bypass techniques\ncurl https://api.example.com/admin/users  # No auth header\ncurl -H \"Authorization: null\" https://api.example.com/admin/users\n```\n\nAuthorization Testing:\n```bash\n# Test IDOR vulnerabilities\n# Access other users' resources\ncurl -H \"Authorization: Bearer $USER_TOKEN\" \\\n  https://api.example.com/users/123  # Your ID\ncurl -H \"Authorization: Bearer $USER_TOKEN\" \\\n  https://api.example.com/users/124  # Someone else's ID\n\n# Mass assignment testing\n# Try to set privileged fields\ncurl -X POST https://api.example.com/users \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -d '{\"name\": \"User\", \"role\": \"admin\", \"is_admin\": true}'\n```\n\n8. Rate Limiting and Abuse Testing:\n\nAPI Limit Testing:\n```bash\n# Test rate limiting\nfor i in {1..100}; do\n    curl -s https://api.example.com/users &\ndone\n\n# Rate limit bypass attempts\n# Try different headers, IPs, tokens\ncurl -H \"X-Forwarded-For: 1.2.3.4\" https://api.example.com/users\ncurl -H \"X-Real-IP: 1.2.3.4\" https://api.example.com/users\n\n# Concurrent request testing\n# Test for race conditions\nab -n 1000 -c 10 https://api.example.com/endpoint\n```\n\nWHAT TO LOOK FOR:\n- **Hidden Endpoints**: Undocumented API endpoints with weaker security\n- **Parameter Manipulation**: Unexpected parameters that change behavior\n- **Authentication Flaws**: Missing auth on sensitive endpoints\n- **Authorization Issues**: IDOR, privilege escalation, mass assignment\n- **Rate Limiting Bypass**: Ways to abuse API limits\n- **WebSocket Vulnerabilities**: Real-time communication security issues\n- **Mobile API Issues**: Different security in mobile vs web APIs\n- **JavaScript Exposures**: Client-side secrets and endpoint leakage\n\nSECURITY IMPLICATIONS:\n- **Expanded Attack Surface**: More endpoints mean more potential vulnerabilities\n- **API Abuse**: Unauthorized access to sensitive functionality\n- **Data Exposure**: Inadequate API security leads to information disclosure\n- **Business Logic Flaws**: API-specific logic vulnerabilities\n- **Authentication Bypass**: Weak API authentication mechanisms\n- **Rate Limit Abuse**: DoS and resource exhaustion attacks\n\nCOMMON PITFALLS:\n- **Incomplete Discovery**: Missing mobile apps or JavaScript analysis\n- **Overly Aggressive Testing**: Triggering rate limits or blocking\n- **Ignoring Mobile APIs**: Different endpoints and security in mobile apps\n- **Missing WebSockets**: Real-time communication vulnerabilities\n- **Parameter Assumption**: Not testing all possible parameter combinations\n- **Authentication Skipping**: Not testing auth on every endpoint\n- **Rate Limit Ignorance**: Getting blocked during testing\n- **Documentation Reliance**: Only testing documented endpoints\n\nTOOLS REFERENCE:\n- **FFUF**: https://github.com/ffuf/ffuf (Fast web fuzzing)\n- **Gobuster**: https://github.com/OJ/gobuster (Directory enumeration)\n- **Dirsearch**: https://github.com/maurosoria/dirsearch (Content discovery)\n- **Arjun**: https://github.com/s0md3v/Arjun (Parameter discovery)\n- **LinkFinder**: https://github.com/GerbenJavado/LinkFinder (JavaScript analysis)\n- **Ferret**: https://github.com/MontFerret/ferret (Web scraping)\n- **JADX**: https://github.com/skylot/jadx (Android decompilation)\n- **Websocat**: https://github.com/vi/websocat (WebSocket testing)\n- **Mitmproxy**: https://mitmproxy.org/ (Traffic interception)\n\nFURTHER READING:\n- API Security Testing: https://owasp.org/www-project-api-security/\n- Web Application Testing: https://owasp.org/www-project-web-security-testing-guide/\n- Mobile API Security: https://owasp.org/www-project-mobile-app-security/\n- JavaScript Security: https://owasp.org/www-pdf-archive/OWASP_JavaScript_Security.pdf\n- GraphQL Security: https://blog.apollographql.com/securing-your-graphql-api-1614ad3dacea\n- WebSocket Security: https://tools.ietf.org/html/rfc6455\n- REST API Security: https://restfulapi.net/security-essentials/",
      "tags": [
        "bugbounty",
        "web-enumeration",
        "api-discovery",
        "endpoint-analysis",
        "javascript-analysis"
      ],
      "related_tools": [
        "ffuf-api",
        "hunter-io",
        "burp-api-scanner",
        "graphql-testing",
        "ml-pipeline-audit"
      ]
    }
  ]
}