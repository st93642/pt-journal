{
  "id": "soc_incident_response_workflow",
  "title": "SOC Incident Response & Case Management",
  "description": "Comprehensive guide to SOC incident response workflows covering TheHive, MISP, Cortex analyzers, playbook automation, and case management best practices.",
  "type": "tutorial",
  "steps": [
    {
      "id": "soc_workflow_overview",
      "title": "SOC Operations & Incident Response Framework",
      "content": "## Security Operations Center Framework\n\nA SOC provides 24/7 security monitoring, detection, and response capabilities using people, processes, and technology.\n\n### SOC Functions\n\n**Core Functions:**\n- **Monitoring** - Real-time security event monitoring\n- **Detection** - Identify threats and anomalies\n- **Analysis** - Investigate and triage alerts\n- **Response** - Contain and remediate incidents\n- **Reporting** - Document and communicate findings\n\n### SOC Tiers\n\n| Tier | Role | Responsibilities |\n|------|------|------------------|\n| L1 | Analyst | Alert triage, initial investigation |\n| L2 | Senior Analyst | Deep investigation, threat hunting |\n| L3 | Expert | Advanced analysis, malware RE, forensics |\n| L4 | Manager | Team leadership, process improvement |\n\n### Incident Response Lifecycle (NIST)\n\n```\n┌─────────────┐     ┌─────────────┐     ┌─────────────┐     ┌─────────────┐\n│ Preparation │ ──→ │ Detection & │ ──→ │ Containment │ ──→ │  Recovery   │\n│             │     │  Analysis   │     │ Eradication │     │             │\n└─────────────┘     └─────────────┘     └─────────────┘     └─────────────┘\n       ↑                                                            │\n       └──────────────── Post-Incident Activity ←───────────────────┘\n```\n\n### SOC Technology Stack\n\n**Detection Layer:**\n- SIEM (Splunk, Elastic, QRadar)\n- EDR (CrowdStrike, Carbon Black, Defender)\n- NDR (Zeek, Suricata, Darktrace)\n- Cloud Security (Prisma, GuardDuty)\n\n**Response Layer:**\n- SOAR (Splunk SOAR, Cortex XSOAR, Swimlane)\n- Case Management (TheHive, ServiceNow)\n- Threat Intel (MISP, OpenCTI, ThreatConnect)\n\n**Analysis Layer:**\n- Sandboxes (Cuckoo, Joe Sandbox, ANY.RUN)\n- Forensics (Volatility, Autopsy, KAPE)\n- Malware Analysis (Ghidra, IDA Pro)\n\n### Key Metrics\n\n| Metric | Description | Target |\n|--------|-------------|--------|\n| MTTD | Mean Time to Detect | < 1 hour |\n| MTTR | Mean Time to Respond | < 4 hours |\n| MTTC | Mean Time to Contain | < 24 hours |\n| Alert Volume | Daily alerts processed | Varies |\n| False Positive Rate | FP / Total Alerts | < 30% |\n| Escalation Rate | L1 → L2 escalations | 10-20% |\n\n### Alert Triage Process\n\n1. **Receive Alert** - SIEM generates alert\n2. **Initial Assessment** - Review alert details\n3. **Contextualize** - Gather additional information\n4. **Classify** - True positive, false positive, or benign\n5. **Escalate or Close** - Based on classification\n6. **Document** - Record findings and actions",
      "tags": ["soc", "incident-response", "framework"],
      "related_tools": ["sigma"]
    },
    {
      "id": "thehive_case_management",
      "title": "TheHive - Security Incident Response Platform",
      "content": "## TheHive Overview\n\nTheHive is an open-source, scalable Security Incident Response Platform designed for SOCs.\n\n### Architecture\n\n```\n[TheHive] ←───→ [Cortex (Analyzers/Responders)]\n    ↓                        ↓\n[Elasticsearch]        [Analyzers]\n    ↓                   - VirusTotal\n[Cases/Alerts]         - Shodan\n                       - MISP\n                       - Abuse.ch\n```\n\n### Installation (Docker)\n\n```yaml\n# docker-compose.yml\nversion: '3'\nservices:\n  elasticsearch:\n    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n    environment:\n      - discovery.type=single-node\n      - xpack.security.enabled=false\n    volumes:\n      - es_data:/usr/share/elasticsearch/data\n\n  thehive:\n    image: strangebee/thehive:5.2\n    depends_on:\n      - elasticsearch\n    ports:\n      - \"9000:9000\"\n    environment:\n      - TH_DB_ES_HOSTS=elasticsearch:9200\n    volumes:\n      - thehive_data:/data\n\n  cortex:\n    image: thehiveproject/cortex:3.1.7\n    depends_on:\n      - elasticsearch\n    ports:\n      - \"9001:9001\"\n    environment:\n      - job_directory=/tmp/cortex-jobs\n\nvolumes:\n  es_data:\n  thehive_data:\n```\n\n### Case Management\n\n**Creating a Case:**\n```json\n{\n  \"title\": \"Phishing Attack - Executive Targeted\",\n  \"description\": \"Spear phishing email targeting CFO\",\n  \"severity\": 3,\n  \"tlp\": 2,\n  \"pap\": 2,\n  \"tags\": [\"phishing\", \"spear-phishing\", \"executive\"],\n  \"tasks\": [\n    { \"title\": \"Analyze email headers\", \"status\": \"Waiting\" },\n    { \"title\": \"Check sender reputation\", \"status\": \"Waiting\" },\n    { \"title\": \"Scan attachments\", \"status\": \"Waiting\" }\n  ]\n}\n```\n\n**TLP (Traffic Light Protocol):**\n- **TLP:RED (4)** - Named recipients only\n- **TLP:AMBER (3)** - Organization only\n- **TLP:GREEN (2)** - Community sharing\n- **TLP:WHITE (1)** - Public sharing\n\n### Observables\n\nAdd indicators to cases:\n\n```python\n# Python API - Add observable\nfrom thehive4py.api import TheHiveApi\nfrom thehive4py.models import CaseObservable\n\napi = TheHiveApi('http://thehive:9000', 'api_key')\n\nobservable = CaseObservable(\n    dataType='ip',\n    data='192.168.1.100',\n    tlp=2,\n    ioc=True,\n    sighted=True,\n    tags=['malicious', 'c2']\n)\n\napi.create_case_observable(case_id, observable)\n```\n\n### TheHive API Examples\n\n```bash\n# Create case\ncurl -XPOST 'http://thehive:9000/api/case' \\\n  -H 'Authorization: Bearer <api_key>' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"title\": \"Malware Infection\",\n    \"description\": \"Detected malware on WORKSTATION01\",\n    \"severity\": 2\n  }'\n\n# Add alert\ncurl -XPOST 'http://thehive:9000/api/alert' \\\n  -H 'Authorization: Bearer <api_key>' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"title\": \"SIEM Alert - Brute Force\",\n    \"type\": \"siem\",\n    \"source\": \"Splunk\",\n    \"sourceRef\": \"alert-123\",\n    \"severity\": 2\n  }'\n\n# Merge alerts to case\ncurl -XPOST 'http://thehive:9000/api/alert/<alert_id>/merge/<case_id>' \\\n  -H 'Authorization: Bearer <api_key>'\n```\n\n### Integration with SIEM\n\n**Splunk → TheHive:**\n```python\n# Splunk alert action - Create TheHive case\nimport json\nfrom thehive4py.api import TheHiveApi\nfrom thehive4py.models import Alert\n\ndef create_thehive_alert(results):\n    api = TheHiveApi(THEHIVE_URL, THEHIVE_API_KEY)\n    \n    for result in results:\n        alert = Alert(\n            title=result['rule_name'],\n            description=result['description'],\n            type='siem',\n            source='Splunk',\n            sourceRef=result['sid'],\n            artifacts=[\n                {'dataType': 'ip', 'data': result['src_ip']},\n                {'dataType': 'ip', 'data': result['dest_ip']}\n            ]\n        )\n        api.create_alert(alert)\n```\n\n### Case Workflow\n\n```\n[Alert Created] → [Analyst Assignment] → [Investigation]\n       ↓                   ↓                    ↓\n[Cortex Analysis]   [Observable Enrichment]  [Tasks Execution]\n       ↓                   ↓                    ↓\n[IOC Extraction] → [MISP Export] → [Case Closure]\n```",
      "tags": ["soc", "thehive", "case-management", "incident-response"],
      "related_tools": ["sigma"]
    },
    {
      "id": "misp_threat_intel",
      "title": "MISP - Malware Information Sharing Platform",
      "content": "## MISP Overview\n\nMISP is an open-source threat intelligence platform for sharing, storing, and correlating Indicators of Compromise (IOCs).\n\n### Core Features\n\n- **IOC Storage** - Structured threat data repository\n- **Correlation** - Automatic indicator correlation\n- **Sharing** - Inter-organization threat sharing\n- **Automation** - API for SIEM/SOAR integration\n- **Taxonomies** - Standardized classification\n- **Galaxies** - Threat actor and malware clusters\n\n### Installation (Docker)\n\n```bash\n# Clone MISP Docker repository\ngit clone https://github.com/MISP/misp-docker.git\ncd misp-docker\n\n# Configure environment\ncp template.env .env\nvim .env  # Set passwords\n\n# Start MISP\ndocker-compose up -d\n```\n\n### MISP Data Model\n\n```\nOrganization\n    └── Event (Container for attributes)\n          ├── Attributes (IOCs)\n          │     ├── ip-src: 192.168.1.100\n          │     ├── domain: malicious.com\n          │     ├── md5: abc123...\n          │     └── url: http://malicious.com/payload\n          ├── Objects (Grouped attributes)\n          │     └── file (name, hash, size)\n          ├── Tags\n          │     ├── TLP:AMBER\n          │     └── misp-galaxy:threat-actor\n          └── Galaxy Clusters\n                └── APT28\n```\n\n### Attribute Types\n\n| Type | Description | Example |\n|------|-------------|---------|\n| ip-src | Source IP | 192.168.1.100 |\n| ip-dst | Destination IP | 10.0.0.50 |\n| domain | Domain name | malicious.com |\n| hostname | Hostname | server.malicious.com |\n| md5 | MD5 hash | d41d8cd98f00b204... |\n| sha256 | SHA256 hash | e3b0c44298fc1c14... |\n| url | Full URL | http://mal.com/payload |\n| email-src | Email sender | attacker@evil.com |\n| filename | File name | malware.exe |\n\n### MISP API Usage\n\n**Python (PyMISP):**\n```python\nfrom pymisp import PyMISP, MISPEvent, MISPAttribute\n\n# Initialize\nmisp = PyMISP(MISP_URL, MISP_API_KEY, ssl=False)\n\n# Create event\nevent = MISPEvent()\nevent.info = 'Phishing Campaign - Banking Malware'\nevent.distribution = 1  # Community\nevent.threat_level_id = 2  # Medium\nevent.analysis = 2  # Completed\n\n# Add attributes\nevent.add_attribute('ip-dst', '192.168.1.100', comment='C2 Server')\nevent.add_attribute('domain', 'malicious-bank.com', comment='Phishing domain')\nevent.add_attribute('md5', 'abc123def456...', comment='Malware hash')\n\n# Push to MISP\nresult = misp.add_event(event)\n```\n\n**Search for IOCs:**\n```python\n# Search by attribute value\nresults = misp.search(value='malicious.com', type_attribute='domain')\n\n# Search by tag\nresults = misp.search(tags='tlp:red')\n\n# Search by date\nresults = misp.search(date_from='2024-01-01', date_to='2024-01-31')\n\n# Export as STIX\nstix_data = misp.search(return_format='stix2', eventid=123)\n```\n\n### Feeds Configuration\n\nEnable threat intelligence feeds:\n\n```json\n{\n  \"Feed\": {\n    \"name\": \"Abuse.ch URLhaus\",\n    \"provider\": \"abuse.ch\",\n    \"url\": \"https://urlhaus.abuse.ch/downloads/csv/\",\n    \"source_format\": \"csv\",\n    \"enabled\": true,\n    \"caching_enabled\": true\n  }\n}\n```\n\n**Popular Feeds:**\n- URLhaus (Malicious URLs)\n- Feodo Tracker (Banking Trojans)\n- SSL Blacklist (Malicious SSL certs)\n- PhishTank (Phishing URLs)\n- Blocklist.de (Attack sources)\n\n### MISP → SIEM Integration\n\n**Export to Splunk:**\n```python\n# Export IOCs for Splunk lookup\nimport csv\n\niocs = misp.search(tags='tlp:green', to_ids=True)\n\nwith open('misp_iocs.csv', 'w') as f:\n    writer = csv.writer(f)\n    writer.writerow(['type', 'value', 'comment'])\n    for event in iocs:\n        for attr in event['Event']['Attribute']:\n            writer.writerow([attr['type'], attr['value'], attr['comment']])\n```\n\n**Splunk Lookup:**\n```spl\nindex=firewall\n| lookup misp_iocs.csv value as dest_ip OUTPUT type, comment\n| where isnotnull(type)\n```\n\n### TheHive ↔ MISP Integration\n\n```python\n# Export case observables to MISP\nfrom thehive4py.api import TheHiveApi\nfrom pymisp import PyMISP, MISPEvent\n\nthehive = TheHiveApi(THEHIVE_URL, THEHIVE_KEY)\nmisp = PyMISP(MISP_URL, MISP_KEY)\n\n# Get case observables\ncase = thehive.get_case(case_id)\nobservables = thehive.get_case_observables(case_id)\n\n# Create MISP event\nevent = MISPEvent()\nevent.info = f\"TheHive Case: {case['title']}\"\n\nfor obs in observables:\n    if obs['ioc']:\n        event.add_attribute(obs['dataType'], obs['data'])\n\nmisp.add_event(event)\n```",
      "tags": ["soc", "misp", "threat-intelligence", "ioc"],
      "related_tools": ["sigma"]
    },
    {
      "id": "cortex_analyzers",
      "title": "Cortex Analyzers & Responders",
      "content": "## Cortex - Powerful Observable Analysis\n\nCortex is a companion product to TheHive that provides automated analysis of observables using analyzers and automated response via responders.\n\n### Architecture\n\n```\n[TheHive] ←──API──→ [Cortex]\n                        │\n            ┌───────────┼───────────┐\n            ↓           ↓           ↓\n      [Analyzers]  [Responders]  [Neurons]\n            │           │\n      ┌─────┴─────┐     └──────────┐\n      ↓     ↓     ↓                ↓\n  VirusTotal  MISP  Shodan    Block IP  Disable User\n```\n\n### Installation\n\n```yaml\n# docker-compose.yml (with TheHive)\ncortex:\n  image: thehiveproject/cortex:3.1.7\n  ports:\n    - \"9001:9001\"\n  environment:\n    - job_directory=/tmp/cortex-jobs\n  volumes:\n    - cortex_data:/var/run/docker.sock\n    - /var/run/docker.sock:/var/run/docker.sock\n```\n\n### Popular Analyzers\n\n| Analyzer | Type | Function |\n|----------|------|----------|\n| VirusTotal_GetReport | Hash/URL/IP | Malware reputation |\n| MISP_Search | All | Search MISP instances |\n| Shodan_Host | IP | Service enumeration |\n| AbuseIPDB | IP | Abuse reports |\n| OTXQuery | IP/Domain/Hash | AlienVault OTX lookup |\n| MaxMind_GeoIP | IP | Geolocation |\n| Yara | File | YARA rule matching |\n| CuckooSandbox | File | Dynamic malware analysis |\n| Cortex_MITRE | Any | MITRE ATT&CK mapping |\n\n### Configuring Analyzers\n\n```json\n// Cortex application.conf\nanalyzer {\n  config {\n    VirusTotal {\n      key = \"your-vt-api-key\"\n    }\n    Shodan {\n      key = \"your-shodan-api-key\"\n    }\n    MISP {\n      url = \"https://misp.example.com\"\n      key = \"misp-api-key\"\n      cert_check = false\n    }\n  }\n}\n```\n\n### Running Analyzers via API\n\n```python\nfrom cortex4py.api import Api\n\napi = Api('http://cortex:9001', 'api_key')\n\n# Run VirusTotal on hash\njob = api.analyzers.run_by_name(\n    'VirusTotal_GetReport_3_1',\n    {\n        'data': 'd41d8cd98f00b204e9800998ecf8427e',\n        'dataType': 'hash',\n        'tlp': 2\n    },\n    force=True\n)\n\n# Wait for result\nimport time\nwhile job.status not in ['Success', 'Failure']:\n    time.sleep(5)\n    job = api.jobs.get_by_id(job.id)\n\n# Get report\nreport = api.jobs.get_report(job.id)\nprint(report.report)\n```\n\n### Responders\n\nAutomate response actions:\n\n| Responder | Action |\n|-----------|--------|\n| Mailer | Send email notification |\n| Redmine | Create ticket |\n| Umbrella | Block domain |\n| AMPforEndpoints | Isolate endpoint |\n| Velociraptor | Collect forensic data |\n| Wazuh | Add IP to blocklist |\n\n### Custom Analyzer\n\n```python\n#!/usr/bin/env python3\n# custom_analyzer.py\n\nfrom cortexutils.analyzer import Analyzer\n\nclass CustomAnalyzer(Analyzer):\n    def __init__(self):\n        Analyzer.__init__(self)\n        self.api_key = self.get_param('config.api_key', None)\n    \n    def run(self):\n        data = self.get_data()\n        data_type = self.data_type\n        \n        # Your analysis logic here\n        result = self.analyze(data)\n        \n        self.report({\n            'summary': {'taxonomies': self.build_taxonomy(result)},\n            'full': result\n        })\n    \n    def build_taxonomy(self, result):\n        return [{\n            'level': 'malicious' if result['malicious'] else 'safe',\n            'namespace': 'Custom',\n            'predicate': 'Analysis',\n            'value': result['score']\n        }]\n\nif __name__ == '__main__':\n    CustomAnalyzer().run()\n```\n\n### Analyzer Chain Automation\n\n```python\n# Run multiple analyzers on observable\ndef analyze_observable(cortex_api, observable):\n    analyzers = [\n        'VirusTotal_GetReport_3_1',\n        'MISP_2_1',\n        'Shodan_Host_2_0',\n        'AbuseIPDB_1_0'\n    ]\n    \n    jobs = []\n    for analyzer in analyzers:\n        try:\n            job = cortex_api.analyzers.run_by_name(\n                analyzer,\n                {\n                    'data': observable['data'],\n                    'dataType': observable['dataType'],\n                    'tlp': 2\n                }\n            )\n            jobs.append(job)\n        except Exception as e:\n            print(f\"Failed to run {analyzer}: {e}\")\n    \n    return jobs\n```\n\n### Integration Flow\n\n```\n[Alert in SIEM]\n       ↓\n[Create TheHive Alert]\n       ↓\n[Add Observables]\n       ↓\n[Auto-run Cortex Analyzers]\n       ↓\n[Enriched Observable Data]\n       ↓\n[Analyst Decision]\n       ↓\n[Run Responders if Malicious]\n```",
      "tags": ["soc", "cortex", "analyzers", "automation"],
      "related_tools": ["sigma"]
    },
    {
      "id": "soar_playbooks",
      "title": "SOAR & Playbook Automation",
      "content": "## Security Orchestration, Automation, and Response\n\nSOAR platforms automate repetitive SOC tasks and orchestrate response across security tools.\n\n### SOAR Benefits\n\n- **Reduce MTTR** - Faster response through automation\n- **Consistency** - Standard response procedures\n- **Scalability** - Handle more alerts with same team\n- **Documentation** - Automatic audit trails\n- **Integration** - Connect disparate security tools\n\n### Playbook Types\n\n**Triage Playbooks:**\n- Alert enrichment\n- IOC lookup\n- Context gathering\n- Classification\n\n**Response Playbooks:**\n- Account disable\n- Host isolation\n- IP blocking\n- Email quarantine\n\n**Hunting Playbooks:**\n- Scheduled threat hunts\n- IOC sweeping\n- Behavioral analysis\n\n### Example Playbook: Phishing Response\n\n```yaml\nname: Phishing Email Response\ntrigger: alert.type == 'phishing'\n\nsteps:\n  - name: extract_indicators\n    action: email.parse\n    inputs:\n      email_id: \"{{ alert.source_ref }}\"\n    outputs:\n      - sender_email\n      - sender_ip\n      - urls\n      - attachments\n\n  - name: check_sender_reputation\n    action: virustotal.check_email\n    inputs:\n      email: \"{{ extract_indicators.sender_email }}\"\n    outputs:\n      - reputation_score\n\n  - name: check_urls\n    action: urlscan.scan\n    inputs:\n      urls: \"{{ extract_indicators.urls }}\"\n    outputs:\n      - url_verdicts\n\n  - name: analyze_attachments\n    action: sandbox.submit\n    inputs:\n      files: \"{{ extract_indicators.attachments }}\"\n    outputs:\n      - malware_results\n\n  - name: decision\n    action: evaluate\n    conditions:\n      - if: \"reputation_score > 80 OR 'malicious' in url_verdicts OR malware_results.malicious\"\n        then: escalate_and_block\n      - else: close_as_fp\n\n  - name: escalate_and_block\n    actions:\n      - action: thehive.create_case\n        inputs:\n          title: \"Confirmed Phishing: {{ alert.title }}\"\n          severity: 3\n      - action: email_gateway.block_sender\n        inputs:\n          sender: \"{{ extract_indicators.sender_email }}\"\n      - action: firewall.block_ip\n        inputs:\n          ip: \"{{ extract_indicators.sender_ip }}\"\n\n  - name: close_as_fp\n    action: alert.close\n    inputs:\n      resolution: false_positive\n      notes: \"Automated analysis found no threats\"\n```\n\n### Automation Candidates\n\n| Task | Automation Potential | Implementation |\n|------|---------------------|----------------|\n| IOC enrichment | High | API lookups |\n| Alert triage | Medium | Rule-based classification |\n| Phishing analysis | High | Email parsing + sandbox |\n| Account lockout | Medium | API + approval workflow |\n| Host isolation | Medium | EDR API + approval |\n| Report generation | High | Template-based |\n\n### n8n SOC Automation Example\n\n```json\n{\n  \"nodes\": [\n    {\n      \"name\": \"Splunk Webhook\",\n      \"type\": \"n8n-nodes-base.webhook\",\n      \"parameters\": {\n        \"path\": \"splunk-alert\",\n        \"httpMethod\": \"POST\"\n      }\n    },\n    {\n      \"name\": \"Enrich with VirusTotal\",\n      \"type\": \"n8n-nodes-base.httpRequest\",\n      \"parameters\": {\n        \"url\": \"https://www.virustotal.com/api/v3/ip_addresses/{{ $json.src_ip }}\",\n        \"headers\": {\n          \"x-apikey\": \"{{ $credentials.virustotal.apiKey }}\"\n        }\n      }\n    },\n    {\n      \"name\": \"Create TheHive Alert\",\n      \"type\": \"n8n-nodes-base.httpRequest\",\n      \"parameters\": {\n        \"method\": \"POST\",\n        \"url\": \"http://thehive:9000/api/alert\",\n        \"body\": {\n          \"title\": \"{{ $json.alert_name }}\",\n          \"source\": \"Splunk\",\n          \"severity\": 2\n        }\n      }\n    }\n  ]\n}\n```\n\n### Metrics for Automation\n\n```python\n# Track automation effectiveness\nmetrics = {\n    'alerts_processed': 1000,\n    'auto_closed': 650,  # 65% automated closure\n    'escalated': 350,\n    'avg_triage_time_manual': '15 min',\n    'avg_triage_time_automated': '30 sec',\n    'time_saved_per_month': '162 hours'\n}\n```\n\n### Playbook Best Practices\n\n1. **Start simple** - Automate one task at a time\n2. **Include human checkpoints** - Don't fully automate high-impact actions\n3. **Log everything** - Maintain audit trail\n4. **Test thoroughly** - Use staging environment\n5. **Monitor metrics** - Track automation effectiveness\n6. **Iterate** - Continuously improve based on feedback\n7. **Document** - Keep playbooks documented and versioned",
      "tags": ["soc", "soar", "playbooks", "automation"],
      "related_tools": ["sigma"]
    },
    {
      "id": "soc_best_practices",
      "title": "SOC Best Practices & Continuous Improvement",
      "content": "## Building an Effective SOC\n\nBest practices for running efficient security operations.\n\n### Alert Management\n\n**Alert Lifecycle:**\n```\n[New] → [Assigned] → [In Progress] → [Resolved/Escalated]\n```\n\n**Alert Classification:**\n- **True Positive** - Confirmed threat\n- **False Positive** - Benign activity triggering alert\n- **Benign True Positive** - Real activity but authorized\n- **True Negative** - No alert, no threat\n\n**Reducing Alert Fatigue:**\n1. Tune detection rules regularly\n2. Implement risk-based alerting\n3. Correlate related alerts\n4. Use suppression for known FPs\n5. Automate repetitive triage\n\n### Documentation Standards\n\n**Case Documentation Template:**\n```markdown\n## Incident Summary\n- **Case ID**: INC-2024-001\n- **Date/Time**: 2024-01-15 14:32 UTC\n- **Severity**: High\n- **Status**: Resolved\n\n## Detection\n- **Alert Source**: Splunk\n- **Rule**: Brute Force Authentication\n- **Initial Indicators**: 500 failed logins from 192.168.1.100\n\n## Investigation\n### Timeline\n- 14:32 - Alert generated\n- 14:35 - Analyst assigned\n- 14:40 - Source IP identified as compromised contractor laptop\n- 14:45 - Account disabled\n- 15:00 - Host isolated\n\n### Findings\n- Compromised credential used from external IP\n- Lateral movement attempted but blocked\n- No data exfiltration detected\n\n## Response Actions\n1. User account disabled\n2. Host isolated from network\n3. Password reset initiated\n4. Forensic image captured\n\n## Lessons Learned\n- MFA should be enforced for all VPN access\n- Contractor access review needed\n```\n\n### Shift Handover\n\n**Handover Checklist:**\n- [ ] Open cases summary\n- [ ] Ongoing incidents status\n- [ ] Pending escalations\n- [ ] System health issues\n- [ ] New threats/IOCs received\n- [ ] Scheduled maintenance\n\n**Handover Template:**\n```markdown\n## Shift Handover: 2024-01-15 Night → Day\n\n### Open Cases\n| Case ID | Severity | Status | Notes |\n|---------|----------|--------|-------|\n| INC-001 | High | In Progress | Awaiting forensics |\n| INC-002 | Medium | Escalated | Pending L2 review |\n\n### Key Events\n- New ransomware variant detected in wild\n- Firewall upgrade scheduled for tonight\n\n### Action Items\n- Follow up on INC-001 forensics\n- Review IOCs from latest threat report\n```\n\n### Continuous Improvement\n\n**Regular Reviews:**\n- **Daily**: Alert queue health\n- **Weekly**: Detection rule effectiveness\n- **Monthly**: SOC metrics review\n- **Quarterly**: Process improvement\n- **Annually**: Full SOC assessment\n\n**Metrics Dashboard:**\n```python\nsoc_metrics = {\n    'operational': {\n        'alerts_processed': 'Daily count',\n        'mttd': 'Mean time to detect',\n        'mttr': 'Mean time to respond',\n        'escalation_rate': 'L1 to L2 %'\n    },\n    'quality': {\n        'false_positive_rate': 'FP / Total',\n        'detection_coverage': 'MITRE coverage %',\n        'rule_effectiveness': 'TP rate by rule'\n    },\n    'team': {\n        'analyst_utilization': 'Work time %',\n        'cases_per_analyst': 'Workload distribution',\n        'training_hours': 'Monthly training'\n    }\n}\n```\n\n### Purple Team Exercises\n\n**Detection Validation:**\n1. Select ATT&CK technique\n2. Execute in controlled environment\n3. Verify detection triggered\n4. Measure detection time\n5. Improve if gaps found\n\n```yaml\n# Purple team exercise template\nexercise:\n  name: \"Credential Dumping Detection\"\n  technique: T1003.001\n  date: 2024-01-15\n  \n  red_team:\n    action: \"Execute Mimikatz sekurlsa::logonpasswords\"\n    target: \"WORKSTATION01\"\n    \n  blue_team:\n    expected_detection: \"LSASS Memory Access Alert\"\n    detection_source: \"Sysmon + Splunk\"\n    \n  results:\n    detected: true\n    detection_time: \"45 seconds\"\n    alert_quality: \"High - included process details\"\n    \n  improvements:\n    - \"Add CommandLine to alert for better context\"\n```\n\n### Training & Development\n\n**Analyst Development Path:**\n1. **L1**: SIEM basics, triage, documentation\n2. **L2**: Deep investigation, threat hunting, scripting\n3. **L3**: Malware analysis, forensics, detection engineering\n4. **Lead**: Team management, process improvement\n\n**Recommended Certifications:**\n- CompTIA Security+\n- CompTIA CySA+\n- GIAC GCIH, GCIA\n- Splunk Certified Analyst\n- Elastic Certified Analyst",
      "tags": ["soc", "best-practices", "metrics", "improvement"],
      "related_tools": ["sigma"]
    }
  ]
}
