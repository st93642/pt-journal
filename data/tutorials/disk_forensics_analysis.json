{
  "id": "disk_forensics_analysis",
  "title": "Disk Forensics Analysis",
  "description": "Comprehensive disk forensics covering acquisition techniques, filesystem analysis, partition structures, and data carving for evidence recovery.",
  "type": "tutorial",
  "steps": [
    {
      "id": "disk_acquisition_fundamentals",
      "title": "Disk Acquisition Fundamentals",
      "content": "OBJECTIVE: Master disk imaging techniques using various tools and understand when to apply different acquisition methods.\n\nACADEMIC BACKGROUND:\nDisk acquisition is the foundation of disk forensics. Creating a forensically sound copy ensures the original evidence remains pristine while enabling thorough analysis. Different scenarios require different acquisition approaches, from simple dead acquisition to complex live imaging of encrypted systems.\n\nACQUISITION FUNDAMENTALS:\n\n1. HARDWARE PREPARATION:\n   ```\n   Pre-Acquisition Checklist:\n   \n   [ ] Destination drive capacity >= source drive\n   [ ] Write blocker tested and verified\n   [ ] Forensic workstation prepared\n   [ ] All cables and adapters available\n   [ ] Documentation forms ready\n   [ ] Hash calculation tools ready\n   \n   Drive Connection Options:\n   | Interface | Write Blocker | Speed | Notes |\n   |-----------|---------------|-------|-------|\n   | SATA | Tableau T35u | Fast | Most common |\n   | USB 3.0 | WiebeTech | Fast | External drives |\n   | IDE | Tableau T8 | Slow | Legacy systems |\n   | NVMe | Tableau T7u | Fastest | Modern SSDs |\n   | PCIe | Adapter needed | Varies | Some M.2 drives |\n   ```\n\n2. DD AND DC3DD IMAGING:\n   ```bash\n   # Basic dd acquisition (use with caution)\n   dd if=/dev/sdb of=/forensics/evidence.dd bs=4M status=progress\n   \n   # DC3DD with built-in hashing (preferred)\n   dc3dd if=/dev/sdb \\\n         hof=/forensics/evidence.dd \\\n         hash=sha256 \\\n         hlog=/forensics/evidence.hash.log \\\n         log=/forensics/acquisition.log \\\n         rec=off \\\n         verb=on\n   \n   # DC3DD with multiple outputs (original + backup)\n   dc3dd if=/dev/sdb \\\n         hof=/forensics/primary/evidence.dd \\\n         hof=/forensics/backup/evidence.dd \\\n         hash=sha256 hash=md5 \\\n         hlog=/forensics/hashes.log\n   \n   # Output interpretation:\n   # rec=off: Don't recover from errors (preserve exact image)\n   # verb=on: Verbose output\n   # hash: Calculate hash during acquisition\n   # hlog: Log file for hash values\n   ```\n\n3. EWF (E01) FORMAT ACQUISITION:\n   ```bash\n   # Using ewfacquire (libewf)\n   ewfacquire /dev/sdb \\\n              -t /forensics/evidence \\\n              -C \"Case-2024-001\" \\\n              -D \"Hard drive from workstation WS-001\" \\\n              -e \"Examiner Name\" \\\n              -E \"Evidence-001\" \\\n              -m physical \\\n              -M logical \\\n              -c deflate:best \\\n              -S 2GiB \\\n              -b 64 \\\n              -g 64 \\\n              -r 2 \\\n              -u\n   \n   # Parameter explanation:\n   # -t: Target file (without extension)\n   # -C: Case number\n   # -D: Description\n   # -e: Examiner name\n   # -E: Evidence number\n   # -m: Media type (physical/logical)\n   # -c: Compression (deflate:best for max compression)\n   # -S: Segment size (2GiB for FAT32 compatibility)\n   # -b: Bytes per sector (usually 64)\n   # -g: Sectors per chunk\n   # -r: Retry count on errors\n   # -u: Unattended mode\n   \n   # Verify E01 image\n   ewfverify /forensics/evidence.E01\n   ```\n\n4. FTK IMAGER (COMMAND LINE):\n   ```bash\n   # FTK Imager CLI (Windows)\n   ftkimager \\\\\\.\\PHYSICALDRIVE1 \\\n             \"E:\\forensics\\evidence\" \\\n             --e01 \\\n             --compress 6 \\\n             --frag 2G \\\n             --verify\n   \n   # Create AD1 (proprietary but includes file-level hashing)\n   ftkimager \\\\\\.\\PHYSICALDRIVE1 \\\n             \"E:\\forensics\\evidence\" \\\n             --ad1 \\\n             --verify\n   ```\n\n5. HANDLING ERRORS:\n   ```bash\n   # ddrescue for damaged drives\n   # First pass: Read good sectors\n   ddrescue -n /dev/sdb /forensics/evidence.dd /forensics/rescue.log\n   \n   # Second pass: Retry bad sectors\n   ddrescue -d -r3 /dev/sdb /forensics/evidence.dd /forensics/rescue.log\n   \n   # Log file interpretation:\n   # Shows exact locations of bad sectors\n   # Allows resuming interrupted acquisition\n   \n   # DC3DD error handling\n   dc3dd if=/dev/sdb \\\n         hof=/forensics/evidence.dd \\\n         hash=sha256 \\\n         nwspc=yes \\\n         log=/forensics/acquisition.log\n   # nwspc=yes: Fill unreadable sectors with zeros\n   ```\n\n6. VERIFICATION PROCEDURES:\n   ```bash\n   # Verify hash matches original\n   sha256sum /dev/sdb\n   # Compare with:\n   sha256sum /forensics/evidence.dd\n   \n   # EWF verification (checks internal hash)\n   ewfverify /forensics/evidence.E01\n   \n   # Expected output:\n   # ewfverify 20171104\n   # ...\n   # MD5 hash stored in file:    a1b2c3d4...\n   # MD5 hash calculated:        a1b2c3d4...\n   # SHA1 hash stored in file:   e5f6a7b8...\n   # SHA1 hash calculated:       e5f6a7b8...\n   # ewfverify: SUCCESS\n   ```\n\nACQUISITION DOCUMENTATION:\n```\nDisk Acquisition Form:\n\nCase Number: 2024-FORENSIC-001\nEvidence ID: IMG-001\nDate/Time Start: 2024-03-15 09:00:00 UTC\nDate/Time End: 2024-03-15 11:30:00 UTC\n\nSource Device:\n  Make/Model: Seagate ST2000DM001\n  Serial: ABC123XYZ\n  Capacity: 2TB (2,000,398,934,016 bytes)\n  Interface: SATA\n\nWrite Blocker:\n  Make/Model: Tableau T35u\n  Serial: WB-78901\n  Verified: YES (test file write failed)\n\nAcquisition Tool:\n  Name: dc3dd\n  Version: 7.2.646\n  Parameters: [as shown above]\n\nOutput:\n  Format: Raw (dd)\n  Location: /forensics/case001/evidence.dd\n  Size: 2,000,398,934,016 bytes\n\nHash Values:\n  Source SHA256: 3a7bd3e2c5e4f6a8b9c0d1e2f3a4b5c6...\n  Image SHA256:  3a7bd3e2c5e4f6a8b9c0d1e2f3a4b5c6...\n  MATCH: YES\n\nExaminer: J. Smith\n```\n\nDETECTION INDICATORS:\n- Hash values match source and destination\n- Complete acquisition log with parameters\n- Write blocker verified before acquisition\n- No errors or documented error handling\n\nCOMMON PITFALLS:\n- Forgetting to verify write blocker\n- Not calculating hash of source first\n- Insufficient destination space\n- Using wrong block size (affects speed)\n- Not documenting acquisition parameters\n\nFURTHER READING:\n- DC3DD documentation\n- libewf documentation\n- NIST Computer Forensics Tool Testing",
      "tags": ["forensics", "disk-imaging", "acquisition", "dd", "ewf", "dfir"],
      "related_tools": ["bulk_extractor", "foremost", "scalpel"]
    },
    {
      "id": "partition_analysis_structures",
      "title": "Partition Analysis and Structures",
      "content": "OBJECTIVE: Understand partition table structures (MBR, GPT) and analyze disk layouts to locate all potential evidence containers.\n\nACADEMIC BACKGROUND:\nPartition tables define how storage is organized on a disk. Understanding these structures is crucial for identifying all data areas, including hidden partitions, unallocated space, and inter-partition gaps. Malicious actors may hide data in areas not visible through normal OS tools.\n\nPARTITION STRUCTURES:\n\n1. MBR (MASTER BOOT RECORD):\n   ```\n   MBR Structure (512 bytes at LBA 0):\n   \n   Offset  Size    Description\n   0x000   446     Boot code\n   0x1BE   16      Partition Entry 1\n   0x1CE   16      Partition Entry 2\n   0x1DE   16      Partition Entry 3\n   0x1EE   16      Partition Entry 4\n   0x1FE   2       Signature (0x55AA)\n   \n   Partition Entry Structure (16 bytes):\n   Offset  Size    Description\n   0x00    1       Boot flag (0x80 = active)\n   0x01    3       CHS start address\n   0x04    1       Partition type\n   0x05    3       CHS end address\n   0x08    4       LBA start address\n   0x0C    4       Number of sectors\n   \n   Common Partition Types:\n   0x00 - Empty\n   0x07 - NTFS/exFAT\n   0x0B - FAT32 (CHS)\n   0x0C - FAT32 (LBA)\n   0x83 - Linux\n   0x82 - Linux Swap\n   0x8E - Linux LVM\n   0x05 - Extended (CHS)\n   0x0F - Extended (LBA)\n   ```\n\n2. GPT (GUID PARTITION TABLE):\n   ```\n   GPT Structure:\n   \n   LBA 0:    Protective MBR\n   LBA 1:    Primary GPT Header\n   LBA 2-33: Partition Entries (128 bytes each)\n   ...       Data partitions\n   LBA -34:  Backup Partition Entries\n   LBA -1:   Backup GPT Header\n   \n   GPT Header Fields:\n   - Signature: \"EFI PART\"\n   - Revision: Usually 1.0\n   - Header Size: 92 bytes\n   - CRC32 of header\n   - Current LBA\n   - Backup LBA\n   - First usable LBA\n   - Last usable LBA\n   - Disk GUID\n   - Partition entries LBA\n   - Number of partition entries\n   - Size of partition entry\n   - CRC32 of partition array\n   \n   GPT Partition Entry:\n   - Partition type GUID\n   - Unique partition GUID\n   - First LBA\n   - Last LBA\n   - Attribute flags\n   - Partition name (72 bytes UTF-16)\n   ```\n\n3. ANALYZING PARTITIONS WITH TSK:\n   ```bash\n   # List all partitions (works with MBR and GPT)\n   mmls /forensics/evidence.dd\n   \n   # Example output:\n   # DOS Partition Table\n   # Offset Sector: 0\n   # Units are in 512-byte sectors\n   #\n   #      Slot      Start        End          Length       Description\n   # 000:  Meta      0000000000   0000000000   0000000001   Primary Table (#0)\n   # 001:  -------   0000000000   0000002047   0000002048   Unallocated\n   # 002:  000:000   0000002048   0001026047   0001024000   NTFS (0x07)\n   # 003:  000:001   0001026048   0976771071   0975745024   NTFS (0x07)\n   \n   # Get detailed partition info\n   mmstat /forensics/evidence.dd\n   \n   # Display file system type in partition\n   fsstat -o 2048 /forensics/evidence.dd\n   ```\n\n4. EXAMINING MBR MANUALLY:\n   ```bash\n   # Extract MBR (first 512 bytes)\n   dd if=/forensics/evidence.dd of=/forensics/mbr.bin bs=512 count=1\n   \n   # View in hex\n   xxd /forensics/mbr.bin | head -40\n   \n   # Parse MBR signature\n   xxd -s 510 -l 2 /forensics/mbr.bin\n   # Should show: 55 aa\n   \n   # Parse partition table entries\n   xxd -s 446 -l 64 /forensics/mbr.bin\n   \n   # Using fdisk (read-only)\n   fdisk -l /forensics/evidence.dd\n   ```\n\n5. GPT ANALYSIS:\n   ```bash\n   # GPT-aware partition listing\n   gdisk -l /forensics/evidence.dd\n   \n   # Extract GPT header\n   dd if=/forensics/evidence.dd of=/forensics/gpt_header.bin bs=512 skip=1 count=1\n   \n   # Check GPT signature\n   xxd -l 8 /forensics/gpt_header.bin\n   # Should show: 45 46 49 20 50 41 52 54 (\"EFI PART\")\n   ```\n\n6. HIDDEN AREAS:\n   ```\n   Areas to Examine:\n   \n   1. Unallocated Space Before First Partition:\n      - MBR leaves 63 sectors traditionally\n      - GPT leaves 2047 sectors\n      - Can hide significant data\n   \n   2. Inter-Partition Gaps:\n      - Space between partitions\n      - May indicate deleted partitions\n   \n   3. Host Protected Area (HPA):\n      - BIOS-protected disk area\n      - Not visible to OS\n   \n   4. Device Configuration Overlay (DCO):\n      - Further hidden area\n      - Used for drive size modification\n   ```\n   \n   ```bash\n   # Detect HPA and DCO (Linux)\n   hdparm -N /dev/sdb    # Shows native vs accessible sectors\n   hdparm --dco-identify /dev/sdb  # DCO information\n   \n   # Remove HPA temporarily\n   hdparm -N pXXXXXXX /dev/sdb  # XXX = max sectors\n   \n   # Extract unallocated space before first partition\n   dd if=/forensics/evidence.dd of=/forensics/pre_partition.dd bs=512 count=2048\n   strings /forensics/pre_partition.dd | head -50\n   ```\n\n7. PARTITION RECOVERY:\n   ```bash\n   # TestDisk for partition recovery\n   testdisk /forensics/evidence.dd\n   # Interactive menu:\n   # 1. Select disk type (Intel for MBR, EFI GPT for GPT)\n   # 2. Analyse current partition structure\n   # 3. Quick Search for deleted partitions\n   # 4. Deep Search if Quick fails\n   \n   # Look for partition signatures in unallocated space\n   sigfind -t ntfs /forensics/evidence.dd\n   sigfind -t ext4 /forensics/evidence.dd\n   \n   # Output shows potential filesystem starts\n   ```\n\nFORENSIC SIGNIFICANCE:\n```\nPartition Analysis Findings:\n\nCase: 2024-FORENSIC-001\nEvidence: IMG-001\n\nDisk Layout:\nTotal Size: 500 GB (976,773,168 sectors)\n\nPartitions Found:\n| # | Type | Start | End | Size | Status |\n|---|------|-------|-----|------|--------|\n| 1 | NTFS | 2048 | 204,800 | 100 MB | EFI System |\n| 2 | NTFS | 204,801 | 976,771,071 | 466 GB | Main |\n| - | Gap | 976,771,072 | 976,773,167 | 1 MB | Unallocated |\n\nHidden Areas Examined:\n- Pre-partition space (sectors 0-2047): Boot code only\n- HPA: Not detected\n- DCO: Not detected\n- End-of-disk: 1 MB unallocated (contains deleted FAT32 signature)\n\nFindings:\n- Deleted partition signature found at sector 976,771,072\n- Indicates previous partition was deleted\n- Recommend carving this area for artifacts\n```\n\nDETECTION INDICATORS:\n- All partitions identified and documented\n- Hidden areas examined\n- HPA/DCO checked\n- Unallocated space analyzed\n\nCOMMON PITFALLS:\n- Missing hidden partitions\n- Not checking for HPA/DCO\n- Ignoring unallocated space\n- Assuming standard partition layout\n\nFURTHER READING:\n- The Sleuth Kit documentation\n- UEFI Specification (GPT)\n- Microsoft MBR documentation",
      "tags": ["forensics", "partitions", "mbr", "gpt", "disk-analysis", "dfir"],
      "related_tools": ["xxd", "hexedit", "binwalk"]
    },
    {
      "id": "file_system_analysis_ntfs",
      "title": "File System Analysis: NTFS",
      "content": "OBJECTIVE: Analyze NTFS file systems to extract metadata, recover deleted files, and identify hidden data in NTFS-specific structures.\n\nACADEMIC BACKGROUND:\nNTFS (New Technology File System) is the primary file system for Windows. Its sophisticated metadata structures provide rich forensic artifacts, including multiple timestamps, alternate data streams, and a journaling system that records changes. Understanding these structures is essential for Windows forensics.\n\nNTFS STRUCTURES:\n\n1. MFT (MASTER FILE TABLE):\n   ```\n   MFT Overview:\n   - One entry per file/directory (1024 bytes typical)\n   - First 16 entries are system metadata files\n   - Each entry contains attributes describing the file\n   \n   Key System MFT Entries:\n   | Entry | Name | Purpose |\n   |-------|------|---------||\n   | 0 | $MFT | MFT itself |\n   | 1 | $MFTMirr | MFT backup |\n   | 2 | $LogFile | Transaction log |\n   | 3 | $Volume | Volume info |\n   | 4 | $AttrDef | Attribute definitions |\n   | 5 | . (root) | Root directory |\n   | 6 | $Bitmap | Cluster allocation |\n   | 7 | $Boot | Boot sector |\n   | 8 | $BadClus | Bad clusters |\n   | 9 | $Secure | Security descriptors |\n   | 10 | $UpCase | Uppercase table |\n   | 11 | $Extend | Extended metadata |\n   \n   Extracting MFT:\n   ```bash\n   # Extract $MFT using icat\n   icat -o 2048 /forensics/evidence.dd 0 > /forensics/MFT\n   \n   # Using FTK Imager\n   # Navigate to [root] > $MFT > Export\n   \n   # Parse MFT with analyzeMFT\n   python analyzeMFT.py -f /forensics/MFT -o /forensics/mft_analysis.csv\n   ```\n\n2. MFT ENTRY STRUCTURE:\n   ```\n   MFT Entry Format:\n   \n   Offset  Size    Description\n   0x00    4       Signature (\"FILE\")\n   0x04    2       Offset to fixup array\n   0x06    2       Number of fixup entries\n   0x08    8       $LogFile sequence number\n   0x10    2       Sequence number\n   0x12    2       Hard link count\n   0x14    2       Offset to first attribute\n   0x16    2       Flags (in use, directory)\n   0x18    4       Used size of entry\n   0x1C    4       Allocated size of entry\n   0x20    8       Base record (for extended entries)\n   0x28    2       Next attribute ID\n   \n   Flags:\n   0x0001 - Entry in use\n   0x0002 - Directory\n   ```\n\n3. NTFS TIMESTAMPS:\n   ```\n   $STANDARD_INFORMATION Timestamps:\n   - Created (C)\n   - Modified (M)  \n   - Accessed (A)\n   - MFT Entry Modified (E)\n   \n   $FILE_NAME Timestamps:\n   - Same four timestamps\n   - Harder to modify (anti-forensics indicator)\n   \n   Timestamp Analysis:\n   ```bash\n   # Parse timestamps from MFT\n   python analyzeMFT.py -f /forensics/MFT -o /forensics/mft.csv\n   \n   # Compare $SI vs $FN timestamps\n   # Discrepancies may indicate timestamp manipulation\n   \n   # Using TSK mactime\n   fls -r -m \"/\" -o 2048 /forensics/evidence.dd > /forensics/body.txt\n   mactime -b /forensics/body.txt -d > /forensics/timeline.csv\n   ```\n\n4. ALTERNATE DATA STREAMS:\n   ```\n   ADS Overview:\n   - NTFS allows multiple data streams per file\n   - Default stream: $DATA (unnamed)\n   - Additional streams: filename:streamname\n   - Used legitimately (Zone.Identifier) and maliciously\n   \n   Finding ADS:\n   ```bash\n   # List all streams in a file\n   getfattr -d /mnt/evidence/file.txt\n   \n   # Using TSK\n   fls -o 2048 /forensics/evidence.dd | grep -i \"\\$DATA\"\n   \n   # Extract ADS content\n   icat -o 2048 /forensics/evidence.dd <inode>:<stream_name>\n   \n   # Windows command (live)\n   dir /r C:\\Users\\*\n   # Shows :$DATA streams\n   \n   # Common legitimate ADS:\n   # Zone.Identifier - Shows file was downloaded from internet\n   # Contains: ZoneId=3 (Internet), HostUrl, ReferrerUrl\n   ```\n\n5. $LOGFILE AND $USNJRNL:\n   ```\n   $LogFile (Transaction Log):\n   - Records all metadata changes\n   - Enables NTFS recovery after crash\n   - Contains recent file operations\n   \n   Extracting $LogFile:\n   ```bash\n   icat -o 2048 /forensics/evidence.dd 2 > /forensics/LogFile\n   # Parse with LogFileParser or similar\n   ```\n   \n   $UsnJrnl (USN Journal):\n   - Change journal tracking all file changes\n   - Located at $Extend\\$UsnJrnl\n   - Contains: filename, timestamp, change reason\n   \n   Change Reasons:\n   - USN_REASON_DATA_OVERWRITE\n   - USN_REASON_DATA_EXTEND\n   - USN_REASON_DATA_TRUNCATION\n   - USN_REASON_FILE_CREATE\n   - USN_REASON_FILE_DELETE\n   - USN_REASON_RENAME_NEW_NAME\n   - USN_REASON_SECURITY_CHANGE\n   \n   ```bash\n   # Extract $UsnJrnl:$J\n   icat -o 2048 /forensics/evidence.dd 11-128-4 > /forensics/UsnJrnl_J\n   \n   # Parse with usn.py or MFTECmd\n   python usn.py -f /forensics/UsnJrnl_J -o /forensics/usn_parsed.csv\n   ```\n\n6. DELETED FILE RECOVERY:\n   ```bash\n   # Find deleted files in MFT\n   fls -r -d -o 2048 /forensics/evidence.dd\n   # -d: Show deleted entries only\n   \n   # Output example:\n   # d/d 39-128-1:    $Recycle.Bin\n   # r/r * 12345-128-1:    deleted_document.docx\n   # (* indicates deleted)\n   \n   # Recover deleted file by inode\n   icat -o 2048 /forensics/evidence.dd 12345 > /forensics/recovered/deleted_document.docx\n   \n   # Bulk recovery of deleted files\n   tsk_recover -o 2048 /forensics/evidence.dd /forensics/recovered/\n   ```\n\n7. SLACK SPACE:\n   ```\n   Slack Space Types:\n   \n   File Slack:\n   - Space between end of file and end of cluster\n   - May contain remnants of previous files\n   \n   RAM Slack:\n   - Space between end of file and end of sector\n   - Modern Windows zeros this\n   \n   Extracting Slack:\n   ```bash\n   # Using blkls to extract unallocated clusters\n   blkls -o 2048 /forensics/evidence.dd > /forensics/unalloc.dd\n   \n   # Search slack for interesting strings\n   strings -a /forensics/unalloc.dd | grep -i \"password\\|secret\"\n   \n   # File slack extraction (requires specialized tools)\n   # Autopsy can display file slack\n   # EnCase extracts slack automatically\n   ```\n\nFORENSIC REPORT SECTION:\n```\nNTFS Analysis Findings:\n\nFile System: NTFS (Version 3.1)\nCluster Size: 4096 bytes\nTotal Clusters: 121,899,391\nMFT Entries Analyzed: 145,672\n\nKey Findings:\n\n1. Timestamp Manipulation Detected:\n   File: C:\\Users\\John\\Documents\\report.docx\n   $SI Created: 2024-01-01 00:00:00 (suspicious)\n   $FN Created: 2024-03-14 09:45:32 (actual)\n   Evidence of backdating attempt\n\n2. Alternate Data Streams Found:\n   | File | Stream | Size | Content |\n   |------|--------|------|---------||\n   | logo.jpg | :secret | 45KB | Encrypted archive |\n   | readme.txt | :hidden | 12KB | Password list |\n\n3. USN Journal Analysis:\n   - 847 file deletions on 2024-03-15\n   - Concentrated in 30-minute window\n   - Indicates mass deletion event\n\n4. Deleted Files Recovered:\n   - 23 documents from user profile\n   - 12 executable files from Temp\n   - 156 browser cache files\n```\n\nDETECTION INDICATORS:\n- MFT fully parsed and analyzed\n- Timestamp discrepancies identified\n- ADS checked on all files\n- USN Journal parsed\n- Deleted files recovered\n\nCOMMON PITFALLS:\n- Missing alternate data streams\n- Not comparing $SI vs $FN timestamps\n- Overlooking USN Journal\n- Incomplete deleted file recovery\n\nFURTHER READING:\n- NTFS Documentation (Microsoft)\n- The Sleuth Kit Reference\n- Brian Carrier's \"File System Forensic Analysis\"",
      "tags": ["forensics", "ntfs", "mft", "windows", "file-system", "dfir"],
      "related_tools": ["strings", "xxd", "bulk_extractor"]
    },
    {
      "id": "file_system_analysis_ext",
      "title": "File System Analysis: EXT2/3/4",
      "content": "OBJECTIVE: Analyze Linux EXT file systems to extract metadata, recover deleted files, and understand journaling mechanisms.\n\nACADEMIC BACKGROUND:\nThe Extended File System (EXT) family is the standard for Linux. EXT4, the current version, features journaling, extents for efficient large file handling, and nanosecond timestamps. Understanding these structures is essential for Linux forensics and cross-platform investigations.\n\nEXT FILE SYSTEM STRUCTURES:\n\n1. SUPERBLOCK:\n   ```\n   Superblock Location:\n   - Primary: Offset 1024 bytes from partition start\n   - Backups: At block group boundaries\n   \n   Key Superblock Fields:\n   - Inode count\n   - Block count\n   - Free block count\n   - Free inode count\n   - First data block\n   - Block size (1KB, 2KB, 4KB)\n   - Blocks per group\n   - Inodes per group\n   - Mount time\n   - Write time\n   - Mount count\n   - Maximum mount count\n   - Magic signature (0xEF53)\n   - State (clean, errors)\n   - Feature flags\n   \n   Examining Superblock:\n   ```bash\n   # Using fsstat\n   fsstat -o 2048 /forensics/evidence.dd\n   \n   # Sample output:\n   # FILE SYSTEM INFORMATION\n   # File System Type: Ext4\n   # Volume Name: root\n   # Volume ID: 12345678-1234-1234-1234-123456789012\n   # \n   # Last Written at: 2024-03-15 17:30:45 (UTC)\n   # Last Checked at: 2024-01-01 00:00:00 (UTC)\n   # Last Mounted at: 2024-03-15 08:00:00 (UTC)\n   # \n   # METADATA INFORMATION\n   # Inode Range: 1 - 12320769\n   # Root Directory: 2\n   ```\n\n2. INODE STRUCTURE:\n   ```\n   EXT4 Inode (256 bytes typical):\n   \n   Offset  Size    Description\n   0x00    2       File mode (permissions + type)\n   0x02    2       Owner UID (low 16 bits)\n   0x04    4       Size (low 32 bits)\n   0x08    4       Access time\n   0x0C    4       Change time (inode)\n   0x10    4       Modification time\n   0x14    4       Deletion time\n   0x18    2       Group ID (low 16 bits)\n   0x1A    2       Hard link count\n   0x1C    4       Block count (512-byte units)\n   0x20    4       Flags\n   0x28    60      Block pointers/extents\n   ...\n   \n   File Types in Mode:\n   0x1000 - FIFO\n   0x2000 - Character device\n   0x4000 - Directory\n   0x6000 - Block device\n   0x8000 - Regular file\n   0xA000 - Symbolic link\n   0xC000 - Socket\n   \n   Examining Inodes:\n   ```bash\n   # Display inode information\n   istat -o 2048 /forensics/evidence.dd 12345\n   \n   # Output example:\n   # inode: 12345\n   # Allocated\n   # Group: 1\n   # uid / gid: 1000 / 1000\n   # mode: rrw-r--r--\n   # size: 4096\n   # num of links: 1\n   # \n   # Inode Times:\n   # Accessed: 2024-03-15 10:30:45 (UTC)\n   # File Modified: 2024-03-14 09:15:00 (UTC)\n   # Inode Modified: 2024-03-14 09:15:00 (UTC)\n   ```\n\n3. EXT4 EXTENTS:\n   ```\n   Extent Structure:\n   - Replaces indirect block pointers in EXT4\n   - More efficient for large files\n   - Stored in inode or extent tree\n   \n   Extent Header:\n   - Magic: 0xF30A\n   - Entries: Number of valid entries\n   - Max: Maximum entries\n   - Depth: 0 for leaf, >0 for index\n   \n   Extent Entry:\n   - Logical block (file offset)\n   - Length (up to 32768 blocks)\n   - Physical block start\n   \n   Viewing Extents:\n   ```bash\n   # istat shows extent information\n   istat -o 2048 /forensics/evidence.dd 12345\n   \n   # Direct sector access\n   blkcat -o 2048 /forensics/evidence.dd <block_number>\n   ```\n\n4. JOURNAL ANALYSIS:\n   ```\n   EXT3/4 Journal:\n   - Typically stored in hidden inode 8\n   - Records metadata changes\n   - May contain deleted file metadata\n   - Circular buffer (overwrites old entries)\n   \n   Extracting Journal:\n   ```bash\n   # Extract journal inode\n   icat -o 2048 /forensics/evidence.dd 8 > /forensics/journal\n   \n   # Parse with jls (journal list)\n   jls /forensics/evidence.dd\n   \n   # Show specific journal entry\n   jcat /forensics/evidence.dd <journal_entry>\n   \n   # Search journal for deleted file metadata\n   strings /forensics/journal | grep -i \"filename\"\n   ```\n\n5. DELETED FILE RECOVERY:\n   ```bash\n   # List deleted files\n   fls -r -d -o 2048 /forensics/evidence.dd\n   \n   # EXT4 recovery with extundelete\n   extundelete /forensics/evidence.dd --restore-all\n   \n   # Recovery limitations:\n   # - EXT4 zeros block pointers on deletion\n   # - Journal may contain old metadata\n   # - File carving often more successful\n   \n   # Using photorec for carving\n   photorec /forensics/evidence.dd\n   ```\n\n6. DIRECTORY STRUCTURES:\n   ```\n   EXT Directory Entry (ext4_dir_entry_2):\n   \n   | Field | Size | Description |\n   |-------|------|-------------|\n   | inode | 4 | Inode number |\n   | rec_len | 2 | Record length |\n   | name_len | 1 | Name length |\n   | file_type | 1 | File type |\n   | name | 1-255 | Filename |\n   \n   File Types:\n   0 - Unknown\n   1 - Regular file\n   2 - Directory\n   3 - Character device\n   4 - Block device\n   5 - FIFO\n   6 - Socket\n   7 - Symbolic link\n   \n   Reading Directories:\n   ```bash\n   # List directory contents\n   fls -o 2048 /forensics/evidence.dd 2  # root inode\n   \n   # Recursive listing\n   fls -r -o 2048 /forensics/evidence.dd\n   ```\n\n7. TIMELINE CREATION:\n   ```bash\n   # Generate body file\n   fls -r -m \"/\" -o 2048 /forensics/evidence.dd > /forensics/body.txt\n   \n   # Include deleted files\n   fls -r -d -m \"/\" -o 2048 /forensics/evidence.dd >> /forensics/body.txt\n   \n   # Create timeline with mactime\n   mactime -b /forensics/body.txt -d > /forensics/ext_timeline.csv\n   \n   # Filter by date range\n   mactime -b /forensics/body.txt -d 2024-03-01..2024-03-15 > /forensics/march.csv\n   ```\n\nFORENSIC REPORT SECTION:\n```\nEXT4 Analysis Findings:\n\nFile System: EXT4\nVolume Label: ubuntu-root\nUUID: 12345678-1234-1234-1234-123456789012\nBlock Size: 4096 bytes\nInode Count: 12,320,768\n\nMount History:\n- Last Mounted: 2024-03-15 08:00:00 UTC\n- Last Written: 2024-03-15 17:30:45 UTC\n- Mount Count: 47\n\nKey Findings:\n\n1. Deleted File Recovery:\n   - 89 deleted files identified\n   - 34 successfully recovered via journal\n   - 55 require file carving\n\n2. User Activity:\n   | User | Home Dir | Last Activity | Files |\n   |------|----------|---------------|-------|\n   | john | /home/john | 2024-03-15 17:30 | 12,456 |\n   | admin | /home/admin | 2024-03-10 09:15 | 2,341 |\n\n3. Suspicious Findings:\n   - /tmp/.hidden directory (hidden by dot prefix)\n   - SUID binary in /tmp: exploit.bin\n   - Deletion of /var/log/* on 2024-03-15\n\n4. Timeline Anomalies:\n   - 2024-03-15 02:00-02:30: 500+ file modifications\n   - Activity during non-business hours\n   - Concentrated in /etc and /var directories\n```\n\nDETECTION INDICATORS:\n- Superblock parsed successfully\n- All inodes analyzed\n- Journal examined for deleted metadata\n- Timeline created with all sources\n\nCOMMON PITFALLS:\n- Forgetting journal analysis\n- Not examining deleted directory entries\n- Missing hidden files (dot prefix)\n- Overlooking SUID/SGID binaries\n\nFURTHER READING:\n- kernel.org EXT4 documentation\n- The Sleuth Kit documentation\n- ext4 disk layout specification",
      "tags": ["forensics", "ext4", "linux", "file-system", "journal", "dfir"],
      "related_tools": ["strings", "foremost", "scalpel", "bulk_extractor"]
    },
    {
      "id": "data_carving_recovery",
      "title": "Data Carving and Recovery",
      "content": "OBJECTIVE: Apply file carving techniques to recover deleted and fragmented files from unallocated space using signature-based and semantic analysis.\n\nACADEMIC BACKGROUND:\nFile carving recovers files based on content rather than file system metadata. When files are deleted, the metadata is often destroyed, but the actual data remains in unallocated space until overwritten. Carving searches for file signatures (magic bytes) and structural patterns to reconstruct files.\n\nCARVING FUNDAMENTALS:\n\n1. FILE SIGNATURES:\n   ```\n   Common File Signatures (Magic Bytes):\n   \n   | Type | Header | Footer | Description |\n   |------|--------|--------|-------------|\n   | JPEG | FF D8 FF | FF D9 | Image |\n   | PNG | 89 50 4E 47 | 49 45 4E 44 | Image |\n   | GIF | 47 49 46 38 | 00 3B | Image |\n   | PDF | 25 50 44 46 | %%EOF | Document |\n   | ZIP | 50 4B 03 04 | 50 4B 05 06 | Archive |\n   | DOCX | 50 4B 03 04 | 50 4B 05 06 | Office (ZIP) |\n   | EXE | 4D 5A | - | Windows PE |\n   | ELF | 7F 45 4C 46 | - | Linux binary |\n   | RAR | 52 61 72 21 | - | Archive |\n   | 7Z | 37 7A BC AF | - | Archive |\n   | MP3 | FF FB / ID3 | - | Audio |\n   | MP4 | 00 00 00 XX ftyp | - | Video |\n   | SQLite | 53 51 4C 69 74 65 | - | Database |\n   \n   Finding Signatures:\n   ```bash\n   # Search for JPEG headers in image\n   sigfind -t jpeg /forensics/evidence.dd\n   \n   # Search for specific hex pattern\n   sigfind /forensics/evidence.dd 504B0304\n   # (ZIP/Office signature)\n   \n   # Manual signature search\n   xxd /forensics/evidence.dd | grep -i \"504b 0304\"\n   ```\n\n2. USING FOREMOST:\n   ```bash\n   # Basic carving with default signatures\n   foremost -i /forensics/evidence.dd -o /forensics/carved\n   \n   # Carve specific file types only\n   foremost -t jpeg,png,pdf,doc -i /forensics/evidence.dd -o /forensics/carved\n   \n   # Verbose output with audit\n   foremost -v -T -i /forensics/evidence.dd -o /forensics/carved\n   \n   # Output structure:\n   # carved/\n   #   audit.txt       # Summary of findings\n   #   jpg/            # Recovered JPEGs\n   #   png/            # Recovered PNGs\n   #   pdf/            # Recovered PDFs\n   #   ...\n   \n   # Custom configuration\n   # Edit /etc/foremost.conf:\n   # type    case-sens   header                  footer          max_size\n   # jpg     y           \\xff\\xd8\\xff           \\xff\\xd9         20000000\n   ```\n\n3. USING SCALPEL:\n   ```bash\n   # Scalpel configuration (/etc/scalpel/scalpel.conf)\n   # Uncomment file types to carve:\n   # jpg y 20000000 \\xff\\xd8\\xff\\xe0\\x00\\x10 \\xff\\xd9\n   # png y 20000000 \\x89PNG \\xff\\xfc\\xfd\\xfe\n   \n   # Run scalpel\n   scalpel /forensics/evidence.dd -o /forensics/scalpel_output\n   \n   # With custom config\n   scalpel -c /forensics/custom_scalpel.conf /forensics/evidence.dd -o /forensics/carved\n   \n   # Faster carving (no footer matching)\n   # Modify config: set footer to empty\n   ```\n\n4. USING PHOTOREC:\n   ```bash\n   # Interactive mode\n   photorec /forensics/evidence.dd\n   # Select partition > Choose file types > Set output directory\n   \n   # Command line mode\n   photorec /d /forensics/carved /cmd /forensics/evidence.dd partition_table,options,search\n   \n   # PhotoRec advantages:\n   # - Understands file structures deeply\n   # - Better fragmented file recovery\n   # - Supports 480+ file formats\n   # - Active development\n   ```\n\n5. USING BULK_EXTRACTOR:\n   ```bash\n   # Bulk extractor for specific data types\n   bulk_extractor -o /forensics/bulk_output /forensics/evidence.dd\n   \n   # Output includes:\n   # email.txt - Email addresses\n   # domain.txt - Domain names\n   # url.txt - URLs\n   # telephone.txt - Phone numbers\n   # ccn.txt - Credit card numbers\n   # ip.txt - IP addresses\n   # jpeg_carved/ - Carved JPEG files\n   # vcard.txt - vCard data\n   # gps.txt - GPS coordinates\n   \n   # Specific features only\n   bulk_extractor -E email -E url -E ccn -o /forensics/bulk_output /forensics/evidence.dd\n   ```\n\n6. HANDLING FRAGMENTED FILES:\n   ```\n   Fragmentation Challenges:\n   - File data split across non-contiguous clusters\n   - Simple header/footer carving may fail\n   - Requires understanding of file structure\n   \n   Advanced Carving Techniques:\n   \n   1. Bifragment Gap Carving:\n      - File split into exactly 2 fragments\n      - Search for matching start/end\n   \n   2. SmartCarving:\n      - Use file structure knowledge\n      - Validate carved file integrity\n   \n   3. Semantic Carving:\n      - Understand internal file format\n      - Validate carved data structures\n   \n   Manual Fragment Recovery:\n   ```bash\n   # Extract potential fragment\n   dd if=/forensics/evidence.dd of=/forensics/fragment1.bin bs=512 skip=1000 count=100\n   \n   # Check file type\n   file /forensics/fragment1.bin\n   \n   # Attempt to open/validate\n   # If partial JPEG: Try adding header\n   # If partial PDF: Try adding header/footer\n   ```\n\n7. CARVING VALIDATION:\n   ```bash\n   # Validate carved files\n   \n   # Check file types\n   file /forensics/carved/jpg/*\n   \n   # Verify JPEG integrity\n   for f in /forensics/carved/jpg/*.jpg; do\n       jpeginfo -c \"$f\" 2>&1 | grep -v \"OK\"\n   done\n   \n   # Verify PDF integrity\n   for f in /forensics/carved/pdf/*.pdf; do\n       pdfinfo \"$f\" 2>&1 | grep -i error && echo \"Error: $f\"\n   done\n   \n   # Calculate hashes for all carved files\n   find /forensics/carved -type f -exec sha256sum {} \\; > /forensics/carved_hashes.txt\n   \n   # Check against known file database (deduplication)\n   # Compare hashes against NSRL or case-specific known files\n   ```\n\n8. SPECIALIZED CARVING:\n   ```bash\n   # SQLite database carving\n   # Header: \"SQLite format 3\\x00\"\n   grep -obaP 'SQLite format 3\\x00' /forensics/evidence.dd\n   \n   # Extract potential SQLite files\n   # Manually extract based on offset\n   \n   # Email carving (PST/OST)\n   # Use pffexport from libpff\n   pffexport /forensics/carved/outlook.pst\n   \n   # Browser data carving\n   # Chrome History is SQLite\n   # Extract and query:\n   sqlite3 /forensics/carved/History \"SELECT url, title FROM urls LIMIT 10;\"\n   ```\n\nCARVING REPORT:\n```\nFile Carving Results:\n\nSource: IMG-001 (Unallocated space)\nTool: Foremost 1.5.7 / PhotoRec 7.1\nDuration: 4 hours 32 minutes\n\nRecovered Files Summary:\n| Type | Count | Total Size | Valid | Invalid |\n|------|-------|------------|-------|--------|\n| JPEG | 1,247 | 2.3 GB | 1,198 | 49 |\n| PNG | 234 | 156 MB | 228 | 6 |\n| PDF | 89 | 445 MB | 82 | 7 |\n| DOCX | 156 | 234 MB | 134 | 22 |\n| XLSX | 45 | 67 MB | 41 | 4 |\n| ZIP | 23 | 890 MB | 19 | 4 |\n| EXE | 67 | 234 MB | 62 | 5 |\n\nNotable Findings:\n1. Deleted photos recovered (potential evidence)\n2. Financial spreadsheets in carved XLSX\n3. Encrypted ZIP archives requiring further analysis\n4. Malware samples in carved executables\n\nCarving Limitations:\n- 156 fragmented files could not be fully recovered\n- Some DOCX files corrupted due to fragmentation\n- Encrypted files carved but content inaccessible\n```\n\nDETECTION INDICATORS:\n- Multiple carving tools applied\n- Carved files validated\n- Hash values recorded\n- False positives filtered\n\nCOMMON PITFALLS:\n- Not validating carved files\n- Missing custom file types\n- Overlooking fragmentation\n- Not filtering known files\n- Insufficient storage for output\n\nFURTHER READING:\n- Foremost documentation\n- PhotoRec/TestDisk documentation\n- \"File Carving\" by Simson Garfinkel",
      "tags": ["forensics", "carving", "recovery", "deleted-files", "unallocated", "dfir"],
      "related_tools": ["foremost", "scalpel", "bulk_extractor", "binwalk", "strings"]
    },
    {
      "id": "steganography_detection",
      "title": "Steganography Detection and Analysis",
      "content": "OBJECTIVE: Detect hidden data in media files using statistical analysis, signature detection, and specialized extraction tools.\n\nACADEMIC BACKGROUND:\nSteganography is the practice of concealing data within innocent-looking carrier files, typically images or audio. Unlike encryption, steganography hides the existence of the secret message. Forensic detection involves statistical analysis of carrier files, known tool signature detection, and systematic extraction attempts.\n\nSTEGANOGRAPHY TYPES:\n\n1. IMAGE STEGANOGRAPHY:\n   ```\n   Common Techniques:\n   \n   LSB (Least Significant Bit):\n   - Modifies least significant bits of pixels\n   - Visually imperceptible\n   - Detectable through statistical analysis\n   \n   DCT Coefficient Modification:\n   - Used in JPEG steganography\n   - Modifies DCT coefficients\n   - Tools: JSteg, F5, OutGuess\n   \n   Palette-Based:\n   - GIF/PNG palette manipulation\n   - Reorders color palette\n   \n   Appended Data:\n   - Data after EOF marker\n   - Easiest to detect\n   ```\n\n2. STEGANALYSIS TOOLS:\n   ```bash\n   # StegDetect - JPEG steganalysis\n   stegdetect /forensics/images/*.jpg\n   \n   # Output interpretation:\n   # image.jpg : jsteg(**) outguess(*)  \n   # ** = high probability\n   # * = possible\n   # negative = not detected\n   \n   # Stegbreak - Attempt to crack password\n   stegbreak -t p -f /wordlists/common.txt /forensics/image.jpg\n   # -t p = JSteg/JPHide dictionary attack\n   \n   # StegSolve - Visual analysis (GUI)\n   java -jar stegsolve.jar\n   # Apply color filters, bit planes, extract data\n   ```\n\n3. OUTGUESS DETECTION AND EXTRACTION:\n   ```bash\n   # OutGuess detection\n   stegdetect -t o /forensics/image.jpg\n   \n   # OutGuess extraction (if password known)\n   outguess -r /forensics/image.jpg /forensics/extracted.txt\n   \n   # With password\n   outguess -k \"password\" -r /forensics/image.jpg /forensics/extracted.txt\n   ```\n\n4. STEGHIDE DETECTION AND EXTRACTION:\n   ```bash\n   # Steghide info (shows if data embedded)\n   steghide info /forensics/image.jpg\n   # Prompts for password; empty password may work\n   \n   # Extract with password\n   steghide extract -sf /forensics/image.jpg -p \"password\"\n   \n   # Brute force with stegcracker\n   stegcracker /forensics/image.jpg /wordlists/rockyou.txt\n   \n   # Steghide supports: JPEG, BMP, WAV, AU\n   ```\n\n5. APPENDED DATA DETECTION:\n   ```bash\n   # Check for data after JPEG EOF\n   # JPEG ends with FF D9\n   xxd /forensics/image.jpg | tail -20\n   \n   # Automated detection with binwalk\n   binwalk /forensics/image.jpg\n   # Shows embedded files and offsets\n   \n   # Extract embedded files\n   binwalk -e /forensics/image.jpg\n   \n   # Manual extraction of appended data\n   # Find EOF offset, extract remainder\n   OFFSET=$(grep -obaP '\\xff\\xd9' /forensics/image.jpg | tail -1 | cut -d: -f1)\n   dd if=/forensics/image.jpg of=/forensics/appended.bin bs=1 skip=$((OFFSET+2))\n   ```\n\n6. STATISTICAL ANALYSIS:\n   ```bash\n   # Chi-square analysis for LSB detection\n   # High chi-square = potential steganography\n   \n   # Using stegexpose\n   stegexpose /forensics/images/\n   # Reports suspicion level 0-1\n   \n   # RS Analysis (Sample Pair Analysis)\n   # Detects LSB steganography in images\n   \n   # Histogram analysis\n   # Compare histogram of suspect vs clean image\n   # LSB embedding changes histogram patterns\n   \n   # PNG analysis\n   pngcheck -v /forensics/image.png\n   # Check for anomalous chunks\n   ```\n\n7. AUDIO STEGANOGRAPHY:\n   ```bash\n   # MP3Stego detection\n   # Hidden data in MP3 frames\n   mp3stego-decode -X -P password /forensics/audio.mp3 /forensics/output.txt\n   \n   # Spectrum analysis\n   # View audio spectrogram for hidden images\n   sox /forensics/audio.wav -n spectrogram -o /forensics/spectrogram.png\n   \n   # Common audio stego tools:\n   # - MP3Stego\n   # - OpenPuff\n   # - DeepSound\n   # - Coagula (image-to-audio-to-image)\n   ```\n\n8. DOCUMENT STEGANOGRAPHY:\n   ```bash\n   # PDF steganography\n   # Check for hidden streams\n   pdf-parser /forensics/document.pdf | grep -i stream\n   \n   # Office document steganography\n   # Extract and analyze\n   unzip /forensics/document.docx -d /forensics/extracted_docx/\n   # Check for unusual files in structure\n   \n   # OpenStego extraction\n   openstego extract -sf /forensics/image.png -xf /forensics/extracted.txt\n   ```\n\n9. SYSTEMATIC DETECTION WORKFLOW:\n   ```bash\n   #!/bin/bash\n   # Steganography detection script\n   \n   TARGET_DIR=\"$1\"\n   OUTPUT_DIR=\"/forensics/steg_analysis\"\n   \n   mkdir -p $OUTPUT_DIR\n   \n   echo \"=== Steganalysis Report ===\" > $OUTPUT_DIR/report.txt\n   \n   # JPEG Analysis\n   echo \"\\n=== JPEG Analysis ===\" >> $OUTPUT_DIR/report.txt\n   for img in $TARGET_DIR/*.jpg $TARGET_DIR/*.jpeg; do\n       [ -f \"$img\" ] || continue\n       echo \"File: $img\" >> $OUTPUT_DIR/report.txt\n       stegdetect \"$img\" >> $OUTPUT_DIR/report.txt 2>&1\n       steghide info \"$img\" --passphrase \"\" >> $OUTPUT_DIR/report.txt 2>&1\n   done\n   \n   # PNG Analysis  \n   echo \"\\n=== PNG Analysis ===\" >> $OUTPUT_DIR/report.txt\n   for img in $TARGET_DIR/*.png; do\n       [ -f \"$img\" ] || continue\n       echo \"File: $img\" >> $OUTPUT_DIR/report.txt\n       pngcheck -v \"$img\" >> $OUTPUT_DIR/report.txt 2>&1\n       binwalk \"$img\" >> $OUTPUT_DIR/report.txt 2>&1\n   done\n   \n   # Binwalk all files\n   echo \"\\n=== Embedded File Detection ===\" >> $OUTPUT_DIR/report.txt\n   for f in $TARGET_DIR/*; do\n       [ -f \"$f\" ] || continue\n       RESULT=$(binwalk \"$f\" | grep -v \"^$\" | tail -n +3)\n       if [ -n \"$RESULT\" ]; then\n           echo \"File: $f\" >> $OUTPUT_DIR/report.txt\n           echo \"$RESULT\" >> $OUTPUT_DIR/report.txt\n       fi\n   done\n   ```\n\nSTEGANALYSIS REPORT:\n```\nSteganography Analysis Results:\n\nFiles Analyzed: 1,247 images, 45 audio files\nTool Suite: stegdetect, steghide, binwalk, stegexpose\n\nPositive Detections:\n\n| File | Tool Signature | Confidence | Extracted |\n|------|----------------|------------|----------|\n| photo_0023.jpg | OutGuess | High | Yes (4KB text) |\n| vacation.jpg | Steghide | Medium | Pending password |\n| logo.png | Appended ZIP | Certain | Yes (encrypted.zip) |\n| music.mp3 | MP3Stego | Low | Testing |\n\nExtracted Content:\n\n1. photo_0023.jpg:\n   - Hidden text file (4,096 bytes)\n   - Contents: List of usernames and passwords\n   - No password protection\n\n2. logo.png:\n   - Appended ZIP archive (2.3 MB)\n   - Password protected\n   - Cracking in progress\n\nStatistical Anomalies:\n- 23 images show elevated chi-square values\n- Recommend further analysis\n\nNegative Results:\n- 1,220 images showed no steganography indicators\n- 43 audio files clean\n```\n\nDETECTION INDICATORS:\n- Multiple steganalysis tools applied\n- Statistical analysis completed\n- Extracted content documented\n- Password cracking attempted\n\nCOMMON PITFALLS:\n- Only checking for one stego tool\n- Missing appended data\n- Not attempting extraction with empty password\n- Overlooking audio steganography\n\nFURTHER READING:\n- \"Hiding in Plain Sight\" by Eric Cole\n- StegExpose documentation\n- Digital Steganography research papers",
      "tags": ["forensics", "steganography", "steganalysis", "hidden-data", "dfir"],
      "related_tools": ["steghide", "outguess", "binwalk", "exiftool", "strings"]
    }
  ]
}
